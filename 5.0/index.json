{
  "index.html": {
    "href": "index.html",
    "title": "What is XMPro? | XMPro",
    "summary": "What is XMPro? XMPro's Application Development Platform empowers engineers and subject matter experts to build real-time applications without coding. The platform consists of 3 main software components: XMPro App Designer A visual page designer that enables you to create custom page designs by dragging blocks from the toolbox onto your page, configure their properties and connect to your data sources, all without having to code. XMPro Data Stream Designer A drag-and-drop interface to visually design Data Streams (a streaming data pipeline). Use XMPro Connectors in your Data Streams to bring in real-time data from a variety of sources, add contextual data, apply analytics, and initiate actions based on events in your data. XMPro Notebook Harnessing the power of the Jupyter Notebook, XMPro Notebook provides an intuitive and flexible interface for data analysis, scientific computing, machine learning, and more. Users can write and execute code independently, facilitating step-by-step exploration and experimentation with real-time data. XMPro Connectors XMPro's extensible integration library includes 100+ Connectors for industrial automation solutions, IoT platforms, historians, enterprise applications, AI/ML, and collaboration solutions. Watch The Demo Video Watch the demo video to see XMPro's platform in action How The Documentation Is Organized Getting Started - New here? Contact us and get started with the End-To-End Use Case by following this detailed tutorial. Resources - A goldmine of general articles, such as release news, a sizing guideline, an icon library, and FAQs to elevate your product experience. Concepts - Get detailed explanations of the platform's essential concepts, like Data Streams, Recommendations, Applications, and Connectors. How-To Guides - Follow step-by-step tutorials to help you create Apps and Data Streams. Blocks - Get detailed descriptions of the components you can use to design your App pages and how to configure them. Administration - Find out how to manage users, licenses, and subscriptions in XMPro. This documentation is only relevant to administrators. Installation - Learn how to Install XMPro in a variety of environments. This documentation is only relevant to administrators. Release Notes - Stay up to date on the latest features and bug fixes. Note The Beta tag indicates incremental functionality, added to prepare for a future feature."
  },
  "src/administration/administrative-accounts.html": {
    "href": "src/administration/administrative-accounts.html",
    "title": "Administrative Accounts | XMPro",
    "summary": "Administrative Accounts Global Administrator Global Administrator is an account that is created when installing XMPro. The username for this account is _admin@xmpro.onxmpro.com_. As a Global Administrator, you will have full access to managing users, companies, subscriptions, and products. Company Administrator A Company Administrator is an account that has been given the Administration Role on the XMPro/Subscription Manager product for their Company. As a Company Administrator, you will have access to managing Users from your Company."
  },
  "src/administration/companies/index.html": {
    "href": "src/administration/companies/index.html",
    "title": "Companies | XMPro",
    "summary": "Companies Companies are the top-level organizational units in XMPro. Each company represents a separate organization that uses the XMPro platform. As an administrator, you can: Register a new company Manage existing companies Manage company subscriptions Manage licenses Companies have their own users, subscriptions, and settings. Users from one company cannot access resources from another company unless explicitly granted access."
  },
  "src/administration/companies/manage-a-company.html": {
    "href": "src/administration/companies/manage-a-company.html",
    "title": "Manage a Company | XMPro",
    "summary": "Manage a Company Warning Please note that this section is intended for Global Administrative users. No other type of user is allowed to manage data about companies and their Subscriptions. Approve/Activate Access Global Administrators may need to grant or modify access for new or existing companies from time to time, for example, when a new company signs up to use Subscription Manager. In this section, we will look at how to approve access for newly registered companies and companies requesting access to certain products. Approving Access for New Companies When a user signs up via the Register page and marks his company as being a new company, the new company will be created, but will not have access to Subscription Manager automatically. Subscription access needs to be approved by a Global Administrator, after which the new user will receive an email and be able to log in to the system as an administrator of his/her company. To approve such a request, please follow the steps below. Open the Company page from the menu. Click on the Company. Click on Subscription Requests. Click on the Request. Click Save. Editing Companies To edit the information of a Company, please follow the steps below. Open the Company's page from the left-hand menu. Select the Company that you would like to edit. Click on Edit. Change the Company information, as required. To change the Company logo, click on the plus-image button and select a new image. Click on Save Note Please note that the Company's icon will replace the XMPro logo in the top-left corner (Whitelabel). Upload a Company Logo Company Logos can be uploaded when managing a company. To upload a Company Logo, follow the steps below: Open the Company's page from the left-hand menu. Select the Company that you would like to edit. Click on Edit. Upload your company icon. Click on Save. Note Any user that logs into that company will be able to see the icon in the top-left corner of App Designer. Active vs Inactive Companies Companies in Subscription Manager can be listed as being either active or inactive. A Company can be deactivated by a Global Administrator if, for example, the Company decided not to use XMPro anymore. If a Company is deactivated, users in that Company will lose their ability to access the system. Inactive Companies can be found by pressing the View Inactive command in the Companies list."
  },
  "src/administration/companies/manage-company-subscriptions.html": {
    "href": "src/administration/companies/manage-company-subscriptions.html",
    "title": "Manage Company Subscriptions | XMPro",
    "summary": "Manage Company Subscriptions Warning Please note that this section is intended for Global Administrative users. No other type of user is allowed to manage data about companies and their Subscriptions. Adding a Subscription for the new Company After the Company is successfully created, you will have to add a Subscription to XMPro Tools for it. To add a Subscription, please follow the steps below. Click on the Subscriptions gauge on the detailed page of the Company. Click on Add. Choose the Data Stream Designer Product. The exact name will depend on your installation, in this example, it is \"DataStreams\". Request a License. Clicking Request a new License will send a request to the XMPro support team for a license for Data Stream Designer for this Company. Warning Clicking Request a new license will only send a license request to XMPro if you have enabled email notifications at the time of installing Subscription Manager Note The steps above need to be completed for both the Data Stream Designer and App Designer Products. Change the Product to App Designer and request another license. Licenses are given on an individual basis by the XMPro support team. When you have received a license for each product, return to this page. Select the Data Stream Designer product and upload its corresponding license and press Save. Then click Add on the Subscriptions page and repeat the steps above for the App Designer product. Now we will add the user to each subscription. Click on the Data Stream Designer product and click the Add button. Select the user and role as well as the permissions the user should have in the product, and click Save. Follow the above steps for the App Designer."
  },
  "src/administration/companies/manage-license.html": {
    "href": "src/administration/companies/manage-license.html",
    "title": "Manage License | XMPro",
    "summary": "Manage License Warning This section is intended for Global Administrative users. No other type of user can manage data about companies and their Subscriptions. Note Each product must have at least one user assigned an admin role, to configure product admin settings and respond to a license expiry warning. Note As noted here, separate licenses are required for AI and XMPro Notebook to access the AI functionality. Request a new License If a company needs to be given access to a product, such as Data Stream Designer, the Company Administrator for that company needs to submit a license request - which is approved by a Global Administrator. Update a License If a Company's license is expiring or expired it will need to be updated. To do this follow the steps below: Click Company in the left menu to open the Companies page. Click on the Company. Click on the Subscriptions gauge to open the Subscriptions page. Click on a Subscription. Click the Update License button in the command bar. Click Generate a license request, enter the number of days, and submit. When you have received the license from XMPro support, upload it. Click Save. Note You can see the expiry date and the number of days remaining for each product on the Subscriptions page. Expiring License When a Company's Subscription has less than 30 days remaining before it expires, a banner will appear at the top of the page of the Product. It will prompt you to contact support to renew the license and ensure you do not lose access to the Product. Expired License When a Company's Subscription has expired, a banner will appear at the top of the page of the Product and you will not be able to do anything with the Product. Please contact support to renew your license. Warning If your subscription has expired, you will need to sign out and back in again for the new license to take effect."
  },
  "src/administration/companies/register-a-company.html": {
    "href": "src/administration/companies/register-a-company.html",
    "title": "Register a Company | XMPro",
    "summary": "Register a Company Register a Company Click on the Sign-Up button on the login page. Follow the steps below: Fill in your first name, last name, and email address. If this is the first time you or someone in your company is signing up to use Subscription Manager, fill in the company name and check the \"Create a new company?\" checkbox. By checking this box, your company will be registered in the system when your account is created. This check box will automatically become visible after you have filled in your company name and click anywhere else on the form. Choose Preferred Language. Choose a unique username, for example, \"keith.miller\". Do not include your company name in your username. Choose a password and confirm your password. Click \"Submit\". Wait for an email, confirming that your company has been registered and that you have been granted access to Subscription Manager. You will only be allowed to use the system after being granted access."
  },
  "src/administration/language.html": {
    "href": "src/administration/language.html",
    "title": "Language | XMPro",
    "summary": "Language Overview XMPro follows the common industry approach for how major no-code/low-code platforms handle translations for technical terms, i.e.: Keep in English: SQL-related terms Programming concepts Industry-standard acronyms Technical protocols Translate: UI navigation elements Error messages Help documentation Descriptive text Certain things are in the primary company language: product roles & email templates. User Preferred Language ... Company Preferred Language ... Exclusions ..."
  },
  "src/administration/subscriptions-admin/index.html": {
    "href": "src/administration/subscriptions-admin/index.html",
    "title": "Subscriptions | XMPro",
    "summary": "Subscriptions Before being able to use any XMPro Product that is supported by the Subscription Manager, your Company will have to have a Subscription for that Product and you will have to be granted access. This process differs slightly, depending on the role that you have within your Company in the Subscription Manager. Subscriptions to products are mainly managed by XMPro administrative users as they can approve or revoke a subscription to a product for a company. Administrative users within a company are given the responsibility to manage the products they have subscription access for in terms of which employees in their Company have access to which Subscription. Manage User Access Setup Auto Approval/Default Subscriptions Request and Apply a License"
  },
  "src/administration/subscriptions-admin/manage-user-access.html": {
    "href": "src/administration/subscriptions-admin/manage-user-access.html",
    "title": "Manage User Access | XMPro",
    "summary": "Manage User Access Warning Please note that this section is intended for Administrative users. No other type of user is allowed to manage a Company's Subscriptions. Adding Users to a Subscription Follow the steps below to give access to a product for a user in a company other than XMPro. Open the Subscriptions page from the left-hand menu. Click on the product the user needs access to. Click the Users button in the command bar. Click on Add. Select the user from the drop-down. Select a role for the user. Select the rights the selected user needs on the product. Click Save. The user will receive an email that access has been granted for the selected product. Approve User Access Request If there is no Auto Approval or Default Subscription setup, the Admin needs to approve a user's Access Request. If someone in your company lodged an access request for a product, an email will be sent to all Company Administrators within your company. The first available person with an administrative role within the Subscription Manager can approve the request. To approve an access request for a user, please follow the steps below. Open the Subscriptions page from the left-hand menu. Select the product for which the access request was lodged. A counter next to the product name will indicate the number of pending access requests you have for that product. Click on Access Requests. Click on the name of the user that lodged the request. Select the role that the user should have on the product from the drop-down, for example, \"General User\". Select the rights the user should have on the product, for example, the rights and roles for Data Stream Designer or rights and roles for the App Designer. Click Save. The user who lodged the request will receive an email notifying him/ her that they have been granted access to the product. Editing Rights and Access for a User If you need to edit rights for a user or a user's role on a product, follow the steps below. Open the Subscriptions page from the left-hand menu. Select the product that you are looking to change a user's rights or access. Click Users in the command bar to open the Users page. Select the user whose rights or role you would like to change on a product. Make any changes to the role of the selected user, as required. Make any changes to the rights of the selected user, as required. Click Save. Note Advise the user to sign out and back in again for the changes to take effect. Removing Access for a User If you need to remove access for a user on a product, follow the steps below. Open the Subscriptions page from the left-hand menu. Select the product that you are looking to revoke a user's access. Click Users in the command bar to open the Users page. Select the user whose rights or role you would like to change on a product. Click Revoke Access. Confirm that you would like to remove access for the selected user on the selected product by clicking Yes. Data Stream Designer Rights and Roles Several rights are maintained in Subscription Manager for Data Stream Designer. Each of these rights represents an aspect of the Data Stream Designer system that a user is allowed to see or access. Persons with administrative rights in Subscription Manager manage all rights. Data Stream Designer Rights The table below lists the rights that can be assigned to a user. Right Description CreateAgent Allows for an Agent to be uploaded. CreateCategory Allows for a Category to be created. CreateCollection Allows for a Collection to be created. CreateUseCase Allows for a Data Stream to be created, in which a user can create a Data Stream. DeleteAgent Allows for an Agent to be deleted. DeleteCategory Allows for a Category to be deleted. DeleteCollection Allows for a Collection to be deleted. DeleteUseCase Allows for a Data Stream to be deleted. DesignUseCase Allows for changes to be made to a Data Stream. This right allows a user to save changes to a Data Stream, as well as configure or delete Agents in a Data Stream. This right also allows for a user to copy a version of the Stream. DisconnectCollectionHosts Allows for the user to disconnect Stream Hosts. EditAgent Allows for an Agent to be edited. This includes managing the versions available in Data Stream Designer for the Agent. EditBusinessCase Allows for a Business Case to be edited. EditCategory Allows for Categories to be edited. EditCollection Allows for a Collection to be edited. EditNotes Allows for Notes to be edited. EditUseCase Allows for a Data Stream to be edited. LiveView Allows for Live Data from a published Data Stream to be viewed. ManageVariables Allows for the management of Variables. PublishUseCase Allows for a user to publish a Data Stream. RevokeCollectionKey Allows for a Collection key to be replaced with a new key. SetHostLogLevel Allows you to change the Host Log Levels between Info or Trace. See the Collection and Stream Host article for more information. ShareUseCase Allows for Data Streams to be shared. ViewAgent Allows for a list of Agents to be viewed. ViewCategory Allows for a Category to be viewed. ViewCollection Allows for a Collection to be viewed. ViewHostLogs Allows for the ability to view logs created for Stream Hosts that are running. ViewHosts Allows for a list of the available Stream Hosts to be viewed. ViewUseCase Allows for a Data Stream to be viewed. Data Stream Designer Default Roles A user is assigned a role and each role has appropriate rights for that function enabled. The table below illustrates which rights are included with each of the default roles. These default roles can be amended by the global administrator - who can also add new roles. Right Administrator User CreateAgent ✓ ✗ CreateCategory ✓ ✗ CreateCollection ✓ ✗ CreateUseCase ✓ ✓ DeleteAgent ✓ ✗ DeleteCategory ✓ ✗ DeleteCollection ✓ ✗ DeleteUseCase ✓ ✓ DesignUseCase ✓ ✓ DisconnectCollectionHosts ✓ ✗ EditAgent ✓ ✗ EditBusinessCase ✓ ✓ EditCategory ✓ ✗ EditCollection ✓ ✗ EditNotes ✓ ✓ EditUseCase ✓ ✓ LiveView ✓ ✓ ManageVariables ✓ ✗ PublishUseCase ✓ ✓ RevokeCollectionKey ✓ ✗ SetHostLogLevel ✓ ✗ ShareUseCase ✓ ✓ ViewAgent ✓ ✓ ViewCategory ✓ ✓ ViewCollection ✓ ✓ ViewHostLogs ✓ ✗ ViewHosts ✓ ✗ ViewUseCase ✓ ✓ ‌App Designer Rights and Roles ‌Several App Designer rights are maintained in Subscription Manager. Each of these rights represents an aspect of the App Designer system that a user is allowed to see or access. Persons with administrative rights in Subscription Manager manage all rights. App Designer Rights The table below lists the rights that can be assigned to a user. Right Description CreateApp Allows for an Application to be created. CreateCategory Allows for a Category to be created. CreateConnector Allows for a Connector to be created. DeleteApp Allows for an Application to be deleted. DeleteAppFile Allows for an App File to be deleted. DeleteCategory Allows for a Category to be deleted DeleteConnector Allows for a Connector to be deleted. DesignForm Allows for changes to be made to a Form. This right allows a user to add, edit, and delete Forms. If a user has the DesignRecommendation right they are able to select Forms for Rules, but not add, edit, or delete a Form. DesignRecommendation Allows for changes to be made to a Recommendation. This right allows a user to save changes to a Recommendation. EditApp Allows for an Application to be edited. EditCategory Allows for a Category to be edited. EditConnector Allows for a Connector to be edited. ManageAccess Allows for Design and Run Access to Apps to be managed. ManageAppConnections Allows for Connections to be added, edited, and deleted. ManageConnectorCategories Allows for categories of Connectors to be added, edited, and deleted. ManageRecommendationAccess Allows for Design and Run Access to Recommendations to be managed. ManageRecommendationCategories Allows for categories of Recommendations to be added, edited, and deleted. ManageTemplate Allows for Templates to be added, edited, and deleted. ManageVariables Allows for Variables to be added, edited, and deleted UploadAppFile Allows for an App File to be uploaded. ViewApp Allows for the user to view Applications in runtime mode. ViewAppBar Allows for the left menu bar to be viewed. ViewCategory Allows for Categories to be viewed. ViewConnector Allows for Connectors to be viewed. ViewRecommendationAlert Allows for Recommendation Alerts to be viewed. ViewTemplate Allows for Templates to be viewed. App Designer Default Roles A user is assigned a role and each role has appropriate rights for that function enabled. The table below illustrates which rights are included with each of the default roles. These default roles can be amended by the global administrator - who can also add new roles. Right Administrator Design User User CreateApp ✓ ✓ ✗ CreateCategory ✓ ✗ ✗ CreateConnector ✓ ✗ ✗ DeleteApp ✓ ✓ ✗ DeleteAppFile ✓ ✓ ✓ DeleteCategory ✓ ✗ ✗ DeleteConnector ✓ ✗ ✗ DesignForm ✓ ✓ ✗ DesignRecommendation ✓ ✓ ✗ EditApp ✓ ✓ ✗ EditCategory ✓ ✗ ✗ EditConnector ✓ ✗ ✗ ManageAccess ✓ ✓ ✗ ManageAppConnections ✓ ✓ ✗ ManageConnectorCategories ✓ ✓ ✗ ManageRecommendationAccess ✓ ✓ ✗ ManageRecommendationCategories ✓ ✗ ✗ ManageTemplate ✓ ✓ ✗ ManageVariables ✓ ✗ ✗ UploadAppFile ✓ ✓ ✓ ViewApp ✓ ✓ ✓ ViewAppBar ✓ ✓ ✓ ViewCategory ✓ ✓ ✓ ViewConnector ✓ ✓ ✗ ViewRecommendationAlert ✓ ✓ ✓ ViewTemplate ✓ ✓ ✗ ‌AI Rights and Roles One right is maintained in Subscription Manager for XMPro AI. It represents an aspect of the AI system that a user is allowed to see or access. Persons with administrative rights in Subscription Manager manage it. AI Rights The table below lists the right that can be assigned to a user. Right Description Access Jupyter Allows for XMPro Notebook to be accessed. AI Default Roles A user is assigned a role and each role has appropriate rights for that function enabled. The table below illustrates which rights are included with each of the default roles. These default roles can be amended by the global administrator - who can also add new roles. Right Administrator Access Jupyter ✓ ‌XMPro Notebook Rights and Roles Access rights for XMPro Notebook are controlled in Jupyter, not Subscription Manager."
  },
  "src/administration/subscriptions-admin/request-and-apply-a-license.html": {
    "href": "src/administration/subscriptions-admin/request-and-apply-a-license.html",
    "title": "Request and Apply a License | XMPro",
    "summary": "Request and Apply a License Warning Please note that this section is intended for Administrative users. No other type of user is allowed to manage a Company's Subscriptions. Request a License Company Administrators can request a License when updating a Subscription for a Company. To request a new License, follow the steps below: Open the Subscriptions page from the left-hand menu. Click on a Product. Click on 'Update License'. Click on Request a new License. Enter the number of days for the License. Click on Submit. Your License request will be sent to XMPro Support. An XMPro team member will get back to you shortly via email to progress the request further. Apply a License If a Company Administrator already has a License, they can apply it to the Product. To apply a License, follow the steps below: Open the Subscriptions page from the left-hand menu. Click on a Product. Click on 'Update License'. Select the License file. Click on Save."
  },
  "src/administration/subscriptions-admin/setup-auto-approvals-default-subscriptions.html": {
    "href": "src/administration/subscriptions-admin/setup-auto-approvals-default-subscriptions.html",
    "title": "Setup Auto Approval/Default Subscriptions | XMPro",
    "summary": "Setup Auto Approval/Default Subscriptions Warning Please note that this section is intended for Administrative users. No other type of user is allowed to manage a Company's Subscriptions. Auto Approval Company Administrators in the Subscription Manager can set up Auto Approval for any users who sign up using the Company name. If Auto Approval is enabled, the Company Administrator does not need to approve access requests individually, instead, the user will automatically gain access to XMPro. To enable Auto Approval, first log in to XMPro Subscription Manager as a Company Administrator. Then: Click Users in the left menu to open the Users page. Open the Access Requests page by clicking the Registration Requests button in the command bar. Open the Auto Approve page by clicking the Setup Auto Approve button in the command bar. Check the Enable auto approve checkbox. Choose a Default Role that will be given to new users. Click Save. Default Subscriptions Company Administrators in the Subscription Manager have the ability to determine if users signing up to the Subscription Manager are given access to products by default. They can also assign users a default specific role, according to what they have configured. For example, if a Company Administrator set the Data Stream Designer to be a default product and set the default role for this product to \"General User\", any new person signing up will be given access to the Data Stream Designer as a general user when the Company Administrator approves their request for access to Subscription Manager. Thus, there is no need to have every user signing up request a subscription to every product they need access to, on top of Subscription Manager, and approve every request individually. To set this up, follow the steps below: Click on Subscriptions from the left-hand menu. Select the product you would like to be a default product. Select the \"Is default?\" check box. Select the role that the new users should hold on this product after they have been automatically been given access from the \"Default Role\" drop-down. Click Save."
  },
  "src/administration/users/business-role-for-a-user.html": {
    "href": "src/administration/users/business-role-for-a-user.html",
    "title": "Change Business Role | XMPro",
    "summary": "Change Business Role Warning Please note that this section is intended for Administrative users. No other type of user is allowed to manage a Company's Subscriptions. To change a user's business role in XMPro, first log in to XMPro as your company administrator. Click on the Users page in the left menu. Select the user whose business role you wish to change, to open the Subscriptions blade. Choose a new business role. Click the Save button."
  },
  "src/administration/users/change-password.html": {
    "href": "src/administration/users/change-password.html",
    "title": "Change Password | XMPro",
    "summary": "Change Password Users can change their password by clicking the profile icon and the Change Password item in the dropdown. If you are on App Designer or Data Stream Designer, this will open Change Password in Subscription Manager, where you can change your password. You are required to enter both your current password and your new password. You will need to enter your new password twice to confirm it. Finally, click on Save."
  },
  "src/administration/users/delete-a-user.html": {
    "href": "src/administration/users/delete-a-user.html",
    "title": "Delete a User | XMPro",
    "summary": "Delete a User Warning Please note that this section is intended for Administrative users. No other type of user is allowed to manage a Company's Subscriptions. To delete users from your company on XMPro, first login as to XMPro as the global administrator. Click on the Companies page in the left menu. Click on the company to which the user currently belongs. Click the Users graph to open the Users blade. Select the user you wish to delete, to open the Subscriptions blade. Click the Delete User button. Click Delete again to confirm the deletion of the user. Warning You cannot undo this delete. Ensure their XMPro objects are shared with a co-owner or unpublished."
  },
  "src/administration/users/index.html": {
    "href": "src/administration/users/index.html",
    "title": "Users | XMPro",
    "summary": "Users A User is an XMPro account shared between all XMPro Products available in the Subscription Manager. Your User's Subscriptions, Rights, and Roles determine what Products you can access, as well as what you are allowed to view and edit within the Products. A Company's Administrator can assign Subscriptions for Products to specific Users within the Company. Invite a User Register an Account Profile Change Password Reset Password Delete a User Change Business Role"
  },
  "src/administration/users/invite-a-user.html": {
    "href": "src/administration/users/invite-a-user.html",
    "title": "Invite a User | XMPro",
    "summary": "Invite a User Warning Please note that this section is intended for Administrative users. No other type of user is allowed to manage a Company's Subscriptions. To invite users to your company on XMPro, first log in to XMPro as your company administrator. Click on the Users page in the left menu. Click on the Invite button in the command bar. Add the emails of your invitees in the Email field. Press enter after each email. Add comments to be shown on the invitation. Click the Send Invite button. The email will have a link to the registration page to sign up for your company in XMPro."
  },
  "src/administration/users/profile.html": {
    "href": "src/administration/users/profile.html",
    "title": "Profile | XMPro",
    "summary": "Profile Any user is able to update their settings using the Subscription Manager. This includes updating your first name, last name, language, email address, or phone number. This is useful if your personal or contact details have changed and you would like to update them on XMPro. How to Edit a Profile Click the icon or the name. Click Edit. This will redirect you to Subscription Manager. Update the details. Click Save. Note If the language selected is English, the Date and Time format for XMPro Products will be determined by the web browser's locale. For example, American English vs Australian English. Note The email and mobile number may take up to an hour to propagate to all XMPro Products."
  },
  "src/administration/users/register-an-account.html": {
    "href": "src/administration/users/register-an-account.html",
    "title": "Register an Account | XMPro",
    "summary": "Register an Account Register an Account Registering on Subscription Manager can be done in different ways, depending on if you have been invited to register, whether someone in your company has registered before or not, and if you are registering for a trial or not. If you received an email, inviting you to sign up, click on the link in the email to open the registration page. Otherwise, click on the Sign-Up button on the login page. Follow the steps below: Fill in your first name, last name, and email address. Enter the name of your company. If you have been invited to sign up and opened the page by clicking on the link in the email you received, you can skip this step, as we would have already received the company name. If you are registering your account through the Sign Up button, you will need to enter your company name. If your admin has set up a company, use the same name they have used. Otherwise, refer to the Register a Company page to follow the steps on how to Register a new company. Choose a unique username, for example, \"keith.miller\". Do not include your company name in your username. Choose a password and confirm your password Click \"Agree\". Wait for an email, confirming that you have been granted access to Subscription Manager. You will only be allowed to use the system after being granted access. If Auto approval is set up, the account will automatically be approved for that company, otherwise, you will need to wait for your company admin to approve your account."
  },
  "src/administration/users/reset-password.html": {
    "href": "src/administration/users/reset-password.html",
    "title": "Reset Password | XMPro",
    "summary": "Reset Password If you have forgotten your password, you will be able to reset it using a password recovery link. This can be done from the login screen by clicking on Reset password. Enter both your username and email address. The email address you enter will be the email address used to send you the recovery link. Finally, click on Send recovery link. You will receive an email with a link that will allow you to change your password. You can then re-attempt to log in with the new password you have set."
  },
  "src/blocks-toolbox/actions/README.html": {
    "href": "src/blocks-toolbox/actions/README.html",
    "title": "Actions Blocks | XMPro",
    "summary": "Actions Blocks Actions blocks in XMPro App Designer enable user interactions and trigger functionality within your applications. These blocks allow users to navigate between pages, submit forms, execute operations, and interact with data sources. Available Actions Blocks Box Hyperlink - A container that acts as a clickable hyperlink Button - A standard button control for triggering actions Data Operations - A block for performing operations on data sources Hyperlink - A text-based hyperlink for navigation Best Practices for Using Actions Blocks Use clear and descriptive labels: Ensure that action labels clearly communicate what will happen when the user interacts with them. For example, use \"Save\" instead of \"OK\" for a button that saves a form. Provide visual feedback: Use visual cues to indicate when an action is being processed or has been completed. This helps users understand the status of their interactions. Consider placement and visibility: Position action blocks where users expect to find them and ensure they are easily visible. Follow standard UI patterns, such as placing primary actions on the right and secondary actions on the left. Implement appropriate validation: Before executing actions that modify data or navigate away from a page, ensure that appropriate validation is performed to prevent data loss or invalid operations. Handle errors gracefully: When actions encounter errors, provide clear and helpful error messages that guide users on how to resolve the issue. Optimize for performance: Actions should be responsive and execute quickly. If an action requires significant processing time, provide feedback to the user and consider using asynchronous processing. Consider accessibility: Ensure that action blocks are accessible to all users, including those using screen readers or keyboard navigation. Use appropriate ARIA attributes and ensure keyboard focus is managed correctly. Examples Form Submission Box (Form Container) ├── Field (Name) │ ├── Textbox ├── Field (Email) │ ├── Textbox ├── Field (Message) │ ├── Text Area ├── Box (Buttons) │ ├── Button (Submit) │ │ ├── On Click (Submit Form) │ ├── Button (Cancel) │ │ ├── On Click (Navigate to Home) Data Grid with Actions Box (Data Grid Container) ├── Data Grid │ ├── Column (ID) │ ├── Column (Name) │ ├── Column (Email) │ ├── Column (Actions) │ │ ├── Button (Edit) │ │ │ ├── On Click (Navigate to Edit Page) │ │ ├── Button (Delete) │ │ │ ├── On Click (Delete Record) ├── Box (Toolbar) │ ├── Button (Add New) │ │ ├── On Click (Navigate to Add Page) │ ├── Button (Refresh) │ │ ├── On Click (Refresh Data) Navigation Menu Box (Navigation Container) ├── Menu │ ├── Menu Item (Home) │ │ ├── Hyperlink (Navigate to Home) │ ├── Menu Item (Products) │ │ ├── Hyperlink (Navigate to Products) │ ├── Menu Item (Services) │ │ ├── Hyperlink (Navigate to Services) │ ├── Menu Item (About) │ │ ├── Hyperlink (Navigate to About) │ ├── Menu Item (Contact) │ │ ├── Hyperlink (Navigate to Contact) Dashboard with Action Cards Box (Dashboard Container) ├── Layout Grid │ ├── Box Hyperlink (Navigate to Sales) │ │ ├── Card (Sales) │ │ │ ├── Text (Sales Summary) │ │ │ ├── Chart (Sales Chart) │ ├── Box Hyperlink (Navigate to Inventory) │ │ ├── Card (Inventory) │ │ │ ├── Text (Inventory Summary) │ │ │ ├── Chart (Inventory Chart) │ ├── Box Hyperlink (Navigate to Customers) │ │ ├── Card (Customers) │ │ │ ├── Text (Customer Summary) │ │ │ ├── Chart (Customer Chart) By effectively using actions blocks, you can create interactive and responsive applications that provide a seamless user experience. These blocks enable users to navigate through your application, interact with data, and trigger functionality that meets their needs."
  },
  "src/blocks-toolbox/actions/box-hyperlink.html": {
    "href": "src/blocks-toolbox/actions/box-hyperlink.html",
    "title": "Box Hyperlink | XMPro",
    "summary": "Box Hyperlink A Box Hyperlink is a Block where you can link to another location or website. Box Hyperlink Properties Appearance Common Properties You can change the visibility of the Box Hyperlink. See the Common Properties article for more details on common appearance properties. Text This is only available if the mode option in the behavior tab is set to true. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/actions/button.html": {
    "href": "src/blocks-toolbox/actions/button.html",
    "title": "Button | XMPro",
    "summary": "Button A Button is a Block that the user can click on which can trigger an event such as loading another page or confirming details on a form. Button Properties Appearance Common Properties Properties that are common to most Blocks include visibility, styling mode, tooltip, and icon; See the Common Properties article for more details on common appearance properties. Type The type of the button can be changed depending on its purpose. Options include danger, normal, success, and default. Text The text that shows on top of the Button. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Enable Focus This determines if the user can navigate to the Button by using the keyboard. This includes using the tab button to switch between text boxes on a form, and then clicking the tab button at the end to highlight and select the Button. Buttons will also be focussed on when you click on them. If a Button is clicked, and no action occurs, the Button will also remain in focus. Validation Common Properties Properties that are common to most Blocks include: groups to validate; See the Common Properties article for more details on common validation properties. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/actions/data-operations.html": {
    "href": "src/blocks-toolbox/actions/data-operations.html",
    "title": "Data Operations | XMPro",
    "summary": "Data Operations A Data Operation Block is a button with additional functionality that allows you to Insert or Delete records from a Data Repeater Block that is bound to a Data Source. Data Operation Properties Appearance Common Properties Properties that are common to most Blocks include Visibility, Styling Mode, Tooltip, and Icon. The Styling Mode, Tooltip, and Icon properties are only available for the Data Operations Block if the Display Mode property is set to 'Button'; See the Common Properties article for more details on common appearance properties. Text The text that shows on top of the Button. If the Display Mode is set to 'Hyperlink', the default text will either be 'Add' or 'Delete', depending on what Mode is selected under Behaviors. Display Mode The Display Mode of a Data Operations Block can either be a Button or a Hyperlink. By default, the Block is configured with either an 'Add' or 'Delete' icon if the 'Button' Display Mode is selected. Type The type of the button can be changed depending on its purpose. Options include Danger, Normal, Success, and Default. This is only available if the Display Mode property is set to 'Button'. Behavior Common Properties The Disabled property is common to most Blocks. The Disabled property is only available for the Data Operations Block if the Display Mode property is set to 'Button'; See the Common Properties article for more details on common behavior properties. Mode There are two modes that you can choose from: Insert and Delete. The Mode determines what operation will be performed on the Data Source and records. 'Insert' will add a new row to the list: 'Delete' will delete a record from the list: Note When a record is inserted or deleted, it does not immediately update the Data Source. To do this, you will need to add a regular Button with 'Update Data Sources' selected. See the Common Properties article for more details on common action properties. Data Source The Data Source that you would like to add a new record to. This is only available if the Mode property is set to 'Insert'. If the Mode property is set to 'Insert', the Data Source property is required for the Data Operations Block. Enable Focus This determines if the user can navigate to the Button by using the keyboard. This includes using the tab button to switch between text boxes on a form, and then clicking the tab button at the end to highlight and select the Button. Buttons will also be focused on when you click on them. If a Button is clicked, and no action occurs, the Button will also remain in focus. This is only available if the Display Mode property is set to 'Button'. Show Confirmation Dialog This can either be set to 'True' or 'False'. If True, a dialog box will appear asking the user if they are sure they want to delete that particular record. This is only available if the Mode property is set to 'Delete'."
  },
  "src/blocks-toolbox/actions/hyperlink.html": {
    "href": "src/blocks-toolbox/actions/hyperlink.html",
    "title": "Hyperlink | XMPro",
    "summary": "Hyperlink A Hyperlink is a Block where you can link to another location or website. Hyperlink Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Text This is the text that will be displayed as a link for the user to click on. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/actions/index.html": {
    "href": "src/blocks-toolbox/actions/index.html",
    "title": "Actions | XMPro",
    "summary": "Actions Box Hyperlink Button Data Operations Hyperlink"
  },
  "src/blocks-toolbox/advanced/index.html": {
    "href": "src/blocks-toolbox/advanced/index.html",
    "title": "Advanced | XMPro",
    "summary": "Advanced Metablock"
  },
  "src/blocks-toolbox/advanced/metablock.html": {
    "href": "src/blocks-toolbox/advanced/metablock.html",
    "title": "Metablock | XMPro",
    "summary": "Metablock Metablock allows pro-code designers to leverage libraries to add their dynamic blocks in XMPro using script files. We recommend leveraging generative AI to write the scripts. This approach can significantly streamline the development process and enhance the functionality of the blocks. Note Only the Presentation File (HTML) is required. Utilize the other properties based on your specific needs for the Metablock behavior. Metablock Properties Behavior Presentation File (HTML) Upload the HTML script file that will be rendered in your Metablock, which is used to create dynamic blocks that may display data from a Data Source or from Value Mapping. <div class=\"foo\">bar</div> Alternatively, you can write your scripts in a single HTML file that includes both CSS and JavaScript. This approach is ideal for smaller applications. <!-- Style with CSS the div element with class foo the color blue --> <style> .foo { color: blue } </style> <!-- Html to show the text \"foo\" --> <div class=\"foo\">foo</div> <!-- JavaScript to change the text \"foo\" to \"bar\" when the page has loaded --> <script> document.addEventListener('DOMContentLoaded', function() { const fooDiv = document.querySelector('.foo'); fooDiv.innerHTML = 'bar'; }); </script> Styling File (CSS) If you wish to add styling, upload a CSS file to style your Metablock control. .foo { color : green; } Script File (JavaScript) If you wish to run JavaScript, upload a JavaScript file for your Metablock. Place any initial/startup values as constants in this file. const foo = 'foo'; Data Source Common Properties Common properties include: filter, sort, show # of results, and skip # of results; See the Common Properties article for more details on common Data Source properties. To use the Data Source property, include these predefined JavaScript functions in your Script File: // Access data source when the metablock is loaded (optional) function onDataLoaded(data) { // Access a value from the data source const foo = data.find(obj => 'foo' in obj).foo; } // Access live updates on the data source after the metablock has been loaded (optional) function onDataChanged(data, changes) { } onDataLoaded(data) sample data format [ { \"ReadingNo\": 911, \"Timestamp\": \"2024-08-16T07:24:00.1791525Z\", \"value\": 3.6695501388374483, \"entityid\": \"static\", \"_$parentProperties\": {}, \"_$parentExpressions\": [], \"_$state\": { \"_$typeName\": \"EntityState\", \"name\": \"Unchanged\" } } ] The data above originates from a data stream that we've set up and it runs once upon page load. Keep in mind that the data format might differ based on your data source configuration. onDataChanged(data, changes) sample data format //data from `data` variable [ { \"ReadingNo\": 1156, \"Timestamp\": \"2024-08-16T08:04:52.3154712Z\", \"value\": 1.5450710600917559, \"entityid\": \"static\", \"_$parentProperties\": {}, \"_$parentExpressions\": [], \"_$state\": { \"_$typeName\": \"EntityState\", \"name\": \"Unchanged\" } } ] //data from `changes` variable [ { \"ReadingNo\": 1156, \"Timestamp\": \"2024-08-16T08:04:52.3154712Z\", \"value\": 1.5450710600917559, \"entityid\": \"static\", \"_$parentProperties\": {}, \"_$parentExpressions\": [], \"_$state\": { \"_$typeName\": \"EntityState\", \"name\": \"Unchanged\" } } ] In this example, both the data and changes variables contain identical data, indicating that there are no updates. However, in a real-world scenario, the changes variable would capture any modifications to the initial data. You can refer to a working example script that demonstrates an Autodesk Forge visualization here. Value Value Mapping If you wish to define value mappings for run-time use, you can configure user-defined key-value pairs. These values remain static during application rendering. The Value Mapping opens a new blade to setup the Key and Value configuration. The options for the Value Source are Static, Dynamic, Expression and Variables. When selecting Server Variables as a Source for the Value Mapping, the list of unencrypted Server Variables will be displayed. Tick the Encrypt checkbox to use an encrypted Server Variable for values like keys, secrets, or password. Note that only plain text values are supported for encrypted Server Variables due to the request proxying process. From v4.4.18, encrypted Server Variables will not have their value available immediately on the Metablock. Instead, you can use them inside a Fetch/XHR request or a WebSocket/MQTT message before being forwarded to the actual target. Fetch/XHR Request - You can use encrypted server variables as part of the URL, Header, or Body of the Fetch/XHR request. WebSocket/MQTT Message - You can use encrypted server variables as part of the WebSocket message. For MQTT Messages, you can use it as part of the following message types: Connect (Username and Password), Publish (Payload), and Subscribe (Subscribe Topics) Proxy Requests Tick to proxy requests on the AD Server, so that encrypted server variables are replaced with the actual value before being forwarded to the target request. This is ticked by default when using an encrypted server variable on the value mapping, but you can opt in to use it even without any encrypted server variable. To use Value Mapping, include this predefined JavaScript function in your Script File: // Access Value mapping data when the metablock is loaded (optional) function onValueMappingLoaded(data){ //Apply a value from the value mapping const foo = data['foo']; } OnValueMappingLoaded(data) sample data format { \"key\": \"Value\", \"isWorking\": true, \"counter\": 10 \"password\": \"{{var-x:Encrypted Variable Name}}\" //Encrypted Server Variable template } Warning Note: The password property will not have the actual value yet when it is mapped from an Encrypted Server Variable. Instead, it is just a template for the Server Variable name. Real World Use Cases Enhancing Chart Display Use Value Mapping to incorporate user input for displaying Harmonic Frequency, maintaining connector integrity while improving data visualization. Fig 1: Enhancing chart display Note GitHub Repository: Chart Display Enhancement View the complete implementation example for enhancing chart display functionality. View on GitHub Streamlining Pump Status Display Leverage Value Mapping to dynamically pass URLs from other data sources or utilize expressions, eliminating the need for manual URL adjustments during version updates. Fig 2: Pump status display Note GitHub Repository: Pump Status Display View the complete implementation example for streamlining pump status display. View on GitHub Autodesk: visualize 2D & 3D models Access and visualize your engineering data and designs from the cloud using Autodesk Platform Services (APS, formerly Forge). Leverage Value Mapping when embedding the APS Viewer in XMPro App Pages to display interactive 2D and 3D views of your designs. Note: This is a simple example to demonstrate the APS Viewer API using an unauthenticated repository. Refer to the authenticated use case for a more complex example that includes security measures for credentials. Fig 3: Autodesk Platform Services Viewer example without authentication Note GitHub Repository: APS View Basic View the complete implementation example for basic Autodesk Platform Services viewer integration. View on GitHub Autodesk: Visualize 2D & 3D models with authentication When authentication is needed to dynamically load 2D and 3D views of your designs using the APS Viewer. We could utilize a Connector or the Value Mapping and use server variables for the credentials. This eliminates the need for hardcoded credentials while maintaining secure access to the visualization platform, Autodesk Platform Services (APS, formerly Forge). See the following Metablock examples on how to use these methods. Autodesk: Authentication using Connector Leverage the REST API Connector to get Token from the authentication service and the Data Source to pass the token to the Metablock. Note GitHub Repository: APS View with Authentication View the complete implementation example for authenticated Autodesk Platform Services viewer integration using Connector. View on GitHub Autodesk: Authenticate using Value Mapping Leverage the Value Mapping to pass an encrypted Server Variable to the Metablock and call the authentication service using a Fetch request to get the Token. Note GitHub Repository: APS View with Authentication from Value Mapping View the complete implementation example for authenticated Autodesk Platform Services viewer integration using Value Mapping. View on GitHub Fig 4: Autodesk Platform Services Viewer example with authentication Creating a Metablock Script: Step-by-Step Guide Step 1: Search for a code snippet Find relevant sample, we search for sample Autodesk Forge code and found the following links: Demo: Very Basic 3D Viewer (autodesk-forge.github.io) Github: viewer-javascript-offline.sample/index.html at gh-pages · Autodesk-Forge/viewer-javascript-offline.sample · GitHub Step 2: Writing your Metablock script Adapt the sample code to the Metablock format. For simplicity, the HTML, CSS & JavaScript has been combined into a single file. <!-- main.html --> <h1>Autodesk Forge Viewer</h1> <div id=\"main\"></div> /* main.css */ h1 { font-family: Arial, sans-serif; color : #333; } // main.js var hasInitialized = false; function onValueMappingLoaded(data) { // Prevent multiple initializations if (hasInitialized) return; hasInitialized = true; // Load the CSS forge dependencies const cssViewerUrl = 'https://developer.api.autodesk.com/modelderivative/v2/viewers/style.min.css?v=v7.*'; loadCSSViewer(cssViewerUrl); // Load the forge viewer var viwerUrl = 'https://developer.api.autodesk.com/modelderivative/v2/viewers/7.*/viewer3D.min.js'; var viewer = loadViewer(viwerUrl); // Get the model URL from the data const modelUrl = data['model_url'] // Load the model into the viewer loadModel(viewer, modelUrl); } function loadViewer(viewer_url) { return new Promise((resolve, reject) => { const script = document.createElement('script'); script.src = viewer_url; script.onload = resolve; script.onerror = reject; document.head.appendChild(script); }); } function loadCSSViewer(css_viewer_url){ return new Promise((resolve, reject) => { const link = document.createElement('link'); link.rel = \"stylesheet\"; link.type = \"text/css\"; link.href = css_viewer_url; link.onload = resolve; link.onerror = reject; document.head.appendChild(link); }); } // Loads the model into the viewer function loadModel(viewer, modelUrl) { viewer.then(() => { var myViewerDiv = document.getElementById('main'); var viewer = new Autodesk.Viewing.Private.GuiViewer3D(myViewerDiv); var options = { 'env': 'Local', 'document': modelUrl }; Autodesk.Viewing.Initializer(options, function onInitialized() { viewer.start(options.document, options); }); }).catch((error) => { console.error('Failed to load Forge viewer:', error); }); } Step 3: Testing your code locally (Optional) Test it locally before implementation by running it from another html file (test-harness.html) via a local webserver. A 3D interactive model of a house should load in your browser. Create the test-harness.html file in the same directory as your Metablock files. !-- test-harness.html --> <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"> <title>Test Harness for XMPro Metablocks</title> <!-- Favicon --> <link rel=\"icon\" type=\"image/x-icon\" href=\"/favicon.ico\"> <!-- Link to the Metablock CSS file --> <link rel=\"stylesheet\" href=\"main.css\"> </head> <body> <!-- Container for the Metablock HTML content --> <div id=\"main\"> <p id=\"loading\">Loading content...</p> </div> <!-- Include the Metablock JavaScript file --> <script src=\"main.js\"></script> <script> // Fetch the content of main.html and inject it into the #main div fetch('main.html') .then(response => response.text()) .then(html => { // Insert the fetched HTML into the #main div document.getElementById('main').innerHTML = html; // Initialize static data for the Metablock // This object allows passing specific initialization data to the JavaScript // through the onValueMappingLoaded function var data = { // model_url: The url of the model to be displayed in the Metablock // This would be passed in from the XMPro Metablock configuration Value Mapping. model_url: \"https://developer-autodesk.github.io/translated-models/dwfx-sample-house/f0224dd3-8767-45c1-ff99-5c9c881b9fee/0.svf\" // Add any other required initialization parameters here, for example: // api_endpoint: \"https://api.example.com/v1\", // debug_mode: true, // theme: \"dark\" } // Call the onValueMappingLoaded function with the initialization data // This function should be defined in main.js and will use the provided data // to set up the Metablock's initial state onValueMappingLoaded(data); }) .catch(error => { // Log any errors that occur during the fetch operation console.error('Error loading main.html:', error); }); </script> </body> </html> Run the test-harness.html in a webserver (node.js) Make sure you have Node.js installed on your computer. You can download it from https://nodejs.org/. Open a terminal or command prompt and navigate to your project folder where the metablock files are. Initialize a new Node.js project by running npm init -y Install Express by running npm install express Create public folder and moved your HTML, CSS & JavaScript files inside Create a file named server.js copy and paste below code in server.js file // server.js const express = require('express'); const path = require('path'); const app = express(); const port = process.env.PORT || 3000; // Serve static files from the 'public' directory app.use(express.static(path.join(__dirname , 'public'))); app.get('/', (req, res) => { res.sendFile(path.join(__dirname, 'public', 'test-harness.html')); }); app.use((req,res) => { res.status(404); res.send(`<h1>Error 404: Resource not found</h1>`); }); // Start the server app.listen(port, () => { console.log(`Server is running on http://localhost:${port}`); }); To start the server, run node server.js Open a web browser and go to http://localhost:3000 Step 4: Configure the Metablock in App Designer Drag the Metablock onto your page. Open Block Properties. Add the 3 Metablock files by clicking on the plus icon and uploading the main.html, main.css, main.js files and selecting each from their respective dropdown. Add a Value Mapping of key model_url and Value https://developer-autodesk.github.io/translated-models/dwfx-sample-house/f0224dd3-8767-45c1-ff99-5c9c881b9fee/0.svf Save the page Launch the page Example Files Refer to the simple Autodesk use case for a complete set of files for this example. Security Features We have added security features in Metablock to safeguard the users from potential attacks, When developing applications, we have selectively enabled the following features: Form Submission Pop-up windows Modal Dialogs JavaScript Features External Resources Allowed Downloads (v4.4.18) Additionally, Metablock allows the use of specific hardware APIs for enhanced application capabilities, including camera, encrypted-media, full-screen, geo-location, speaker, accelerometer, gyroscope, magnetometer, and midi. FAQs Why did the JavaScript code in my Metablock not execute on page load? Due to the timing of function instantiation, we recommend checking the document's ready state instead of relying on the load event: Check document's ready state: if (document.readyState === 'complete') { // add your logic here } Alternatively use one of the existing functions. function onValueMappingLoaded(data) { // add your logic here } How can I load multiple script files? From v4.4.18, you can load external script files by including a script block - the same as you would usually do in a html file. The same applies to style/CSS files. <script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script> You can also reference resources (js, css, image) uploaded on your App Files folder by following the correct format for the URL when referencing. Prefix the path with \"./AppFiles/\" and append the path of the App Files resource: \"./AppFiles/{path on the App Files}\" See the following example for the html that links different resources from the App File: App Files For an App Files folder structure that looks like this: offline_files/ ├── offline_image.png ├── offline-script.js └── offline-styles.css HTML Link the resources by following the correct format. ex. \"./AppFiles/offline_files/offline-script.js\" <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"> <title>My Web Page</title> <!-- Loading style resource from AppFiles --> <link rel=\"stylesheet\" href=\"./AppFiles/offline_files/offline-styles.css\"> </head> <body> <!-- Loading image resource from AppFiles --> <img id=\"image\" src=\"./AppFiles/offline_files/offline-image.png\" alt=\"Offline Image\"> <div class=\"container\"> <h1>Welcome to My Web Page</h1> <p>This is a sample page that uses <span class=\"highlight\">AppFiles</span> resources for js, css and images.</p> <button id=\"clickMe\">Click Me!</button> <p id=\"counter\">Button clicks: 0</p> </div> <!-- Loading script resource from AppFiles --> <script src=\"./AppFiles/offline_files/offline-script.js\"></script> <!-- Loading script resource from an external link --> <script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script> <script> $(document).ready(function() { let flipped = false; $('#image').click(function() { flipped = !flipped; $(this).css('transform', flipped ? 'scaleX(-1)' : 'scaleX(1)'); }); }); </script> </body> </html> Note GitHub Repository: Link App Files Resources Example View the complete implementation example for linking App Files resources. View on GitHub Warning Note: Displaying the Metablock may take some time since it needs to finish loading all referenced App File resources before it is shown on the Application. Avoid referencing heavy files from the App Files and use external resources instead. You can also dynamically load JavaScript files but only for external resources and not from the App Files. function loadScript(url) { return new Promise((resolve, reject) => { const script = document.createElement('script'); script.src = url; script.onload = resolve; script.onerror = reject; document.head.appendChild(script); }); } Why is the Metablock throwing 500 errors related to styling and script files? This can occur if your HTML file includes inline script import code that does not follow the correct format. Only link external resources or make sure the file is uploaded on App Files and the URL format is correct. <!-- unsupported import script --> <link rel=\"stylesheet\" href=\"styles.css\"> <!-- unsupported import script --> <script src=\"app.js\"></script> <!-- valid html --> <span>foo</span>"
  },
  "src/blocks-toolbox/ai/README.html": {
    "href": "src/blocks-toolbox/ai/README.html",
    "title": "AI Blocks | XMPro",
    "summary": "AI Blocks AI blocks in XMPro App Designer provide powerful artificial intelligence capabilities that can be integrated directly into your applications. These blocks leverage advanced AI technologies to enhance your applications with intelligent features such as natural language processing, content generation, and contextual assistance. Available AI Blocks Azure Copilot - AI assistant powered by Microsoft Azure AI services ChatGPT Copilot - AI assistant powered by OpenAI's ChatGPT technology Best Practices for Using AI Blocks Define clear use cases: Identify specific use cases where AI can add value to your application. AI blocks are most effective when they address well-defined problems or enhance specific user experiences. Set appropriate expectations: Communicate clearly to users about the capabilities and limitations of AI features in your application. This helps manage user expectations and builds trust. Provide context: AI models perform better when given appropriate context. Design your application to provide relevant context to AI blocks, such as user history, current task, or domain-specific information. Implement user feedback mechanisms: Allow users to provide feedback on AI-generated content or suggestions. This feedback can help improve the AI's performance over time and identify areas for improvement. Consider privacy and security: Be mindful of the data being sent to AI services. Ensure that sensitive information is handled appropriately and in compliance with relevant regulations. Design for graceful degradation: Ensure that your application can still function effectively if AI services are unavailable or if responses don't meet expectations. Monitor and evaluate performance: Regularly monitor the performance of AI blocks in your application. Track metrics such as accuracy, relevance, and user satisfaction to identify opportunities for improvement. Examples Customer Support Assistant Box (Support Assistant Container) ├── Text (Welcome message) ├── ChatGPT Copilot │ ├── Configuration │ │ ├── System Prompt (You are a helpful customer support assistant...) │ │ ├── Temperature (0.7) │ │ ├── Max Tokens (1000) │ ├── Chat Interface │ │ ├── Message History │ │ ├── User Input │ │ ├── Send Button Document Analysis and Summarization Box (Document Analysis Container) ├── File Uploader │ ├── Button (Upload Document) ├── Azure Copilot │ ├── Configuration │ │ ├── System Prompt (Analyze and summarize the uploaded document...) │ │ ├── Temperature (0.5) │ │ ├── Max Tokens (2000) │ ├── Output Display │ │ ├── Text (Summary) │ │ ├── Text (Key Points) │ │ ├── Text (Recommendations) Data Insights Assistant Box (Data Insights Container) ├── Data Grid (Data Display) ├── ChatGPT Copilot │ ├── Configuration │ │ ├── System Prompt (You are a data analysis assistant...) │ │ ├── Temperature (0.2) │ │ ├── Max Tokens (1500) │ ├── Chat Interface │ │ ├── Message History │ │ ├── User Input │ │ ├── Send Button ├── Box (Insights Display) │ ├── Text (Generated Insights) │ ├── Chart (Visualization) By effectively integrating AI blocks into your applications, you can provide intelligent, context-aware experiences that enhance user productivity, provide valuable insights, and automate complex tasks. These AI-powered features can significantly improve the value and capabilities of your XMPro applications."
  },
  "src/blocks-toolbox/ai/azure-copilot.html": {
    "href": "src/blocks-toolbox/ai/azure-copilot.html",
    "title": "Azure Copilot | XMPro",
    "summary": "Azure Copilot The Azure Copilot block utilizes the Azure OpenAI service to provide advanced AI chat functionality in your application. Azure Copilot Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Prompt Input Height (px) The height in pixels of the prompt display within the overall block size. Adjust this value to best suit your design: higher for a portrait block and lower for a landscape block - or desktop vs mobile. Response Welcome Message The initial text displayed in the response area. Disclaimer Message The disclaimer message displayed below the prompt input. Behavior Use Variables Tick to select static variables for the Azure OpenAI Endpoint, Azure OpenAI Key, and Azure OpenAI Deployment ID, or manually enter the values. Azure OpenAI Endpoint Specifies the resource endpoint for creating an Azure OpenAI service within the user's block. You can obtain your API Endpoint within the Azure Portal. Azure OpenAI Key This secret key is essential for the Azure OpenAI service, allowing the user to interact with the service. You can obtain your API key within the Azure Portal. Azure OpenAI Deployment ID The model version (e.g., gpt-4, dall-e, gpt-3-turbo) that the designer intends to use in their Copilot block. System Prompt Influence the personality of the AI's response."
  },
  "src/blocks-toolbox/ai/chatgpt-copilot.html": {
    "href": "src/blocks-toolbox/ai/chatgpt-copilot.html",
    "title": "ChatGPT Copilot | XMPro",
    "summary": "ChatGPT Copilot The ChatGPT Copilot block utilizes the ChatGPT OpenAI service to provide advanced AI chat functionality in your Application. ChatGPT Copilot Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Prompt Input Height (px) The height in pixels of the prompt display within the overall block size. Adjust this value to best suit your design: higher for a portrait block and lower for a landscape block - or desktop vs mobile. Response Welcome Message The initial text displayed in the response area. Disclaimer Message The disclaimer message displayed below the prompt input. Behavior Use Variables Tick to select a static variable for the ChatGPT OpenAI Key, or manually enter the value. ChatGPT OpenAI Key The key required to authorize interaction with the ChatGPT OpenAI service. You can obtain your API key by accessing the \"API keys\" section within the OpenAI API platform. ChatGPT Models The desired model version (e.g., gpt-4, dall-e, gpt-3-turbo). System Prompt Influence the personality of the AI's response."
  },
  "src/blocks-toolbox/ai/index.html": {
    "href": "src/blocks-toolbox/ai/index.html",
    "title": "AI | XMPro",
    "summary": "AI Azure Copilot ChatGPT Copilot"
  },
  "src/blocks-toolbox/basic/README.html": {
    "href": "src/blocks-toolbox/basic/README.html",
    "title": "Basic Blocks | XMPro",
    "summary": "Basic Blocks Basic blocks are the fundamental building blocks of XMPro applications. They provide essential functionality for user input, data display, and interaction. These blocks are the most commonly used components in application development. Available Basic Blocks Calendar - Date selection and calendar display component Check Box - Toggle control for boolean values Color Selector - Component for selecting colors Data Grid - Tabular data display with sorting, filtering, and editing capabilities Date Selector - Component for selecting dates Dropdown Grid - Dropdown component with grid-based selection Embedded Page - Component for embedding other pages within a page File Library - Component for managing and displaying files File Uploader - Component for uploading files Html Editor - Rich text editor for HTML content Image - Component for displaying images Indicator - Visual indicator for status or state List - Component for displaying lists of items Lookup - Component for looking up values from a data source Number Selector - Component for selecting numeric values Radio Buttons - Selection control for choosing one option from a set Range Slider - Component for selecting a value from a range Select Box - Dropdown selection component Switch - Toggle switch for boolean values Tags - Component for displaying and managing tags Text - Component for displaying text Text Area - Multi-line text input component Textbox - Single-line text input component Tree Grid - Hierarchical data display with grid capabilities Tree List - Hierarchical list component Best Practices for Using Basic Blocks Choose the right input type: Select the appropriate input block based on the type of data you're collecting. For example, use a Date Selector for dates, a Number Selector for numbers, and a Select Box for selecting from a predefined list of options. Provide clear labels: Always include clear labels for input blocks to help users understand what information is being requested. Use validation: Implement validation on input blocks to ensure that users provide valid data. This can prevent errors and improve the user experience. Consider accessibility: Ensure that your application is accessible to all users by providing appropriate ARIA labels, ensuring keyboard navigation works correctly, and maintaining sufficient color contrast. Optimize for performance: Be mindful of the number of blocks you use, especially data-intensive blocks like Data Grid and Tree Grid, as they can impact performance. Use consistent styling: Maintain consistent styling across your application to provide a cohesive user experience. Implement responsive design: Ensure that your application works well on different screen sizes by using responsive design techniques. Examples Form with Various Input Types Box (Form Container) ├── Field (Name) │ ├── Textbox ├── Field (Email) │ ├── Textbox (with email validation) ├── Field (Date of Birth) │ ├── Date Selector ├── Field (Gender) │ ├── Radio Buttons │ ├── Option (Male) │ ├── Option (Female) │ ├── Option (Other) ├── Field (Interests) │ ├── Tags ├── Field (Comments) │ ├── Text Area ├── Box (Buttons) │ ├── Button (Submit) │ ├── Button (Cancel) Data Display Box (Data Display Container) ├── Data Grid │ ├── Column (ID) │ ├── Column (Name) │ ├── Column (Email) │ ├── Column (Status) │ │ ├── Indicator │ ├── Column (Actions) │ │ ├── Button (Edit) │ │ ├── Button (Delete) Search and Filter Box (Search Container) ├── Field (Search) │ ├── Textbox │ ├── Button (Search) ├── Field (Category) │ ├── Select Box ├── Field (Date Range) │ ├── Date Selector (From) │ ├── Date Selector (To) ├── Field (Price Range) │ ├── Range Slider By effectively using basic blocks, you can create intuitive, functional, and user-friendly applications that meet your users' needs."
  },
  "src/blocks-toolbox/basic/calendar.html": {
    "href": "src/blocks-toolbox/basic/calendar.html",
    "title": "Calendar | XMPro",
    "summary": "Calendar The Calendar is a Block that displays a Calendar and allows the user to select the required date within a specified date range. This is useful to use on forms where the user needs to enter a date for a particular field. It is also useful for displaying certain important dates to the user. Calendar Properties Appearance Common Properties You can specify if the Calendar is visible, or if tooltips are enabled. See the Common Properties article for more details on common appearance properties. Show Today Button This specifies if the button that takes the user back to the current date is displayed. Zoom Levels This specifies the time frame of selectable dates. Options include month, year, decade, and century. Min and Max Zoom Levels This specifies the limit on where the user can zoom in and out of the dates. For example, they can zoom until they reach the page that shows the yearly view, and can only zoom out to see decades. Behavior Common Properties The read-only and disabled properties are common to most Blocks; See the Common Properties article for more details on common behavior properties. Min and Max This only lets the user select dates within a limited range. First Day of the Week Changes the day of the week that the Calendar starts on. Value Common Properties The Value property is common to most Blocks; See the Common Properties article for more details on common value properties. The accepted values for the Calendar include the selected date or time that the user clicks on. This can either be a date, number, or sequence of characters. The Date option will accept the date directly. The number option will accept the date using a timestamp. The string option will accept the date as a sequence of characters provided they are in the correct format: \"yyyy-MM-dd\" (for example, \"2017-03-06\") \"yyyy-MM-ddTHH:mm:ss\" (for example, \"2017-03-27T16:54:48\") \"yyyy-MM-ddTHH:mm:ssZ\" (for example, \"2017-03-27T13:55:41Z\") \"yyyy-MM-ddTHH:mm:ssx\" (for example, \"2017-03-27T16:54:10+03\") Disabled Dates Data Source Common Properties If set to the Dynamic Data Source option, additional options include filtering, sorting, showing a number of results, and skipping a number of results. See the Common Properties article for more details on common Data Source properties. Static Items If a Dynamic Data Source is not used, you can enter key dates to display manually under the Data section. Dynamic Data Source This option allows you to connect the control to a specific Data Source such as a database to pull data dynamically. This will give you additional options to sort, filter, show, or skip certain records. Data The data allows you to choose a date based on the connected Data Source. This can be configured when using static items for disabled dates Data Sources. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/checkbox.html": {
    "href": "src/blocks-toolbox/basic/checkbox.html",
    "title": "Check Box | XMPro",
    "summary": "Check Box A Checkbox is a control that allows the user to tick an option. This is useful to use on forms where the user only needs to select something that requires a 'Yes' or 'No' type of option for a particular field. Check Box Properties Appearance Common Properties You can change the visibility and tooltip for a Checkbox which is common to most Blocks; See the Common Properties article for more details on common appearance properties. Label The label is the text that shows next to the Checkbox. Behavior Common Properties The disabled and read-only properties are common to most Blocks; See the Common Properties article for more details on common behavior properties. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. The value dictates whether or not the Checkbox was selected. This can either be true or false. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/color-selector.html": {
    "href": "src/blocks-toolbox/basic/color-selector.html",
    "title": "Color Selector | XMPro",
    "summary": "Color Selector The Color Selector lets the user select from a range of colors using the selector dropdown. Once the user selects the color, the hex value of the color is displayed in the input box. This is a useful tool for the user to select colors visually. Color Selector Properties Appearance Common Properties The Color Selector has properties that are common to most Blocks: visible, styling mode, tooltip, placeholder, and clear buttons; See the Common Properties article for more details on common appearance properties. Behavior Common Properties Common options for the behavior include read-only and disabled. See the Common Properties article for more details on common behavior properties. Apply Value Mode When the use buttons option is selected, the user has to select from the OK or Cancel buttons at the bottom of the color picker. Accept Custom Value If this is enabled, the user will be able to type in or copy and paste their own hex value into the input box. If this is disabled, this will not be possible and the user can only select a color from the dropdown. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. The value determines the starting color for the Color Selector. Only a sequence of characters that are equal to a known hex color will be accepted. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/data-grid.html": {
    "href": "src/blocks-toolbox/basic/data-grid.html",
    "title": "Data Grid | XMPro",
    "summary": "Data Grid A Data Grid allows you to display important information to the user in a grid format. This is useful for displaying all records from a database, or a selected number of records from a database. Data Grid Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Show Borders Will show borders around the grid. Show Headers Will show the headers/column title. Show Column Lines Will show a vertical line between columns. Show Row Lines Will show a horizontal line between rows. Alter Row Color The background color of the odd rows will be grey. Show Column Chooser Column Chooser button will be displayed and the user has the ability to hide/show columns. Enable Paging The default option is to show all the results. The user can specify how many items should be displayed per page and pages will be displayed under the grid. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Allow Selection Allows the user to select an item from the grid. Allow Multiple Selection Allows the user to select multiple items from the grid. Multiple Selection Mode Choose how the select all and deselect all will be applied to the Data Grid: Page - recommended for large datasets (200+ rows). All Pages - recommended for small datasets. Note Note: applies when paging and multiple selection are enabled. Multiple Selection Mode Choose how the select all and deselect all will be applied to the Data Grid: Page - recommended for large datasets (200+ rows). All Pages - recommended for small datasets. Note: applies when paging and multiple selection are enabled. Allow Adding Add button will be displayed and the user can add/insert rows by clicking on it. Allow Deleting The delete button will be displayed on the right side of the row. Allow Updating This will enable editing the row by clicking the item. Allow Search This will let you search the grid with the search bar. Edit Mode Grid data can be edited in several modes. Set the Edit Mode property to specify the mode. Mode Description Batch A user edits data cell by cell. Changes are not updated until a user clicks the Save button. In this mode, the \"Add\" button is found above the grid rather than in the grid's header row, along with the Save and Reset buttons. Batch With External Save A user edits data cell by cell. Changes are not updated until a user clicks an external Block (e.g. a Button) with Update Data Sources corresponding to the grid's data source. Cell A user edits data cell by cell. Changes are saved once a cell loses focus, or discarded if a user presses Esc. Row A user edits data row by row. When a user clicks an \"Edit\" button in the right-most column, the corresponding row enters the editing state, and the \"Save\" and \"Cancel\" buttons appear in the right-most column. Pressing the \"Save\" button will update your data source immediately. Allow Search This will show a search bar at the top of the Data Grid. Allow Export to Excel The export button will be displayed and by clicking it will export the grid into an excel file. Enable Column Filtering This will let you filter the results per column by clicking the filter icon next to the column name. Enable Row Filtering The search bar will be added for each column and the user can search the results. Enable Filter Panel Create Filter button will be displayed and clicking it will open a Filter Builder. If a user changes the filter expression in the Filter Panel the changes are reflected in the Enable Row Filtering and Enable Column Filtering, and vice versa. Default Filter This defines the default filter selected in the Filter Panel. Anyone visiting the page for the first time will have the same filter applied to the Data Grid. For example, every time this Data Grid has loaded records that start with the letter \"C\" are displayed. The filter will still be applied if the filter panel is disabled, which will prevent the user from changing the filter. Allow Grouping Auto-Adjust Column Widths Will try to adjust the width of the column to show results as much as possible. Store User Customization Changes made to the grid are saved in the cookies on your browser between page refresh and window changes. This can include column reordering, resizing and applied filters. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. Data Source Common Properties Properties that are common to most Blocks include: filter, sort, show # of results, and skip # of results; ‌See the Common Properties article for more details on common Data Source properties. The Data Source property is required for the Data Grid. Columns List of all columns from the selected Data Source. Users can reorder or change the visibility, name, type, alignment, width, set it as read-only, and set the Editor type. Format If the Type field is set to Number, you have the option to format the field as default (none), currency, or percentage. Currency If the Format field is set to Currency, choose which currency symbol to display. Date Time Format If the Type field is set to Date or Date Time, you can enter a custom format for the Date or the Date Time. By default, the values are displayed in the user's browser's locale format. Editor Type - Lookup The lookup field will only appear when the cell or the row is in edit mode. The Lookup editor type has three configurable properties. The column's value is automatically mapped to the Text property. For more details about Data Source see the Common Properties article for more details on common data source properties. Display Field is the value of what text will be displayed. Value Field selection from the new Data Source needs to match the value that is in the cell. Editor Type - Hyperlink It will show the value in the field as a Hyperlink. The Hyperlink editor type is based on the Hyperlink block. See the Hyperlink article for more details on how to configure the Hyperlink block. The column's value is automatically mapped to the Text property. Editor Type - Indicator The value in the field has to be a valid color format. The indicator editor type is based on the Indicator block with less configurable options. See the Indicator article for more details on how to configure the Indicator block. The column's value is automatically mapped to the Text property. Open in New Tab/Window Tick for the URL to open in a new tab/window, instead of redirecting the current tab. This applies when the Editor Type is set to 'Hyperlink'. Note We recommend opening XMPro URLs in the same tab/window - as users may experience degraded performance when a large number of XMPro tabs are opened. Column Reordering Reordering columns is possible at runtime and is enabled by default on every Grid. Users can change the order by dragging one column to another position. Column Resizing Resizing columns is possible at runtime and is enabled by default on every Grid. Users can resize the columns by dragging the edge of the column. Action Common Properties Properties that are common to most Blocks include: Navigate to and Show Confirmation Dialog; See the Common Properties article for more details on common action properties. Override Grid Values When saving grid rows to a Data Source, you may want to override some values. For instance, if you want to update a column with the current date and time, or replace a column with a Parameter or Variable. To do this follow these instructions: On the Data Grid, enable the Allow Updating property and set the Edit Mode to Batch With External Save. Then, under the Action accordion in the Block Properties of a Button or other Block, click the button with the gear icon of the corresponding Data Source to the Data Grid. Press the + button to the right of Override Values, select the column to override, and press Add. In the Value column of Override Values, choose a static or dynamic value. Press Apply on the Update Data Source page, and Save the App Page."
  },
  "src/blocks-toolbox/basic/date-selector.html": {
    "href": "src/blocks-toolbox/basic/date-selector.html",
    "title": "Date Selector | XMPro",
    "summary": "Date Selector The Date Selector is an input field that allows users to select a date. When they open the drop-down arrow, the Date Selector shows a calendar format where they can easily and visually see the dates of the year. Date Selector Properties Appearance Common Properties You can change the visibility, styling mode, placeholder, and tooltip. See the Common Properties article for more details on common appearance properties. Adaptive Behavior For some screen sizes, the date picker may not fit across the screen. If enabled, this allows the box to be displayed in a different format, for example, the date box is displayed without the large analog clock and uses a digital clock instead. This is useful for smaller devices such as mobile or IPads. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Type This specified the format of the date. The options are date, time, or date and time. Picker Type This specifies the way the calendar or clock is displayed to the user. Options for this include default, calendar, list, rollers, or native. The native option uses the date format based on the device's local settings, while the default and calendar options follow the browser's display language. List Interval Specifies the intervals between the date or time options on the list. Show Analog Clock Specifies whether or not the analog clock is displayed. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/dropdown-grid.html": {
    "href": "src/blocks-toolbox/basic/dropdown-grid.html",
    "title": "Dropdown Grid | XMPro",
    "summary": "Dropdown Grid A Dropdown Grid is a dropdown that displays a grid of data to the user. The Data Grid can be connected to a Data Source to retrieve and display specific values. This is useful for dynamically creating the dropdown from items that already exist and may change over time. Dropdown Grid Properties Appearance Common Properties You can change the visibility, styling mode, placeholder, tooltip, and the visibility of the clear button; See the Common Properties article for more details on common appearance properties. Grid The visibility of the borders, column lines, row lines, and headers of the grid can be specified. By default, the borders, column lines, row lines, and headers are set to true. Options for the grid include showing or hiding the borders, headers, column lines, or column rows. For details on these common grid properties, see the Data Grid article. Behavior Common Properties The Dropdown Grid behavior includes changing the read-only, disabled. See the Common Properties article for more details on common behavior properties. Allow Paging This specifies whether the content on the grid is separated into pages. Enable Column Filtering Allows the user to filter for a specific column in the list. Enable Row Filtering Allows the user to filter for a specific row in the list. Page Size Specifies the number of records that are displayed to the user for each page. This will only work if allow paging is set to true. Allow Grouping This option gives the user the ability to group records together. Store User Selection When enabled, your selection at runtime is saved in your browser's local data, so that it is remembered when the page reloads. This includes re-opening the App and returning from a drill-down. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. Data Source Common Properties Properties that are common to most Blocks include: filter, sort, show # of results, and skip # of results; See the Common Properties article for more details on common Data Source properties. The Data Source property is required for the Dropdown Grid. Data Display Expression The expression is a user-friendly name for what the user can see. For example, the text that is showing in one of the rows of the dropdown. The Display Expression property is required for the Dropdown Grid. Value Expression This is the actual value stored in the background of the application in the code. For example, instead of true or false, it would be 0 or 1. The Value Expression property is required for the Dropdown Grid. Columns Order The order allows you to specify the format for the columns. This includes the visibility of the columns, the alignment, the captions, or the width. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/embedded-page.html": {
    "href": "src/blocks-toolbox/basic/embedded-page.html",
    "title": "Embedded Page | XMPro",
    "summary": "Embedded Page Embedded Pages allow the user to see a preview of a page for another website. This is useful if you want the user to visually see content from another website without linking to it and without them leaving the application. Embedded Page Properties Appearance Common Properties You can change the visibility of the embedded page, which is common to most blocks; See the Common Properties article for more details on common appearance properties. Behavior Enable Scrollbars When selected, the scroll bars will be visible to the user. Deselecting these will disable the scrollbars. URL This is the URL of the web page to display within the embedded page block. This is the most important property of the Embedded Page block. Usage Notes The embedded page block is used to display an external web page on your app page. This can be used to display relevant instructions or information from external or internal sites without needing to navigate away from the application. Links within the embedded web page will navigate the embedded page itself, not the browser. This means that the user won't have the normal browser methods of going back. Therefore, the embedded page should be carefully selected to contain all of the necessary information and prevent scenarios where your users navigate away and cannot return. Tip When selecting a page to embed, consider whether it contains all the necessary information and whether links within that page might lead users to navigate away from the content they need. Additional Resources For more information on how to use Embedded Pages, you can refer to the following resources: How To Use Embedded Pages - XMPRO App Designer Toolbox (Video)"
  },
  "src/blocks-toolbox/basic/file-library.html": {
    "href": "src/blocks-toolbox/basic/file-library.html",
    "title": "File Library | XMPro",
    "summary": "File Library The File Library Block allows you to upload and store multiple files in your App. Files can be uploaded, downloaded, or deleted. This can be useful if you want to share certain files with users who have access to your App. Searching for files in the File Library To search for files in the File Library Block, enter the file name of the file you would like to search for. The File Library Block will automatically filter the files and show you the search results. File Library Properties Appearance Common Properties You can change the visibility of the File Library, which is common to most blocks; See the Common Properties article for more details on common appearance properties. Behavior Show All Users Files This allows you to toggle between seeing only the files that you have uploaded, or the files that other users that have access to the App have uploaded. Allowed File Extensions This allows you to specify the types of files that are allowed to be uploaded. If left blank, any file type can be uploaded. If a file extension is listed, (for example, a .png file), the File Library Block will not allow you to upload any other file except those with a .png extension. You can add file library extensions in the following way: Max File Size (MB) This determines the maximum file size that can be uploaded. If you attempt to upload a file that exceeds the max size, it will not be uploaded. Allow Delete This specifies if each file can be deleted or not. Each file has a checkbox next to it that allows you to delete the file. When Allow Delete is set to false, the checkboxes next to the files are no longer visible, so files cannot be selected and deleted. Allow Upload This specifies if the upload icon in the top-right of the File Library block is visible or not. If visible, the user can click on the icon to upload files. If not visible, they will be unable to upload files."
  },
  "src/blocks-toolbox/basic/file-uploader.html": {
    "href": "src/blocks-toolbox/basic/file-uploader.html",
    "title": "File Uploader | XMPro",
    "summary": "File Uploader A File uploader is a Block that allows the user to upload files in an application. The File can be uploaded, downloaded, or deleted. This can be useful if you want to share certain files with users who have access to your App. File Uploader Properties Appearance Common Properties Properties that are common to most Blocks include visibility, styling mode, tooltip, and icon; See the Common Properties article for more details on common appearance properties. Label The text that shows up next to the button. Select Button Text The text that shows on top of the Button. Upload Failed Message The text of the message that is shown to the user when a file upload fails. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Allowed File Extensions This allows you to specify the types of files that are allowed to be uploaded. If left blank, any file type can be uploaded. If a file extension is listed, (for example, a .png file), the File Uploader will not allow you to upload any other file except those with a .png extension. You can add file type extensions in the following way: Max File Size (MB) This determines the maximum file size that can be uploaded. If you attempt to upload a file that exceeds the max size, it will not be uploaded. Multiple Upload This allows you to upload multiple files. All selected files are zipped and then uploaded to the application. File Name Prefix This option is available when Multiple Upload is enabled. It allows you to add a prefix to the zip file created by Multiple Upload. Allow Delete This allows the user to delete the uploaded file. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. Validation Common Properties Properties that are common to most Blocks include: groups to validate; See the Common Properties article for more details on common validation properties. Action Common Properties Properties that are common to most Blocks include: navigate to and show confirmation dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/html-editor.html": {
    "href": "src/blocks-toolbox/basic/html-editor.html",
    "title": "Html Editor | XMPro",
    "summary": "Html Editor The HTML Editor allows the user to create notes and style them. Styling includes changing the font, size, font-weight, or heading style of the text. The user can also add bullet points, numbered lists, images, quotes, links to websites, and more. This is useful if you would like the user to have an area where they can write and save notes. HTML Editor Properties Appearance Common Properties You can change the visibility of the HTML Editor; See the Common Properties article for more details on common appearance properties. Toolbar This specifies if the toolbar at the top can be visible. Behavior Common Properties The behavior includes changing the HTML Editor to be read-only or disabled. See the Common Properties article for more details on common behavior properties. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. The HTML Editor accepts any sequence of characters as a value and anything else that is entered such as images. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/image.html": {
    "href": "src/blocks-toolbox/basic/image.html",
    "title": "Image | XMPro",
    "summary": "Image The Image Block allows you to display a specific image to the user. This is useful if you would like to add visuals to the page to style the App, or to present important information to the user in a way that will stand out and attract attention - guiding your visitor's line of sight. Important Strike a balance between style and performance. Keep in mind that the larger the file size and the more images added to a single App Page, the longer the loading time. This effect will be felt during both design (open and save of an App) and run time. When in doubt, use fewer images and aim for a file size of 200kb or less. Image Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Image Source Choose whether the image is stored in App Files (default) or Embedded. The App Files option, added in v4.4.17, is the recommended image source - embedded files bloat the app size and cannot be copied/downloaded/reused. Image You can select the Image you want to be displayed. The following image file types are supported: BMP, GIF, JPEG, PNG, SVG, and WEBP. Behavior The Image block doesn't have specific behavior properties beyond the common ones. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties. Additional Information SVG file types are supported for all image properties, which was added in v4.1.13. This allows for scalable vector graphics that maintain quality at any size. In v4.4.17, a new \"Image Source\" property was added to the Image Block, allowing images to be stored in App Files. This enhancement allows images to be shared across multiple blocks and improves storage and retrieval efficiency. Previously, images could only be embedded within individual blocks."
  },
  "src/blocks-toolbox/basic/index.html": {
    "href": "src/blocks-toolbox/basic/index.html",
    "title": "Basic | XMPro",
    "summary": "Basic Calendar Checkbox Color Selector Data Grid Date Selector Dropdown Grid Embedded Page File Library File Uploader HTML Editor Image Indicator List Lookup Number Selector Radio Buttons Range Selector Select Box Switch Tags Text Area Text Textbox Tree Grid Tree List"
  },
  "src/blocks-toolbox/basic/indicator.html": {
    "href": "src/blocks-toolbox/basic/indicator.html",
    "title": "Indicator | XMPro",
    "summary": "Indicator The Indicator Block shows a point at a particular location on the page and allows you to indicate something important in a specific area. It is useful for attracting the user's attention to a particular point or spot on the page. Indicator Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Text This is the text that is displayed inside the Indicator. Mode The mode indicates the shape of the Indicator. Size This specifies the size of the Indicator. Color This species the color of the Indicator. X-Axis and Y-Axis This specifies where the Indicator is positioned along an X-axis and Y-axis. Label The visibility of the label can be set to never, on hover, or always. The position of the label can be set to either top, bottom, left, or right. The color of the text and the background can be changed. The padding determines how much spacing shows between the text and the edge of the box. The border radius option specifies the outer edge and corners of the block around the label. Action Common Properties Properties that are common to most Blocks include: navigate to and show confirmation dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/list.html": {
    "href": "src/blocks-toolbox/basic/list.html",
    "title": "List | XMPro",
    "summary": "List A List is a UI component that displays a collection of items in the form of a list. The List is scrollable if there are too many items to fit in its container, or it can also be separated into pages. A List can be connected to a Data Source to retrieve and display specific values. Lists can be useful if you want to display a list of items to the user. Tip It is recommended that you read the article listed below to improve your understanding of Data Sources. How to Create and Manage Data Sources List Properties Appearance Common Properties Properties that are common to most Blocks include visible and tooltip; See the Common Properties article for more details on common appearance properties. Enable Paging The default option is to show all the results. The user can specify how many items should be displayed per page and pages will be displayed under the List. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Search Enabled It will add a search bar where the user can search the items in the List. Value Common Properties This option is used to select the default value and must match a value from the Data Source. See the Common Properties article for more details on common value properties. Data Source ‌Data sources can be Static or Dynamic. Static values have to be entered manually while Dynamic will get the value from the provided Data Source. See the Common Properties article for more details on common Data Source properties. The Data Source property is required for the List. Static Items If a Dynamic Data Source is not used, you can enter key dates to display manually under the Data section. Dynamic Data Source This option allows you to connect the control to a specific Data Source such as a database to pull data dynamically. This will give you additional options to sort, filter, show, or skip certain records. Data Display Expression The expression is a user-friendly name for what the user can see. For example, the text that is showing in the List. The Display Expression property is required for the List. Grouping This is only available if the Data Source is Dynamic. Here we have the option to set how the items in the list will be grouped. If Grouping is enabled, the Group By Expression property is required for the List. Action Common Properties Properties that are common to most Blocks include: Navigate to and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/lookup.html": {
    "href": "src/blocks-toolbox/basic/lookup.html",
    "title": "Lookup | XMPro",
    "summary": "Lookup The Lookup is a UI component that allows a user to search for an item in a collection shown in a drop-down menu. This is useful when there are many options or items to select from and it may be hard for the user to find one particular item. This UI control allows the user to navigate to the item faster. Lookup Properties Appearance Common Properties Properties that are common to most Blocks include visible, styling mode, placeholder, tooltip and show clear button; See the Common Properties article for more details on common appearance properties. Styling Mode Placeholder and Show Clear Button Placeholder is the text that will be displayed before a value is selected. Show Clear Button will add a button to clear the selected item. Dropdown Title Title of the Lookup when it's open for selection. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Enable Search It will add a search bar where the user can search the items in the Lookup. Value Common Properties This option is used to select the default value and must match a value from the Data Source. See the Common Properties article for more details on common value properties. Data Source ‌Data sources can be Static or Dynamic. Static values have to be entered manually while Dynamic will get the value from the provided Data Source. The Data Source property is required for the Lookup Block. Static Items If a dynamic data source is not used, you can enter key dates to display manually under the Data section. Dynamic Data Source This option allows you to connect the control to a specific data source such as a database to pull data dynamically. This will give you additional options to sort, filter, show, or skip certain records. See the Common Properties article for more details on common data source properties. Data This is only available if the Data Source is Dynamic. Here we have the option to set the values of the buttons as well as what text will be displayed. ‌ See the Common Properties article for more details on common data properties. Display Expression The expression is a user-friendly name for what the user can see. For example, the text that is displayed to the user. The Display Expression property is required for the Lookup Block. Value Expression This is the actual value stored in the background of the application in the code. For example, instead of true or false, it would be 0 or 1. The Value Expression property is required for the Lookup Block. Grouping This is only available if the Data Source is Dynamic. Here we have the option to set how the items in the Lookup will be grouped. If grouping is enabled, the Group By Expression property is required for the Lookup Block. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/number-selector.html": {
    "href": "src/blocks-toolbox/basic/number-selector.html",
    "title": "Number Selector | XMPro",
    "summary": "Number Selector In scenarios where the user should select a number, the Number Selector is an input field that gives the user the option to do so. When the user enters a value, the field automatically makes sure the value entered is a number. Important Number Selector automatically converts the entered value into a scientific notation if it is greater than 21 digits for an integer value and greater than 6 digits for a decimal value. Number Selector Properties Appearance Common Properties The Number Selector has the option to change its visibility, styling mode, set a placeholder, show tooltips, and show clear button. See the Common Properties article for more details on common appearance properties. An option that is specific to Number Selector is Show Spin Buttons. Style Show Clear Button The clear button will appear on the right side. Clicking the button will remove the value from the control. Show Spin Buttons The up and down buttons will be shown on the right side of the control which the user can use to increase or decrease the current value. Behavior Common Properties The Number Selector has the option to set the option for read-only and disabled. See the Common Properties article for more details on common behavior properties. Options that are specific to Number Selector are min, max, format. Min and Max Affects the minimum and maximum values that Number Selector can accept. Format This will format the value to the format that was specified. In the example below, it will show it as a currency. Read Only and Disabled This affects whether or not the Number Selector value can be changed and if it can only be read and not manipulated. Value The Number Selector accepts numbers only. The value can be static, dynamic, or an expression. See the Common Properties article for more details on common value properties. Validation Common Properties Properties that are common to most Blocks include: validation Group, required, pattern, and message; See the Common Properties article for more details on common validation properties. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/radio-buttons.html": {
    "href": "src/blocks-toolbox/basic/radio-buttons.html",
    "title": "Radio Buttons | XMPro",
    "summary": "Radio Buttons The RadioGroup is a UI component that contains a list of options for users to choose from. This is useful if you only want the user to select a single item out of the options in the list. Radio Buttons Properties Appearance Common Properties The Radio Button has the option to change its visibility. See the Common Properties article for more details on common appearance properties. An option that is specific to Radio Button includes the ability to change its orientation. Orientation The default value is Vertical which means Radio Buttons will be displayed top to bottom. By changing to Horizontal, the Radio Buttons will be displayed left to right. Behavior Common Properties The disabled property is common to most Blocks; ‌See the Common Properties article for more details on common behavior properties. Disable This affects the Radio Buttons group to be shown as read-only. Value Common Properties This option is used to select the default value and must match a value from the Data Source. See the Common Properties article for more details on common value properties. Data Source Common Properties ‌A Data Source can be Static or Dynamic. Static values have to be entered manually while Dynamic will get the value from the provided Data Source. See the Common Properties article for more details on common Data Source properties. The Data Source property is required for Radio Buttons. Static Items If a dynamic Data Source is not used, you can enter key dates to display manually under the Data section. Dynamic Data Source This option allows you to connect the control to a specific Data Source such as a database to pull data dynamically. This will give you additional options to sort, filter, show, or skip certain records. Data Display Expression The expression is a user-friendly name for what the user can see. For example, the text that is displayed to the user. The Display Expression property is required for Radio Buttons. Value Expression This is the actual value stored in the background of the application in the code. For example, instead of true or false, it would be 0 or 1. The Value Expression property is required for Radio Buttons. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/range-selector.html": {
    "href": "src/blocks-toolbox/basic/range-selector.html",
    "title": "Range Slider | XMPro",
    "summary": "Range Slider A Range Slider is an input field that can be used to select a numeric value within a given range. This is useful when there is a limited number of options the user should select from and eases the validation for the user's input. Range Slider Properties Appearance Common Properties The Range Slider has the option to change its visibility and to show tooltips. See the Common Properties article for more details on common appearance properties. Options that are specific to Range Sliders include the ability to change the mode, range, or labels. The appearance of the labels such as the positioning and format of the labels can also be configured. Mode In point mode, only the single point that the user selected will be visible. When in range mode, the Range Slider allows you to specify whether or not to show the range line between the two selected values. Show Range When the show range option is set to true, the range that is selected will be highlighted. Show Labels Show labels will add a value on both sides of the slider so the user will know the numeric range. Label Position This gives you the option to add the labels either above the slider or underneath the slider. Label Format The label format option allows you to choose what type of numeric range the slider is. Some of the options that are available include but are not limited to currency, decimal, fixed point, seconds, minutes, days, or hours. Behavior Common Properties Properties that are common to most Blocks include: read-only and disabled. See the Common Properties article for more details on common behavior properties. Min and Max This affects the minimum and maximum values for where the range starts. Step This affects the intervals that are allowed between the values that can be chosen. For example, if the step interval is set to 50, and the user selects 45, the slider value will automatically be set to 50. Value If the point option is selected as the mode, there will only be one value. However, if the range option is selected as the mode, you can choose a start value or an end value. Point Value This determines what the selected value is when the mode is set to the point option. Range Start and End value This determines the range that is selected from the start value to the end value. This is available when the range option is selected for the mode. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/select-box.html": {
    "href": "src/blocks-toolbox/basic/select-box.html",
    "title": "Select Box | XMPro",
    "summary": "Select Box The Select Box component is an editor that allows a user to select an item from a drop-down list. This is useful when there are many options or items to select from and it may be hard for the user to find one particular item. This UI control allows the user to navigate to the item faster. Select Box Properties Appearance Common Properties A Select Box has the option to change its visibility, styling mode, placeholder, tooltip and show clear button. See the Common Properties article for more details on common appearance properties. Styling Mode Placeholder and Show Clear Button The placeholder is the text that will be displayed before a value is selected. The show clear button will add a button to clear the selected item. Behavior Common Properties The select box has the option to be disabled and read-only. See the Common Properties article for more details on common behavior properties. Enable Search The user can search the items in the select box. Store User Selection When enabled, your selection at runtime is saved in your browser's local data, so that it is remembered when the page reloads. This includes re-opening the App and returning from a drill-down. Value Common Properties This option is used to select the default value and must match a value from the Data Source. See the Common Properties article for more details on common value properties. Data Source Common Properties ‌The Data source can be Static or Dynamic. Static values have to be entered manually while Dynamic will get the value from the provided Data Source. See the Common Properties article for more details on common Data Source properties. The Data Source property is required for the Select Box. Static Items If a Dynamic Data Source is not used, you can enter key dates to display manually under the Data section. Dynamic Data Source This option allows you to connect the control to a specific Data Source such as a database to pull data dynamically. This will give you additional options to sort, filter, show, or skip certain records. Data This is only available if the Data Source is Dynamic. Here we have the option to set the values of the buttons as well as what text will be displayed. ‌ See the Common Properties article for more details on common data properties. Display Expression The expression is a user-friendly name for what the user can see. For example, the text that is displayed to the user. The Display Expression property is required for the Select Box. Value Expression This is the actual value stored in the background of the application in the code. For example, instead of true or false, it would be 0 or 1. The Value Expression property is required for the Select Box. Grouping This is only available if the Data Source is Dynamic. Here we have the option to set how the items in the select box will be grouped. If Grouping is enabled, the Group By Expressions property is required for the Select Box. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/switch.html": {
    "href": "src/blocks-toolbox/basic/switch.html",
    "title": "Switch | XMPro",
    "summary": "Switch The Switch is a UI component that can be in two states: \"On\" and \"Off\". This is useful to show the end-user if something is turned on or running. Switch Properties Appearance Common Properties The switch has the option to change its visibility and show tooltips. See the Common Properties article for more details on common appearance properties. An option that is specific to the Switch is to change the state between ON and OFF. Switch On Text and Switch Off Text The ability to change the Switch state text. Default values are ON and OFF. Behavior Common Properties The Switch can be read-only and disabled. See the Common Properties article for more details on common behavior properties. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/tags.html": {
    "href": "src/blocks-toolbox/basic/tags.html",
    "title": "Tags | XMPro",
    "summary": "Tags Tags can be labels used to group certain contents or topics of the website together. A TagBox is a field that allows the user to select multiple Tags (such as items or categories) from a drop-down menu. Tags Properties Appearance Common Properties Tags have the option to change their visibility, show tooltips, set placeholder, and change the styling. See the Common Properties article for more details on common appearance properties. Options that are specific to Tags are Multiline, Show Clear Button, Show Dropdown Button, Show Selection Controls. Styling Mode Placeholder Tags, unlike some other controls, have default placeholder text. The default value is \"Select\". Show Clear Button The clear button will appear on the right side. Clicking the button will remove all the Tags from the control. Show Dropdown Button Show Selection Controls Multiline Behavior Common Properties Tags have the option to be disabled and read-only. See the Common Properties article for more details on common behavior properties. Options that are specific to Tags are Enable Search and Apply Value Mode. Readonly Disabled Enable Search Will allow the user to type in box and results will be updated. Apply Value Mode The default option is Use Button which will show the OK and Cancel buttons. Instantly it will add the tag when it's selected. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. The value should be an array of strings. For example, if we put the following in the Value field [\"Sydney\", \"New York\", \"London\"] the results will be the following. Data Source Common Properties ‌A Data Source allows Dynamic Source only. The Dynamic Source will get the value from the provided Data Source. See the Common Properties article for more details on common Data Source properties. The Data Source property is required for Tags. Data Display Expression The expression is a user-friendly name for what the user can see. For example, the text that is showing in one of the rows of the dropdown. The Display Expression property is required for Tags. Value Expression This is the actual value stored in the background of the application in the code. For example, instead of true or false, it would be 0 or 1. The Value Expression property is required for Tags. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/text-area.html": {
    "href": "src/blocks-toolbox/basic/text-area.html",
    "title": "Text Area | XMPro",
    "summary": "Text Area A Text Area is an input field that allows the user to input a large amount of text. It is an element of a form that is usually used for comments, descriptions, or any other input that requires multiple sentences to be written. Text Area Properties Appearance Common Properties The Text Area has the option to change its visibility, styling mode, placeholder, and to show tooltips. See the Common Properties article for more details on common appearance properties. Options that are specific to Text Areas include the ability to change the min and max height of the input field. Max and Min Height This specifies the minimum and maximum height and the way in which the Text Area expands. Behavior Common Properties Common options for the behavior include read-only and disabled. See the Common Properties article for more details on common behavior properties. Max Length Max Length specifies how many characters are allowed in the input area. Spellcheck Spellcheck gives you the ability to enable if the text area is checked for spelling errors. Value Common Properties This specifies the starting value of the text area. If left blank, then the starting value of the text area will be empty. The text area can accept any sequence of letters, numbers, or symbols as a value. See the Common Properties article for more details on common value properties. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/text.html": {
    "href": "src/blocks-toolbox/basic/text.html",
    "title": "Text | XMPro",
    "summary": "Text A text is a control that allows you to type any text value or sequence of characters. Text Properties Appearance Common Properties You can change the visibility and tooltip properties for a Text Block; See the Common Properties article for more details on common appearance properties. Style Select the styling option for the text. Text The text displayed on the canvas and at runtime. Behavior The Text block doesn't have specific behavior properties beyond the common ones. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties. Additional Information Tooltip Support As mentioned in the v4.1.13 release notes, a tooltip can be added to the Text Block. This is useful to keep the text short and use a tooltip for longer descriptions. Text Wrapping In v4.1.0, text wrapping was improved for the Text control to better handle long text content."
  },
  "src/blocks-toolbox/basic/textbox.html": {
    "href": "src/blocks-toolbox/basic/textbox.html",
    "title": "Textbox | XMPro",
    "summary": "Textbox A Textbox is an input field that allows the user to input text. It is an element of a form that is usually used for inputs such as a name, or any other input that requires a small amount of text to be written. Textbox Properties Appearance Common Properties You can change the visibility, styling mode, and tooltip, placeholder, and clear buttons for a Textbox. See the Common Properties article for more details on common appearance properties. Show Clear Buttons When selected, an additional cancel button can be seen on the side at the end of the Textbox. Behavior Common Properties Properties that are common to most Blocks include: read-only and disabled. See the Common Properties article for more details on common behavior properties. Mode The mode is the type of text that should be entered. The options to choose from are email, password, search, telephone number, text, or URL. Max Length Max Length specifies how many characters are allowed in the input area. Spellcheck Spellcheck gives you the ability to enable if the text box is checked for spelling errors. Masks A masked text box allows the user to enter a value in a specific pattern. The mask determines the input that needs to be entered, for example, a phone number pattern like +1 (X00) 000-0000. The mask character is the character that will show to mask the part that needs to be entered. The Mask Invalid Message is the message that is displayed when the entered text does not match the specified pattern. Value Common Properties A common property for Textbox is the Value. See the Common Properties article for more details on common value properties. Action Common Properties Properties that are common to most Blocks include: navigate to and show confirmation dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/tree-grid.html": {
    "href": "src/blocks-toolbox/basic/tree-grid.html",
    "title": "Tree Grid | XMPro",
    "summary": "Tree Grid Tree Grid Properties Appearance Common Properties You can change the visibility of the Tree Grid. See the Common Properties article for more details on common appearance properties. See the Data Grid article for details on other common grid appearance properties: Show Borders, Show Headers, Show Column Lines, Show Row Lines, and Enable Paging. Define how the scrollbar behaves: Virtual: Rows are loaded when they get into the viewport and removed once they leave it. Infinite: Each next page is loaded once the scrollbar reaches the end of its scale. Standard: The pager informs the main navigation and scrolling is available only if the rows do not fit. None: There is no scrollbar. Instead, the control grows to fit the number of rows. Behavior Common Properties You can disable the Tree Grid. See the Common Properties article for more details on common behavior properties. See the Data Grid article for details on other common behavior properties: Allow Selection, Allow Deleting, Allow Updating, Allow Search, Enable Column Filtering, Enable Row Filtering, and Auto-Adjust Column Widths. Tip When searching a Tree Grid, the search results include their parents: If your result includes a parent, the children will not be available to expand unless they also meet the search criteria. If your result includes a child, the parents are listed for navigation - even if they don't meet the search criteria. Allow Adding When it's enabled, there are two places where the user can add a new record: an Add button appears at the top of the Tree Grid and in the right-most column. The Add button in the top-right corner adds a new record at the root level of the Tree Grid. The Add option in the right-most column adds a new child record. For example, if you select 'Add' under 'Arthur', a new record is added as a child of the 'Arthur' record. Edit Mode The user can edit the data in several modes. The option is only available when Allow Updating is enabled. Mode Description Batch A user edits data in cells across multiple rows - indicated by a green border. Changes are not applied until the user clicks the Save button. Click Reset to revert the changes. Batch With External Save As with Batch mode, the user edits data in cells across multiple rows - indicated by a green border. However, the user must add a separate block (such as a Button) to apply the changes. Manually configure this button's Update Data Sources section in Block Properties: select a Data Source (such as the Tree Grid's Data Source), and the action(s) to be taken (update, refresh, or delete). Cell A user edits the data cell by cell. Changes are saved once a cell loses focus, or discarded if a user presses Esc. Row The user edits data row by row. When a user clicks the Edit button in the right-most column, the corresponding row becomes editable and Save and Cancel buttons appear in the right-most column. Click the Save button to apply the changes. Allow Drag & Drop When it's enabled, it will show the drag icon by default in front of the row. The user can change the location of the row by clicking the icon and dragging the row. A row can be dragged inside another row to nest it underneath. If this is disabled, reordering is not available. The Drag and Drop option is only available when the Edit mode is set to either 'Row' or 'Cell'. Show Drag Icons When it's enabled, it will show the drag icon in front of the row. The user can reorder the row by clicking the icon and dragging the row. If this is disabled, the user can click anywhere on the row and drag the row. Maximum Tree Depth The limit for the Maximum Tree Depth determines how many levels of nested records the user will be allowed to expand and view. For example, if there is no Maximum Tree Depth limit set, the user will be able to expand and view all nested records. If the Maximum Tree Depth limit is set to 2, the user can only expand records until the second level, and they will no longer be able to expand any further. The Maximum Tree Depth limit also applies to adding and updating rows. The option to add a new row is only available for records within the Max Tree Depth limit specified. Store User Selection When enabled, your selected row is saved at runtime in your browser's local storage, so that you return to the same row when the page reloads without having to re-navigate the tree. This includes re-opening the App and returning from a drill-down. Value Common Properties The value property is common to most Blocks. See the Common Properties article for more details on common value properties. If the value is set to the ID of a record in a Data Source, that record will be selected when the application is launched. Data Source Common Properties Properties that are common to most Blocks include data source, filter, sort, show # of results, and skip # of results. See the Common Properties article for more details on common Data Source properties. The Data Source property is required for the Tree Grid. Data Parent Id The Parent Id tells the component how the fields are connected to each other. The Parent Id refers to the Id of the parent record. For example, in the hierarchy of employees, multiple people could report to one manager, so their parent Ids would be the Id of the person they are listed underneath. If the parent Id of a record is set to null or 0, it will automatically be placed as a root or main parent element on the tree. The Parent Id property is required for the Tree Grid. Columns Common Properties See the Data Grid article for details on common column properties: Format, Currency, Date Time Format, Editor Type - Lookup, Editor Type - Hyperlink, and Editor Type - Indicator, and Open in New Tab/Window. Order The order allows you to specify the format for the columns. This includes the visibility of the columns, the alignment, the captions, or the width. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/basic/tree-list.html": {
    "href": "src/blocks-toolbox/basic/tree-list.html",
    "title": "Tree List | XMPro",
    "summary": "Tree List The Tree List UI component is a tree-like representation of textual data. This component is useful when we want to display something that has a hierarchy. Tree List Properties Appearance Common Properties Properties that are common to most Blocks include visible and tooltip. See the Common Properties article for more details on common appearance properties. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Search Enabled A search bar will be shown on top of the list and the user can search the data. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. When an Id is entered into the value field, it detects it automatically. Data Source Common Properties Properties that are common to most Blocks include: filter, sort, show # of results, and skip # of results; See the Common Properties article for more details on common Data Source properties. The Data Source property is required for the Tree List. Data Display The Display property is required for the Tree List. Id The Id property is required for the Tree List. Parent Id Properties include the Parent Id so the component knows how the fields are connected to each other. The Parent Id refers to the Id of the parent record. For example, in the hierarchy of employees, multiple people could report to one manager, so their parent Ids would be the Id of the person they are listed underneath. If the parent Id of a record is set to null or 0, it will automatically be placed as a root or main parent element on the tree. See the Common Properties article for more details on common data properties. The Parent Id property is required for the Tree List. Action Common Properties Properties that are common to most Blocks include: Navigate To and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/common-properties.html": {
    "href": "src/blocks-toolbox/common-properties.html",
    "title": "Common Properties | XMPro",
    "summary": "Common Properties Appearance This determines how the control looks. For example, this may include colors, text, or the visibility of certain aspects of the control. Visible This determines if the Block can be seen or if it is hidden. Styling Mode This specifies the style of the control, including if it is underlined, highlighted, or outlined. Placeholder This will show a temporary hint or description inside the field to help the user know what information is required. It disappears when the user enters a value. Tooltip This displays extra information about the field when the user hovers their mouse over it. Show Clear Button This determines if a clear button shows next to the value that the user entered. The clear button will clear the entered value if it is clicked. Icon The mode of the icon refers to the different ways the icon can be uploaded or added onto the control. This includes adding a pre-built icon from the library, uploading your own icon, or using the URL of an icon that exists on the web. Format The format refers to the type or way that data is presented. Options for these include currency, decimal, exponential, fixed point, large number, percent, thousands, millions, billions, trillions, milliseconds, seconds, minutes, or hours. Behavior This describes the behavior of a control. For example, read-only or disabled prevents the user from modifying the control. Read Only Disabled Value The value is the value that is taken from the control such as the user input, or the default value of the control that you predefine. Data Source Data Sources can be created for a page in the application and can be used to display contextual or real-time data to the user. Data sources can include databases or data streams and can be bound to controls on the page. Note It is recommended that you read the article listed below to improve your understanding of Data Sources. How to Create and Manage Data Sources Filter This allows you to filter the records to only display certain results that meet a condition. For example, displaying all records last modified in 2021. Sort This allows you to sort records in increasing or decreasing order. Show # of Results Shows a limited number of results. Skip # of Results This will skip a number of records in the list. Show Default Row This will determine if the default row is always shown, only shown when empty, or never shown. Validation Validation involves making sure the user enters the correct information on controls such as a form. Fields or Fieldsets (a group of fields) can be added to the page with a corresponding confirm button for the form. If the button and fields are configured to have validation and the user clicks on the confirm button, the fields in the form will be validated. Field Validation Group The validation group is able to group multiple forms on a page, each with its own action button. For example, if the user clicks on the confirm button for validation group 1, only the fields under that validation group will be validated. Required If the field is blank, the form will not be submitted and an error will show. Pattern If the user enters a value that does not match a specific pattern (for example, the input must contain at least two words), the form will not be submitted and an error will show. Validation patterns use Regular Expressions (regex) to pattern search the value and determine validity. Note For more information on Regular Expressions, see the JavaScript RegExp Reference article on w3schools. Message This is the text that displays to the user when the user did not enter the value correctly. Action Groups to Validate This is an option for buttons that allows you to choose the validation group the button should validate. Action The action refers to any event that may be triggered when the user clicks on a Block or part of a Block. For example, the page may redirect to another page or website, a data source may be updated, or a confirmation dialog may appear. Navigate To This configures the page or website that the webpage will navigate to when the user clicks on a control. The options are: Landing Page takes you to the current App's landing page Page takes you to the specified page of the current App, optionally in a new tab/window Previous Page takes you to the previous page of the browser URL takes you to the specified URL (any website), optionally in a new tab/window Page The page to which the user is redirected, which is applicable when Navigate To is set to 'Page'. See the Navigate Between Pages article for more information about navigating between pages. URL The URL to which the user is redirected, which is applicable when Navigate To is set to 'URL'. Note You can use a mailto link with the URL navigation to open a default mail program (for example, Microsoft Outlook) with an email address already added into the receiver field. See the Navigating Using Back URL article for more information about appending a back URL so that the user can return to the page. Open in New Tab/Window Tick for the URL to open in a new tab/window, instead of redirecting the current tab. This applies when Navigate To is set to 'Page' or 'URL'. Pass Page Parameters You can use parameters if you want to send particular values to another page. For example, you may want to send the value of a control to another page as the user is navigating to it, in order to change the data on that page dynamically. See the Pass Parameters between Pages article for more information about how to pass parameters between pages. Update Page Data You can configure what and how the data should be updated on the current page. See the Page Data article for more information. Update Data Sources Operations include inserting records, updating, deleting, or refreshing a data source. For example, if the user clicks on a button, the details they entered can then be inserted as a record in the database. If multiple operations are required, the order that these actions are executed can be changed. For example, you may want to update the database first before deleting a record. If the execution condition option is set to true, you will then be able to add a condition that will be checked before operations are executed. You also have the option to override the fields that are in the data source. Note If you're enabling an operation on a Block that does not populate or visualize from a Data Source, such as a Button, first bind a Data Source to either the Block or its parent. Confirmation Dialog If the confirmation dialog option is enabled, a confirmation message dialog box will appear when the user clicks on the button. The title and message of the dialog box can be configured as well as the text on the continue and cancel buttons."
  },
  "src/blocks-toolbox/device-input/README.html": {
    "href": "src/blocks-toolbox/device-input/README.html",
    "title": "Device Input Blocks | XMPro",
    "summary": "Device Input Blocks Device Input blocks allow users to interact with your XMPro applications using various device capabilities, such as cameras and location services. These blocks enable the capture of real-world data directly through the user's device. Available Device Input Blocks Location Capture - Captures the user's geographical location using the device's GPS or network-based location services Visual Media Capture - Captures photos or videos using the device's camera Best Practices for Using Device Input Blocks Request permissions appropriately: Device input blocks often require specific permissions from the user (e.g., camera access, location access). Ensure that your application requests these permissions at the appropriate time and provides clear explanations of why they are needed. Handle permission denials gracefully: Users may deny permission for your application to access certain device features. Your application should handle these situations gracefully and provide alternative ways for users to accomplish their tasks. Consider device capabilities: Not all devices have the same capabilities. Some may have multiple cameras, while others may have limited or no location services. Design your application to adapt to the available device capabilities. Optimize for performance: Capturing and processing device input can be resource-intensive. Optimize your application to minimize battery drain and ensure smooth performance. Provide feedback: Give users clear feedback when device input is being captured or processed. This helps users understand what's happening and can improve the overall user experience. Respect privacy: Be transparent about how device input data is used and stored. Only capture the data you need, and ensure that sensitive data is handled securely. Test on multiple devices: Test your application on a variety of devices to ensure that device input blocks work correctly across different hardware and software configurations. Examples Location-Based Asset Tracking Box (Asset Tracking Container) ├── Location Capture │ ├── Button (Capture Location) ├── Field (Asset ID) │ ├── Textbox ├── Field (Asset Name) │ ├── Textbox ├── Field (Asset Type) │ ├── Select Box ├── Field (Notes) │ ├── Text Area ├── Box (Buttons) │ ├── Button (Save) │ ├── Button (Cancel) Field Inspection with Photo Documentation Box (Inspection Container) ├── Field (Inspection ID) │ ├── Textbox ├── Field (Inspector) │ ├── Textbox ├── Field (Date) │ ├── Date Selector ├── Visual Media Capture │ ├── Button (Take Photo) │ ├── Image (Preview) ├── Field (Condition) │ ├── Select Box │ ├── Option (Good) │ ├── Option (Fair) │ ├── Option (Poor) ├── Field (Notes) │ ├── Text Area ├── Box (Buttons) │ ├── Button (Submit) │ ├── Button (Save Draft) Mobile Data Collection Box (Data Collection Container) ├── Location Capture │ ├── Button (Capture Location) │ ├── Map (Location Preview) ├── Visual Media Capture │ ├── Button (Take Photo) │ ├── Image (Preview) ├── Field (Sample ID) │ ├── Textbox ├── Field (Sample Type) │ ├── Select Box ├── Field (Measurements) │ ├── Number Selector ├── Field (Observations) │ ├── Text Area ├── Box (Buttons) │ ├── Button (Submit) │ ├── Button (Save Draft) By effectively using device input blocks, you can create applications that leverage the capabilities of modern devices to capture and process real-world data, enabling a wide range of use cases from field inspections to asset tracking and beyond."
  },
  "src/blocks-toolbox/device-input/index.html": {
    "href": "src/blocks-toolbox/device-input/index.html",
    "title": "Device Input | XMPro",
    "summary": "Device Input Location Capture Visual Media Capture"
  },
  "src/blocks-toolbox/device-input/location-capture.html": {
    "href": "src/blocks-toolbox/device-input/location-capture.html",
    "title": "Location Capture | XMPro",
    "summary": "Location Capture The Location Capture Block allows users to capture their current device location. This is useful when composing Applications such as a mobile inspection app and the user may be required to include the asset location when logging an issue. Location Capture Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Capture Button Text The text displayed on the capture button. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Value Latitude Value The Latitudinal value that is taken from the control such as when the capture button is clicked. Longitude Value The Longitudinal value that is taken from the control such as when the capture button is clicked. Validation Common Properties The Validation Group and Required properties are common to most Blocks; See the Common Properties article for more details on common validation properties. Required Message The text of the error message that is displayed to the user if no location data has been captured. Capture Failed Message The text of the error message that is displayed to the user if the location capture fails for any reason. The reason for the failure is appended to it, e.g. \"User denied the request for Geolocation\"."
  },
  "src/blocks-toolbox/device-input/visual-media-capture.html": {
    "href": "src/blocks-toolbox/device-input/visual-media-capture.html",
    "title": "Visual Media Capture | XMPro",
    "summary": "Visual Media Capture The Visual Media Capture Block enables users to capture a photo or a video or upload an existing media file. This is useful when composing Applications such as a mobile inspection app and the user may be required to include an image when logging an issue. Visual Media Capture Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Capture Button Text The text displayed on the capture button. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Allowed File Extensions This allows you to specify the types of files that can be uploaded. If left blank, any file type can be uploaded. If a file extension is listed, (for example, a .png file), the Visual Media Capture will not allow you to upload any other file except those with a .png extension. Max File Size This setting dictates the maximum allowable file size for uploads. If you attempt to upload a file that exceeds the maximum size, it will not be uploaded. Provider The supported external cloud storage providers are Azure Blob or Amazon S3. Use Variables Tick to use variables for the provider-related properties. Blob Connection String The blob connection string (applies to the Azure Blob Provider only). Blob Container Name The blob container name (applies to the Azure Blob Provider only). Access Key The Amazon S3 access key (applies to the Amazon S3 Provider only). Secret Key The Amazon S3 secret key (applies to the Amazon S3 Provider only). Bucket Name The Amazon S3 bucket name (applies to the Amazon S3 Provider only). Region The Amazon S3 region (applies to the Amazon S3 Provider only). Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. We recommend using a dynamic value property so that when you upload media files, the URLs are bound to the value property, with enclosed brackets and comma-separated. You can utilize a stored proc to save the file URLs into a data source and view them by adding the URL as a hyperlink to a Data Grid. -- Sample code to populate the file URLs to a SQL table CREATE PROCEDURE [dbo].[sp_MobileSpec_Update] ( @MobileId BIGINT, @MediaArray NVARCHAR(MAX), @UploadDate DATETIME2(7), @UploadUser NVARCHAR(150) ) AS BEGIN SET NOCOUNT ON IF (@MediaArray IS NOT NULL AND @MediaArray != '') BEGIN DECLARE @IDs TABLE (ID NVARCHAR(MAX)) -- Use NVARCHAR(MAX) to store URLs -- Populate @IDs table with the result of dbo.SplitString function INSERT INTO @IDs (ID) SELECT Value FROM dbo.SplitString(@MediaArray, ',') -- Iterate over each URL and insert into the table DECLARE @ID NVARCHAR(MAX) DECLARE cur CURSOR FOR SELECT ID FROM @IDs OPEN cur FETCH NEXT FROM cur INTO @ID WHILE @@FETCH_STATUS = 0 BEGIN DECLARE @LastSlashPosition INT = LEN(@ID) - CHARINDEX('/', REVERSE(@ID)) + 1 DECLARE @FileName NVARCHAR(MAX) = SUBSTRING(@ID, @LastSlashPosition + 1, LEN(@ID) - @LastSlashPosition) SET @FileName = SUBSTRING(@FileName, CHARINDEX('/', @FileName) + 1, LEN(@FileName)) -- Process each URL here INSERT INTO [MobileInspectionApp_AppFile] ([MobileInspectionAppId], [AppFileId], [UploadDate], [UploadUser], [URL]) VALUES (@MobileId, @FileName, @UploadDate, @UploadUser, @ID) FETCH NEXT FROM cur INTO @ID END CLOSE cur DEALLOCATE cur UPDATE [MobileInspectionAppTest] SET [AppFileId] = 'Files attached' WHERE [Id] = @MobileId END END Validation Common Properties The Validation Group and Required properties are common to most Blocks; See the Common Properties article for more details on common validation properties. Required Message The text of the error message that is displayed to the user when no media file has been captured or uploaded. Capture Failed Message The text of the error message that is displayed to the user if the media capture fails for any reason."
  },
  "src/blocks-toolbox/index.html": {
    "href": "src/blocks-toolbox/index.html",
    "title": "Blocks Toolbox | XMPro",
    "summary": "Blocks Toolbox Actions Advanced AI Basic Common Properties Device Input Layout Recommendations Visualizations Widgets"
  },
  "src/blocks-toolbox/layout/accordion.html": {
    "href": "src/blocks-toolbox/layout/accordion.html",
    "title": "Accordion | XMPro",
    "summary": "Accordion An Accordion is a group of Accordion Items that shows other Blocks and content within them. An Accordion Item can be expanded or collapsed and is therefore useful for grouping content together. They are also useful for hiding content into collapsed sections when there is a lot of content on the page. Adding a new Accordion Item To add a new Accordion Item, you can either click on an Accordion Item or the Accordion itself and click the plus button in the toolbar. Note See the Canvas article for more details on these controls. Cloning Accordions or Accordion Items You can clone both Accordion Items and the whole Accordion itself. To clone an Accordion Item, select an Accordion Item and click on the clone symbol in the top right-hand Block toolbar. This will create a copy of an existing Accordion Item inside the Accordion. Note See the Canvas article for more details on these controls. When the whole Accordion is cloned, two separate Accordions will be created. It will not create an Accordion inside the existing Accordion. Reordering Accordion Items Accordion Items can be reordered within the Accordion. To reorder an Accordion Item, click and drag the move button in the toolbar to place the Accordion Item somewhere else. Accordion Items cannot be dragged outside of the Accordion itself. However, Accordion Items can be dragged into other Accordions. Note See the Canvas article for more details on these controls. Adding Blocks to an Accordion Item To add Blocks inside the Accordion Items, Drag and drop other Blocks into the Accordion from the canvas toolbar or elsewhere in the canvas. Warning The height and width of the Accordion will be determined by the Blocks contained in it. To guarantee consistent behavior, items inside the Accordion must have a set pixel height and width in the style manager, not a percent or auto. Accordion Item Properties Appearance Common Properties The accordion has properties that are common to most Blocks: visibility and icon; See the Common Properties article for more details on common appearance properties. Title This is the title that shows at the top of the Accordion Item. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Accordion Properties Appearance Common Properties The Accordion has properties that are common to most Blocks: visibility and tooltip. See the Common Properties article for more details on common appearance properties. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Allow Expanding Multiple This determines if it is possible to expand multiple Accordion items at once. Collapsible By default, all Accordion Items can be collapsed except for one which must remain open. If the collapsible option is set to true, the user can collapse all Accordion Items. Selected Index This specifies which Accordion Item is open by default. The starting index is 0, which refers to the first item on the list. Data Source Common Properties The Accordion has properties that are common to most Blocks: filter, sort, show # of results, skip # of results, and show default row. See the Common Properties article for more details on common Data Source properties."
  },
  "src/blocks-toolbox/layout/box-and-data-repeater-box.html": {
    "href": "src/blocks-toolbox/layout/box-and-data-repeater-box.html",
    "title": "Box & Data Repeater Box | XMPro",
    "summary": "Box & Data Repeater Box A Box is a simple Block that allows you to add data or other elements inside it. This can be used as a container to store a group of other Blocks. A Data Repeater Box is a Box that allows you to repeat data multiple times, including data that is coming from a Data Source. If a text field is added to the Data Repeater Box, that text Block can be bound to a field coming from the Data Source. The Data Repeater Box will then repeat the data for that field for each record. Warning Take care with repeated elements that also have a Data Source, such as a Lookup, as their Data Source is fetched for every record returned by the Data Repeater's Data Source. A large result set may result in a timeout. You can use the Show # of Results under the Data Source property to limit the repetition of the blocks. Box Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Data Source Common Properties The Box has properties that are common to most Blocks: filter, sort, show # of results, and skip # of results; See the Common Properties article for more details on common data source properties. Data Repeater Box Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Data Source Common Properties The data repeater box has properties that are common to most Blocks: filter, sort, show # of results, skip # of results, and show default row; See the Common Properties article for more details on common Data Source properties."
  },
  "src/blocks-toolbox/layout/card-and-content-card.html": {
    "href": "src/blocks-toolbox/layout/card-and-content-card.html",
    "title": "Card & Content Card | XMPro",
    "summary": "Card & Content Card A Card is a Block that allows you to configure certain metrics and values. This is useful if you would like to display data to the user in a particular format. The Content Card acts as a container or wrapper around other Block contents that you put inside it. Card Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Data Source Common Properties The Card has properties that are common to most Blocks: filter, sort, show # of results, skip # of results, and show default row; See the Common Properties article for more details on common Data Source properties. Content Card Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Data Source Common Properties The content card has properties that are common to most Blocks: filter, sort, show # of results, skip # of results, and show default row; See the Common Properties article for more details on common Data Source properties."
  },
  "src/blocks-toolbox/layout/field-and-fieldset.html": {
    "href": "src/blocks-toolbox/layout/field-and-fieldset.html",
    "title": "Field & Fieldset | XMPro",
    "summary": "Field & Fieldset A Field is a Block where the user can enter details and is useful for collecting information on a Form. Fieldsets are Blocks that already contain Fields and can be used to group Fields within a larger Form. Fields or groups of Fields can be validated to ensure the user has entered the correct input. Fieldset Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Data Source Common Properties The fieldset has properties that are common to most Blocks: data source, filter, sort, show # of results, skip # of results, and show default row; See the Common Properties article for more details on common Data Source properties. Field Label Properties Appearance Common Properties The tooltip property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Label The text of the field label can be specified."
  },
  "src/blocks-toolbox/layout/horizontal-and-vertical-stacked-layouts.html": {
    "href": "src/blocks-toolbox/layout/horizontal-and-vertical-stacked-layouts.html",
    "title": "Stacked Layout Horizontal & Vertical | XMPro",
    "summary": "Stacked Layout Horizontal & Vertical Horizontal Stacked Layouts separate a given area into columns. Vertical Stacked Layouts separate a given layout into rows. Columns or rows can be added or reduced to change the layout. This Block can be useful if the position of the page contents needs to be displayed right-to-left or top-to-bottom. Add a Box to the Horizontal Layout To add a horizontal pane, select a pane and click on the plus symbol in the top-right Block toolbar. Note See the Canvas article for more details on these controls. Delete a Box in the Horizontal Layout To delete a horizontal pane, select a pane and click on the delete 'bin' symbol in the top-right block toolbar. Note See the Canvas article for more details on these controls. Add a Box to the Vertical Layout To add a Box to a Vertical Layout, select a pane and click on the plus symbol in the top-right block toolbar. Note See the Canvas article for more details on these controls. Delete a Box in the Vertical Layout To delete a vertical pane, select a pane and click on the delete 'bin' symbol in the top-right block toolbar. Note See the Canvas article for more details on these controls. Horizontal and Vertical Layout Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Data Source Common Properties The Vertical and Horizontal Layouts have properties that are common to most Blocks: filter, sort, show # of results, skip # of results, and show default row; See the Common Properties article for more details on common Data Source properties."
  },
  "src/blocks-toolbox/layout/index.html": {
    "href": "src/blocks-toolbox/layout/index.html",
    "title": "Layout | XMPro",
    "summary": "Layout Accordion Box and Data Repeater Box Card and Content Card Field and Fieldset Horizontal and Vertical Stacked Layouts Layout Grid Menu Scroll Box Tabs Templated List Toolbar"
  },
  "src/blocks-toolbox/layout/layout-grid.html": {
    "href": "src/blocks-toolbox/layout/layout-grid.html",
    "title": "Layout Grid | XMPro",
    "summary": "Layout Grid A Layout Grid is a Block that separates a given area into a grid. Columns and rows can be added or reduced to change the size of the grid. This Block can be useful if the style and position of the page contents need to be displayed in a grid-like format. Adding a new Row To add a new row, select the cell and click on the up symbol in the top-right hand block toolbar. This will then select the parent of the cell, which is the row. Then, click on the plus button in the toolbar. Note See the Canvas article for more details on these controls. Adding a new Column To add a new column, select any cell and click on the plus button in the top-right hand block toolbar. Note See the Canvas article for more details on these controls. Deleting a Row To delete a row, highlight a cell, click on the up symbol in the top-right hand block toolbar to take you to the parent row. Go back to the top-right hand toolbar and click on the delete bin symbol. Note See the Canvas article for more details on these controls. Deleting a Column To delete a column, highlight a cell, go to the top-right hand toolbar and click on the delete bin symbol. Note See the Canvas article for more details on these controls. Row & Cell Properties Appearance Ratio You can specify the ratio of each column or row of the layout grid. This determines how much space that column takes relative to the other columns. To change the ratio of a column, select the cell, and go to block properties. To change the ratio of a row, select a cell, click on the up icon in the top-right block toolbar, then go to block properties. For example, the following images show the changes made to the ratio of the first column. Here, the first column has a ratio of 3. Here, the first column has a ratio of 5."
  },
  "src/blocks-toolbox/layout/menu.html": {
    "href": "src/blocks-toolbox/layout/menu.html",
    "title": "Menu | XMPro",
    "summary": "Menu A Menu is a list of options, commands, or pages presented to the user that they can select. This can be used for navigation purposes, such as separating the app or page into sections that the user can be directed to. Adding Menu Items Once a Menu Block has been added to the screen, menu items can be added by using the Items property under Behavior in Block Properties. A separate area will open that will allow you to add items to your Menu. Here you can specify the text that will display on the link, and the page the app will navigate to when the user clicks on the link. To edit an item, click the item on the grid, and edit mode will be enabled. Menu items can be reordered and moved inside to create a submenu by clicking the left icon and dragging it into position. Menu Properties Appearance Common Properties The menu has properties that are common to most Blocks: visibility and tooltips, See the Common Properties article for more details on common appearance properties. Options that are specific to the Menu include collapse when space is limited, orientation, and submenu direction. Collapse When Space is Limited If the width of the menu is longer than the screen, it will collapse. Applies only if the orientation is \"horizontal\". Orientation Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Items The Items section is used to configure the menu items. If Menu is left unconfigured, by default it will display all the pages of the app. Hide Submenu on Mouse Leave Hide submenu on mouse leave is when we have a submenu and if this option is enabled it will collapse the menu, otherwise, a click is required to close the menu."
  },
  "src/blocks-toolbox/layout/scroll-box.html": {
    "href": "src/blocks-toolbox/layout/scroll-box.html",
    "title": "Scroll Box | XMPro",
    "summary": "Scroll Box The Scroll Box is a box that will create scrollbars if the content is larger than the box. In order for the scrollbar to work properly, the containing element must not have a display value of flex. This is useful if you have lots of content that cannot fit in one area of the webpage, but you would still like the user to view all the content. Scroll Box Properties Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Direction This determines the direction of the scrollbar. The scrollbar can be horizontal, vertical, or both. Swipe to Scroll This setting enables the scrollbar when it is swiped with the finger, for example, on a touch screen device such as a phone or IPad."
  },
  "src/blocks-toolbox/layout/tabs.html": {
    "href": "src/blocks-toolbox/layout/tabs.html",
    "title": "Tabs | XMPro",
    "summary": "Tabs Tabs are Blocks that allow you to separate and view related items together. Tabs can be added or removed to the tab Block if needed. They are useful for creating sections that the user can switch between or grouping related groups into one area of the page. Adding a Tab To add a new Tab, select the whole tab Block or an individual Tab and click on the plus symbol in the top-right hand Block toolbar. Note See the Canvas article for more details on these controls. Deleting a Tab To delete a Tab, select the whole Tab Block or an individual Tab and click on the bin symbol in the top-right hand Block toolbar. Note See the Canvas article for more details on these controls. Navigating Between Tabs You can navigate between the Tabs within the canvas itself. Click on each Tab to open the contents within that particular Tab. Reordering Tabs Tabs can be reordered by clicking and dragging them to change the order. When a Tab is highlighted, hold the move icon and drag the Tab to another location within the Block. Note See the Canvas article for more details on these controls. Tab Properties Appearance Common Properties Tabs have properties that are common to most Blocks: visibility and tooltip. See the Common Properties article for more details on common appearance properties. Selected Index The selected index determines which tab is open by default. The index starts from 0, which means that an index of 0 refers to the first Tab, an index of 1 refers to the second Tab, and so on. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Hide Tab Navigation When enabled, a hidden icon appears to the left of the tab icon and name on the Canvas. The user will see the selected tab's content at runtime, but they cannot see the tabs or click on another tab. The navigation between tabs is controlled by the Selected Index property, e.g. by an expression. Note This is useful when a header or footer section is reused across multiple pages. For example, one page is used in three different drill-down scenarios. The top one-third differs based on the drill-down type and the bottom two-thirds is the same for all scenarios. Rather than cloning the page and maintaining all three, place the top one-third in a Tab Block - and set the Selected Index to a parameter passed from the previous page to control which tab's content is shown. Data Source Common Properties Tabs have properties that are common to most Blocks: filter, sort, show # of results, and skip # of results; See the Common Properties article for more details on common Data Source properties. Tab Item Properties Appearance Title and Icon Each Tab has a heading that labels that particular tab section. An icon can also be added for visual purposes."
  },
  "src/blocks-toolbox/layout/templated-list.html": {
    "href": "src/blocks-toolbox/layout/templated-list.html",
    "title": "Templated List | XMPro",
    "summary": "Templated List Templated Lists allow you to display a list of data to the users. This is useful for displaying information from a Data Source such as a database. It is also useful to group information so the user can see a list of items underneath their corresponding categories and expand and collapse them as needed. How to Add items to a Templated List Columns of data can be added to a Templated List on the canvas. To add an item, select one of the fields and click on the plus symbol to add a new field next to it. Fields can also be cloned by clicking on the clone button from the same top-right hand toolbar. Note See the Canvas article for more details on these controls. To bind a column to a particular field from the Data Source, highlight the text in one of the columns and modify the text property under Appearance in Block Properties How to Delete Templated List items To delete an item in the templated list, highlight one of the boxes and click on the delete button in the toolbar. Note See the Canvas article for more details on these controls. Templated List Properties Appearance Common Properties The templated list has properties that are common to most Blocks: visibility and tooltip. See the Common Properties article for more details on common appearance properties. Enable Paging When paging is enabled, the items in the list will be grouped into pages. Page Size You can specify the number of items that display on the page at any given time. Scrolling Mode If enable paging is off, only virtual, infinite and none scrolling mode options will be available. If enable paging is on, only the standard and none scrolling mode options will be available. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Search Enabled The search enabled option shows a search bar at the top of the list. This lets the user search for a particular record. Data Source Common Properties If you bind a data source to the templated list, the text labels for each column will need to bind to the columns coming from the data source. Once this is configured, data from the database will display in the list. The templated list has properties that are common to most Blocks: filter, sort, show # of results, and skip # of results; See the Common Properties article for more details on common Data Source properties. The Data Source property is required for Templated Lists. Grouping Enable Grouping You can choose to group the items on the list by the columns. In the designer mode, when the enable grouping option is selected, a new group field will appear which will act as the area where the grouping headings will be displayed. If Grouping is Enabled, the Group By Expression property is required for Templated Lists. This will categorize related records together, which can be expanded and viewed when the application is launched. Allow Collapsing and Expand by Default Allow collapsing lets the user collapse the contents of the group so they are temporarily hidden. If this is set to false, the user will be unable to collapse the grouped content. Expand by default determines if the list items are collapsed or expanded by default. Action Common Properties The templated list has properties that are common to most Blocks: navigate to, update data sources, and show confirmation dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/layout/toolbar.html": {
    "href": "src/blocks-toolbox/layout/toolbar.html",
    "title": "Toolbar | XMPro",
    "summary": "Toolbar The Toolbar is a UI component that can contain items that are used to manage screen content. Those items can be plain text or other blocks such as images and are useful for showing options to the user in a more visual form than a regular menu. Toolbar Properties Appearance Common Properties Toolbars have properties that are common to most Blocks: visibility and tooltip. See the Common Properties article for more details on common appearance properties. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Toolbar Item Properties Adding Toolbar Items The Toolbar Block has 3 areas, before, center, and after. Adding new items can be done in two ways. The first one is to add it by clicking the plus sign when you have either the toolbar or toolbar item selected. This will create a new item with default settings. Note See the Canvas article for more details on these controls. If you have the toolbar selected and add a new item it will be added to the before section which is the first one from the left. If you have the toolbar item selected and click the plus sign, the new item will be added to the same section as the selected item. Items can be moved by dragging and dropping them to the desired section. You can also add items by clicking the copy button when one of the items is selected. This will create a new item with the exact same settings as the selected item. Appearance Common Properties You can change the visibility, styling, add a tooltip and change the icon. See the Common Properties article for more details on common appearance properties. Text Tooltip items can have text next to the icon. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Locate in overflow menu Auto - It will try to fit items as long as they are fully visible. Always - It will hide the item even if there is enough space to show it. Never - It will show the items at all times. Some items may overlap.\\ Validation Common Properties The groups to validate property is common to most Blocks; See the Common Properties article for more details on common validation properties. Action Common Properties The toolbar has properties that are common to most Blocks: navigate to and show confirmation dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/recommendations/alert-action.html": {
    "href": "src/blocks-toolbox/recommendations/alert-action.html",
    "title": "Alert Action | XMPro",
    "summary": "Alert Action Configure a button to perform one of the following actions on an open Recommendation Alert: Mark As Resolved Mark As False Positive Save Share Assign The button text - and in some cases the icon - are defaulted when the action property is selected, but the designer can override these properties. The action button will be disabled at run-time should the alert be archived. Fig 1: Alert Action Alert Action Properties Appearance Common Properties Properties that are common to most Blocks include visible, styling mode, tooltip, and icon; See the Common Properties article for more details on common appearance properties. Type The type of the button can be changed depending on its purpose. Options include danger, normal, success, and default. Text The text that shows on top of the Button. Behavior Common Properties Properties that are common to most Blocks include disabled; See the Common Properties article for more details on common behavior properties. Alert ID Supply an Alert Identifier on which the selected action will be performed. Action The action to be performed on the alert. Action Description Mark as Resolved Someone reviewed the issue, took mitigation steps, and considered the matter resolved. Mark as False Positive Someone reviewed the issue, determined that the asset doesn't have an issue or it was triggered while in Maintenance/Service mode, and considered the matter closed. Save Saves the changes made on the Recommendation Alert. Share Ability to share the Recommendation Alert to users that have run access to the Recommendation. Selected users will receive an email with the note and a link to the Recommendation Alert. Assign Ability to Assign (or Reassign) responsibility for the Recommendation Alert to a user that has run access to the Recommendation. The default selection is the logged-in user. When this action is performed, the action is recorded on the Timeline and in the Discussion - thus notifying the assignee. Enable Focus This determines if the user can navigate to the Button by using the keyboard. This includes using the tab button to switch between text boxes on a form, and then clicking the tab button at the end to highlight and select the Button. Buttons will also be focused on when you click on them. If a Button is clicked, and no action occurs, the Button will also remain in focus. Action Configure actions to be triggered when the user clicks the button. For detailed instructions see the Common Properties article for more details"
  },
  "src/blocks-toolbox/recommendations/alert-event-data.html": {
    "href": "src/blocks-toolbox/recommendations/alert-event-data.html",
    "title": "Alert Event Data | XMPro",
    "summary": "Alert Event Data The conditions that gave rise to the alert, i.e. the data received by the Data Stream. If \"Log Data On All Occurrences\" is checked in the Rule, this data will be updated as new data is received. Fig 1: Event Data for an Alert Alert Event Data Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Title Optional text that shows at the top of the block and defaults to \"Event Data\". Behavior Alert ID Supply an Alert Identifier and its Event Data is displayed when the Page is opened. Allow Export to Excel This determines if the user can export the grid as an Excel file."
  },
  "src/blocks-toolbox/recommendations/alert-form.html": {
    "href": "src/blocks-toolbox/recommendations/alert-form.html",
    "title": "Alert Form | XMPro",
    "summary": "Alert Form The Alert Form is a place where relevant information can be entered. It is only available if the Recommendation has a Form configured. Fig 1: Form functionality for an Alert Alert Form Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Behavior Alert ID Supply an Alert Identifier and the Form associated with its Recommendation Rule is displayed when the Page is opened, with the given Alert's values."
  },
  "src/blocks-toolbox/recommendations/alert-list.html": {
    "href": "src/blocks-toolbox/recommendations/alert-list.html",
    "title": "Alert List | XMPro",
    "summary": "Alert List The Alert List will show a list of all the Alerts for the selected Recommendations. Alert List Properties Behavior Recommendations This will display a list of Alerts for Recommendations. Before launching the App, you can select which Recommendations to show the Alerts for. Fig 1: Alert List Recommendations Type The identifier filter options are Asset, Process, KPI, and Entity. ID The Identifier used to filter the Recommendation Alerts. Fig 2: Alert List ID"
  },
  "src/blocks-toolbox/recommendations/alert-survey.html": {
    "href": "src/blocks-toolbox/recommendations/alert-survey.html",
    "title": "Alert Survey | XMPro",
    "summary": "Alert Survey The Alert Survey allows the user to provide feedback on whether the triggered Recommendation Alert was helpful or not in preventing unplanned downtime. Fig 1: Alert Survey Alert Survey Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Behavior Alert ID Supply an Alert Identifier and its survey is displayed when the Page is opened."
  },
  "src/blocks-toolbox/recommendations/alert-timeline.html": {
    "href": "src/blocks-toolbox/recommendations/alert-timeline.html",
    "title": "Alert Timeline | XMPro",
    "summary": "Alert Timeline A list of the activities that have occurred on an Alert. If this list includes a hyperlink for an escalated alert, configuration properties allow the designer to determine the behavior of that hyperlink. Perhaps the design is for all alerts to be shown using the same Page, or use a formula to show archived alerts on a different Page in the same or a different App (use the URL option to accomplish this). Fig 1: Alert Timeline Alert Timeline Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Title Optional text that shows at the top of the block and defaults to \"Alert Timeline\". Behavior Alert ID Supply an Alert Identifier and its timeline is displayed when the Page is opened. Navigate To This configures the page or website that the webpage will navigate to when the user clicks on a linked alert's hyperlink: Page takes you to the specified page of the current App, optionally in a new tab/window URL takes you to the specified URL (any website), optionally in a new tab/window Page The page to which the user is redirected, which is applicable when Navigate To is set to 'Page'. Fig 2: Navigate To and Page properties See the Navigate Between Pages article for more information about navigating between pages. URL The URL to which the user is redirected, which is applicable when Navigate To is set to 'URL'. Fig 3: Navigate To, URL, Open in New Tab/Window, and Alert Paramater Name properties Open in New Tab/Window Tick to open in a new tab/window, instead of redirecting the current tab. Alert Parameter Name Supply the parameter name of the Page/URL that will be used to navigate to the escalated alert. It is used to append the escalated Alert Identifier."
  },
  "src/blocks-toolbox/recommendations/alert-triage.html": {
    "href": "src/blocks-toolbox/recommendations/alert-triage.html",
    "title": "Alert Triage | XMPro",
    "summary": "Alert Triage The Alert Triage is an area that provides useful information on suggested actions to resolve the Alert, and links to relevant resources. It is only available if the Recommendation Rule has Triage Instructions enabled. Fig 1: Triage data for an Alert Alert Triage Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Title Optional text that shows at the top of the block and defaults to \"Triage Instructions\". Behavior Alert ID Supply an Alert Identifier and the the Triage Instructions associated with its Recommendation Rule are displayed when the Page is opened."
  },
  "src/blocks-toolbox/recommendations/index.html": {
    "href": "src/blocks-toolbox/recommendations/index.html",
    "title": "Recommendations | XMPro",
    "summary": "Recommendations Alert Action Alert Analytics Alert Discussion Alert Event Data Alert Form Alert List Alert Timeline Alert Triage Alert Survey Recommendation Chart"
  },
  "src/blocks-toolbox/recommendations/recommendation-alert-discussion.html": {
    "href": "src/blocks-toolbox/recommendations/recommendation-alert-discussion.html",
    "title": "Alert Discussion | XMPro",
    "summary": "Alert Discussion The Alert Discussion is an area in which messages can be posted to collaborate with members of your team about an Alert. Messages can be sent or read by anyone who has access to the Recommendation Alert. Messages are displayed with the latest message at the bottom of the list. Any messages which have not been read since the last time you visited the page will be below the \"Last Read\" line break. You can search for messages that contain a certain word or phrase by typing in the search bar at the top. You can add a message by typing in the editor at the bottom of the discussion section and clicking the button with a paper plane icon at the bottom right corner. Advanced text editing can be opened by clicking the button with an underlined letter A icon at the bottom left corner. You can mention another user by typing the @ symbol or clicking the button with the @ symbol, which will pop up a list of users. Clicking on a user will mention them in the message and send them a notification email when the message is sent. Fig 1: Discussion functionality. Summary Although each discussion is specific to a particular Recommendation Alert, you have the option to include a summary at the top for easy navigation to all alert discussions related to a specific Identifier. Alert discussions most recently contributed to will appear at the top. At runtime, you can sort by a different column, add a filter, or use the column chooser to change the columns displayed. The discussions on archived alerts are hidden by default. Tick Show Archived to see all alert discussions, for this entity, to which you have access. *Fig 2: Summary navigation.* Alert Discussion Properties Behavior Type The Identifier options are Asset, Process, KPI, Work Order, Work Request, Entity, and None (default). ID Supply an Identifier to show a filtered summary grid of Alerts that match the given Identifier. It is required when Type is not None. Alert ID The Alert ID is optional. Supply a value to default the alert discussion displayed when the Page is opened. Note If an ID is provided without an Alert ID, the bottom of the block will be empty when the Page is opened. In this case, the user should select a Recommendation Alert from the grid to see its alert discussion. Action Configure actions to be triggered when the user clicks the Alert ID of a row in the summary grid. For example, enable the user to navigate to the alert page. For detailed instructions see the Common Properties article for more details"
  },
  "src/blocks-toolbox/recommendations/recommendation-analytics.html": {
    "href": "src/blocks-toolbox/recommendations/recommendation-analytics.html",
    "title": "Alert Analytics | XMPro",
    "summary": "Alert Analytics Alert Analytics is an area in which the number of Alerts for an Identifier over a period of time can be compared - with an optional alert ranking filter. The Identifiers of an Alert is defined in the Run Recommendation Agent of the Recommendation's Data Stream. The Entity Identifier is mandatory, whereas the Asset, KPI, and Process Identifiers are optional. The analytics section compares the currently viewed period of alerts with the previous period and displays the difference as a percentage. The statistics compared are: The number of Alerts generated The number of Alerts that were auto escalated The number of Alerts marked as false positive The number of Alerts resolved. Below the breakdown, there is a stacked bar chart of the number of Alerts for the Identifier over time. Below that is a horizontal bar of the number of Alerts for the Identifier in the selected period, separated by Rule. Fig 1: The recommendation analytics for Entity ID 1 over the last 30 days and for all alert rankings. Alert Analytics Properties Behavior Type The identifier options are Asset, Process, KPI, and Entity. ID The Identifier used to filter and show analytics on all Recommendation Alerts."
  },
  "src/blocks-toolbox/recommendations/recommendation-chart.html": {
    "href": "src/blocks-toolbox/recommendations/recommendation-chart.html",
    "title": "Recommendation Chart | XMPro",
    "summary": "Recommendation Chart The Recommendation Chart shows the number and severity of unresolved Alerts for the selected Recommendations. Recommendation Chart Properties Behavior Recommendations This will display the number and severity of unresolved Alerts for the selected Recommendations. Before launching the App, you can select which Recommendations to display the data for. Fig 1: Recommendation Chart showing unresolved alerts"
  },
  "src/blocks-toolbox/visualizations/README.html": {
    "href": "src/blocks-toolbox/visualizations/README.html",
    "title": "Visualizations | XMPro",
    "summary": "Visualizations Visualization blocks in XMPro App Designer provide powerful tools for displaying data in visual formats. These blocks enable you to create charts, maps, gauges, and other visual representations that help users understand complex data at a glance. Available Visualizations Autodesk Forge - 3D model viewer powered by Autodesk Forge Autodesk Forge (Legacy) - Legacy version of Autodesk Forge visualization Azure Digital Twin Hierarchy - Hierarchical view of Azure Digital Twins Bar Gauge - Visual representation of a value within a range using a bar Chart - Versatile charting component for various chart types Circular Gauge - Visual representation of a value within a range using a circular gauge D3 Visualization - Custom visualizations using D3.js Esri Map - Geographic mapping using Esri ArcGIS Image Map - Interactive image with clickable regions Linear Gauge - Visual representation of a value within a range using a linear gauge Map - Geographic mapping component Pie Chart - Circular chart divided into sectors Pivot Grid - Interactive pivot table for data analysis Polar Chart - Circular chart with values plotted against angle and radius Power BI - Embedded Power BI reports and dashboards Sparkline - Small, word-sized chart Time Series Analysis - Specialized chart for time series data Tree Map - Hierarchical data visualization using nested rectangles Unity - 3D visualization using Unity Unity (Legacy) - Legacy version of Unity visualization Best Practices for Using Visualizations Choose the right visualization: Select the appropriate visualization type based on the data you want to display and the insights you want to convey. Keep it simple: Avoid cluttering visualizations with unnecessary elements. Focus on the key data points and insights. Use consistent styling: Maintain consistent colors, fonts, and styles across your visualizations for a cohesive user experience. Provide context: Include titles, labels, and legends to help users understand what they're looking at. Enable interactivity: Where appropriate, enable interactive features such as tooltips, zooming, and filtering. Optimize for performance: Be mindful of the amount of data you're visualizing, especially for real-time or large datasets. Ensure accessibility: Make sure your visualizations are accessible to all users, including those with visual impairments. By effectively using visualization blocks, you can create powerful dashboards and reports that help users gain insights from complex data and support decision-making across a wide range of business scenarios."
  },
  "src/blocks-toolbox/visualizations/autodesk-forge-1.html": {
    "href": "src/blocks-toolbox/visualizations/autodesk-forge-1.html",
    "title": "Live Feed | XMPro",
    "summary": "Live Feed The Live Feed Block is a dynamic visualization block that allows users to incorporate their own IP Live Feed camera into an application. This block provides real-time visual insights directly within the app interface. By integrating a live feed, users can monitor events as they unfold in real-time. When used in conjunction with other blocks within App Designer, it allows users to not only view real-time events but also to monitor and visualize key statistics related to the area under surveillance. This combination of live visuals and data-driven insights provides a comprehensive overview of the situation, enabling users to respond more effectively to changing conditions. Note The controls at runtime will depend on the camera software used. Live Feed Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Behavior Live Feed URL Enter the URL of the IP live camera. The contents of the feed will load automatically from this URL. Note The live feed will be streamed on the canvas once the URL has been provided. Enable Scrollbars The live video feed is confined by the block's dimensions on the canvas. Enabling the \"Enable Scrollbars\" option removes these limitations, displaying the video feed at its original size. If the native size exceeds the block dimensions, users can use scroll bars to help navigate."
  },
  "src/blocks-toolbox/visualizations/autodesk-forge.html": {
    "href": "src/blocks-toolbox/visualizations/autodesk-forge.html",
    "title": "Autodesk Forge | XMPro",
    "summary": "Autodesk Forge Note This Block has been deprecated and will be removed in a future version. Please update your Apps by implementing the Metablock as shown in the example provided. The Autodesk Forge Block integrates Autodesk Forge into the page. Autodesk Forge is a platform that offers APIs that allow you to access engineering data and designs from the cloud. Some APIs allow you to embed 2D or 3D views of your design into a webpage. The Autodesk Construction Cloud platform (ACC) is another feature that allows the user to construct new engineering designs using web apps. For more details, visit the official Autodesk Forge website. Autodesk Forge Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Settings Warning The user must have an account on AutoDesk Forge to be able to use this section. Use Variables This allows you to choose between manually entering a value for the Client ID and Client Secret or selecting from a static variable. Client ID and Client Secret This is the ID and Client Secret which can be found on the AutoDesk profile. The Client ID and Client Secret properties are required for the Autodesk Forge Block. API Location Currently, there are only two options. US and EMEA which stands for Europe, Middle East, and Africa. Bucket Choose the container to store the model file. Model File This is the Autodesk file that will be rendered in the application. Extension An option to upload a JavaScript file so the user can interact with the model as shown in the model file. Template: class {Class Name} extends Autodesk.Viewing.Extension { load() { //script when extension is loaded return true; } unload() { //script when extension is unloaded return true; } onDataLoaded(data){ //Apply data to Forge Model } onDataChanged(data, changes){ //Respond to live updates on the dataset by updating Forge Model } } Autodesk.Viewing.theExtensionManager.registerExtension('{Extension Name}', {Class Name}); Data Source Common Properties Properties that are common to most Blocks include: filter, sort, show # of results, and skip # of results; See the Common Properties article for more details on common Data Source properties."
  },
  "src/blocks-toolbox/visualizations/azure-digital-twin-hierarchy.html": {
    "href": "src/blocks-toolbox/visualizations/azure-digital-twin-hierarchy.html",
    "title": "Azure Digital Twin Hierarchy | XMPro",
    "summary": "Azure Digital Twin Hierarchy The Azure Digital Twin Hierarchy is an interactive UI component that visualizes a large amount of time-oriented data. It allows the user to compare data at run-time based on asset ID by dropping markers on the chart, as well as panning and zooming, and can show or hide specific assets or parameters via the hierarchy panel. Azure Digital Twin Hierarchy connects directly to Azure through its Azure Digital Twin, Azure Data Explorer, Tenant Id, Client Id, and Client Secret. Azure Digital Twin Hierarchy Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. X Axis Label Format Determines how the date is formatted on the x-axis of the chart and pan & zoom panel. Label Format Image 12-Hour Clock (2 Lines) 12-Hour Clock (1 Line) 24-Hour Clock (2 Lines) 24-Hour Clock (1 Line) Enable Display Grid This determines whether the ellipsis menu contains the Display Grid option, which shows the selected data in a grid. Enable Download as CSV This determines whether the ellipsis menu contains the Download as CSV option, which allows you to download the selected data as a CSV file. Pan & Zoom Mode Decide how the Pan & Zoom panel is displayed: \"Hidden\" removes the panel entirely, \"Compact\" is a single-line component, and \"Full\" displays a Pan & Zoom with secondary panning and zooming for fine-tuning the selection. Pan & Zoom Mode Image Full Compact Hidden Pan & Zoom Color The color of the Pan & Zoom component. Interval Size The default value for the Interval Size slider, which allows you to fine-tune the granularity of the displayed data. The displayed line chart data will be averaged over this interval. Range This determines the starting date for the Pan & Zoom. The end date of the Azure Digital Twin Hierarchy is determined by the time when the block is loaded. The Pan & Zoom range will update automatically with live data. Initial Selection This determines the time interval that is initially selected in the Pan & Zoom component and, correspondingly, the line chart. The selection will always start at the right side of the Pan & Zoom component. Display Avg, Min, Max, and Envelope This determines whether the line chart will display only the average values as a plain line, or the minimum, maximum, and envelope over the selected Interval Size. Show Tooltip On Hover This determines whether a tooltip will appear when the cursor hovers over a line. The tooltip will display the values of the hovered point on the line. Enable Zoom This determines whether you can click and select on the chart to zoom into the selection. Show X Axis This determines whether the x-axis line and labels for the line chart are shown. Show Y Axis This determines whether the y-axis line and labels for the line chart are shown. Default Y Axis Type This determines the default Y Axis type, which can be changed at run-time using the button at the top-left corner of the line chart. The options are: Stacked: the selected parameters are separated into different panes stacked vertically. Shared: the selected parameters share a single pane with a single y-axis from the lowest to highest values in any line. Overlap: the selected parameters share a single pane with multiple y-axes, with the lowest and highest value of each line chart displayed on the axis at the bottom and top. Show Dots This determines whether the points on the lines will display as dots. Interpolation Function This property allows you to define how the lines behave in the line charts. Function Line Monotone X Linear Step Step Before Step After Basis Cardinal Catmull-Rom Palette You can override the default colors by adding custom colors. The colors are used for each parameter in the line chart. If the number of parameters is greater than the number of colors specified, the colors will repeat. Behavior Default Selection It shows the hierarchy tree view and it allows the user to pre-select the assets. Note The Data Source section needs to be filled out and authenticated before selecting. Recommendations The Alerts for selected Recommendations will be displayed at run-time as markers on the chart: the Alert's created time is used as the timestamp and its title as the text. Note Known limitations: The marker title space is limited and the Alert title may be truncated. Some HTML special characters (e.g.<) used in the Alert title will be encoded. Show Alerts For Visible Assets Only Tick to apply the selected Assets as a filter on the Recommendation Alerts. Data Source Use Variables This allows you to choose between manually entering the Endpoints, Tenant Id, Client Id, and Secret, or selecting them from static variables. Azure Data Explorer Endpoint Requires the URL to the Azure Data Explorer site. Azure Digital Twin Endpoint Requires the URL to the Azure Digital Twin models. Tenant Id Requires the Azure Active Directory Tenant Id. Client Id Requires the Azure Application Client Id. Client Secret Requires the Azure Application Client Secret. Database After the above details are verified and authenticated, a Database must be selected. This Azure Data Explorer database will be used to pull the data. Data Mapping The mapping is required so the Azure Digital Twin Hierarchy block knows how to bind the Digital Twin models selection with the Azure Data Explorer data. Note The Data Source section needs to be filled out and authenticated before mapping. Select New Root Select a new default root for the hierarchy. Note The Data Source section needs to be filled out and authenticated before selecting the new root. Auto Refresh This determines whether the Azure Digital Twin Hierarchy will automatically poll data from Azure Data Explorer - or the user must manually refresh the page. Refresh Rate The rate at which the Azure Digital Twin Hierarchy will poll for updated data."
  },
  "src/blocks-toolbox/visualizations/bar-gauge.html": {
    "href": "src/blocks-toolbox/visualizations/bar-gauge.html",
    "title": "Bar Gauge | XMPro",
    "summary": "Bar Gauge This Block allows you to display data in the format of a Bar Gauge. The Bar Gauge includes several circular bars that each indicate a single value. Bar Gauges are useful for displaying and visualizing numeric values within a certain range. Bar Gauge Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Options that are specific to Bar Gauges include the ability to change the title, font color, bar spacing, and the visibility and format of the label. Title This is the text that shows on top of the Bar Gauge. Font Color This changes the color of the text above the Bar Gauge. Bar Spacing This determines how much space there is between each bar. This can only be seen if there are multiple values on the Bar Gauge. Label The visibility of the label can be toggled. To display the data in a different format, the format property can also be changed. Options for this include (but are not limited to) displaying the data as a currency, decimal, fixed point, percent, or time. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Start Range and End Range The start and end range define the boundaries of where the values of the Bar Gauge should start and end. Value Common Properties The value property is common to most Blocks; See the Common Properties article for more details on common value properties. Multiple values can be entered into the Bar Gauge. When multiple values are visible, multiple bars appear."
  },
  "src/blocks-toolbox/visualizations/chart.html": {
    "href": "src/blocks-toolbox/visualizations/chart.html",
    "title": "Chart | XMPro",
    "summary": "Chart The Chart is an interactive UI component that visualizes data from local or remote storage using a great variety of series types, including Line, Spline, Area, Spline Area, Bar, Scatter, Bubble, and Range. The Chart allows multiple panes and axes, as well as panning and zooming, and can show and hide specific series by clicking the label. Chart Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Orientation This determines the direction that the data is presented on the graph. If set to horizontal, the data will be presented from bottom to top. If set to vertical, the data will be presented from left to right. Legend Visibility This determines if the legend can be seen or if it is hidden. Hide Series on Legend Click When the legend is clicked, and the Hide Series On Legend Click option is enabled, the series that is selected will disappear from the graph. Alignment This determines the placement of the legend around the graph. Allow Export The export button will be displayed on top. Clicking the button will export the Chart in a PNG format. Allow Print The print button will be displayed on top. Clicking the button will print the Chart. Show Drilldown When this is enabled, configured Action properties are triggered when the user clicks on the chart. Axes Y-Axis The Y-axis is the left-hand vertical axis or part of the graph. You can have multiple Y-axis on a Chart. A new Y-axis can be added from the Block Properties tab when a Chart is selected. To add a Y-axis, go to the Block Properties tab, expand Axis, and click on the plus symbol above the list of Y-axes. If you have multiple panes with multiple series, the Y-axis will only show on the pane that the series is on. In other words, a Y-axis will only be shown on the panes where it is being used. Type Changing the type will affect the X-Axis. Depending on the type, X-Axis can only accept the selected type. This property is available for both Y and X Axes. Axis Line Color This specifies the color of the line for the axis. This property is available for both X and Y axes. The Y-Axis line color will change the color of the vertical line of the graph and the X-Axis line color will change the color of the horizontal line of the graph. Enable Pan and Zoom The user can zoom in and out for a better view. If it's enabled, on top of the Chart there will a scroll bar which the user can use to move around. This property is only available for the X-Axis. Range Start and End Specify what range the Chart should show by default. If not specified it will show the min and max value of the provided data. If the Chart scroll and zoom are changed, it will override the default values selected. Both X and Y axes ranges can be specified. When the range is specified, the maximum range for the zoom and pan will be the length of the Chart. Display Grid Lines This determines if the grid lines within the Chart are displayed. This property is available for both X and Y axes. Grid Line Color This changes the color of the grid lines within the Chart. This property is available for both X and Y axes. Title Color This changes the color of the title within the Chart. This property is available for both X and Y axes. Display Labels This toggles the visibility of the labels that show on the X-axis. This property is available for both X and Y axes. Label Color The colors of the label that shows along the X-axis can also be changed. Value Margins Enabled If this is set to 'true', margins are added between the start and end values on the graph. For example, on a bar graph, the margin will move the first bar more to the right so the full bar is inside the graph, and all columns will be equal in width. It will also add a margin between the end and the last bar. If this is set to 'false', the first and last bars may not be fully inside the chart, so the middle bars may be larger than the first and last bars. This property is only available on the X-Axis. Tick Positions This determines the placement of the labels along the axis. If the between labels option is selected, the labels appear in between the ticks. If the cross labels option is selected, the labels appear on the ticks. This property is only available on the X-Axis. Tick Interval This specifies how large the intervals are between values on the Y-Axis. This property is only available on the Y-Axis. Position This indicates which side the Y-axis is displayed on. This property is only available on the Y-Axis. Data Source Common Properties The Chart has properties that are common to most Blocks: filter, sort, show # of results, and skip # of results; The Data Source property is required for the Chart. ‌See the Common Properties article for more details on common data source properties. Data/Series We can add or modify the existing series. ‌For details on common data properties, see this article. There are 8 main types of Charts, Line, Spline, Area, Spline Area, Bar, Scatter, Bubble, and Range. Stacked bars are another type of data series. They let you stack bars on top of each other, instead of aligning them next to each other. This is useful when comparing total amounts across each bar group. Full Stacked column also stacks bars together, however, this is usually in the form of a percentage. Full stacked bars are useful if you want to compare data using a whole and part-to-whole relationship. They stack bars on top of each other Panes Panes are sections of the graph that can contain their own series. If there are many series being shown, they can be separated and shown on multiple panes. A single pane can have multiple series. Panes can be modified when creating a series. This can be done by clicking on the 'Edit' button next to 'Panes.' Action In Charts, the action is triggered by clicking on a series. Common Properties The Chart has properties that are common to most Blocks: Navigate to and Show Confirmation Dialog; See the Common Properties article for more details on common action properties. Note Action properties are not triggered unless Show Drilldown under Appearance is enabled."
  },
  "src/blocks-toolbox/visualizations/circular-gauge.html": {
    "href": "src/blocks-toolbox/visualizations/circular-gauge.html",
    "title": "Circular Gauge | XMPro",
    "summary": "Circular Gauge This Block allows you to display data in the format of a Circular Gauge. The Circular Gauge includes a circle to indicate a single value or multiple values. Circular Gauges are useful for displaying and visualizing numeric values within a certain range. Circular Gauge Properties Appearance Common Properties The Circular Gauge has the option to change its visibility. See the Common Properties article for more details on common appearance properties. Options that are specific to Circular Gauges include the ability to change the title, font color, tick interval, and the style of the primary and sub-values. Title This is the text that shows on top of the Circular Gauge. Font Color This changes the color of the text above the Circular Gauge. Tick Interval This determines the distance between ticks on the outer circle of the Circular Gauge. Primary Value Indicator Type This determines the style of the primary indicator showing on the Circular Gauge. This determines the shape of the marker that points to the value on the Circular Gauge. Options include a rectangle needle, triangle needle, two-color needle, range bar, triangle marker, and text cloud. Primary Value Format Text as Percentage This is only available if the indicator type is a text cloud. Enabling this will show the text on the screen as a percentage. Primary Value Indicator Color This determines the color of the indicator. Primary Value Indicator second color This option is only available if the indicator type is a two-color needle. It determines the color of the second needle. Primary Value Indicator offset This determines how far away the needle or marker is when pointing to the value. Sub Value Indicator Type This determines the style of the sub-values showing on the Circular Gauge. The indicator refers to the shape of the marker that points to the value on the gauge. Sub Value Format Text as Percentage This is only available if the indicator type for the sub-value is a text cloud. Enabling this will show the text on the screen as a percentage. Sub Value Indicator Color This determines the color of the sub-values. Sub Value Indicator Second Color This option is only available if the sub-value indicator type is a two-color needle. It determines the color of the second needle. Sub Value Indicator Offset This determines how far away the needle or marker is when pointing to the sub-value. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Start Range and End Range The start and end range define the boundaries of where the values of the Circular Gauge should start and end. Range The range allows you to change the color of different ranges on the gauge. Value You can show but a single value on the Circular Gauge, as well as sub-values."
  },
  "src/blocks-toolbox/visualizations/d3-visualization.html": {
    "href": "src/blocks-toolbox/visualizations/d3-visualization.html",
    "title": "D3 Visualization | XMPro",
    "summary": "D3 Visualization D3 Visualization is a library for producing dynamic, interactive data visualizations in web browsers. The D3 Block allows you to integrate these dynamic visualizations onto a page of your app using certain script files. D3 Visualization Properties Behavior Script Upload the HTML script file that will be rendered in the D3 control, which is used to create data visualization which will allow you to display data from a Data Source. The data on the graphs will update in real-time. For more information on how to create D3 scripts, visit this website. The official D3 website explains how to script these visualizations and transformations. They also have a list of examples and code samples that can be used to create visualizations in different formats, such as sunbursts or graphs. Version 6.1.1 of the D3 library is supported. The template is the base of the script that is used to create the visualizations. Any sample code taken from examples on D3 can be copied into a script template. The Script property is required for the D3 Visualization Block. Note To upload a script, it first needs to be uploaded using the App Files Manager. See the Manage App Files article for more details. Script template: <div id=\"myCanvas\"></div> <script src=\"../../content/scripts/d3.js\"></script> <script> /////////////Add d3 script here to transform #myCanvas///////////// /////////////////////////////////////////////////////////////////// function onDataLoaded(data){ //Apply data to d3 svg canvas } function onDataChanged(data, changes){ //Respond to live updates on the dataset by updating d3 svg canvas } </script> The onDataLoaded(data) function is where you would write code to respond to the data that is being sent into the script or D3 control. For example, when the data gets loaded, you would want to display the points. The onDataChanged(data, changes) function is where you would write code to respond to any changes made to the data so the visualization will adapt in real-time and show live data. Below is an example of a working script that shows data along an X-axis and Y-axis. Download D3 Chart v2.zip Data Source Common Properties Data from this Data Source will be displayed using the script attached. Properties that are common to most Blocks include: filter, sort, show # of results, and skip # of results; See the Common Properties article for more details on common Data Source properties. The Data Source property is required for the D3 Visualization Block."
  },
  "src/blocks-toolbox/visualizations/esri-map.html": {
    "href": "src/blocks-toolbox/visualizations/esri-map.html",
    "title": "Esri Map | XMPro",
    "summary": "Esri Map This Block allows you to integrate an Esri Map into the page. An Esri Map has additional features to a regular map such as allowing you to visualize additional geographical information, terrain formation, or topographical information for a given area. Esri Map Properties Appearance Base Map Choose the visual context for the map from the options listed below: Base Map Description Thumbnail Dark Grey (default) Shows the world on a gray canvas to focus your attention on thematic content. Topography Shows geographical details including the height and shape of mountains, sea levels, and other geographical features such as rivers. Streets Shows highway-level and street-level data for the world. Major roads are highlighted and all roads are labeled. Streets Night Shows highway-level and street-level data for the world, designed for use at night or in a low light environment. Major roads are highlighted and all roads are labeled. Satellite Shows high-resolution satellite imagery for many areas. Hybrid Shows high-resolution satellite imagery for many areas, with road labels or location references overlaid on top. Gray Shows the world on a light gray canvas to focus your attention on thematic content. National Geographic Provides a detailed view of political boundaries, and emphasises certain characteristics of the land such as mountains. Oceans Designed for Marine GIS professionals to provide important reference points within the Oceans and Seas of the world. Open Street Map Open Street Map (OSM) is a collaborative project to create an open, editable neighborhood map. The Esri replica is updated continuously with the latest edits. Terrain Shows terrain details including the height of the land and sea. Allow pan and rotate Adds a button to the map which allows the user to rotate the map. Longitude, Latitude, Height, and Tilt Angle The map will load the location specified with Longitude, Latitude, Height, and Tilt Angle. Behavior Use Variables This allows you to choose between manually entering a value for the API Key or selecting from a static variable. API Key The API key is used to get the private feature layers. For more details, visit the official Esri map documentation. The API Key property is required for the Esri Map when there are feature layers added. Show Basemap Gallery This will add a button on the map and give the option to change the Base Map layout. Allow Show Current Location This will show the user's current location on the map. Requires the location of the device. Feature Layers A Feature Layer is a single layer overlaid on the base map that can be created in a variety of ways and display different visualizations. Spatial feature layers include features that use Geometry and allow you to render the scene in either 2D or 3D. These features also provide more information about the real world which can be displayed through pop-up windows within the scene. Non-spatial feature layers do not provide this information about geographical features. For more details, visit the official Esri Map documentation. Markers Data Source Mode This can be changed to either use Static Items or a Dynamic Data Source. In both cases, markers need to be configured in the Data section. If the static items option is chosen, markers for locations can be entered manually under the Data section. If the Dynamic Data Source option is chosen, marker locations coming from the Data Source can be used. See the Common Properties article for more details on common Data Source properties. Data Markers for locations can be manually added and they will show on the map. Actions are triggered when you click on a marker on the map. Markers are entered by Longitude and Latitude. Markers can also have a text label that will be shown on top of the marker. Action Common Properties Actions are triggered when you click on a label marker on the map. Properties that are common to most Blocks include: navigate to and show confirmation dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/visualizations/image-map.html": {
    "href": "src/blocks-toolbox/visualizations/image-map.html",
    "title": "Image Map | XMPro",
    "summary": "Image Map The Image Map Block allows you to render dynamic and static content onto an Image. You can drag on content such as indicators or text and these render on top of the image at runtime, at the specified coordinates. The Image Map Block accepts an image, and this aspect ratio is maintained when the Block is resized on the canvas; at run-time when the window is resized; or the App is launched on differently sized displays, such as a tablet or a large control room monitor. Static and/or dynamic data can be added and their aspect ratio is also maintained so that they autoscale with the image. The static content is a container used to lock the position of other Blocks, for example, to show general information on the corners of a plant diagram. For the best results, specify the position as a percentage and the text size as vh/vw. Note vw and vh are length units representing 1% of the viewport size for viewport width (vw) and height (vh), respectively. They are ideal for specifying size - especially text - in a responsive design because they are independent of the base font size. A dynamic template is a container of other Blocks, linked to a data source. An instance of the template will show at run-time for each data point returned by the data source, positioned at the data point's specified X and Y coordinates. Multiple dynamic templates can be added if data points have different behavior and/or different data sources/filters. For example, you may have a different color indicator and a different drill-down action per asset type, such as conveyors, borers, and crushers. Besides autoscaling, the second feature of the Image Map Block is a tooltip located top left of the image to tell you the exact X/Y coordinates of any point on the image at design time. Move your mouse across the image on the canvas to decide the exact placement of data points or static content. Image Map Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Image Source Choose whether the image is stored in App Files (default) or Embedded. The App Files option, added in v4.4.17, is the recommended image source - embedded files bloat the app size and cannot be copied/downloaded/reused. Image Select the background Image. Tooltip A tooltip in the top left corner of the image shows the coordinates of the mouse location when hovering over the canvas. You can use this at design time to determine the X/Y position to render your static and dynamic content. Dynamic Templates Dynamic Templates are layers on the Image Map Block that act as containers for additional Blocks like Text, Indicator, etc. These Blocks can be bound to values that come from the Dynamic Template's Data Source. A Text Block is added by default to get you started - it can be amended or replaced. One Dynamic Template is added by default and cannot be removed. No instances will show during run-time unless its Data Source, X Value, and Y Value are configured. Data Source Common Properties The Data Source property is common to most Blocks; ‌See the Common Properties article for more details on common Data Source properties. Data X Value The X Value determines the horizontal position of the Dynamic Template's run-time instances. Acceptable values are percentages, i.e. between 0 and 100. Y Value The Y Value determines the vertical position of the Dynamic Template's run-time instances. Acceptable values are percentages, i.e. between 0 and 100. Note The X and Y Values determine the run-time position of each instance of the dynamic template. You can adjust the template's position on the canvas under block styling. Positioning Although the runtime position is determined by the X and Y values, you can amend the canvas position by changing the top and left percentages in the Block Styling menu's Advanced position and displayed styling accordion. You can also change the Width and Height to a percentage or vw/vh in the Dimension accordion, and font size to vw/vh in the Typography accordion to ensure that the text is responsive. Adding a Dynamic Template To add another Dynamic Template, select any Dynamic Template and click on the plus button in the top right Block toolbar. Removing a Dynamic Template To remove a Dynamic Template, select the Dynamic Template and click on the delete button in the top right Block toolbar. Note The default Dynamic Template cannot be removed. Static Content Static Content is a layer on the Image Map Block that acts as a container to lock the position of additional Blocks like Text, Indicator, etc. A Text Block is added by default to get you started. It can be amended or replaced. Positioning Unlike Dynamic Templates, the canvas and the runtime position are the same for Static Content. You can manually position it anywhere on the image by changing the top and left percentages in the Block Styling menu's Advanced position and displayed stylingaccordion. You can also change the Width and Height to a percentage or vw/vh in the Dimension accordion, and font size to vw/vh in the Typography accordion to ensure that the text is responsive. Adding Static Content To add Static Content, select the Image Map Block and click on the plus button in the top right Block toolbar. Note If your Image layer covers the Image Map, click the up button in the top right Block toolbar. Removing Static Content To remove Static Content, select it and click on the delete button in the top right Block toolbar. Binding Data To Static Content Add a Box Block to reference a Data Source within the Static Content layer - such as Live Data from Data Streams. Once a Data Source has been configured for the Box, you can bind data on any blocks added inside via the Dynamic Properties option."
  },
  "src/blocks-toolbox/visualizations/index.html": {
    "href": "src/blocks-toolbox/visualizations/index.html",
    "title": "Visualizations | XMPro",
    "summary": "Visualizations Autodesk Forge Azure Digital Twin Hierarchy Bar Gauge Chart Circular Gauge D3 Visualization Esri Map Image Map Linear Gauge Live Feed Map Pie Chart Pivot Grid Polar Chart Power BI Sparkline Time Series Analysis Tree Map Unity Unity (Legacy)"
  },
  "src/blocks-toolbox/visualizations/linear-gauge.html": {
    "href": "src/blocks-toolbox/visualizations/linear-gauge.html",
    "title": "Linear Gauge | XMPro",
    "summary": "Linear Gauge This Block allows you to display data in the format of a Linear Gauge. The Linear Gauge is a scale that indicates a single value or multiple values. Linear Gauges are useful for displaying and visualizing numeric values within a certain range. Linear Gauge Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Options that are specific to Linear Gauges include the ability to change the orientation, title, font color, tick interval, and the style of the primary and sub-values. Orientation This determines if the Linear Gauge is displayed horizontally or vertically. Title This is the text that shows on top of the Linear Gauge. Font Color This changes the color of the text above the Linear Gauge. Tick Interval This determines the number interval of the Linear Gauge. Primary Value Indicator Type This determines the shape of the marker that points to the value on the gauge. Options include a rectangle, circle, rhombus, range bar, triangle marker, and text cloud. Primary Value Format Text as Percentage This is only available if the indicator type is a text cloud. Enabling this will show the text on the screen as a percentage. Primary Value Indicator Color This determines the color of the indicator. Primary Value Indicator Offset This determines how far away the needle or marker is when pointing to the value. Sub Value Indicator Type This determines the style of the sub-values showing on the Linear Gauge. The indicator type refers to the shape of the needle that points to the value on the gauge. Sub Value Format Text as Percentage This is only available if the indicator type for the sub-value is a text cloud. Enabling this will show the text on the screen as a percentage. Sub Value Indicator Color This determines the color of the sub-values. Sub Value Indicator Offset This determines how far away the need or marker is when pointing to the sub-value. Behavior Common Properties The disabled property is common to most Blocks; See the Common Properties article for more details on common behavior properties. Start Range and End Range The start and end range define the boundaries of where the values of the Linear Gauge should start and end. Range The range allows you to change the color of different ranges on the gauge. Value You can show a single value on the Linear Gauge, as well as multiple sub-values."
  },
  "src/blocks-toolbox/visualizations/map.html": {
    "href": "src/blocks-toolbox/visualizations/map.html",
    "title": "Map | XMPro",
    "summary": "Map This Block adds a map to the page. This is useful if you want to show locations to the user, such as where to find something. A Data Source can be connected to the Map to load predefined target locations. The map can then be useful for displaying locations stored in a database. Map Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Options that are specific to maps include the ability to change the latitude, longitude, and zoom level. Latitude & Longitude This is the default coordinator location of the Map. Zoom The default zoom amount of the Map. Behavior Common Properties The disabled property is common to most Blocks; Some of the properties are visible only when the dynamic mode option is enabled in Markers Data Source. See the Common Properties article for more details on common behavior properties. Use Variables This allows you to choose between manually entering a value for the Provider API Key or selecting from a static variable. Provider Warning Google map and Google Static requires Provider API Key and the user needs to provide their own otherwise Google Static will not load and Google map will be shown in development mode. Bing does not require a Provider API Key to show the map. If the Mode is Google or Google Static, the Provider API Key property is required for the Map. This specified the provider of the Map. The default provider is Bing and can be changed to Google or Google static. If you have a customized map experience already set up on Google or Bing Maps, you can enter your Provider API Key. Type This determines the layout of the map. Options include Roadmap (default), satellite, or hybrid. Enable Navigation Controls This determines if the navigation controls on the right-hand side of the map are visible. Auto-Adjust Position to Markers This will automatically change the camera position of the map to the area where the markers are. Show Marker Labels This determines if the markers of a location are visible. Actions are triggered when you click on a label marker on the Map. Overlay This sub-section of Behavior only applies when the Provider option is Google. Geo Json A GeoJSON file of type .json, representing simple geographical features, can be uploaded to the App Files and overlaid on the Map. Image An image file can be uploaded to the App Files and overlaid on the Map. Once an Image is selected, it is required to specify the Image South West point & Image North East point for correct positioning. Image South West point The coordinates of the South West point of the Image, in the format latitude, longitude. Image North East point The North East coordinates of the Image, in the format latitude, longitude. Image Tilt Enter the number of degrees to tilt the image. The default is zero. Markers Data Source Mode This can be changed to either use static items or a dynamic data source. In both cases, markers need to be configured in the Data section. If the static items option is chosen, markers for locations can be entered manually under the Data section. If the dynamic data source option is chosen, marker locations coming from the Data Source can be used. See the Common Properties article for more details on common Data Source properties. Data Markers for locations can be manually added and they will show on the Map. Markers are entered by Longitude and Latitude. Actions Common Properties Actions are triggered when you click on a label marker on the map. Actions are only available if the dynamic mode option is enabled in Markers Data Source. Properties that are common to most Blocks include: navigate to and show confirmation dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/visualizations/pie-chart.html": {
    "href": "src/blocks-toolbox/visualizations/pie-chart.html",
    "title": "Pie Chart | XMPro",
    "summary": "Pie Chart This Block allows you to display data in the format of a Pie Chart. This is useful if you want to show categorical data represented as a slice on the Pie Chart, and to express a part-to-whole relationship between multiple variables. Pie Chart Properties Appearance The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Options that are specific to Pie Charts include the ability to change the type, palette, and legend. Type This determines if the pie graph is in the shape of a pie or donut. Inner Radius This is only available if the type of Pie Chart is a donut. Palette You can specify a custom color for each section of the Pie Graph. Legend This specifies where the legend is located around the Pie Chart. Labels This will toggle whether or not labels around each section are visible. If labels are enabled, you also have the option to show a connecting line from the Pie Chart to the label. Labels can also be formatted, and numerical data from the Pie Chart can be displayed as decimals, percentages, seconds, and more. Data Source Common Properties Data Sources can be connected to a Pie Chart. This will allow you to display data on the Pie Chart. See the Common Properties article for more details on common Data Source properties. Data Argument Field This is the name, ID, or any other unique field of a record from the Data Source. Value This is the value you want to display using the Pie Chart."
  },
  "src/blocks-toolbox/visualizations/pivot-grid.html": {
    "href": "src/blocks-toolbox/visualizations/pivot-grid.html",
    "title": "Pivot Grid | XMPro",
    "summary": "Pivot Grid This Block allows you to display data in the format of a Pivot Grid. The Pivot Grid can display the data in a customizable way and allows the users to specify which rows and columns are compared against each other. It consists of the grid itself as well as a field chooser which allows you to change the way the data is represented. Pivot Grid Properties Appearance Common Properties Options for the appearance include its visibility. See the Common Properties article for more details on common appearance properties. Options that are specific to Pivot Grids include the options to show borders, show column totals, show column grand totals, show row totals, show row grand totals, show drill down, and show totals prior. For details on common grid properties, see the Data Grid article. Show Column Totals This specifies if the totals across each row are counted and displayed on the side of a grouped column. Show Column Grand Totals This specifies if the totals across each row are counted and displayed on the side. Show Row Totals This specifies if the totals across each column are counted and displayed after each grouped row. Show Row Grand Totals This specifies if the totals for each column are counted and displayed at the bottom. Show Drilldown When this is enabled, selecting any of the values in the data region will open a grid that drills down for each record. Show Totals Prior By default, the totals for columns and rows are displayed at the end of the grouped row or column. If this option is enabled, the totals for columns or rows will be displayed before them, instead of after. Behavior Options for the behavior include sorting the data by summary, allowing sorting, allowing filtering, and retaining the layout. Allow sorting by summary This allows the user to sort by each individual column. To sort, right-click on a column and select Sort by this Column. Allow Sorting This displays an arrow next to the row or column name. This lets the user sort the order of the columns and rows based on their names. Allow Filtering This displays a filter icon next to the row or column name. This allows the user to filter the rows or columns to only display certain values. Retain Layout If set to true, this will save the column, row, and data layout configuration in the browser. If changes are made to the Pivot Grid, and the user leaves the page and comes back later, the layout of the table will be the same as before they left it. If this option is set to false, the layout will reset to the default fields specified under Fields. Data Source Common Properties Data Sources can be connected to a Pivot Grid. This will allow you to display data on the Pivot Grid. See the Common Properties article for more details on common Data Source properties. The Data Source property is required for the Pivot Grid. Fields The fields specify the default fields that are visible for the rows and columns on the Pivot Grid. The fields can be bound to a row or column from the Data Source and certain properties can be configured. Area This specifies where on the Pivot Grid the data will be shown. This includes whether it is shown on the row, column, data area, or filter area. Data Type The data type of the row, column, or cell. This can be a number, string of characters, true or false value, or a date. Data Field This is the field from the Data Source that is going to be used when displaying the data."
  },
  "src/blocks-toolbox/visualizations/polar-chart.html": {
    "href": "src/blocks-toolbox/visualizations/polar-chart.html",
    "title": "Polar Chart | XMPro",
    "summary": "Polar Chart This Block allows you to display data in the format of a Polar Chart. This is a useful way to visualize multivariate data and to plot one or more groups of values over common variables. For example, each series can represent a particular observation or group of data points, and these can be compared to other data sets in the same graph. Polar Chart Properties Appearance Common Properties Options for the appearance include its visibility. See the Common Properties article for more details on common appearance properties. Polar Charts also include the spider web, start angle, tick interval, argument line color, display grid lines, grid-line color, display labels, and tick position options. The series and alignment of the chart can also be configured. Spider Web This determines the shape of the Polar Chart. Start Angle This specifies the starting point of the line in the middle of the Polar Chart. Tick Interval This determines how many grid lines appear between each value if the outer argument is a number. A tick interval of 0 is the default value. Argument Line Color This changes the line color of the argument or outer field. Display Grid Lines This toggles the visibility of the grid lines in the middle of the graph which separates each value. Grid Line Color This changes the color of the lines in the middle of the graph which separate each value. Display Labels This determines if the labels are visible or not. Tick Positions This determines if the ticks on the argument line are aligned with the labels. Hide Series on Legend Click This allows you to toggle the visibility of each of the series when it is clicked on in the legend. Alignment This specifies the alignment of the legend. Options include top-left, top-center, top-right, bottom-left, bottom-center, or bottom-right. Data Source Common Properties Properties that are common to most Blocks include: filter, sort, show # of results, and skip # of results; See the Common Properties article for more details on common Data Source properties. The Data Source property is required for the Polar Chart. Data Series This determines what fields or data displays on the Polar Chart. The fields can be selected from a connected Data Source."
  },
  "src/blocks-toolbox/visualizations/power-bi.html": {
    "href": "src/blocks-toolbox/visualizations/power-bi.html",
    "title": "Power BI | XMPro",
    "summary": "Power BI Power BI is a control that allows you to embed reports inside your application. Power BI is a business analytics service that provides a platform where users can create interactive visualizations of data that can be used on reports or event boards. For more details, visit the official Microsoft website. Power BI Properties Appearance Common Properties Options for the appearance include its visibility. See the Common Properties article for more details on common appearance properties. Behavior Use Variables This allows you to choose between manually entering a value for the Report ID or selecting from a static variable. If the Application Mode is set to 'Application', Use Variables will also allow you to select a static variable for the Group Id, Tenant Id, Application Id, and Application Secret. Report Id The report Id can be found inside the URL of the report you want to embed. To find the report's Id: Sign in Power BI. Open the report you want to embed. Copy the GUID from the URL. The GUID is the number between /reports/ and /ReportSection. For example, if the url has .../reports/de0db6db-232f-b5b5-1abe1d71da76/ReportSection...., the report Id you would enter is de0db6db-232f-b5b5-1abe1d71da76. The Report Id property is required for the Power BI Block. Authentication Mode There are two options for the authentication mode: user and application. User authentication is used when you want to embed the report for your organization. The users will be required to sign in and have a Power BI account. This will also require you to have a Power BI embedded license for this. Application authentication will embed the contents of the Power BI report into the page and the user will not be asked to sign in to view the report. In order to set up application authentication, the group Id, tenant Id, Application Id, and Application secret of your report need to be entered. For more information about where to find the value for these fields, read the official Microsoft Documentation. If the Authentication mode is set to 'Application', the Group Id, Tenant Id, Application Id, and Application Secret properties are required for the Power BI Block."
  },
  "src/blocks-toolbox/visualizations/sparkline.html": {
    "href": "src/blocks-toolbox/visualizations/sparkline.html",
    "title": "Sparkline | XMPro",
    "summary": "Sparkline A Sparkline is a Block that allows you to display data. A Sparkline can only display one series or data set in the graph and are therefore small graphs that do not take up much space. They can be embedded into text or easily added to the cells of a table. This is useful for displaying very specific data that focus on a single variable. Sparkline Properties Appearance Common Properties The Sparkline has the option to change its visibility and to show a tooltip. See the Common Properties article for more details on common appearance properties. Options that are specific to Sparkline include the ability to change the type, change color, highlight first and last point, change point size and format. Type There are eight types of Sparkline. Area, Bar, Line, Spline, Spline Area, Step Area, Step Line, and Win/Loss. Highlight First and Last Point This will highlight/circle the first and last value points on the series, which should be located at the start and end of the line/series. First and Last Point Color This will change the color used to highlight the first and last points. Show Min and Max This will highlight the min and max value on the Sparkline. Min and Max Color This will change the color of the min and max highlighter. Line Color This will change the color of the line. Line Width This will change the width of the line. Point Color This will change the color of the point. Point Size This will change the radius of the point. Background Color This will change the background color of the tooltip. Format This will display the values in the selected format when the tooltip is shown. Data Source Common Properties Properties that are common to most Blocks include: filter, sort, show # of results, and skip # of results; ‌See the Common Properties article for more details on common Data Source properties. The Data Source property is required for the Sparkline Block. Data This is where you can configure what X and Y-Axis to show on the graph. The X-Axis and Y-Axis properties are required for the Sparkline Block. Ignore Empty Points If the value is empty it will not show it on the Sparkline."
  },
  "src/blocks-toolbox/visualizations/time-series-analysis.html": {
    "href": "src/blocks-toolbox/visualizations/time-series-analysis.html",
    "title": "Time Series Analysis | XMPro",
    "summary": "Time Series Analysis The Time Series Analysis is an interactive UI component that visualizes large amounts of time-oriented data. The Time Series Analysis empowers comparing data at run-time based on asset ID by dropping markers on the chart panning and zooming showing and hiding specific assets or parameters via the hierarchy panel Performance The Time Series Analysis is a specialized graphing tool that addresses the time series of asset attributes. By its nature, it will process many data points (in some cases millions); thus, extracting and processing this complex data can take time. Large data sets can place a strain on your computing resources. There is no expectation that a time series analysis will perform to the same level as bar charts in a Business Intelligence product like PowerBI. The approach to computational capability is no different than having a massive single Excel sheet or multiple sheets. We have chosen not to implement hard limits like similar products e.g. Microsoft ADX, as the data sources our customers use are wide and varied. Note Read the article below to improve your understanding of factors that impact performance. A look beneath the hood of XMPro Charts and Time Series Analysis Connector Selection Choose either a Connector designed for large volumes of data (e.g. TSC SQL Server Connector) - or one that does not reload with each interaction (e.g. SQL Server Connector). If there isn't a specialized TSC Connector available for your data source yet, you can utilize the ITSAConnector interface to build one. Link to resource Time Series Analysis Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Show Legend Determines if the legend is displayed or not. X Axis Label Format Determines how the date is formatted on the x-axis of the chart and pan & zoom panel. Label Format Image 12-Hour Clock (2 Lines) 12-Hour Clock (1 Line) 24-Hour Clock (2 Lines) 24-Hour Clock (1 Line) Enable Toolbar Determines whether the toolbar is displayed or not. The toolbar contains the button to change the y-axis type and the ellipsis menu. Enable Display Grid Determines whether the ellipsis menu contains the Display Grid option, which shows the selected data in a grid. Enable Download as CSV Determines whether the ellipsis menu contains the Download as CSV option, which allows you to download the selected data as a CSV file. Pan & Zoom Mode This determines how the Pan & Zoom panel is displayed. Setting it to \"Hidden\" will remove the panel entirely, while \"Compact\" is a single-line component, and \"Full\" will display a Pan & Zoom with secondary panning and zooming for fine-tuning the selection. Pan & Zoom Mode Image Full Compact Hidden Pan & Zoom Color This determines the color of the Pan & Zoom component. Interval Size This determines the default value for the Interval Size slider. The slider allows you to fine-tune the granularity of the displayed data. The displayed line chart data will be averaged over this interval. Range - Static This determines the starting date for the Pan & Zoom. The end date of the Time Series Chart is determined by the row with the latest timestamp. The Pan & Zoom range will update automatically with live data. Note The static range is used unless Dynamic Start and Dynamic End are not zero. Range - Dynamic Start This determines the starting date for the Pan & Zoom. If changed dynamically at runtime, the Pan & Zoom range will reload to reflect the new start. The Dynamic Start date must be before the Dynamic End date. Range - Dynamic End Unlike the Static Range where the end date is determined by the row with the latest timestamp, this value specifies the end date for the Pan & Zoom. If changed dynamically at runtime, the Pan & Zoom range will reload to reflect the new end. Initial Selection This determines the time interval initially selected in the Pan & Zoom component and, correspondingly, the line chart. The selection will always start at the right side of the Pan & Zoom component. Initial Selection Unit of Time This determines which unit of time measurement is applied to the initial selection value. The options are Minutes, Days, or Hours. Upon launching the application, the initial selection and the unit of time can be observed on the interval timeline. Display Avg, Min, Max, and Envelope This determines whether the line chart will display only the average values as a plain line, or the minimum, maximum, and envelope over the selected Interval Size. Show Tooltip On Hover This determines whether a tooltip will appear when the cursor hovers over a line. The tooltip will display the values of the hovered point on the line. Enable Zoom Determines whether you can click and select on the chart to zoom into the selection. Show X Axis This determines whether the x-axis line and labels for the line chart are shown. Show Y Axis This determines whether the y-axis line and labels for the line chart are shown. Default Y Axis Type This determines the default Y Axis type, which can be changed at run-time using the button at the top-left corner of the line chart. If set to \"Stacked\" the selected parameters will be separated into different panes stacked vertically. If set to \"Shared\" the selected parameters will share a single pane with a single y-axis from the lowest to highest values in any line. If set to \"Overlap\", the selected parameters will share a single pane with multiple y-axes, with the lowest and highest value of each line chart displayed on the axis at the bottom and top. Show Dots Determines whether the points on the lines will display as dots. Interpolation Function This property allows you to define how the lines behave in the line charts. Function Line Monotone X Linear Step Step Before Step After Basis Cardinal Catmull-Rom Palette You can specify a custom color for each parameter in the line chart. If the number of parameters is greater than the number of colors specified, the colors will repeat. Behavior Recommendations The Alerts for selected Recommendations will be displayed at run-time as markers on the chart: the Alert's created time is used as the timestamp and its title as the text. Note Known limitations: The marker title space is limited and the Alert title may be truncated. Some HTML special characters (e.g.<) used in the Alert title will be encoded. Entity ID Specify an Entity ID field to filter the Recommendation Alerts. Data Source Common Properties A Data Source can be connected to a Time Series Chart. This will allow you to display data on the Time Series Chart. ‌See the Common Properties article for more details on common data source properties. The Data Source property is required for the Time Series Chart. Note Known limitations: SQL is not advised because large volumes of data may cause read issues and/or performance issues. Azure Data Explorer is the recommended time series data source. When adding a new field or expression to a Data Source already connected to a Time Series Chart, follow these steps for them to appear in the Time Series Chart configuration options: Save the Data Source. Open the Time Series Chart's Block Properties. Save the Application. Data Timestamp Expression This is the column that the data will base its x-axis on. It must be a Date Time type column. For efficient performance, it is recommended to have an index in descending order on this column in your database. The Timestamp Expression property is required for the Time Series Chart. Default Selection You can choose the line charts that the Time Series Chart will start with. If Group By Asset is disabled, you can select which parameters will be selected by default. If Group By Asset is enabled and a Hierarchy Data Source is selected, you will be able to select which Hierarchy items will be selected by default for each parameter. Hierarchy Group By Asset This determines whether the data is to be grouped by an Asset Id column on the Data Source. If not enabled, the line chart will display a single line for each parameter selected. Asset Id Expression This is the column by which data will be grouped into separate lines. Each unique value in this column will have a line. If you choose to enable Hierarchy, this is also the Foreign Key that provides a link to the Id Expression of the Hierarchy Data Source. When Group By Asset is true, the Asset Id Expression property is required for the Time Series Chart. Show Hierarchy This determines whether the Hierarchy is displayed. The hierarchy is the left panel containing a tree grid that allows you to modify the selected assets and parameters. Data Source A Hierarchy Data Source can be connected to a Time Series Chart. This will allow you to display data in the Hierarchy of the Time Series Chart. See the Common Properties article for more details on common data source properties. Id Expression The Id Expression is the identifying column for the Hierarchy. The values in this column are linked to the Asset Id Expression of the line charts, and the Parent Id Expression. If the Hierarchy Data Source is selected, the Id Expression property is required for the Time Series Chart. Name Expression The Name Expression is a user-friendly name for what the user can see. For example, the text that is showing in the List. If the Hierarchy Data Source is selected, the Name Expression property is required for the Time Series Chart. Parent Id Expression The Parent Id Expressions determine how the Hierarchy knows which rows are connected to each other as parent and child. The Parent Id refers to the Id of the parent row. If the Parent Id expression is not defined, the Hierarchy will have a flat structure. Resource Expression The Resource Expression determines whether a row is a Resource Row and can have parameters selected for it. For example, each area in a mine may have many pumps, but only the pumps are Resources and have a Motor Current, etc. If Resource Expression is not defined, only the leaf nodes in the tree will be Resources."
  },
  "src/blocks-toolbox/visualizations/tree-map.html": {
    "href": "src/blocks-toolbox/visualizations/tree-map.html",
    "title": "Tree Map | XMPro",
    "summary": "Tree Map The Tree Map is a UI component that displays hierarchical data by using nested rectangles. In the Tree Map component, hierarchical data is represented by a set of nested rectangles whose sizes are proportional to the visualized values. Tree Map operates with plain and hierarchical data sources. Also, it can visualize a hierarchy reconstructed from a flat data source. Tree Map Properties Appearance Common Properties You can change the visibility of the Tree Map. See the Common Properties article for more details on common appearance properties. Tiling Algorithm Select the tiling algorithm that will be used to determine the position and size of tiles and groups: Slice and Dice Squarified Strip Layout Colorizing Determine the colorizing algorithm. Palette You can override the default colors by adding custom colors. Range Determine the range and how the tiles should be colorized based on the range. Only available if Colorizing is set to Range or Gradient. Breadcrumbs Position Determines the position of the Breadcrumbs. Behavior Show Drilldown When this is enabled, selecting any of the values in the Tree Map will drill down for that tile or group. Maximum Depth Determine how many hierarchical levels must be visualized. Data Source Common Properties Properties that are common to most Blocks include data source and filter. See the Common Properties article for more details on common Data Source properties. The Data Source property is required for the Tree Map. Data Display Expression The expression is a user-friendly name for what the user can see. For example, the text that is displayed to the user. The Display Expression property is required for the Tree Map Value Expression This is the value that is used to set the size of the tiles and the groups. The Value Expression property is required for the Tree Map. Id The Id property is required for the Tree Map Parent Id The Parent Id tells the component how the fields are connected to each other. The Parent Id refers to the Id of the parent record. For example, in the hierarchy of employees, multiple people could report to one manager, so their parent Ids would be the Id of the person they are listed underneath. If the parent Id of a record is set to null or 0, it will automatically be placed as a root or main parent element on the tree. The Parent Id property is required if the Data Source is a plain data source. For hierarchical data sources, the Parent Id property is not needed. Tooltip Determines the text that will be shown when hovering over a block. Action Common Properties Properties that are common to most Blocks include: Navigate To, Update Page Data, Groups To Validate, and Show Confirmation Dialog; See the Common Properties article for more details on common action properties."
  },
  "src/blocks-toolbox/visualizations/unity-1.html": {
    "href": "src/blocks-toolbox/visualizations/unity-1.html",
    "title": "Unity (Legacy) | XMPro",
    "summary": "Unity (Legacy) The Unity Block can display data that is received via the Data Source and it is interactive by configuring the Action on the Button or any other component that has that option to update the Data Source. Warning This Block only supports Unity 2019 and Unity WebGL content is not currently supported on mobile devices. For newer Unity versions use the new Unity Block. Note Unity integration with an App Use the XMPro Integration asset on the Unity Asset Store. The asset includes a demo project and its own documentation and tutorial. Note Disable Keyboard Capture Is your keyboard non-responsive once a Unity model is loaded? Follow this guide to prevent the keyboard input from being locked to the Unity model. Model Interaction You can interact with models that have been designed in Unity to be interacted with, by using the controls/events that the model was designed to use. Unity Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Loading Bar Image This property gives the user an option to upload an image that will be displayed on top of the loading bar. The default option is no image and just displays the loading bar. Loading Bar Color This will change the color of the default bar to the selected color. Behavior Here we need to configure the Unity control. All files come from the Unity build itself. Code File Select the Unity web assembly code file. The Code File property is required for the Unity Block. Data File Select the Unity data file. The Data File property is required for the Unity Block. Framework File Select the Unity framework file. The Framework File property is required for the Unity Block. Note For more details on how to upload or manage files, see the Manage App Files article. Data Source Common Properties A Data Source is used to send data to the Unity Block. Properties that are common to most Blocks include: filter, sort, show # of results, and skip # of results; See the Common Properties article for more details on common Data Source properties."
  },
  "src/blocks-toolbox/visualizations/unity.html": {
    "href": "src/blocks-toolbox/visualizations/unity.html",
    "title": "Unity | XMPro",
    "summary": "Unity The Unity Block can display data that is received via the Data Source, and it is interactive by configuring the Action on the Button or any other component that has that option to update the Data Source. Warning This Block only supports Unity 2020 and above and Unity WebGL content is not currently supported on mobile devices. For Unity 2019 use the Unity (Legacy) Block. Note Unity integration with an App Use the XMPro Integration asset on the Unity Asset Store. The asset includes a demo project and its own documentation and tutorial. Note Disable Keyboard Capture Is your keyboard non-responsive once a Unity model is loaded? Follow this guide to prevent the keyboard input from being locked to the Unity model. Model Interaction You can interact with models that have been designed in Unity to be interacted with, by using the controls/events that the model was designed to use. Unity Properties Appearance Common Properties The visibility property is common to most Blocks; See the Common Properties article for more details on common appearance properties. Loading Bar Image This property gives the user an option to upload an image that will be displayed on top of the loading bar. The default option is the Unity logo and the loading bar. Loading Bar Color This will change the color of the default bar to the selected color. Behavior Here we need to configure the Unity control. All files come from the Unity build itself. Code File Select the Unity web assembly code file. The Code File property is required for the Unity Block. Data File Select the Unity data file. The Data File property is required for the Unity Block. Framework File Select the Unity framework file. The Framework File property is required for the Unity Block. Note For more details on how to upload or manage files, see the Manage App Files article. Data Source Common Properties A Data Source is used to send data to the Unity Block. Properties that are common to most Blocks include: filter, sort, show # of results, and skip # of results; See the Common Properties article for more details on common Data Source properties."
  },
  "src/blocks-toolbox/widgets.html": {
    "href": "src/blocks-toolbox/widgets.html",
    "title": "Widgets | XMPro",
    "summary": "Widgets Note The Widgets section of the Blocks Toolbox contains all the Widgets that you have created as well as Widgets that others in your Company have created and made visible to everyone. See the Manage Widgets article for more detail on Widgets."
  },
  "src/concepts/agent/index.html": {
    "href": "src/concepts/agent/index.html",
    "title": "Agent | XMPro",
    "summary": "Agent An Agent is a reusable object which forms the building block of a Data Stream. When a number of Agents are connected together, a Data Stream is formed. Each Agent is designed to perform a specific function in the stream. For example, they can be used to retrieve data from a database in real-time, display data, filter, sort the data, or save the data somewhere else, depending on the function of that individual Agent. Agents are needed to connect to specific systems. Since Agents are individual components, new Agents can also be added and integrated into the Data Stream to complete a specific functionality. Video Presentation Discussing Agents and Collections Each Agent consists of code, settings, and other properties that are packaged into a file that can be uploaded to Data Stream Designer. XMPro has a library of Agents available to use. To acquire any of these Agents, please contact your XMPro sales representative or write to us at support@xmpro.com. Alternatively, since Agents can be written by anyone that has some knowledge of programming and has access to the required technologies, you can write your own Agent by following these instructions. Categories In Data Steam Designer, Agents are divided into different categories, depending on the overall function they perform. There are six different categories available: Action Agents, Context Providers, Listeners, Transformations, AI & Machine Learning, Recommendations, and Functions. To be able to distinguish them properly, they have been tagged with a certain color as well as an abbreviation. These categories are separate from the App and Data Stream Categories. Action Agents An Action Agent is an Agent that consumes events in a stream and then performs internal or external (third-party) actions, e.g. sending notifications or performing data warehouse updates. Action Agents output a response after each event has been processed. For example, the Azure SQL Action Agent writes data to an Azure SQL database. Context Providers Context providers are Agents that provide context to a stream by consuming reference or static data and making it available. For example, the SQL Server Context Provider provides static data to the Data Stream by reading the data in a database table and sending it to the next Agent. Listeners Listeners are Agents that listen for data or events from sensors and third-party systems. For example, the MQTT Listener listens for data from sensors as it is posted to MQTT. Transformations Transformation Agents alter the shape or form of data. For example, the Join Transformation joins data it receives from two separate data sources. AI & Machine Learning AI & Machine Learning Agents allow you to run advanced AI to transform the data. For example, Azure ML, IBM Watson, and Jupyter Notebook. Recommendations Recommendation Agents are related to Recommendations and let you complete actions such as running recommendations, updating recommendations, and more. Functions Functions perform specific mathematical or statistical operations on data. For example, the FFT Function performs forward FFT calculations on the data it receives. Settings An Agent consists of code and user settings. The code defines the actions an Agent performs in any Data Stream. The settings are the input for the code that executes, provided by the user when adding the Agent to a Data Stream, such as authentication credentials. For example, consider the SQL Server Writer Agent. The function this Agent performs in a Data Stream is to take the data it receives and write it to a table in a database. The settings a user must define for the Agent so it can do that are as follows: Name of the SQL Server instance SQL Server username Whether SQL Server authentication should be used or not SQL Server password Database to which the data should be written Whether a new table should be created or not Table to which data should be written - if the user wishes to use an existing table Name of the table that should be created if the user wants to write the data to a new table If database triggers should be fired when a record is inserted Endpoints Endpoints provide entry and exit points to the Agent. The input endpoint allows the Agent to receive data from another Agent, whereas the output endpoint enables the Agent to pass data to another Agent. They are represented on the Data Stream canvas as green rectangles. The error endpoint allows an Agent to send any error data further along a part of the stream, designed to handle data records or events that do not meet certain requirements. It is represented on the Data Stream canvas as a red rectangle. Finding Agents The search bar can be used to find any specific Agents that you may be looking for. There is a dropdown option where you can specify to search through everything in Data Stream Designer, or only for Agents. Versions Agents can keep track of their different versions. Versions of an Agent can be copied, and changes made to it can be created as a new version without affecting previous versions. See the Version article for more details on versions. Publish and Unpublish Data Streams On the Agents page, there will be a number next to the version if the agent has been used in a Data Stream. Click the number to view a list of all Data Streams that are using that Agent version. Here you can directly unpublish or publish a Data Stream. As an Admin, this is useful if you need to unpublish a Data Stream and you don't have access to it. See the How to Admin Unpublish Override article for more details. Actions on the Agent Action Description Add Adds a new Agent. Select Selects multiple Agents. Delete Deletes the Agent. Save Saves any changes made to the Agent up to this point. Discard Discards any changes made to the Agent up to this point. Delete Versions Deletes selected versions of the Agent. Further Reading Agent FAQs How to Create and Manage Agents How to Run an Integrity Check How to Upgrade a Stream Object Version How to Use Error Endpoints Virtual vs Non-Virtual Agents"
  },
  "src/concepts/agent/virtual-vs-non-virtual-agents.html": {
    "href": "src/concepts/agent/virtual-vs-non-virtual-agents.html",
    "title": "Virtual vs Non-Virtual Agents | XMPro",
    "summary": "Virtual vs Non-Virtual Agents There can be two types of Agents in Data Streams; Virtual and Non-Virtual Agents. When packaging an Agent using the Stream Integration Manager, it is important to specify if an Agent is Virtual by making sure that the Virtual checkbox is correctly ticked. Virtual Agents A Virtual Agent is an Agent that is not bound to a certain environment to be able to function, for example, the Azure SQL Listener is an Agent which can be configured anywhere as it will always have access to the globally available Azure SQL Server, which it needs to integrate with. Non-Virtual Agents An Agent can be classified as Non-Virtual if it relies on a specific environment to function. Non-Virtual Agents need to interact with a system that is only available in a specific environment, for example, the SQL Server Listener. The SQL Server Listener is an Agent that can only be configured while it is on the same local area network as the SQL Server instance it needs to connect to. As shown in the diagram above, even though both Virtual and Non-Virtual Agents ultimately run on the Stream Host, there is a considerable difference in how they are handled at design time. A Virtual Agent can be configured even if no Stream Host is online, but this is not possible for a Non-Virtual one. Virtual Agents are also very fast as the engine doesn't have to go all the way to the Stream Host to configure them and this results in a smoother user experience. Note Virtual Agents can be configured even if there is no Stream Host online, but Non-Virtual Agents require a Stream Host to be online."
  },
  "src/concepts/application/app-files.html": {
    "href": "src/concepts/application/app-files.html",
    "title": "App Files | XMPro",
    "summary": "App Files App Files are a way to import files into an Application. App Files are managed through the App Files command or through the + button next to related properties in the Block Properties of a Page. Some Blocks allow the selection of App Files for some Block Properties. The App Files explorer allows you to use, rename, delete, and perform more actions on an uploaded file. App Files are useful in many scenarios, for example, if you need specific files to integrate Unity or D3 Visualizations onto the page. List of Blocks that use App Files Unity D3 Visualization Unity Files that can be uploaded for Unity include the Unity web assembly code file, Unity data file, and Unity framework file for a Unity project. See the Unity article to view the files you will need to integrate a Unity project. D3 Visualization Files that can be uploaded for D3 Visualizations include an HTML script that is used to create data visualization which will allow you to display data from a data source in real-time. See the D3 Visualizations article for more information about how to write and upload a script. Actions on the App Files Action Description New directory Creates a new directory under the specified directory or at the root Files directory. Upload files Uploads files into the specified directory or at the root Files directory. Change View Allows the view to be changed from Thumbnails to Details. Refresh Refreshes the App Files. If any changes have been made it also opens the Progress popup, which displays the recent history. Download Downloads the selected App File(s). Move to Moves the selected App File(s) to a different directory. Copy to Copies the selected App File(s) to a different directory. Rename Renames the selected App File. Delete Deletes the selected App File(s). Clear Selection Clears the selected App Files(s). Further Reading How to Manage App Files"
  },
  "src/concepts/application/block-properties.html": {
    "href": "src/concepts/application/block-properties.html",
    "title": "Block Properties | XMPro",
    "summary": "Block Properties Block Properties are properties that define the appearance and behavior of the Block. This allows you to customize the block's content such as the heading text, or configure any data you would like to display on your application. Each block type has different properties. To access the Block Properties tab, double-click a Block in the canvas or click on a Block in the canvas and click the Block Properties command. Properties are split into several common categories. Click on a category to expand the accordion and see the Properties in that category. The common categories are as follows: Category Description Appearance Properties that define how a Block looks. Behavior Properties that define how a Block behaves. Value Properties that define what value a Block has. Data Source Properties that define what Data Source the Block has (applies to Blocks that allow a Data Source to be attached). Data, Columns, Items Properties that define what the Data Source properties are mapped to, or allow a static data set to be created (applies when relevant to the Block). Grouping Properties that define how the Data Source is grouped (applies when relevant to the Block). Action Properties that define what action, and validation to perform, and what Data Source to update when it or items inside the Block are clicked (applies to Blocks that allow an action). Validation Properties that define what validation should be performed on the value of the Block before allowing an action (applies to Blocks that allow user input). Dynamic and Expression Properties Some properties have the option of being a Dynamic or Expression property. If the property has a button on the left with an A icon and \"Static Value\" when you hover it, it can be a Dynamic or Expression Property. Press the button to cycle through the modes. Dynamic properties allow you to select a value for the property from the Page Parameters, Variables, User Details, Device Details, and from a column or expression of the current row of a parent Block's Data Source. User Details Property Description Username Returns the Username of the user that is signed in. First Name Returns the First Name of the user that is signed in. Last Name Returns the Last Name of the user that is signed in. Full Name Returns the Full Name of the user that is signed in, using the format \"[First Name] [Last Name]\". Email Returns the Email of the user that is signed in. Preferred Language Returns the regional language tag of the logged in user's preferred language. Use this to adjust text when an App will be used in multiple languages: Iif(userPreferredLanguage == \"en-US\", \"Hello world\", \"Oi Worldo\") Language Tag English (United States) en-US svenska sv-SE Português (Brasil) pt-BR Русский ru-RU Español es-ES Nederlands nl-NL Deutsch de-DE français fr-FR 中文 (Zhōngwén) zh-CN ελληνικά el-GR Türkçe tr-TR čeština cs-CZ suomi fi-FI Italiano it-IT Magyar hu-HU 日本語 (にほんご) ja-JP slovenski jezik sl-SI Tiếng Việt vi-VN Device Details Property Description IsMobile Returns True boolean value if the App is open on a mobile device. Example: For Mobiles and/or Tablets will be True. IsDesktop Returns True boolean value if the App is open on a desktop device. Example: For Laptops and/or Desktops will be True. Culture Returns the Device culture/language. Example: If the language is set to US English will return en-US. Note See the Data Integration article for more information on Data Sources. Expression properties allow you to create short scripts to create a custom value from all the above options. See the Variable and Expressions article to learn more about Expressions. The Dynamic and Expression properties will have all the Block's ancestor's Data Sources displayed in the order of closest ancestor to furthest. For example, in the following images, the bottom-most Text Block in the Page Layers has two ancestors that have a Data Source: the Data Repeater Box and the Templated List. Therefore the two data sources are listed in the Text Block's Dynamic and Expression property dropdowns. Further Reading How to Use Dynamic Properties How to Use Expression Properties How to Use Validation"
  },
  "src/concepts/application/block-styling.html": {
    "href": "src/concepts/application/block-styling.html",
    "title": "Block Styling | XMPro",
    "summary": "Block Styling When a Block is selected, it can be styled under the 'Block Styling' tab in the Toolbox. Styling can include changing the text color, background color, borders, typography, or dimensions of the Block. This allows you to customize the look and feel of the application based on themes or color palettes for your specific organization. You can also customize the style of certain actions such as hovering over or clicking a button, or changing the style for every second Block. Style Groups A Block can also be assigned to a style group where a common set of styles can be configured and applied to multiple Blocks at the same time. Certain Blocks such as content cards or cards that are dragged onto the canvas already have pre-existing style groups, such as grids. These will show up under the 'Style Group'. If you have a Style Group selected and make changes to any of the styling configurations, the styling will automatically be applied to all the Blocks that are also in that style group. For example, if two grids have a style group called box-card, and you select only one of the grids and change the background to light blue, that change will also be applied to the other grid. To make changes without affecting other blocks, deselect the style group and make the changes. You can add multiple style groups at a time. If a Block has multiple style groups and you only want to apply styling to one of them, make sure only that style group is selected when configuring new styles. If multiple style groups are selected and the styling is changed, the styling will be applied to both of them together. For example, if you have two style groups, box-card, and lightgreen, and you apply styling to both of them, that styling will only be applied to Blocks that have both box-card and lightgreen style groups. Devices Styles can also be configured for different devices. See the Devices article for more details on devices. Style Sections Dimension Style CSS Property Width width sets the width of an element. Height height sets the height of an element. Min Width min-width defines the minimum width of an element. Min Height min-height defines the minimum height of an element. Max Width max-width defines the maximum width of an element. Max Height max-height defines the maximum height of an element. Margin margin-top sets the top margin of an element. margin-right sets the right margin of an element. margin-bottom sets the bottom margin of an element. margin-left sets the left margin of an element. Padding padding-top sets the top padding (space) of an element. padding-right sets the right padding (space) of an element. padding-bottom sets the right padding (space) of an element. padding-left sets the right padding (space) of an element. Note When not using 'auto', the supported css units for the dimension properties are: fixed: px relative: % and vh/vw Flex Layout Note Recommended reading: Flex and How to Use Flex. Style CSS Property Direction flex-direction specifies the direction of the flexible items: Row, Row reverse, Column, or Column reverse. Justify justify-content aligns the flexible container's items when the items do not use all available space on the main-axis (horizontally): Start, End, Space between, Space around, or Centre. Align Items align-items specifies the default alignment for items inside the flexible container: Start, End, Bottom, Stretch, Centre. Wrap flex-wrap specifies whether the flexible items should wrap or not: No wrap, Wrap, Wrap reverse. Grow flex-grow is an integer that specifies how much the item will grow relative to the rest of the flexible items inside the same container. Align Self align-self specifies the alignment for the selected item inside the flexible container: Auto, Start, End, Bottom, Stretch, Centre. Typography Style CSS Property Font font-family specifies the font for an element: Arial, Arial Black, Brush Script MT, Comic Sans MS, Courier New, Georgia, Helvetica, Impact, Lucida Sans Unicode, Tahoma, Times New Roman, Trebuchet MS, Verdana Font size font-size sets the size of a font. Either string or an integer along with a fixed (px) or relative (%, em, rem, vh, or vw) css unit. Font Weight font-weight sets how thick or thin characters in text should be displayed: Thin, Extra-Light, Light, Normal, Medium, Semi-Bold, Bold, Extra-Bold, or Ultra-Bold. Font Style font-style specifies the font style for a text. Normal, italic, or oblique. Line Height line-height specifies the height of a line using a fixed (px) or relative (%, em, rem, vw, or vh) css unit. Font Color color specifies the color of text by name, RGB, or RGBA. Text Align text-align specifies the horizontal alignment of text in an element: Left (default), Center, Right, or Justify. Text Decoration text-decoration specifies the decoration added to the text: Underline, Strikethrough, or None (default). Word Spacing word-spacing increases or decreases the space in pixels between words in a text (default normal). Letter Spacing letter-spacing increases or decreases the space between characters in a text (default normal). Either string or an integer along with a fixed (px) or relative (%, em, or rem) css unit. Wrap Text Sets whether text should be wrapped: Yes or No. Wrap Text At The options are Spaces, Capitals and Symbols, and Anywhere. Decorations Style CSS Property Background Color background-color sets the background color of an element by name, RGB, or RGBA. The background of an element is the total size of the element, including padding and border (but not the margin). Border Width border-top-width sets the width of an element's top border in px or em. border-right-width sets the width of an element's right border in px or em. border-bottom-width sets the width of an element's bottom border in px or em. border-left-width sets the width of an element's left border in px or em. Border Style border-style sets the style of an element's four borders: Solid, Dotted, Dashed, Double, Groove, Ridge, Inset, Outset, or None. Border Color border-color sets the color of an element's four borders by name, RGB, or RGBA. Border Radius Add rounded borders to the corners of elements: border-top-left-radius defines the radius of the top-left corner. border-top-right-radius defines the radius of the top-right corner. border-bottom-left-radius defines the radius of the bottom-left corner. border-bottom-right-radius defines the radius of the bottom-right corner. Background background adds one or more image layers, each comprising: Image (file or URL) Repeat (repeat, repeat-x, repeat-y, no-repeat) Position (left top, left center, left bottom, right top, right center, right bottom, center top, center center, center bottom, Attachment (scroll, fixed, local) Size (auto, cover, contain) Advanced Styling These styling options are rarely needed, but they provide additional flexibility for expert users. Advanced position and displayed styling Style CSS Property Display display specifies the type of rendering box of an element: block, inline, inline-block, flex (default), or none. Position position specifies the type of positioning used for an element: static (default), relative, absolute, or fixed. Top* top sets the vertical position of a positioned element (default auto). Right* right sets the horizontal position of a positioned element (default auto). Left* left sets the horizontal position of a positioned element (default auto). Bottom* bottom sets the vertical position of a positioned element (default auto). Note The supported css units for properties marked with a * are: fixed: px relative: % and vh/vw Extra advanced styling Style CSS Property Transition transition adds one or more transition effect layers, each comprising: transition-property (all, width, height, background-color, transform, box-shadow, opacity) transition-duration how many seconds the effect lasts Easing (linear, ease, ease-in, ease-out, ease-in-out) Perspective perspective defines how far the object is away from the user. A lower value will result in a more intensive 3D effect than a higher value. Z Index z-index specifies the stack order of a positioned element. Transform Apply 3D mouseover effects to transformable elements: rotateX() rotates an element around its X-axis at a given degree. rotateY() rotates an element around its Y-axis at a given degree. rotateZ() rotates an element around its Z-axis at a given degree. scaleX() defines a 3D scale transformation by giving a value for the X-axis. scaleY() defines a 3D scale transformation by giving a value for the Y-axis. scaleZ() defines a 3D scale transformation by giving a value for the Z-axis. Pointer Events pointer-events defines whether or not an element reacts to pointer events: All (default) or None. Cursor cursor sets the mouse cursor, if any, to show when the mouse pointer is over an element: Auto (default), Allowed, Help, None, Pointer, Progress, Wait, Zoom In, or Zoom Out. Note: Pointer Events must be set to All for the Cursor changes can be applied. Advanced flex layout styling Style CSS Property Flex Container flex-container enables all flexible items be the same length, regardless of content. Shrink flex-shrink is an integer that specifies how the item will shrink relative to the rest of the flexible items inside the same container. Basis flex-grow is an integer that specifies how much the item will grow relative to the rest of the flexible items inside the same container. Order order is an integer that specifies the order of a flexible item relative to the rest of the flexible items inside the same container. Typography advanced styling Style CSS Property Text Shadow text-shadow adds one or more layers to the text, each comprising an X position, Y position, and Blur (px or %) - as well as a Color (name, RGB, or RGBA). Advanced decoration styling Style CSS Property Overflow overflow sets the desired behavior when content does not fit in the parent element box (overflows) in the horizontal and/or vertical direction: visible (default), hidden, scroll, or auto. Opacity opacity sets the transparency of an element, where 1 is not at all transparent, 0.5 is 50% see-through, and 0 is completely transparent. Box Shadow box-shadow adds one or more shadow layers to an element, each comprising an X position, Y position, Blur, and Spread (px or %) - as well as a Color (name, RGB, or RGBA) and Shadow Type (Outside, Inside). Further Reading How to use Block Styling and Devices How to use Flex"
  },
  "src/concepts/application/block.html": {
    "href": "src/concepts/application/block.html",
    "title": "Block | XMPro",
    "summary": "Block A Block is an element or control available to be added to the Page. Blocks make up the foundation of the Application's design and content, including any text, headings, images, or data that needs to be displayed to the user of the Application. Blocks are accessed through the Blocks tab in the page designer and can be added to the Page by dragging them onto the Canvas. Blocks can also be searched by typing in the search bar at the top. List of Blocks Layout Accordion Box & Data Repeater Box Card & Content Card Fieldset & Field Layout Grid Menu Scroll Box Stacked Layout Horizontal & Vertical Tabs Templated List Toolbar Basic Calendar Check Box Color Selector Data Grid Date Selector Dropdown Grid Embedded Page File Library File Uploader Html Editor Image Indicator List Lookup Number Selector Radio Buttons Range Slider Select Box Switch Tags Text Text Area Textbox Tree Grid Tree List Device Input Location Capture Visual Media Capture AI Azure Copilot ChatGPT Copilot Actions Box Hyperlink Button Data Operations Hyperlink Recommendations Alert Action Alert Analytics Alert Discussion Alert Event Data Alert Form Alert List Alert Timeline Alert Triage Alert Survey Recommendation Chart Visualizations Autodesk Forge Azure Digital Twin Hierarchy Bar Gauge Chart Circular Gauge D3 Visualization Esri Map Image Map Linear Gauge Live Feed Map Pie Chart Pivot Grid Polar Chart Power BI Sparkline Time Series Analysis Tree Map Unity Unity (Legacy) Advanced Metablock Note Can't find the Block you're looking for? Contact support to submit a feature request. Further Reading How to Create and Manage Widgets"
  },
  "src/concepts/application/canvas.html": {
    "href": "src/concepts/application/canvas.html",
    "title": "Canvas | XMPro",
    "summary": "Canvas The App Designer Canvas is a drag and drop editor for creating customized web pages. UI Blocks are elements or controls such as a textbox that can be dragged from the toolbox to anywhere on the Canvas. See the UI Blocks article for more details on UI Blocks. This is the functionality that allows anyone on your team to create and deploy applications without needing to be a programmer. Controls such as graphs, gauges, or charts can be populated with real-time data from different systems. For example, live data from running systems or machines can be displayed directly to the user. See the Data Integration article for more details on integrating data sources into the page. The Blocks that are added onto the Canvas are what make up the overall design of a Page for the Application. Each Page in the App has its own Canvas that can be customized, and this can be opened by going into the Application and editing the Page. Block Toolbar A Block is outlined in blue on the canvas when it is selected. A blue toolbar will appear on the top-right corner of the Block which will provide options to move, clone, or do other actions on the Block. Note that some of these only apply to certain elements that allow these functions. Action Icon Description Move Allows you to click and drag the Block to move it to a different location on the Canvas. You can also click and drag from anywhere on the Block itself, but the Block may be obscured by its children. Select Parent Selects the parent of the currently selected Block. Clone Clones the selected Block. Add Adds a new section of the Block, for example, a new tab or column. Save As Widget Saves the selected Block and its inner Blocks as a Widget, which allows this group to be re-used later. See the Widgets article for more details on Widgets. Delete Deletes the Block. Canvas Hierarchy Blocks are organized on the Canvas using a hierarchy. The Canvas itself is made up of Blocks nested under other Blocks, and this makes up the overall design of the Page. When each Block is selected, it will be outlined and can help identify what part of the hierarchy it belongs to, including all of its parent Blocks and children Blocks. For example, there could a parent Block that contains multiple Blocks inside it, to form a grid of gauges containing a different value each. The hierarchy can also be viewed as a list in the Page Layouts tab in the Toolbox. See the Page Layers article for more details on Page Layers. Data Sources You can connect Data Sources to blocks on the canvas by going to 'Data Source' under 'Block Properties'. This allows you to view data on the Page based on a connected Data Source. See the Data Integration article for more details on Data Sources. Further Reading How to Design Pages"
  },
  "src/concepts/application/data-integration.html": {
    "href": "src/concepts/application/data-integration.html",
    "title": "Data Integration | XMPro",
    "summary": "Data Integration Data Integration refers to connecting an Application to a source of data, be it a database, a Data Stream, a Recommendation, or something else. Data Integration is needed if you want to display any real-time or context data to the user, such as through statistics or graphs. The App has a number of Data Sources, which connect to a source of data through a connector, using the parameters defined in a Connection. App Designer Connector Connectors allow you to connect to third-party sources of data. You can assume that Connectors have already been set up by your Company Administrator. See the Connectors article for more details on Connectors. XMPro has a library of Connectors available to use. To acquire any of these Connectors, please contact your XMPro sales representative or write to us at support@xmpro.com. Alternatively, since Connectors can be written by anyone that has some knowledge of programming and has access to the required technologies, you can write your own Connector by following these instructions. Connection The parameters defined in a Connection allow the App to connect to a source of data like a SQL Database and expose the entities as Data Sources within the Page. Connection parameters can include credentials such as a username, password, path, URL, or location identifier that you can use to make a remote connection to the Data Source. For example, connection parameters to connect to an SQL Database would include the Server Name, Authentication type, Username, and password. A new App will have the Recommendations Connector and the Data Stream Connector by default. Connections are managed in an App by clicking the App Data command. Any Connections that were created with an older version of a Connector will have an upgrade icon. The properties of a Connection are dependent on the type of Connector. To see the properties of a Connection, click the Connector in the list of Connectors above. Upgrade the Connection If the Connector has a newer version, an upgrade icon will appear on the App Data list indicating that the Connection can be upgraded, and the Upgrade action will become available. This upgrades the Connection to use the latest uploaded version of the Connector. Data Source Data Sources are a link to a specific Entity in a Connection's Entities, for example, a table in a SQL database. Data Sources are managed through the Page Data tab of a Page. You can add a new Data Source by clicking on the + button to the right of the Data Sources heading, and edit a Data Source by clicking on the pencil button to the right of the Data Source. If the Connection has the ability to have Live Data Updates, the checkbox will be visible. If checked, the Data Source will automatically update the Blocks when new data becomes available without refreshing the Page. Primary Key A primary key is the column or columns that contain values that uniquely identify each row in a table. Without a primary key, we cannot update, insert or delete data in the table. The Primary Key is a required field and cannot be empty. If the selected Entity has a Primary Key it will be specified automatically in the Primary Key field otherwise it has to be specified manually by selecting one or multiple columns from the list. Data Source Validation A Data Source may become invalid due to several issues. The most common ones can be expired passwords, deleted entity or unreachable servers. If a Data Source becomes invalid a count will be visible on the Page Data tab to notify the user. If you click the Page Data tab of the page, an exclamation mark will be visible in front of the Data Source name and hovering over the exclamation mark will show a detailed error. Data Source in the Page Blocks A Data Source may be attached to many Blocks. Blocks that allow Data Sources to be attached have a section in Block Properties called Data Source. If a Data Source is applied to a Block, depending on what type of Block it is, it will either repeat itself or repeat its child elements per the number of rows of the Data Source or use the data to populate its items or visualization. For example: Repeating Blocks will display a single record in each block, and a new block will be created for every record in the data source. All blocks will be created with the same styling as the first one. Blocks that populate items will display all records in a single Block. The parameters of the Data Source are then made available to its Action if it allows one, and all its descendants' Dynamic and Quick Expression value bindings. Note See the Block Properties article for more information on Dynamic and Quick Expression values. List of Data Source Blocks The following Blocks populate their items or visualization with rows from the Data Source. Accordion Autodesk Forge Chart D3 Visualization Data Grid Dropdown Grid List Lookup Pie Chart Pivot Grid Polar Chart Radio Buttons Select Box Sparkline Tabs Tags Templated List Tree Grid Tree List Unity The following Blocks repeat themselves/create a new block for each record in the Data Source: Box & Data Repeater Box Card & Content Card Fieldset Horizontal Stacked Layout Vertical Stacked Layout Parameters If a Data Source has Input Parameters, the Parameters option will be available. Here you can add a Static or Dynamic Value to each Input Parameter. Filter A Filter may be applied to the Data Source on the Block, which will then only retrieve data that matches the Filter. You can add new conditions or groups by clicking the + button. Groups can be nested within each other to create advanced logic. In an \"And\" group, all the conditions must be true, and in an \"Or\" group, only one of the conditions must be true to trigger an Alert. As an example, in the following Filter, both of the following must be true for the data: Average must be greater than 50, And V1, V2, or V3 must be greater than 60. Sort You can sort the data by any field in ascending or descending order. Show/Skip You can choose to only retrieve a certain number of items and/or skip a certain number of items by adding values to Show # of Results and Skip # of Results. Show Default Row If the control is of the type where the block repeats itself/creates a new block for each record, the Show Default Row option will be available. This defines whether an empty row will be added at the end of the rows received from the Data Source, allowing you to insert a new row into the Data Source. Further Reading How to Create and Manage Connections How to Create and Manage Data Sources How to use Data Sources in the Page"
  },
  "src/concepts/application/devices.html": {
    "href": "src/concepts/application/devices.html",
    "title": "Devices | XMPro",
    "summary": "Devices An App can be deployed on multiple devices such as a laptop, tablet, or phone. The style and position of the Blocks can be configured to make sure it is compatible with the screen width of the device. This is needed in order for you to view the way the Application looks on multiple devices, and to ensure users have a good user experience regardless of the screen size they are viewing your Application on. Responsive Design All pre-built page layouts come with predefined styles and media queries to ensure that Blocks are responsive on different devices. When using a pre-built layout, the positions of the Blocks will automatically change when switching between desktop, tablet, and mobile in order to fit everything comfortably on the page regardless of the screen width. Configuring Desktop, Tablets, and Phones Changes such as block styling made to desktop devices are automatically applied to devices of all sizes. Changes made to tablet devices affect screens smaller than 1366 pixels, and changes made to mobile mode affect screens smaller than 896 pixels. If a different style is configured for both desktop and mobile mode, the mobile mode style will override the styles of larger devices when viewing in mobile mode. The same applies to the tablet. The styles applied to devices are applied to both the selected style group and the selected state as well. Further Reading Block Styling How to use Block Styling and Devices How to use Flex"
  },
  "src/concepts/application/flex.html": {
    "href": "src/concepts/application/flex.html",
    "title": "Flex | XMPro",
    "summary": "Flex Flex (CSS Flexbox Layout Module) is a way to design flexible responsive layouts for web pages. The main concept behind flex is the flex container. If you set a container to display: flex;, its child items' width or height will be expanded or shrunk to best fill the space available. The direction the flex items will be stacked in is determined by the flex-direction property. The options include row, row-reverse, column, and column-reverse. The alignment of the items in the main-axis (horizontal if flex-direction is row or row-reverse, vertical if flex-direction is column or column-reverse) is determined by the justify-content property. The options include flex-start, flex-end, space-between, space-around, and center. The alignment of the items in the cross-axis (vertical if flex-direction is row or row-reverse, horizontal if flex-direction is column or column-reverse) is determined by the align-items property. The options include flex-start, flex-end, stretch, and center. The child items of a flex container have a say in how they are altered. The flex-grow property on the child of a flex container defines whether the item should be the desired ratio of this item compared to its siblings. The flex-shrink property defines how much a flex item will shrink relative to the rest of the flex items. Best used in conjunction with the flex-basis property. The flex-basis property specifies the initial length of an item on the main-axis. Further Reading How to Use Flex in a Page"
  },
  "src/concepts/application/index.html": {
    "href": "src/concepts/application/index.html",
    "title": "Application | XMPro",
    "summary": "Application An XMPro Application or App is an event-driven web application created using XMPro's no-code App Designer. It enables subject matter experts to create and deploy real-time, event intelligence applications without being a programmer. This means that Engineers and subject matter experts can build apps in days or weeks without further overloading IT, enabling your organization to accelerate and scale your digital transformation. Applications are accessed through the App Designer Categories dashboard or the Applications button on the left menu. Finding Applications The search bar can be used to find any specific Apps that you may be looking for. There is a dropdown option where you can specify to search through everything in App Designer, or only for Apps. Overview Applications are grouped into categories, which are selected in the App properties. They are displayed on the App Designer home page dashboard and in the Applications list under their category. The dashboard shows the Apps' name, description, and icon as well as the publish status and date last modified. Applications have a Default Theme, which is the theme selected when any new pages are created. Each page can have its own theme. Page An Application is made up of one or more Pages. A Page is a web page within the Application that can be built using the no-code App Designer. The Application starts with a Landing Page, which acts as the main home page and is the first page to open when a user opens the application. Users can edit Pages or build the content on the webpage by selecting and dragging Blocks such as controls or text onto a Canvas. An application can then be launched in order to see a preview of what the Application would look like during runtime. Pages can also be configured to display real-time or contextual data directly from a source of data, such as a database, Data Stream, or Recommendation. This can be done using Data Integration. Pages can also be configured to navigate to other pages, where data can also be passed between pages using parameters. See the Page article for more information on pages. Versions Different versions of Applications can be made to keep track of any major or minor changes made. Versions of an application can be opened by selecting the 'Versions' tab when editing the application. Viewing a particular version will open the application for that version. Copying a version allows you to continue working and making changes to the application while maintaining a version of it before you made changes, which can also act as a backup mechanism. See the Version article for more information on versions. Access An Application can be shared with other users. The person who originally created the Application will be listed as the owner and can never lose his/her right to access it unless it is deleted. When the application is shared with another user, the person sharing it can decide whether to give them co-owner, read, or write access to the application. See the Manage Access article for more information on managing access. Template An Application can be saved as a Template which can then be used again by you or other users when creating a new Application. The Template will show as a pre-designed application that can be selected when configuring the layout of the new App. See the Templates article for more information on Templates. Company Landing Page A Company Landing Page can be set for what Application Landing Page the user will see when they first open App Designer. You can choose to set a Company Landing Page for both Desktop or Mobile. You can select a different App for Desktop and a different App for Mobile. See the Manage Landing Pages article for more information on Templates. Actions on the Application Action Description Properties Opens the properties for the selected App. Also allows you to Delete the App. App Data Opens the App Data section. See the Data Integration article for more details about Data Integrations. Publish/Unpublish Publishes or unpublishes the Application. Manage Access Allows you to manage which users are allowed to view or modify this Application. Versions Versioning for the Application. Save Template Saves the current Application as a Template to create new Applications from. See the Templates article for more information on templates. Notes Opens the Notes, which allows you to add notes about the Application for collaboration and future-proofing. Export Export the Application. Clone Clone the Application App Files Opens the App Files, which allows you to manage files uploaded to this app. See the App Files article for more details about App Files. Save Saves any changes made to the Application up to this point. Discard Discards any changes made to the Application up to this point. Delete Deletes the Application. Add Page Allows you to add and import a Page to the Application. The Add Page button is located at the top right corner of the App Pages list. See the Page article for more information on Pages. Further Reading How to Create and Manage Applications How to Create and Maintain notes How to Manage Themes How to Set a Company Landing Page"
  },
  "src/concepts/application/metablocks.html": {
    "href": "src/concepts/application/metablocks.html",
    "title": "Metablocks | XMPro",
    "summary": "Metablocks New XMPro block release XMPro's Metablock lets users embed custom HTML, JavaScript and CSS directly into an AD App Page. This allows for the creation of highly tailored and interactive components. By connecting these blocks to your own data sources, you can develop solutions that seamlessly integrate with XMPro Data streams and data sources. Metablock offers a way to extend the functionality of XMPro, enabling advanced customization and real-time data interaction. Key Features Custom Embedding Embed custom HTML, JavaScript and CSS to create unique components within your app pages. Data Source Integration Connect Metablock to various data sources to enhance data interaction and visualization. Customizable Key-Value Pairs users can define their own key-value pairs and seamlessly utilize them within their application. Advanced Customization Leverage the flexibility of Metablock to tailor the functionality and appearance of your applications to meet specific requirements. Use Cases for Metablocks A small list of potential examples of the use of Metablocks includes: Specialist Graphing Rendering 3D Images From Apps Like Autodesk or Unity Collaboration Boards Like Excalidraw or Miro Gen AI Interfaces Live Vision Monitoring and Visualization Tools to Offer an Alternative to Grids Future Capabilities Metablock is set to evolve with exciting new features and enhancements. Our goal is to empower users by integrating familiar tools and providing an enriched custom experience. Summary In essence, Metablocks is a flexible and customizable tool that improves application development with advanced visualizations and integration features. Its evolving capabilities allow users to create and manage custom Metablocks easily, keeping applications adaptable and up-to-date. Focused on user flexibility and smooth integration, Metablocks is a key asset for modern application development."
  },
  "src/concepts/application/navigation-and-parameters.html": {
    "href": "src/concepts/application/navigation-and-parameters.html",
    "title": "Navigation and Parameters | XMPro",
    "summary": "Navigation and Parameters It is possible to allow navigation between Pages of an App by configuring the Action of a Block, and pass data to the Page by configuring the Pass Page Parameters option. You can add Parameters to the Page you are navigating to, and configure what value should be passed to them when the button is clicked. You can choose Dynamic or Static values. Parameters may be needed if you want to send particular values onto another page as the user clicks on it. For example, if you have a list of machines, and a user selects one, the application may open a new page that displays information for that particular machine. In that case, you may want to pass the ID of the machine the user clicked on to the page that is being opened. You can add and edit Parameters for the current Page in the Page Data tab. Parameters have a Type that restricts what type of data can be sent to the Parameter. The options for Type are Boolean, DateTime, Double, Int, Long, and String. The following Blocks allow Action: Box Hyperlink Button Chart Esri Map Data Grid Hyperlink Indicator List Map Templated List Toolbar Tree Grid Tree List Further Reading How to Navigate between Pages How to Pass Parameters Between Pages"
  },
  "src/concepts/application/page-layers.html": {
    "href": "src/concepts/application/page-layers.html",
    "title": "Page Layers | XMPro",
    "summary": "Page Layers Blocks are organized on the canvas in a hierarchy. The Page Layers tab in the toolbox displays a tree list representation of the hierarchy. This can make selecting blocks simpler and easier as some applications may have many nested layers and it can be difficult to select them on the canvas itself. This allows you to find the exact block you need to manipulate. Parent Blocks can be expanded to view their nested Child blocks underneath. See the Canvas article for more details on the canvas hierarchy. The visibility of the block and the location of the blocks on the canvas can also be moved using this Page Layers list. A Block on the canvas will be outlined if it is selected. If the Page Layers tab is opened, the list will also update to show where the block is on the hierarchy. The number on the right shows how many children blocks the selected block has. Actions on the Page Layers Action Description Change visibility Changes the visibility of the selected Block. If changed to hidden, the Block will not be seen on the canvas or when the page is launched. Expand Expands a selected Block to see the children. Collapse Collapses a selected Block's children. Select Selects a Block. The selected block will be outlined on the canvas. Drag/Move Moves the Block to a different location. This will also change the Block's location on the canvas. Rename Renames the outline surrounding the Block. The Block's name is not shown anywhere when in view mode, it is purely for the sake of clarity in edit mode. Further Reading How to use Page Layers"
  },
  "src/concepts/application/page.html": {
    "href": "src/concepts/application/page.html",
    "title": "Page | XMPro",
    "summary": "Page A Page is a web page built with XMPro's No Code App Designer. Applications can have one or more Pages in them and can navigate and pass data between Pages. One of the Pages is marked as a Landing Page, which means it functions as a home page and is the first page that will be navigated to when opening an App. Pages can be edited by clicking on a page in the App Pages list while editing an Application, or by clicking the edit button in the top right of a page while viewing an Application if you have edit access. When editing a Page you can click and drag the grey header to scroll left and view the list of Pages for the whole App. The Page editor has the following sections: Area Description Blocks and Properties You can switch between the tabs by clicking on the commands at the top. You can drag and drop blocks from the Blocks (Toolbox) tab into the Canvas, customize Block styling and properties from their respective tabs, manage Parameters, Variables, and Data Sources from the Page Data Tab, and see a hierarchical view of the Canvas in the Page Layers tab. For more details on each concept, visit the Page Layers article, Blocks article, Block Styling article, Navigation and Parameters article, Variables and Expressions article, and Data Integration article. Actions Actions can be performed on the page by clicking on commands here. The commands in the middle of the command bar switch between different screen widths and apply a media query to any Block Styles applied while selected Devices The commands in the middle of the command bar switch between different screen widths or Devices and apply a media query to any Block Styles applied while selected. See the Devices article for more details on Devices. Canvas The Canvas is a no-code drag and drop editor for creating customized web pages. UI elements and blocks such as text boxes, graphs, or other various controls can be dragged onto the Canvas from the toolbox to build the contents of the Page. See the Canvas article for more detail on the canvas. Theme You can select from two themes for Pages: Light and Dark. An example of each theme is shown below. Light Dark Page Layouts When a Page is created there is a choice between 12 different Page Layouts. The layouts have built-in responsive styles and reshape into a single column in a smaller screen layout. The layouts are as follows: Page Layout Order of Cards on Mobile Responsive Page Layout Example Desktop Mobile Actions on the Page Action Description Save Saves any changes made to the Page up to this point. Discard Discards any changes made to the Page up to this point. Undo Undo any changes made to the Page up to this point. Redo Redo any changes made to the Page up to this point. Show Borders Switches the Canvas between two modes: Bordered, in which every block has a dotted outline around them (invisible when viewing the Page), and Unbordered, in which blocks do not have outlines and are shown as they will be when viewing the Page. Export Exports the Page layout. Does not include Data Sources. Settings Opens the Page Settings, where you can change the Name and Theme, and delete the page. Launch Launches the page as it will be viewed in the Application. Delete Deletes the Page. Further Reading How to Create and Manage Pages How to Import an App Page How to Design Pages for Mobile How to Navigate Between Pages How to Pass Parameters Between Pages"
  },
  "src/concepts/application/template.html": {
    "href": "src/concepts/application/template.html",
    "title": "Template | XMPro",
    "summary": "Template Templates are pre-designed Applications that can be selected when creating a new Application. Templates can be used to save time without having to build a whole new app layout from scratch, and also allow you to create a consistent theme or design that you can use across all your Applications. The base Template that the App Designer starts with is the Blank App. The Blank App creates an Application with one Landing Page and provides a choice of Page Layout the same as creating a new Page. Other templates are designed and saved by a user and have whatever page layouts the Application had when it was saved as a template. Templates can be searched by name, and filtered by category. When you click a Template it will give you a preview with screenshots, Name and Description, and a list of Pages that the Template contains: Templates are created by clicking Save as Template on an App. This will create a Template that has the Pages of the App. The Thumbnail screenshot will be shown on the New App page, and all the screenshots will be visible after clicking on the Template on the New App Page. Note Please note that any Data Sources on the Pages will not be saved into the Template. Existing Templates are managed by clicking the Templates button in the left menu. Finding Templates The search bar can be used to find any specific Templates that you may be looking for. There is a dropdown option where you can specify to search through everything in App Designer, or only for Templates. Actions on the Template Action Description Save Saves any changes made to the Template up to this point. Discard Discards any changes made to the Template up to this point. Delete Deletes the Template. View Navigates to the Template view. Export Exports the Template. Further Reading How to Create and Manage Templates"
  },
  "src/concepts/application/variables-and-expressions.html": {
    "href": "src/concepts/application/variables-and-expressions.html",
    "title": "Variables and Expressions | XMPro",
    "summary": "Variables and Expressions Variables Variables are a way to store a value for later use, or, when in Expression mode, to calculate a value from other Variables, Parameters, user input, data from Data Sources, and various Functions, Constants, and Operators. Variables are managed through the Page Data tab in the page editor. They have two modes - Value and Expression. In Value mode, the Variable takes the latest changed value of the Block's value. In Expression mode, the Blocks' values are overridden by the calculated value of the Variable. Expressions An Expression is an extra column on a Data Source that calculates its value according to the designed expression. Quick Expressions A Quick Expression is a quick one-off expression you can assign to a Block Property. To access Quick Expressions, cycle through the property's modes with the button on the left until it becomes an Expression. Expression Editor The Expression Editor is where an Expression is built. At the top is a text area in which you can type the expression. Below the text area are three sections - the categories, the Expression terms, and the description areas. Clicking on a category will show different items in the Expression terms area, and clicking on an Expression term will show a description of the term in the description area. Double-clicking an Expression Term will enter that term in the text area at the position of the cursor. Variables Example In the following example, the Circular Gauges take their value from Variables. There are three variables - A, B, and C. A and B are in Value mode, and C is in Expression mode with the following expression: {Variable.A} + {Variable.B} Further Reading How to Create and Manage Variables and Expressions"
  },
  "src/concepts/category.html": {
    "href": "src/concepts/category.html",
    "title": "Category | XMPro",
    "summary": "Category Overview A Category is a container that groups related Data Streams and Applications. Categories are shared between core XMPro Products to provide a homogenous environment. They are displayed as cards on the home page of the Data Stream Designer and App Designer. Clicking on the card will navigate to a dashboard showing the Data Streams or Apps associated with that Category. Categories are useful as they allow you to group your Data Streams, Applications, or other XMPro Objects into logical areas. Organizations have the flexibility to create Categories based on their specific requirements such as the organizational structure of their asset hierarchy. Finding Categories The search bar can be used to find any specific Categories that you may be looking for. There is a dropdown option where you can specify to search through everything in App Designer, or only for Categories. Empty Categories A Category that doesn't have any Apps or Data Streams inside it will not be shown on the dashboard. App and Data Stream Indicators An indication of the state of the items contained within a Category is shown at the bottom of each tile. What the numbers represent is as follows: The number of published Apps or Data Streams. The number of unpublished Apps or Data Streams. Default Category The Data Stream Designer or App Designer will have one Category defined after it is initially installed, called \"My Sandbox\". This Category is used as a default Category as there is a requirement for all Data Streams or Apps to belong to a Category. In terms of the Application, no Data Stream or Application is allowed to exist if it doesn't belong to a Category. After installing Data Stream Designer or App Designer, you can create any Category you like. However, when the default Category is left empty (not containing any Data Streams or Apps), it will not display on the landing page after at least one other Category is created. You will still be able to see it on the Categories page and create Data Streams or Apps in it. Once you've created a Data Stream or App in it, it will show up on the landing page once again. Deleting a Category If you delete a Category, all of the Apps or Data Streams inside of that Category get put into My Sandbox. Order The way Categories are displayed on the list can be reordered. This can be done by selecting the reorder option and selecting and dragging the Categories to reorder them. Further Reading How to Create and Manage Categories"
  },
  "src/concepts/collection.html": {
    "href": "src/concepts/collection.html",
    "title": "Collection and Stream Host | XMPro",
    "summary": "Collection and Stream Host Note It is recommended that you read this documentation along with the articles listed below to improve your understanding of how Stream Hosts and Collections work. Agents Data Stream Processing Overview Watch the video below for an introduction to Stream Hosts and Collections, and their role in enabling scalable real-time data processing. Whether you're overseeing a few assets or thousands, stream hosts and collections provide the flexibility, efficiency, and scalability needed to transform your data operations. Video 1: How XMPro Stream Hosts and Collections Enable Scalable, Real-Time Data Processing Stream Hosts A Stream Host is an application that can be installed as a Docker container, a Windows Service, or a Console Application. Stream Hosts enable Data Streams to run and execute actions and are also responsible for getting the configurations of Non-Virtual Agents. In other words, the Stream Host application needs to be running for Agents in a Data Stream to process the data, according to the design of the Stream. Both Virtual and Non-Virtual Agents essentially run on a Stream Host, but how they are handled at design time differs greatly. Non-Virtual Agents require a Stream Host to be online for Data Stream Designer to be able to get their configurations, but Virtual Agents don't need a Stream Host to be running. Collections Stream Hosts are grouped into different Collections, which are created and maintained in Data Stream Designer. A Collection can be defined as a Category that contains a set of Stream Hosts that run the same Data Streams. Each Stream Host is associated with a Collection by keeping the ID of the Collection in the appsettings.json file of the Stream Host, which can be found in the location where the Stream Host has been installed. Thus, all the Stream Hosts that have the same Collection ID stored in this file, will automatically fall under the Collection that has that ID. After creating a Collection within Data Stream Designer, you can associate a Data Stream with a default Collection. Unless changes are made for individual Agents in your Data Stream, each Agent will use this Collection to perform the actions it was designed to perform. However, Data Stream Designer allows you to build a stream in which some Agents use one Collection and others use a different Collection. For more information on how to configure this, click here. Along with the Collection ID, the appsettings.json file contains other configurations for the Stream Host. Each of these configurations are listed and described in the table below. Property Description ID Uniquely identifies the Stream Host. Name Name of the Stream Host. Collection ID ID of the Collection associated with the Stream Host. Rank Indicator of the preference given to the Stream Host. This especially applies when more than one Stream Host with the same Collection ID is running. The Stream Host with the lowest rank will be used to get the configurations of Non-Virtual Agents. The rank has a default value of 0. See Stream Host Rank. Secret Used to verify the connection between the Stream Host and the Collection. This field needs to correspond to the Key that is stored for a Collection in Data Stream Designer. If this key is revoked/replaced, all Stream Hosts will be disconnected. Server URL URL that the Stream Host needs to use to connect to Data Stream Designer. Cryptography key Key that the Stream Host will use to encrypt or decrypt secure user settings, for example, a SQL Server Password. The table below contains a list of the configurations stored for a Collection along with a description for each. This information can be found by opening the Collections page from the left-hand menu in Data Stream Designer and selecting your Collection from the list. Please note that the only field you will not be able to change is the ID of the Collection. Property Description ID Uniquely identifies the Collection. Key Used to verify the connection between the host and Data Stream Designer. If this key is revoked/replaced, all Stream Hosts will be disconnected. Name Name of the Collection. Remote Receiver See Remote Receivers and Publishers. Remote Publisher See Remote Receivers and Publishers. Metadata Tags that have been added to the Collection. Publish and Unpublish Data Streams On the Collections page, click More and Data Streams to view a list of all Data Streams that are using a given Collection. Here you can directly unpublish or publish a Data Stream. As an Admin, this is useful if you need to unpublish a Data Stream and you don't have access to it. See the How to Admin Unpublish Override article for more details. Finding Collections The search bar can be used to find any specific Collections that you may be looking for. There is a dropdown option where you can specify to search through everything in Data Stream Designer, or only for Collections. Actions on the Collection Action Description New Adds a new Collection. Select Selects multiple Collections. Delete Deletes the selected Collections. Save Saves any changes made to the Collection up to this point. Discard Discards any changes made to the Collection up to this point. Stream Hosts Opens a new page with a list of hosts that have installed this Collection. Connection Profile Download the Connection Profile used in the installation of a Stream Host. Download Host Download the installation file for the selected platform. Variables Manage the Collection's Variables. Data Streams Opens a new page with a list of all Data Streams in the selected Collection. Revoke Key Revokes the current key and will generate a new one. Hosts that are using the revoked key will be unable to connect until their configuration is manually updated. Delete Deletes the selected Collection. Remote Receivers and Publishers The Remote Receiver and Remote Publisher properties are used to bridge the gap between Agents in a stream that is associated with different Collections, for example: Consider having a stream that has two Agents: Listener_A, which is associated with Collection_A, and Action_Agent_B, which is associated with Collection_B Listener_A needs to communicate to Action_Agent_B, but they belong to different Collections. As a result, the engine will automatically use the Remote Receiver and Publisher to pass data from one Collection to another. Please note that only MQTT is currently supported for this functionality. Example: Consider a stream that has the following Agents: Event Simulator Event Printer For the purpose of this example, the Event Simulator will be named ES_1 and the Event Printer EP_1, where ES_1 is using Collection_A and EP_1 is using Collection_B. Since these two Agents are using two different Collections, data flow from ES_1 to EP_1 is not possible as there is no physical connection (the Stream Hosts in these Collections can be on different machines in different parts of the world). To solve this problem and allow data flow from ES_1 to EP_1, the Collection EP_1 is using needs to be set up as follows: The Remote Receiver for Collection_B needs to be set to MQTT and the broker address needs to be specified. The Remote Publisher for Collection_B needs to be set to MQTT and the broker address needs to be specified. When the stream is published now, the data simulated by ES_1 will be published to MQTT, which will enable the engine to get the data EP_1 expects by listening for it on MQTT. Thus, data flow between ES_1 and EP_1 has been established. The below image is an example of the configuration for Collection_B. Connection Profiles Overview A Connection Profile is a file, containing certain details about a Collection, that can be downloaded from Data Stream Designer. The purpose of this file is to make the installation process of Stream Hosts easier by providing you with an option to upload this file to the Stream Host installer instead of manually specifying the Collection information. This file contains the values described in the table below. Property Description Device Name Name of the Stream Host. This name will be the same as the device name that needs to be specified when downloading a Collection Profile. If you install the Stream Host as a Windows Service, the service name and device name will be the same. Collection ID The ID of the Collection the Stream Host will be associated with. Secret Used to verify the connection between the stream host and the Collection. If this key is revoked/replaced, all stream hosts will be disconnected. Server URL URL that the Stream Host needs to use to connect to Data Stream Designer. This is the URL of the instance of Data Stream Designer that has been installed on the server. Key Key used to encrypt or decrypt user settings. Download a connection profile To download an installation profile, follow the steps below: Open the Collections page from the left-hand menu. Select the Collection you would like to install the Stream Host for. Click Connection Profile. Enter a Device Name. Click OK. The download will start automatically. Stream Host Installation To install a Stream Host, please refer to these instructions. Set Log Level The Log Level determines the type of information or level of detail that will be logged. The two Log Levels are Trace and Info. Info The Info Log level is the default Log Level. This will only log Info level messages or logs, which include details on when a Stream Host is starting or stopping. Any errors related to Connections or the Stream Host itself will also be logged at this level. Trace The Trace Log level will log more detailed messages and errors about the Data Stream or specific Agents themselves. This is very useful for debugging as it can log information about what is happening inside the code itself, such as which methods are being called and when. Using the Trace Log Level for a long period of time can take up a lot of space on the hard drive. Selecting the Trace Log Level will log both Trace and Info Level Logs. Stream Host Rank All the Stream Hosts contained in a Collection will be used to run the Data Streams associated with that Collection. However, you can choose which Stream Host should be responsible for getting the configurations of Non-Virtual agents. The rank given to a Stream Host defines what preference the Stream Host will be given in such a scenario. The Stream Host with the lowest rank will be picked by the system. All Stream Hosts will always have a default rank value of 0. Example Consider having a Data Stream with the following Agents: MQTT listener Filter transformation SQL Server Writer The purpose of this Data Stream is to get temperature readings from a sensor on a machine, filter the readings that are higher than 120°C and write these values to a table in a SQL Server database. All three agents are configured to use Stream Hosts in the \"Mine 09\" Collection to run (see image below). However, to get the user settings for the SQL Server Writer Action Agent, which is a Non-Virtual Agent, Data Stream Designer will pick and use the first Stream Host available. This can be changed by setting the rank of the Stream Host you want to use to be lower than the other Stream Hosts that are available. Further Reading How to Create and Manage Collections"
  },
  "src/concepts/connector.html": {
    "href": "src/concepts/connector.html",
    "title": "Connector | XMPro",
    "summary": "Connector Overview A Connector is a pre-built integration plug-in for the XMPro App Designer that allows you to connect to third-party data sources without writing code. They can be used when integrating data from data sources such as a database into an Application. This can include real-time data from machines, websites, other streaming data, or contextual data such as the make or model of a certain item. Connectors are useful if you want to use the data within an Application or display the data to the user on a page of an Application. Data Sources can include databases, Data Streams, or Recommendations. See the Data Integration article for more details. You can assume that Connectors have already been set up by your Administrator. Each Connector consists of code, settings, and other properties that are packaged into a file that can be uploaded to App Designer. XMPro has a library of Connectors available to use. To acquire any of these Connectors, please contact your XMPro sales representative or write to us at support@xmpro.com. Alternatively, since Connectors can be written by anyone that has some knowledge of programming and has access to the required technologies, you can write your own Connector by following these instructions. Category Connectors can be grouped into categories. This category is separate from the App and Data Stream Categories. Settings A Connector consists of code and user settings. The code defines the actions a Connector performs in App Designer. The settings are the input for the code that executes, provided by the user when adding the Connector to App Designer, such as authentication credentials. For example, consider the SQL Server Connector, which retrieves data from a SQL database. The settings a user must define for the Connector so it can do that are as follows: Name of the SQL Server instance SQL Server username Whether SQL Server authentication should be used or not SQL Server password Database to which the data should be written Finding Connectors The search bar can be used to find any specific Connectors that you may be looking for. There is a dropdown option where you can specify to search through everything in App Designer, or only for Connectors. Adding a Connector Connectors can be added by uploading their XMP file on the connectors page. Each version of a Connector has its own XMP file. When uploading an app, any missing Connectors that the app needs must be updated or uploaded for the app to be imported successfully. Versions Connectors can have multiple versions. For example, a new version of a Connector can be created if there are any changes or updates made to it. Changes or updates made to new versions of a Connector will not affect the previous versions. Each version of a Connector has its own XMP file. When uploading a Connector, a specific version of that Connector will be uploaded. To upload a different version, you will need to upload the XMP file for that specific version you want to use. When you view a Connector, you can see the list of specific versions for that Connector. The number of apps using each version is shown next to the version number. Apps that you do not have access to will not show on the list. When you upload a new version, the new version will be displayed in this list. When selecting a Connector to use in an app, the application will automatically choose the latest version available. Note When a new version of a Connector is uploaded, any apps using older versions may need to be upgraded. See the Data Integration article for more information on how to upgrade an app's connection. View and Edit Applications There is an alternate way to view or edit Applications directly from the Connectors page. When viewing a Connector, you will see the number of Applications using each version of the Connector. Expand to see the full list of Applications, which can be viewed by clicking on the Application or edited by clicking the Edit button. Publish and Unpublish Apps You can also publish or unpublish an Application that uses that version of the Connector. As an Admin, this is useful if you need to unpublish an Application and you don't have access to it. See the How to Admin Unpublish Override article for more details. Actions on the Connector Action Description Add Adds a new Connector. Select Selects multiple Connectors. Delete Deletes the Connector. Manage Categories Creates and edits categories to organize the Connectors. These categories are separate from the App and Data Stream Categories. Save Saves any changes made to the Connector up to this point. Discard Discards any changes made to the Connector up to this point. Delete Versions Deletes a selected version of a Connector. You can only delete versions that don't have any apps using that version of the Connector. If you don't have access to an app that a version is using, you still cannot delete the version. Further Reading How to Create and Manage Connectors"
  },
  "src/concepts/data-stream/index.html": {
    "href": "src/concepts/data-stream/index.html",
    "title": "Data Stream | XMPro",
    "summary": "Data Stream A Data Stream is a visual display of data flow, letting you integrate and connect various systems or data sources to view your information. This includes real-time data from machines, websites, or other streaming sources, as well as contextual data like an item's make or model. The Data Stream Designer lets you see all connected data in one place and manipulate it in different ways, such as aggregating, filtering, displaying, or saving to another database. You can monitor data to spot critical events like machine failures, without needing coding skills. Video Presentation Discussing Data Stream Designer Data Stream's flow is represented by agents connected by arrows, enabling data processing at each agent based on its function, allowing you to view and perform actions on data from multiple sources in one place. Note We recommend reading this documentation in conjunction with the Agent article to enhance your understanding of data streams. Finding Data Streams Use the search bar to find specific Data Streams, and select from the dropdown menu to search either throughout Data Stream Designer or only for Data Streams. Data Stream Type The Type selected in the Properties affects your choice of how often and when polling-based Agents run. Streaming (Default): This allows you to specify a Polling Interval in seconds on polling-based Agents in the Stream Object configuration. Polling starts immediately and continues indefinitely. Recurring: This allows you to specify granular options to schedule polling-based Agents in the Stream Object configuration. Options allow you to control the start time, repetition interval, and end time or number of repetitions. There is also the option to repeat indefinitely. Agent Event Queue Capacity v4.4.17: Replaced 'Event Buffer' for clarity in understanding how many events are buffered. The Data Stream includes an advanced option to manage high event volumes, or complex stream configurations. The Agent Event Queue Capacity property allows for a higher number of events to be queued for each Stream Object within the Data Stream reducing the risk of event loss. By default, the Agent Event Queue Capacity is set to 128 events per Stream Object. Warning Increasing the Agent Event Queue Capacity may result in the Stream Host consuming more memory. The Canvas Data streams are crafted in an interactive canvas, allowing you to drag agents from the toolbox to the drawing area. In the same environment, configure agent settings, manage versions, define business cases, and more. Stream Objects on the canvas can be duplicated or deleted, and for easy identification and access, they're marked with a unique color and abbreviation. The Toolbox The toolbox is a component in the Data Stream Designer that allows you to choose an Agent from a library of Agents that have been uploaded to the system and drag the agent from the toolbox to the Canvas when building a stream. All agents in the toolbox will always be the latest version and will all be available for all users, regardless of their role, unless a user does not have permission to view any of the Agents. Agents are grouped by category in the toolbox. To expand a category, click on the arrow next to the category name. Please note that if no agents in a particular category are uploaded, the entire category will be hidden. Thus, if you are missing some of the categories in the toolbox, it is likely that there aren't any Agents uploaded belonging to that category. Building a stream Note See the Manage Data Streams article for detailed instructions and an example of how to build your first stream. Actions on the Data Stream Action Description Save Saves any changes made to the Data Stream up to this point. Discard Discards any changes made to the Data Stream up to this point. Properties Opens the properties for the Data Stream. Also allows you to Delete the Data Stream. Business Case Opens the Business Case for the Data Stream. Notes Opens the Notes, which allows you to add notes about the Application for collaboration and future-proofing. Versions Versioning for the Data Stream. Timeline Opens the Timeline, which shows a timeline of the history of the Data Stream. Manage Access Allows you to manage which users are allowed to view or modify this Data Stream. Integrity Check Verifies if the agents in your stream are configured correctly. Logs Allows you to check for log messages for the Stream Host being used to run the Data Stream. Error Flow Toggles between being able to view and configure the default error Agent for the Stream, which collects all the errors from all agents with an Error endpoint. Publish/Unpublish Publishes or unpublishes the Recommendation, which makes it start listening for data from the Data Stream. Configure (Agent) Opens the configuration page for the selected Stream Object. Upgrade (Agent) Upgrades the selected Stream Object to the latest Agent Version. Only available if the selected Stream Object's Agent is not the latest version. Delete (Agent) Deletes the selected Stream Object from the canvas and Data Stream. Help (Agent) Opens the help page for the selected Stream Object's Agent. Delete Deletes the Data Stream. Export Export the Data Stream as an encrypted file. Clone Clones the Data Stream as a new Data Stream. Further Reading How to Create and Manage Data Streams How to Manage Recurrent Data Streams How to Troubleshoot a Data Stream"
  },
  "src/concepts/data-stream/running-data-streams.html": {
    "href": "src/concepts/data-stream/running-data-streams.html",
    "title": "Running Data Streams | XMPro",
    "summary": "Running Data Streams Running Data Streams Data Streams need to be running to start performing the functions they have been designed to do. When you click on the \"Publish\" button, your Stream will start running. As soon as this button is clicked, the engine will look at which Collection each Agent in the Data Stream is associated with. It will then look at which Stream Hosts are available for use in each Collection and use those Stream Hosts to allow Agents in that Collection to execute actions. To read more about how Stream Hosts and Collections work, click here. To verify which collection an Agent will use, click on the \"Configure\" button. Viewing Live Data The Live View functionality in Data Stream Designer allows you to view data as it is processed by the Agents in your Stream. For each Agent in your Stream, you can let the data display in either a grid, gauge, or chart. To view this data, select the \"Live View\" button after publishing your Stream. Next, select the Agents you would like to view the data for. Note Pre v4.3.7, users should close the Live View before navigating away to signal to the Stream Host to stop sending the data. Further Reading How to Use Live View"
  },
  "src/concepts/data-stream/stream-object-configuration.html": {
    "href": "src/concepts/data-stream/stream-object-configuration.html",
    "title": "Stream Object Configuration | XMPro",
    "summary": "Stream Object Configuration Data Stream and Agent Configuration User Settings All Agents will individually be associated with a Collection. This Collection may or may not be different from the default Collection set for your Data Stream. This setting will always be listed among the rest of the user settings. There are a number of Agents that do not require any settings, for example, the Event Printer Agent. This Agent simply prints events and you do not need to specify settings such as a server URL, username, password, or upload a file. Other Agents, however, require settings to be filled in before you can successfully run the stream. For example, consider having a CSV listener Agent in your Data Stream. The CSV listener Agent will require you to specify the following values: Specify a polling interval (seconds) Upload a CSV file Specify the CSV definition (name of each column in the CSV file along with what data type the values in each column are) If these values have been provided correctly, the data will be read from the CSV file you specified when you publish your stream. Input Mapping and Arrow Configuration Some Agents allow inputs to be mapped if the Require Input Map property has been set to true during packaging. What Input Mapping allows you to do is to specify that a specific Agent receives its input in a specific structure. This causes the arrows leading to an Agent to be made configurable and will allow the user to map the inputs of an agent to incoming attributes, for example: Consider having the following Agents in a stream: CSV Listener SQL Server Writer The CSV Listener is configured to get data from a file that contains the following headings: Timestamp (of type DateTime) ReadingNo (of type Long) Temperature_A01 (of type Double) Vibration_A01 (of type Double) Result (of type Double) The task the SQL Server Writer needs to perform is to write the data it receives to a SQL Server database, but it expects the structure of the data to be in a specific format. The table we need to write the data to has the following columns: ID (bigint, identity column) ReadingNo (bigint) Temperature (float) Vibration (float) Results (float) Timestamp (datetime) For the data to be written to the database in a specific format, you need to map the correct columns in the CSV file to the correct SQL Server table columns. To do this, both the CSV Listener and the SQL Server Writer Agents need to be configured first. To configure an Agent, click on the Agent and then on the “Configure” button. Fill in all the details required, for example, the SQL Server instance name and credentials. Next, you can go ahead and configure the Input Mapping by clicking on the arrow that connects the CSV Listener and the SQL Server Writer Agents. Then, click on “Configure“. Choose which column should be mapped to which column by selecting the correct value from the drop-down menu for each row. Please note that the data types of the items being mapped to each other need to be the same. If not, the value in the left column will be disabled and you will not be able to select it. Remember that, even though the same principle applies to all Agents, input mapping might be done differently for different Agents. Mapping Functions In some cases, you might have to map a large number of inputs for an Agent. Some functions have been implemented to make the process of mapping a large number of fields easier, such as Match by Expression, AutoMap, and Show Unmapped. AutoMap By clicking on the “AutoMap” button, Data Stream Designer will match all the fields that are common between the Agents involved, for example, if you look at the stream in the image below, you will notice that both the SQL Server Writer Agent and the CSV Listener has the fields listed below in common, which will automatically be mapped if they have the same data type. ReadingNo Timestamp Match by Expression The Match by Expression function allows for an expression to be used to make mapping a large number of fields easier and quicker. The fields can be mapped by using any of the following options: Prefix Postfix Expression The Prefix option allows you to specify that columns should be matched based on the first part of a column name, for example: In the CSV listener Agent, there is a column named “A01_Temperature“ In the SQL Server Writer Agent, there is a column named “Temperature“ In the images below, “A01” is specified as the postfix. Based on the prefix given, the column “A01_Temperature” in the CSV Listener can be matched to the column “Temperature” in the SQL Server Writer Agent. The Postfix option allows you to specify that columns should be matched based on the last part of a column name, for example, In the file uploaded to the CSV listener Agent, there are columns named “Temperature_A01“ and “Vibration_A01“ In the table referenced in the SQL Server Writer Agent configurations, there are columns named “Temperature“ and “Vibration“ In the images below, “_A01” is specified as the postfix. Based on the postfix given, the columns “Temperature_A01“ and “Vibration_A01“ in the CSV Listener can be matched to the columns “Temperature“ and “Vibration“ in the SQL Server Writer Agent. The Expression option allows you to use a regular expression to match the columns, for example, In the file uploaded to the CSV Listener Agent, there is a column named “Device_Temperature_Fahrenheit“ In the table referenced in the SQL Server Writer Agent configurations, there is a column named “Temperature“ In the images below, “Device_$1_Fahrenheit” is used as the regular expression. Based on this expression, the column “Device_Temperature_Fahrenheit” in the CSV listener is mapped to the column “Temperature” in the SQL Server Writer Agent. Show Unmapped The Show Unmapped function allows you to filter the rows displayed, based on if the columns have been mapped. If you chose to filter items based on if they are mapped or not, all the records that haven’t been mapped yet will be listed, for example, In the image below, “ReadingNo” and “Timestamp” have been mapped for both Agents using the AutoMap function. However, there are three records that remain that need to be mapped. In some scenarios, there might be a lot more records with some being mapped and others not. Further Reading How to Manage Input Mappings How to Configure a Stream Object"
  },
  "src/concepts/data-stream/timeline.html": {
    "href": "src/concepts/data-stream/timeline.html",
    "title": "Timeline | XMPro",
    "summary": "Timeline History: Timeline Changes to a Data Stream are recorded and stored in the database so that the user can view a history of any changes made by themselves or others. This can therefore be used as a collaboration tool to see the changes users make (even if it's only a single user), as well as notes about things that need to be addressed. These changes can be viewed from the canvas by clicking the \"Timeline\" button. Every time an event occurs, it will be added to a timeline in the form of a block, displaying the following: The time and date the change occurred. The name of the person who made the change. The area where the change was made, for example, \"Tags\". The description of the change. Adding Notes Most of the items added to the timeline are added by the system itself, for example, if the version of the Stream increased or if someone changed a setting or configuration of one of the Agents. However, occasionally you may want to add an explanatory notes to the timeline. Filtering The timeline can be filtered in two ways: the type of event logged and the context. Examples of event types are changes made to Agents or version numbers that have been increased. Each type is named after the element on which the change was made. The types of events that can be filtered are as follows: Agent Attributes Canvas Configure Note Publish Share Tag Unpublish Version You can also filter by context, i.e. you can view all changes, or only the events that apply to a specific version. Canvas changes apply to a version, whereas sharing access or changing attributes apply to the data stream as a whole. Further Reading How to Manage the Timeline"
  },
  "src/concepts/data-stream/verifying-stream-integrity.html": {
    "href": "src/concepts/data-stream/verifying-stream-integrity.html",
    "title": "Verifying Stream Integrity | XMPro",
    "summary": "Verifying Stream Integrity Verifying Stream Integrity Data Stream Designer offers the capability to verify if the Agents in your Stream are configured correctly and warns you if there are any issues with them. This is done to ensure the integrity of your Data Stream and to make sure all input fields are valid and accurate. To verify the integrity of your Stream, you can simply click on the “Integrity Check” button. When clicking this button, each agent will call the Validate method in its code. This method contains a set of rules that needs to be satisfied, for example, the SQL Server Agent needs to have the following values specified: SQL Server instance name Username Password (if SQL authentication is used) Database name Table name If any of these values are incorrect or not specified, the Agent will be marked with red, and its code will return a list of errors that it found, which you will see in the form of a list when you hover over the Agent with your mouse cursor. To read more about how the code works, see the Building Agents article. Further Reading How to Run an Integrity Check"
  },
  "src/concepts/insights/data-delivery-insights.html": {
    "href": "src/concepts/insights/data-delivery-insights.html",
    "title": "Data Delivery Insights | XMPro",
    "summary": "Data Delivery Insights Stream Hosts Foundational Premise: Streaming Signals for Event Intelligence Back to Basics The premise of a Stream Host is to ingest streaming signals as messages into the Data Stream. The premise for a Data Stream is the capability to ingest a fire hose and achieve the desired outcome even if not all the data elements are delivered. Consider how this contrasts with an ETL system. Neither has a primary goal of guaranteed delivery. What this means If a value (e.g. a temperature reading) in the Data Stream is measured against a rule value and a call to action is created when a threshold is reached, there is no impact if the Data Stream misses some readings. These misses could occur for several reasons, one of which is buffering. There are buffers in the Data Stream, but if they overflow and values are missed, the premise is intact. In scenarios where multiple transactions occur concurrently, the Stream Host processes the first transaction and buffers the next. However, if the buffer reaches maximum capacity and another transaction is received, the Stream Host will drop the subsequent transaction to prevent potential bottlenecks. Guaranteed Delivery – Processing Files There are circumstances where there needs to be a guarantee for the delivery of the data and the ‘dropping’ of data is unsuitable for the use case. In these circumstances, the design should adopt a pattern that ensures auditable delivery. Explanation If there is a single batch, data is split into 80 separate messages by an agent within the Data Stream, however, the next agent processes the data significantly more slowly than the previous agent which causes buffering to occur, with 80 messages coming through almost immediately the SH is unable to buffer some messages and therefore drops them. Recent Improvement The v4.4.0 release includes a Stream Host with superior \"buffer\" functionality. The new Window Agent supports a delay in transmitting events to the next Agent in a Data Stream. This enhancement aims to mitigate the risk of excessive event data buffering within the Stream Host. The flow of events can be regulated to prevent potential overload scenarios, ensuring smoother data processing and system stability. Data Stream Design Considerations and Patterns When discussing the Data Stream design there are other considerations that, by way of example, point to how patterns could be applied as the design depends on the data profile and orchestrating the data. Not all ingested messages are processed Introduce a mechanism to allocate batch IDs to ensure a message is processed. This relies on tracking individual messages outside the Data Stream (e.g. in a SQL table). If configured correctly, this can avoid duplication if a message is re-processed. Another consideration could be to split the Data Stream and use storage (e.g. SQL) to process each message/record individually: Data Stream 1 ingests the message and saves it as a record in a table. Data Stream 2 then processes each record row by row. Introduce a delay Introduce a delay in the Data Stream by including a “delay” Agent during processing to ensure messages are completely processed before a new message is received. Small polling interval When the polling interval of the listener is small (e.g. 5 or 10 seconds), the short time frame usually results in a Data Stream that is less performant. Consider a longer polling interval. A general observation is that when event intelligence monitors for asset failure, subject to certain use cases, a polling interval of 3600 seconds (i.e. one hour) is sufficient to timeously perceive degradation."
  },
  "src/concepts/landing-pages.html": {
    "href": "src/concepts/landing-pages.html",
    "title": "Landing Pages & Favorites | XMPro",
    "summary": "Landing Pages & Favorites Overview A list of categories is displayed by default when you open App Designer or Data Stream Designer. In App Designer, this can be changed to display a custom landing page instead. When a custom landing page is set for a company, any user from that specific company will see that landing page when they first open App Designer. An App can be used as a landing page as long as it is published. This is useful if a company has a main App that they access and prevents them from continuously navigating to that App. Apps and Data Streams can be favorited. This is useful for Apps or Data Streams that are frequently used, and favoriting them will allow them to appear on the main page of Subscription Manager for quick and easy access. Blocks can also be favorited. This is useful for Blocks that are frequently used by a designer, and favoriting them will allow them to appear on the Favorites category of App Designer's Blocks for quick and easy access. Note It is recommended that you read this documentation along with the articles listed below to improve your understanding of how Apps and Data Streams work. Application Data Stream Default Landing Page When you load Data Stream Designer or App Designer, the default landing page lists the categories that contain Data Streams or Apps respectively. Indicators at the bottom of each category card inform how many Data Streams/Apps are: Published Draft Errors (published Data Streams with errors) Click the category card to view all the contents, or on the counter for a filtered view. Favoriting Apps and Data Streams Apps and Data Streams can be favorited for quick and easy access. When you favorite an App or Data Stream, they will appear on the main page in Subscription Manager. If there are no favorited Apps or Data Streams, Subscription Manager will display a list of published Apps and Data Streams instead, if there are any. If there are no Favorited or published Apps or Data Streams, no Apps or Data Streams will show. There are also direct links to allow you to create an App, Data Stream, or Recommendation by clicking on the 'Create New' button. Note To learn more about how to Favourite Apps or Data Streams, visit the How to Manage Landing Pages article. Company Landing Page You can choose to set an App as the Landing Page, which overrides the default landing page. The landing page for the App selected will be the first page all users in the company see when opening App Designer. You can select different Apps for Desktop and Mobile. Note You can only choose from published Apps to be a landing page. To learn more about how to set a Company Landing Page, visit the How to Manage Landing Pages article. Desktop To view the Landing Page for Desktop, open App Designer on a Desktop computer. You can also click on the company icon in the top-left corner. Mobile To view the Landing Page for Mobile, open App Designer on a Mobile device. You can also click on the company icon in the top-left corner. Further Reading How to Manage Landing Pages & Favorites"
  },
  "src/concepts/manage-access.html": {
    "href": "src/concepts/manage-access.html",
    "title": "Manage Access | XMPro",
    "summary": "Manage Access Managing the access of users is important as it can improve the security of XMPro Objects. Permissions are given to users only based on what they need to do, for example, someone who only needs to view something can be given read access. This can hide additional functionality that users do not need and also protect against unintentional tampering. Whether or not you can design a particular data stream, application, or other XMPro Objects is determined by the permissions that you have on it. The person that originally created the XMPro Object will be listed as the owner and can never lose his/her right to access it unless it is deleted. Other users can then be assigned read or read-and-write access. Grant Permissions Granting permissions makes it easier for multiple users to collaborate on one particular XMPro Object. It also makes it easier to grant permissions to multiple users who are only allowed to view or read it without making changes, possibly to just give feedback or to discuss part of the XMPro Object. Permissions: Owner The Owner has full permission to make any changes required to the XMPro Object. The owner is also allowed to give other users access or change the permissions of existing users. Permissions: Co-Owner The Co-Owner has full permission to make any changes required to the XMPro Object. The Co-Owner is also allowed to give other users or change the permissions of existing users, except removing or changing the Owner's permissions. Permissions: Write A person who has Write access will be allowed to view, edit, publish and unpublish the XMPro Object. Permissions: Read The Read permission will allow a person to view the XMPro Object, but making any changes to the XMPro Object will be prohibited. Permission Matrix Permission/Operation Owner Co-Owner Write Read View ✓ ✓ ✓ ✓ Publish/Unpublish ✓ ✓ ✓ ✗ Edit ✓ ✓ ✓ ✗ Delete ✓ ✓ ✗ ✗ Manage Versions • View ✓ ✓ ✓ ✓ • Create/Copy ✓ ✓ ✓ ✗ • Delete ✓ ✓ ✗ ✗ Manage Access ✓ ✓ ✗ ✗ Actions on the Manage Access page Action Description Add Adds a user. Select Selects multiple users. Edit Edits the permissions of a particular user. Cancel Discards any changes made to the user's permissions up to that point. Delete Deletes a user. Manage Run Access Warning For Apps, if a User has Design Access they will also automatically have access to run the App in view mode. However, for Recommendations, a User can only view Recommendation Alerts if they or their Business Role has Run Access, regardless of whether they have Design Access to the Recommendation. Business Roles (Company Administrator) Business Roles are a hierarchical representation of the different areas of an organization. When managing access for XMPro Products, the Business Roles defined in Subscription Manager are used. Business Roles are managed by the Administrator of a Company through the Users page. All new users will automatically be added under the default 'All Employees' Business Role. Users can be moved, but not deleted from this list. A User can only be listed once underneath one Business Role. Business Role of a User Alternatively, a user's business role can also be managed from the user blade. See Change Business Role. Sync Business Roles from Azure Entra ID If Azure Entra ID has been linked as your External Identity Provider, you can specify a claim name that Azure Entra ID or the graph API will pass to Subscription Manager. When a user logs in, Subscription Manager will look at the value specified in this Claim and assign them to the Business Role with the same name. Note If a Business Role with the same name doesn't exist, it will be created as a child under the default Business Role, 'All Employees'. Actions on the Manage Run Access page Action Description Save Saves any changes made to the Manage Run Access up to this point. Discard Discards any changes made to the Manage Run Access up to this point. Further Reading How to Manage Access"
  },
  "src/concepts/recommendation/action-requests.html": {
    "href": "src/concepts/recommendation/action-requests.html",
    "title": "Action Requests | XMPro",
    "summary": "Action Requests An Action Request is a mechanism to trigger actions in another system while attending to an Alert, such as updating data, sending notifications, or additional processing. This is made possible with the Action Request Agents in the Data Stream Designer. Note It is recommended that you read this documentation along with the articles listed below to improve your understanding of how action requests work. Recommendation Alert Form Data Stream Stream Object Configuration Open an Action Request An Action Request is opened when a user clicks a button on a user-defined Form in a Recommendation Alert. The Action Request includes data derived from the Alert, Form, and Button clicked. Note If you add a button to a Form, ensure there is a corresponding Data Stream to process the Action Requests - or they will remain open and unprocessed. Process an Action Request The Read Action Request Agent polls App Designer for new Action Requests for the specified Recommendation and passes that data to the next Stream Object in the Data Stream for processing. The Read Action Request Agent also sends all open Action Requests when the Data Stream is first published - so that any Action Requests opened while the stream was not running can be processed. The Close Action Request Agent closes Action Requests from upstream. Processed Action Requests must be closed, or they will be reprocessed if the Data Stream is restarted. Outputs of the Read Action Request Stream Object Output Description RequestId The Id of the specific button press. This should be passed to the Close Action Request Stream Object's Action Id. AlertId The Id of the Recommendation Alert. AlertDescription The Headline of the Recommendation Alert. AlertComments The current Notes of the Recommendation Alert. ActionRequested The time that the button was pressed. ActionParameters A JSON string of the Recommendation Alert's Form's values at the time the button was pressed."
  },
  "src/concepts/recommendation/auto-escalate.html": {
    "href": "src/concepts/recommendation/auto-escalate.html",
    "title": "Auto Escalate | XMPro",
    "summary": "Auto Escalate Auto Escalate is only available if Enable Execution Order is checked. Auto Escalate prevents more than one pending Recommendation Alert from existing at once for a single business event. When an Alert is created, if Auto Escalate is checked, any previously created Recommendation Alert that has not yet been Resolved or Marked as False Positive in the Recommendation is marked as Resolved. Example In the following Recommendation, there are three Rules. In each Rule, there is Rule Logic that evaluates whether the Average field from the received data is greater than 50, 70, and 90. A Recommendation Alert has been created because the Recommendation received a data row with 66.8 as the Average value: Then the Recommendation receives a data row from the Data Stream with greater than 90 Average value. It will: Evaluate the data against the first rule: Exceeded 90°C. The average value is greater than 90, so it will evaluate as true. Create a Recommendation Alert based on the Exceeded 90°C Rule, and resolve the pending Recommendation Alert."
  },
  "src/concepts/recommendation/deleted-items.html": {
    "href": "src/concepts/recommendation/deleted-items.html",
    "title": "Deleted Items | XMPro",
    "summary": "Deleted Items When you delete a Recommendation, there may be archived Recommendation Alerts created by that Recommendation that you don't want to delete. In order to facilitate this, deleting a Recommendation, Recommendation Version, or Rule will move the item to the Deleted Items. Items that are deleted will not generate new Recommendation Alerts, and will not be visible in other areas of the App Designer and Data Stream Designer. For example, deleted items will not show when selecting a Recommendation to filter on in the Recommendations Block or Stream Objects. Deleting the Recommendation itself will also delete all versions and rules within that Recommendation. Deleting a version will also delete all rules within the version. The Recommendation itself will not be deleted, and only the deleted version and rules will show in the deleted items list. Deleted items can be accessed through the Deleted Items button on the Recommendations page. Note Items that have not been deleted don't have a select box, and cannot be restored or permanently deleted. Alert Count Column When you view deleted items, an Alert Count Column will be displayed next to the items. This will show the number of Alerts that were triggered previously for the deleted Rule. Clicking on an Alert Count for a deleted Rule will display the list of Alerts in the Recommendation Alerts table. Selection Selecting a Recommendation will select and expand all Versions and Rules for that Recommendation. Selecting a Version will select and expand all the Rules for that Version. When an item is deselected, only that item will be deselected. For example, if you deselect a Recommendation, only the recommendation will be deselected. The Version and Rules for that Recommendation will remain selected. Similarly, if you deselect a Version, only the Version will be deselected. Any rules for that Version will remain selected. If all Versions are deselected in a Recommendation, that Recommendation will be deselected, as you cannot have a Recommendation without a Version. Restore Items To restore items, select them and press the Restore button. Restored items will return to their original state before being deleted. Restored items will start generating Recommendation Alerts if the Recommendation is published. It is possible to restore an item while its parent item is still deleted. In this case, the restored item will not be visible anywhere but will become visible when the parent item is restored. If you restore an item without selecting the parents of the item, the parents will be restored as well. For example, if you select a Rule (and do not select its version or Recommendation), the Rule will be restored and the version and recommendation will still be automatically restored as well, even if they were not selected. Permanently Delete Items Warning Warning! Recommendation Alerts will also be permanently deleted when permanently deleting items. To permanently delete items, select them and press Delete. The items, any child items, and any Recommendation Alerts generated from them will be deleted forever. Actions on the Deleted Items Action Description Restore Restores the Deleted item. Delete Permanently deletes the item. Select All Toggles between selecting and deselecting all the items in the deleted items list. Expand All Expands all Recommendations and Versions to see all Versions and Rules underneath. Collapse All Collapses any already expanded Recommendations. Further Reading How to Manage Deleted Recommendation Items"
  },
  "src/concepts/recommendation/execution-order.html": {
    "href": "src/concepts/recommendation/execution-order.html",
    "title": "Execution Order | XMPro",
    "summary": "Execution Order If Execution Order is enabled, the Rules will be evaluated one by one in ascending order when data is received from the Data Stream. If the data doesn't match the Rule Logic, it will move on to the next Rule and evaluate again. If the data does match the Rule Logic, it will create a Recommendation Alert and stop evaluating against any subsequent Rules. Example In the following Recommendation, there are three Rules. In each Rule, there is Rule Logic that evaluates whether the Average field from the received data is greater than 50, 70, and 90. In the case that the Recommendation receives a data row in which the Average value is 86, it will: Evaluate the data against the first rule: Exceeded 90°C. 86 is not greater than 90, so it will evaluate as false and move on. Evaluate the data against the second rule: Exceeded 70°C. 86 is greater than 70, so it will evaluate as true. Create a Recommendation Alert based on the Exceeded 70°C Rule."
  },
  "src/concepts/recommendation/form.html": {
    "href": "src/concepts/recommendation/form.html",
    "title": "Form | XMPro",
    "summary": "Form A Form is a collection of fields that appear on Recommendation Alerts. Forms are how relevant information can be entered and changed over the course of resolving an Alert. Forms can also contain buttons that allow specific actions to be performed in other business systems, like creating a work order in your EAM system. The Action Request Agent in the Data Stream Designer will pass the data from your form to other systems. Note See the Action Requests article for more details on Action Requests. When a Recommendation Alert is created from the Rule, the Rule's selected Form is used to determine the fields (Blocks) that will appear in the alert. Forms are managed through the Recommendations page. The same form can be seen as created in a Recommendation Alert: Category Forms can be organized into different categories. This refers to the category under which the Form is found in the Form list. This category is separate from the App and Data Stream Categories. Actions on the Form The following Actions can be taken on a Recommendation Form: Action Description Blocks Opens the list of Blocks that are available to the Form. Properties Opens the properties for the selected Block. Save Saves any changes made to the Form up to this point. Discard Discards any changes made to the Form up to this point. Settings Opens the Form Settings, where you can modify the Form's Name and Category or delete the Form. Manage Versions Versioning for the Form. Manage Access Allows you to manage which users are allowed to view or modify this Recommendation and the Recommendation Alerts created by this Recommendation. Clone Clones the Form as a new Form. Export Export the Form as an encrypted file. Delete Deletes the Form. Blocks The following Blocks can be added to a Recommendation Form: Name Description Text A control that displays text. Textbox A control for the user to input text. Text Area A control for the user to input a large amount of text (multiline). Numberbox A control for the user to input a numeric value. Datebox A control for the user to input a date. Checkbox A control that allows the user to tick an option. Dropdown A control that allows the user to select from a predefined list. Grid A control that displays tabular data, updated as a JSON Array by an Update Recommendation Agent in a Data Stream. It is read-only when viewed in App Designer. It is used to add information for users reviewing or resolving Recommendation Alerts, such as a Data Stream configured to listen for changes in an external work order system and update the Alert. Button A control that can be clicked to trigger an event or action. Blocks are added to the Form by dragging from the Blocks tab. Blocks can be re-ordered by dragging them up and down The properties of a Block are available in the Properties tab after clicking on a Block to select it. A Block can also be deleted by clicking on the delete button in the selection toolbar: Block Properties Property Description Property Description Name Name of the recommendation. This is usually one or two words that describe the form. Name is how the Block is differentiated for Data Stream Agents. Caption The caption is displayed above the Block. (Text) Caption Style The style of the text Block. Options include Heading 1 - 4, Body, Metric, and Small Text. Read Only A flag that determines whether the field will allow a new value to be added on the Alert. Required A flag that determines whether the Block must have a value before the Alert can be saved. (Dropdown) Items The items that are available for selection in the dropdown. Text is shown in the dropdown, and Value is what will be selected and saved. (Button) Button Style The style of the button in the Recommendation Alert: Text: The button has no borders. The text color depends on the Button Type. Outlined: The button has a colored outline. The border color depends on the Button Type. Contained: The button has a colored background. The color depends on the Button Type. If the Button Type is Normal, it has a black outline. (Button) Button Type The color of the button in the Recommendation Alert: Danger: Red. Default: Blue. Normal: White or Black. Success: Green. Note Number Selector automatically converts the entered value into a scientific notation if it is greater than 21 digits for an integer value and greater than 6 digits for a decimal value. Further Reading How to Create and Manage Forms Action Requests: creating work orders in Data Streams with a Form button"
  },
  "src/concepts/recommendation/index.html": {
    "href": "src/concepts/recommendation/index.html",
    "title": "Recommendation | XMPro",
    "summary": "Recommendation Recommendations enable engineers or employees of an organization to respond to critical events based on expert knowledge in the organization before the opportunity expires, while managers can close the loop by monitoring that it is done in a timely and appropriate manner. Recommendation Alerts are advanced alerts that are triggered when a critical event occurs. Alerts get created when real-time data meets the conditions of recommendation rules. The Alerts are then discovered by employees through email or SMS notifications and the monitoring of systems. Discussions allow users to message each other about the particular event that triggered the alert. Other people who view the alert can also view those discussions to be up-to-date with any new information. Triage Instructions are instructions given to help whoever is resolving the Recommendation Alert. Custom Forms can also be shown to the user when they view an alert. Users can use the forms to enter relevant information over the course of resolving the Alert. In practical terms, Recommendations observe live data from a Data Stream with a Run Recommendation Agent and evaluate the data against conditions defined in their Rules. If a Rule's condition is met, a Recommendation Alert is created from the Rule. Recommendations are created and managed in the App Designer. To manage Recommendations, click the Recommendations button in the menu on the left, and then click on the Manage Recommendations button. Finding Recommendations The search bar can be used to find any specific Recommendations that you may be looking for. There is a dropdown option where you can specify to search through everything in App Designer, or only for Recommendations. Category Recommendations can be grouped into categories. This refers to the category under which the Recommendation is found in the Recommendations list. Data Stream This is Data Stream from which the Recommendation will receive data from. Enable Execution Order A flag that determines whether the Rules will be evaluated in ascending order or all at once. See the Execution Order article to read more about the Execution Order. Auto-Escalate A flag that determines whether an existing pending Recommendation Alert should be resolved and escalated to a newly created Alert. This would occur when new data is received that meets a Rule's Logic further up the Execution Order of the current Recommendation Alert's Rule. See the Auto-Escalate article to read more about the Auto-Escalate. Rules Rules determine the conditions for creating Recommendation Alerts, and what created alerts should look like. Variables Variables are a way to transform the data received from the Data Stream before applying it to the Rule Logic. Actions on the Recommendation Action Description Save Saves any changes made to the Recommendation up to this point. Discard Discards any changes made to the Recommendation up to this point. Publish/Unpublish Publishes or unpublishes the Recommendation, which makes it start listening for data from the Data Stream. Manage Access Allows you to manage which users are allowed to view or modify this Recommendation and the Recommendation Alerts created by this Recommendation. Timeline Upcoming feature. Versions Versioning for the Recommendation. Delete Deletes the Recommendation. Clone Clones the Recommendation as a new Recommendation. Export Export the Recommendation as an encrypted file. Further Reading How to Create and Manage Recommendations How to Create and Manage Variables"
  },
  "src/concepts/recommendation/notification.html": {
    "href": "src/concepts/recommendation/notification.html",
    "title": "Notification | XMPro",
    "summary": "Notification A Notification defines how users will be notified when a Recommendation Alert occurs. A Recommendation Alert occurs when a Rule condition is met and triggers the Alert to happen. Notifications are set for a recommendation Rule. Each Rule can have multiple Notifications, each based on different conditions that can trigger an Alert. You can add a new Notification by pressing the plus button on the top right of the notifications. Triggers Notifications have several triggers. When they happen, will notify everyone who is subscribed to the notification. The triggers are as follows: New Recommendation When \"Send Recommendation when a new recommendation is generated\" is checked, subscribers will be notified when a new Recommendation Alert is created from the same Rule. Status Change When \"Resolved\" is checked, subscribers will be notified when a Recommendation Alert created by the same Rule is resolved. When \"False Positive\" is checked, subscribers will be notified when a Recommendation Alert created by the same Rule is marked as False Positive. Notes When \"Send notification when notes are added to a recommendation\" is checked, subscribers will be notified when Notes are added or changed on a Recommendation Alert created by the same Rule. Time Pending When \"Send a notification after\" is checked, subscribers will be notified the specified amount of time after a Recommendation Alert is created from the same Rule if the Alert has not been resolved. When \"And repeat notification\" is checked, subscribers will be notified the specified number of times, waiting the specified amount of time between each notification, if a Recommendation Alert has still not been resolved. For example, in the image below, subscribed users will be notified once every hour for two hours that a Recommendation Alert has not been created and hasn't been resolved. Channels Email When a trigger occurs, everyone who has subscribed and has entered a correct email address in their profile will receive an email. SMS When a trigger occurs, everyone who has subscribed and has entered a correct mobile phone number (in international format) in their profile will receive an SMS. Note The email and mobile number that you use to receive notifications can be changed when updating the user settings. Notification Template When a Recommendation Alert is triggered by a critical event, the user can receive a notification via text message or email. The notification contains a message that notifies the user of the Recommendation Alert. You can choose to create a custom message template for when a notification is triggered, or use a default template provided. Note To learn more about Notification Templates, visit the How to Manage Notification Templates article. Subscribe Notification Settings are available only if the user has run access. Notification Settings are managed individually by each User. To manage your subscriptions, hover over your user profile in the top-right of the page in App Designer, and click \"Notification Settings\". By default, you will not be subscribed to any Notifications. You can subscribe to an individual Notification, Rule, Recommendation, or Category by checking it in the list and saving. If an item is checked, you are subscribed to all Notifications — as well as Notifications that may be created in the future — within the item, and you will be notified when Notifications are triggered. Further Reading How to Create and Manage Notifications How to Manage Notification Templates How to Subscribe to Notifications"
  },
  "src/concepts/recommendation/recommendation-alert.html": {
    "href": "src/concepts/recommendation/recommendation-alert.html",
    "title": "Recommendation Alert | XMPro",
    "summary": "Recommendation Alert Recommendation Alerts are advanced alerts that are triggered when real-time data meets the criteria defined in a Recommendation Rule. They notify you when certain conditions occur in your data and provide decision support for how to take action. The Recommendation Alerts are found by clicking on the Recommendations button in the menu on the left of the App Designer. The grid provides an overview of all the Alerts that you have access to. The rightmost Status column shows whether the Alert is Pending or Resolved. You can order, filter by specific values, search the alerts by any of the columns, and search in all columns in the Search bar. To see Resolved as well as Pending Alerts, check the \"Show Archived\" checkbox. Click on an Alert in the grid to navigate to the Recommendation Alert details. Finding Recommendation Alerts The search bar can be used to find any specific Recommendation Alerts that you may be looking for. There is a dropdown option where you can specify to search through everything in App Designer, or only for Recommendation Alerts. Detailed View The Recommendation Alert page provides details of the alert. It allows you to input information into the Form, view Triage Instructions, have a Discussion with your team, and see the alert Timeline and Analytics. Headline The headline of the Alert. Generated by the Rule Headline. Recommendation Details A paragraph on the details of the Alert. Generated by the Rule Description. Event Data The data received by the Data Stream. If \"Log Data On All Occurrences\" is checked in the Rule, this data will be updated as new data is received. Notes An area to write notes and observations. Actions This area contains the actions that can be performed on a Recommendation Alert. Assign and Reassign Reassign added in v4.4.4 Ability to Assign (or Reassign) responsibility for the Recommendation Alert to a user that has run access to the Recommendation. The default selection is the logged-in user. When this action is performed, the action is recorded on the Timeline and in the Discussion - thus notifying the assignee. Share Ability to share the Recommendation Alert to users that have run access to the Recommendation. Selected users will receive an email with the note and a link to the Recommendation Alert. Save Saves the changes made on the Recommendation Alert. Mark as False Positive Someone reviewed the issue, determined that the asset doesn't have an issue or it was triggered while in Maintenance/Service mode, and considered the matter closed. Mark as Resolved Someone reviewed the issue, took mitigation steps, and considered the matter resolved. Form A form where relevant information can be entered. It is only available if the Recommendation has an attached Form. Accessed by clicking on the Form tab. For more details on how to add actions to a form button, see Recommendation Actions. Triage Instructions An area that provides useful information on actions to take to resolve the Alert and links to relevant resources. It is only available if the Recommendation has Triage Instructions enabled. Accessed by clicking on the Triage Instructions tab. Discussion An area in which messages can be posted to collaborate with members of your team. Each discussion is specific to a particular Recommendation Alert. A more detailed explanation can be found below. Timeline All previous alerts created by the same Rule and a list of all the events to happen on this Alert. Analytics An area in which the number of Alerts for the Asset (the Entity Identifier specified in the Run Recommendation Agent) can be compared, as well as a breakdown by Generated, Auto Escalated, False Positive, and Resolved alerts over a period of time. A more detailed explanation can be found below. Discussion The discussion section is an area in which messages can be sent by anyone who has access to the Recommendation Alert. Messages are displayed with the latest message at the bottom of the list. Any messages which have not been read since the last time you visited the page will be below the \"Last Read\" line break. You can search for messages that contain a certain word or phrase by typing in the search bar at the top. You can add a message by typing in the editor at the bottom of the discussion section and clicking the button with a paper plane icon at the bottom right corner. Advanced text editing can be opened by clicking the button with an underlined letter A icon at the bottom left corner. You can mention another user by typing the @ symbol or clicking the button with the @ symbol, which will pop up a list of users. Clicking on a user will mention them in the message and send an email to them when the message is sent. Analytics The analytics section compares the currently viewed period of alerts with the previous period and displays the difference as a percentage. The statistics compared are: The number of Alerts generated The number of Alerts that were auto-escalated The number of Alerts marked as false positive The number of Alerts resolved. Below the breakdown, there are two charts: The number of all Recommendation Alerts for the Asset (the Entity Identifier specified in the Run Recommendation Agent). A breakdown of all Recommendation Alerts by Rule for the Asset in the selected period. Further Reading How to Manage Alerts Manage Alerts on Mobile"
  },
  "src/concepts/recommendation/recommendation-scoring.html": {
    "href": "src/concepts/recommendation/recommendation-scoring.html",
    "title": "Scoring | XMPro",
    "summary": "Scoring What is Alert Ranking and Alert Scoring? When setting up a Recommendation, authors are able to influence the order in which Alerts will be shown. Ranking and Scoring help the alert recipient prioritize recommendations according to their importance. What is the difference between Alert Ranking and Alert Scoring? Alert Ranking allows users to rank a recommendation as High/Medium/Low. Alert Scoring is an alternate fine-tuning of the alert ranking by specific factors such as recommendation, category, rule, and an optional value from the Data Stream. By allowing the author to assign a calculated score to an Alert instead of a ranking, you can have even more detailed control over its importance level. This Score also helps the alert recipient to understand its relative importance. Note Authors still have the option to use Alert Ranking instead of Alert Scoring if they prefer. How is the scoring calculated? This feature allows recommendation authors to assign numerical values (1-10) to various aspects during configuration. These values are then multiplied, resulting in an alert score. score = recommendation factor * category factor * rule factor * optional factor The score is calculated at the time the alert is generated and is not recalculated should any of the factors be updated. Where are scoring values added? The values used to score an Alert could be configured in these different areas: Recommendation – assesses the significance of the recommendation itself Recommendation Category – evaluates the importance of the recommendation's category Recommendation Rule - when managing a rule within a recommendation Recommendation Optional - an Optional Rule Factor value retrieved from the Data Stream. Viewing the recommendation scoring When viewing the Recommendation Alerts list, The Recommendation Scoring is displayed on the Score Column, and the Alerts are arranged in a descending order based on their Scoring. You can also view the Scores using the Score Factor Matrix. To open the Score Factor Matrix: Open Manage Recommendations Click on “More” ellipses Click the \"Score Factor Matrix\" button Note This table only shows an estimate as the Optional Factor of the Recommendation could not be determined until the Alert is generated. Viewing the Score Factor history on a timeline The changes made on a Score Factor Recommendation can be viewed on a timeline in the following areas: Category Timeline – when observing score factor changes within this timeline. Recommendation & Rule Timeline – when viewing score factor changes within this timeline."
  },
  "src/concepts/recommendation/rule.html": {
    "href": "src/concepts/recommendation/rule.html",
    "title": "Rule | XMPro",
    "summary": "Rule A Rule defines the conditions for triggering a Recommendation Alert and what the created Recommendation Alert should look like. Multiple Rules can also be grouped into one Recommendation. Rule Logic Data sent from the selected Data Stream is passed through the Rule Logic and if the conditions created are met by the data, a new Recommendation Alert will be created. You can add new conditions or groups by clicking the + button. Groups can be nested within each other to create advanced logic. In an \"And\" group, all the conditions must be true, and in an \"Or\" group, only one of the conditions must be true to trigger an Alert. As an example, in the following Rule Logic, both of the following must be true to trigger an Alert: Average must be greater than 50, And V1, V2, or V3 must be greater than 60. Alert Headline & Description This refers to the headline and description that the Recommendation Alert will be created with. Any tag (starting with @) will be replaced with the value output from the Data Stream. Alert Ranking The priority level that the Recommendation Alert will be created with. Priority level determines the order in which the Alerts will be displayed. Impact Metric The measurable impact of the business event detected by the Recommendation Rule. This will be shown on Alerts in the Recommendation Block in App Pages. Enable Form A flag that determines whether the Recommendation Alert will be created with a Form. Select Form The Form that the Recommendation Alert will be created with. Form Version The Version of the Form that the Recommendation Alert will be created with. Additional Recommendation Management Column An additional column in the Recommendation Alerts grid. Any tag (starting with @) will be replaced with the value entered in the corresponding field in the Form. Resolution Resolution determines whether new data from the Data Stream will automatically resolve the Recommendation Alert if the Rule Logic is no longer true. Manual Resolution: A user must manually resolve each Recommendation. Automatic Resolution: Recommendation auto resolves when trigger conditions are no longer true. This may impact performance, as it might continuously trigger and resolve a large number of Recommendations at a time if the data fluctuates frequently. Recurrence Recurrence determines whether new data from the Data Stream will create new Recommendation Alerts if a Pending Recommendation Alert already exists and the Rule Logic is true. If the conditions created by the Rule Logic are met by the data, and if Recurrence is set to All Occurrences or First Occurrence and no Pending Alert exists, a new Recommendation Alert will be created. First Occurrence: The current recommendation must be resolved before others can be triggered for the same rule. All Occurrences: A new recommendation will be triggered every time the rule conditions are true. Recurrence will be disabled and be considered to be the First Occurrence if the Recommendation has Execution Order enabled. Log Data On Determines whether new data from the Data Stream will log new data in the Event Data grid if the Rule Logic is true. First Occurrence: Current recommendation will only log data on the first occurrence. All Occurrences: New alert data will be triggered every time the rule conditions are true. Triage Instructions Instructions to help whoever is resolving the Recommendation Alert. Enable Triage Instructions is a flag that determines whether the Recommendation Alert will be created with Triage Instructions. Resources A list of links on the Recommendation Alert to help whoever is resolving the Recommendation Alert. Enable Resources is a flag that determines whether the Recommendation Alert will be created with Resources. Notifications This refers to the list of Notifications that will be sent out to everyone who is subscribed. View Related Alerts You can view Alerts that are directly related to a Rule. To do this, open the Rule's page and click on Alerts at the top. This will take you directly to the Alerts list table, which will be filtered to only display the Alerts related to the specific rule you are viewing. Actions on the Rule Action Description Save Saves any changes made to the Rule up to this point. Discard Discards any changes made to the Rule up to this point. Clone Clones the Rule as a new Rule in this Recommendation. Delete Deletes the Rule from this Recommendation. Further Reading How to Create and Manage Rules"
  },
  "src/concepts/variable.html": {
    "href": "src/concepts/variable.html",
    "title": "Variable | XMPro",
    "summary": "Variable Variables are placeholders used to maintain integration keys and secrets. They can be used by IT administrators, engineers, or other users to store and use credentials or passwords in a safe and secure manner. They provide a central point to maintain credentials that can improve security. Engineers and other users can reference and use these credentials without knowing the actual value they contain. More secure credentials such as passwords can be encrypted to add an extra layer of security. Variables can be added in both the App Designer and the Data Stream Designer. The value of the Variable is only available in the environment it is created in. For example, if the Variable is created in the Data Stream Designer, both the name and value of the Variable will be available in the Data Stream Designer. However, in the App Designer, only the name will be available and the value will be left empty. Finding Variables The search bar can be used to find any specific Variables that you may be looking for. There is a dropdown option where you can specify to search through everything in App Designer, or only for Variables. Category Variables can be grouped into categories. This category is separate from the App and Data Stream Categories. Encrypt Value If selected, the value of a Variable will be encrypted. This way the value cannot be seen by any user. If not selected, the value can be seen when the Variable is selected and configured. If a value is not encrypted, and you select encrypt value, the value that is already in the input field will be cleared automatically. Similarly, if the value is already encrypted, and you deselect encrypt value, the value already entered will be cleared. Value The value of the Variable, for example, the username, server name, or password. Using a Variable Once a Variable has been saved, the Variable can be selected from a dropdown list when you are required to fill in forms or credentials. For example, in order to connect to a database to display data on your App, you will need to connect to it using a server name, username, and password. Actions on the Variable Action Description Add Adds a new Variable. Select Selects multiple Variables. Manage Categories Creates and edits categories to organize the variables. These categories are separate from the App and Data Stream Categories. Save and Close Saves any changes made to the Variable up to this point. Discard Discards any changes made to the Variable up to this point. Delete Deletes the Variable. Further Reading How to Create and Manage Variables"
  },
  "src/concepts/version.html": {
    "href": "src/concepts/version.html",
    "title": "Version | XMPro",
    "summary": "Version Version Management Versioning provides traceability, which is the ability to view all revisions and changes made throughout an XMPro Object's history, including changes made during each development stage. Adding new versions also allows different team members to work on and make changes to an XMPro Object that is currently in use by other people. This allows others to continue using it without any downtime. Making changes on a new version of an XMPro Object also allows you to maintain a version of it before you made changes, which can also act as a backup mechanism. If major issues are found in the new version, you are easily able to switch back to an older one if needed. Each XMPro Object keeps track of different versions, including: Data Streams Agents and Connectors Applications Recommendations Forms Minor version increases are automatically handled by the system every time you make changes to the particular XMPro Object and save those changes. However, control over how major version increases are handled is given, to some extent, to the user as versions can easily be copied or removed. Copying a version allows you to continue working and making changes to the XMPro Object while maintaining a version of it before you made changes, which can also act as a backup mechanism. To view the available versions for a particular XMPro Object, click on the \"Versions\" button. When you open an XMPro Object, the latest version is automatically opened. Even if there is an older version published, the latest version will still be opened. Published Versions A published version is a version of the XMPro Object that is published and viewable and usable to others. See the Publish article for more details on published XMPro Objects. Versions that are published will display a green play symbol next to the version number. Copying Versions When copying a version, all properties and inner components of the XMPro Object's version will be duplicated as a new version. Deleting Versions Published versions cannot be deleted. When an XMPro Object only has a single version or one last remaining version, that version also cannot be deleted. Actions on the Version Action Description View/Open Opens that particular version of the XMPro Object. Copy Copies the selected version as a new version, with a higher version number. Delete Deletes the Version. Further Reading How to manage Versions"
  },
  "src/concepts/xmpro-ai/index.html": {
    "href": "src/concepts/xmpro-ai/index.html",
    "title": "XMPro AI | XMPro",
    "summary": "XMPro AI Unlock a world of possibilities XMPro AI provides an end-to-end solution to operationalize AI in your existing business processes. Augment your business processes with XMPro AI to gain a competitive edge through automated decision-making. Easily embed developed AI models into XMPro data streams to analyze vast amounts of data and generate real-time insights, enabling you to make informed decisions quickly. XMPro AI is baked into our modules, from the agents, reading and contextualizing your sensor data, to the rapid development of AI Models within our XMPro Notebook, and dashboards in our Application Designer - all of which help to make sense of the data and to create intelligent digital twins. XMPro can be deployed on the cloud, On-Premise, or the edge. With XMPro AI, you can make data-driven decisions with confidence, maximizing efficiency and driving business growth. Fig 2: XMPro AI - How It Works Embedded AI Leverage Machine Learning (ML) to extract actionable insights from vast data volumes, uncover hidden patterns, predict outcomes, and drive business growth and efficiency. Advanced Analytics and Predictive Insights Visit our Blueprints, Accelerators, and Patterns repository to see how you can embed AI: Remaining Use of Life (RUL) Data Stream, which uses our Python Agent, in the Smart Manufacturing Accelerator. The Asset Monitoring - Binary Classification Pattern utilizes our Binary Classification Agent. The Liner Wear Prediction - Regression Pattern utilizes our Regression Agent. The Vertical Travel - Forecasting Pattern utilizes our Forecasting Agent. Innovation AI Utilize XMPro Intelligent Digital Twins and XMPro Notebooks for scalable and cost-effective innovation with AI. Simulation and Optimization Conduct simulations, real-time visualizations, explore different configurations, predict outcomes, and identify parameters for improving efficiency, productivity, or energy consumption. Augmented AI Interact with systems, applications, and proprietary data using natural language commands, fostering effortless communication, enhanced user experiences, and increased adoption of intelligent automation solutions. Co-Pilot Capability in App Designer Build a widget to harness OpenAI from within your Application. Ask for advice from your co-pilot and paste the results into the related recommendation alert. Note This example is running on the public version of ChatGPT. Contact us for more information on how to do this using your Azure OpenAI Service, trained on your own IP. ChatGPT Capability in XMPro Notebook Ask ChatGPT for help from within XMPro Notebook. Model Governance Support As AI scales within the organization, corporate guardrails require AI to be modeled within an MLOps framework. Our MLflow Agent is the first in a series, that enables effective model governance using a popular MLOps toolset. This empowers data scientists to promote new model versions within MLflow without going back to edit the XMPro Data Stream. In the example below, version 1 of a model is configured and the Data Stream is published. Observe that the first event printed confirms model version one was used to make a prediction. We then switch to MLflow to promote version 2 to production. Observe that when we switch back to the Data Stream output, model version two is seamlessly used to make the next prediction. Fig 7: A new version promoted in MLflow is seamlessly picked up and processed in the Data Stream."
  },
  "src/concepts/xmpro-ai/xmpro-notebook.html": {
    "href": "src/concepts/xmpro-ai/xmpro-notebook.html",
    "title": "XMPro Notebook | XMPro",
    "summary": "XMPro Notebook Overview XMPro Notebook provides an intuitive and flexible interface for data analysis, scientific computing, machine learning, and more. Users can write code and execute cells independently, which facilitates step-by-step exploration and experimentation with real-time data. Getting Started XMPro Notebook is an embedded version of Jupyter and can be accessed from the waffle menu on the top left navigation, and by navigating to \"AI\". Quickstart Guide Once opened there is a handy quick-start guide that acts as an introduction on how to use XMPro Notebook. Note The first time an XMPro notebook user session loads, the infrastructure is provisioned in real-time, meaning that the application will take a few seconds to load. ChatGPT XMPro AI has built-in ChatGPT functionality through the use of Python Magics. Once you've provided your ChatGPT API Key, you can use line magic to provide a single line of input, or cell magic to provide multiple lines of input. Set your ChatGPT API Key # Set your ChatGPT API Key %chatgpt -k \"<your ChatGPT api-key>\" Line magic: %chatgpt Example input: %chatgpt \"show a correlation plot for the iris dataset\" Example output: import seaborn as sns import matplotlib.pyplot as plt iris = sns.load_dataset('iris') corr = iris.corr() sns.heatmap(corr, annot=True, cmap='coolwarm') plt.show() Cell magic: %%chatgpt Example input: %%chatgpt \"improve this plot example\" import matplotlib.pyplot as plt x = [1, 2, 3, 4, 5] y = [5, 4, 3, 2, 1] plt.plot(x, y, 'ro') plt.xlabel('X axis') plt.ylabel('Y axis') plt.title('Example Plot') plt.show() Example output: import matplotlib.pyplot as plt import numpy as np # Generate some random data x = np.random.randint(0, 10, size=50) y = np.random.randint(0, 10, size=50) colors = np.random.rand(50) # Create a scatter plot with different marker sizes and colors plt.scatter(x, y, s=50*x, c=colors, alpha=0.5) # Set axis labels, limits, and title plt.xlabel('X axis') plt.ylabel('Y axis') plt.xlim(0, 10) plt.ylim(0, 10) plt.title('Random Data Scatter Plot') # Add a colorbar legend plt.colorbar() # Display the plot plt.show() MLops MLflow is a well-known open-source MLops platform that streamlines the machine learning lifecycle: to create instances of models and run them in a structured and organized manner. This example illustrates how to leverage the MLflow Python library to create an instance of a machine learning model and execute it within your MLflow environment. Example input: # Importing necessary libraries from mlflow.models.signature import ModelSignature from mlflow.types.schema import ColSpec, Schema import mlflow from sklearn.linear_model import LinearRegression import numpy as np # Generate some sample data for training X = np.array([[1], [2], [3], [4], [5]]) y = np.array([2, 4, 6, 8, 10]) # Create an instance of Linear Regression model model_lr = LinearRegression() # Fit the model to the training data model_lr.fit(X, y) # Define a schema for the input and output of your model # In this case, both input and output are single columns of string type sig = ModelSignature( inputs=Schema([ColSpec(name=\"input\", type=\"string\")]), outputs=Schema([ColSpec(name=\"output\", type=\"string\")]), ) # Set the tracking URI for MLflow # This is the address where the MLflow server is running # Replace the IP address and port number with the ones for your server mlflow.set_tracking_uri('http://<URI>:<PORT>') # Start a new MLflow run # This represents a single execution of the model training code mlflow.start_run() # Log the trained model with MLflow mlflow.sklearn.log_model( sk_model=model_lr, artifact_path=\"model\", registered_model_name=\"LinearRegression\", signature=sig ) # End the MLflow run mlflow.end_run() Example output: Successfully registered model 'LinearRegression'. Created version '1' of model 'LinearRegression'. Libraries Libraries are a collection of pre-written code and functions that can be imported and used in programs to simplify development and add additional functionality. The following Python libraries are pre-installed in XMPro Notebook: altair beautifulsoup4 bokeh bottleneck cloudpickle conda-forge::blas=*=openblas cython dask dill h5py ipympl ipywidgets matplotlib-base mlflow numba numexpr numpy openai opencv python pandas patsy protobuf pytables scikit-image scikit-learn scipy seaborn sqlalchemy statsmodels sympy widgetsnbextension xlrd If any additional libraries are needed, the installation can be performed in the Notebook Cell. Below is an example command for a Python library: pip install <your library name> Please contact XMPro if you would like to propose another library added to the set of defaults. Warning Any library you load is only valid for the session and will need to be reinstalled when a new session is created. Licensing Unlike other XMPro products, two product licenses are required: one for the core AI product, and a second for XMPro Notebook. For more information on how to request a license, please view the instructions on how to Request a License."
  },
  "src/getting-started/browser-requirements.html": {
    "href": "src/getting-started/browser-requirements.html",
    "title": "Browser Requirements | XMPro",
    "summary": "Browser Requirements Supported Browsers The XMPro platform can be run on a variety of browsers and operating systems. The latest two major releases of the following browsers are supported on the indicated operating systems: Browser Windows macOS iOS Android Google Chrome ✓ ✓ ✓ ✓ Apple Safari ✗ ✓ ✓ ✗ Microsoft Edge ✓ ✓ ✗ ✗ Mozilla Firefox ✓ ✓ ✗ ✗ Opera ✓ ✓ ✗ ✗ Supported Operating Systems The following operating systems are supported for browsers running the XMPro platform: Operating System Supported versions Windows Windows 10 or later macOS 10.13 or later iOS iOS 10 or later Android 5 or later Third-Party Cookies The XMPro Platform requires third-party cookies on web browsers to be allowed/enabled for it to function properly. Follow the steps below to enable cookies on the different browsers. Note Enabling third-party cookies is essential for the XMPro platform to function correctly. Without this setting, you may experience issues with authentication and certain features. Google Chrome On your computer, open Chrome. At the top right, click More, then Settings. Under \"Privacy and security,\" click Site settings. Click Cookies. Next to \"Blocked,\" turn on the switch to turn on cookies. For more information, you can visit the Official Google Chrome Documentation. Microsoft Edge Open Microsoft Edge, select Menu (3 dots icon on the top right corner of the browser) > Settings > Site permissions > Cookies and site data Turn on \"Allow sites to save and read cookie data (recommended)\" to unblock cookies Turn off \"Block third-party cookies\" or add desired sites in the \"Allow\" section to unblock cookies. For more information, you can visit the Official Microsoft Documentation. Apple Safari In the Safari app on your Mac, choose Safari > Preferences Click Privacy Unselect \"Block all cookies\". For more information, you can visit the Official Apple Documentation."
  },
  "src/getting-started/end-to-end-use-case.html": {
    "href": "src/getting-started/end-to-end-use-case.html",
    "title": "End-To-End Use Case | XMPro",
    "summary": "End-To-End Use Case Note This Use Case assumes the XMPro platform is installed and configured, or you are using the Free Trial that has everything set up for you. This step-by-step tutorial is meant to be an introduction to using the XMPro platform. Completing it will give you a solid foundation to understand the more advanced concepts and detailed how-to guides. This tutorial will explain how to create and design a Data Stream, configure Stream Objects to ingest, analyze, transform, and perform actions on data. You will also learn how to set up a Recommendation to generate alerts based on rule logic, create and design an App, create Data Sources and Connections, and configure a simple Data Grid and Chart. Warning Please note that the XMPro platform requires third-party cookies to be enabled on your browser. Use Case Let's assume there is a power plant that uses a heat exchanger to keep the turbine cool and at the optimum temperature. The heat exchanger circulates water between the cooling tower and the heat exchanger to dissipate heat. To keep a proper circulation of liquid, there are three pumps [A, B, C] installed. Each Pump has a sensor that provides live data for Flow Rate (L/m) and Temperature (°C) using MQTT. Unless the Pump is under maintenance the Flow Rate should be above 15000 L/m and Water temperature should be below 130°C. Engineers should be alerted if the average flow rate falls below 250 L/s. If the average temperature starts to rise above 130°C then a critical level alert should be raised. Engineers should be provided a view to check the history of pump telemetry, maintenance records, and reservoir level to enable them to take necessary action. 1. Design Data Streams with Real-Time Data Sources The Use Case requires that we gather the Flow Rate and Temperature data from three pumps constantly, and pass it on to be analyzed and have actions performed on the data. We will achieve this with the use of Data Streams. A Data Stream is a visual representation of a flow of data. It is created through the Data Stream Designer. To access the Data Stream Designer, log into your XMPro Account and press the button in the top-left corner of the screen and click on the Data Stream Designer item. A Data Stream has four components: Ingesting data through Listener Agents Contextualizing sensor data/telemetry through Context Provider Agents Analyzing and transforming data through Transformation and AI Agents Performing actions or outputting data to other integrations through Recommendation and Action Agents We will follow those four steps below. Read & Wrangle Live and Context Data In this section, we will simulate reading data from pump sensors and a metadata store, and combine the data together into a single flow. Note See the Data Stream Concept article for more information on Data Streams. To begin, we will need to create a new Data Stream. To create a Data Stream, follow the steps below: Open the New Data Stream page from the left-hand menu. Give the Data Stream a name. For example, \"Pump Condition Monitoring\" Select the Type \"Streaming\". Data Streams of the Streaming type will run polling Agents at a set interval, for instance, every 10 seconds, whereas Recurrent Data Streams run on a customizable schedule, for instance, once a day at 12am. The recurring type only applies to polling-based Stream Objects, which we won't use in this example. Select the category under which the Data Stream is to be added. Feel free to load a suitable icon. If you do not, the default icon will be used. Sample icons can be found in the Icon Library. Select a collection that will be used to publish Data Stream. Enter a description to best describe the Data Stream. Click on \"Save\". In a production environment, Data Streams would integrate with external data emitters through Agents like OSIsoft PI or MQTT Listeners. However, for the sake of keeping the example simple, we won't be using any Agents that require an environment to be set up. Instead, we will be simulating the data with the Event Simulator, Calculated Field, and CSV Context Provider Agents. To simulate the telemetry from the pumps, follow the steps below: Drag into the canvas one of each of the following Agents: Event Simulator (Listener) Calculated Field (Transformation) CSV (Context Provider) Join (Transformation) Note Refer to How to Upload an Agent to Data Stream Designer if you are not able to find the Agents in the toolbox or the correct versions. You can search for the Agent in the search bar, and click and drag the Agent into the canvas to add it. An instance of an Agent added to the canvas is referred to as a Stream Object. Once you have all four Stream Objects in the Data Stream canvas, rename them as follows: Event Simulator as \"Simulate Pump Data\" Calculated Field as \"Add Pump Identifier\" CSV as \"Simulate Context Data for Assets\" Join as \"Contextualize Data\" To change the name of a Stream Object, click the text and edit it. Your stream should end up looking like this: Once you have renamed all four Stream Objects, connect them with arrows as follows: \"Simulate Pump Data\" to \"Add Pump Identifier\" \"Add Pump Identifier\" to \"Contextualize Data\" (first input) \"Simulate Context Data for Assets\" to \"Contextualize Data\" (second input) To connect two Stream Objects, click and drag the green rectangle (Output) at the bottom edge of the first Stream Object, move the cursor to the green rectangle on the left edge of the second Stream Object (Input). Your connected Stream Objects should look like this: Now we will configure the added Stream Objects. Save your Data Stream now and after every change to propagate the changes throughout the Data Stream. Note See the article on how to configure Stream Objects for more information. Simulate Pump Data We will need to simulate ingesting data about flow rate and temperature from sensors in the pumps. We can achieve this with the Event Simulator Agent. The \"Simulate Pump Data\" Event Simulator will constantly generate data defined by the Event Definitions at a rate defined by the Events per Second property. Note To edit the configuration of a Stream Object, either double-click it or click it once to select it and click the \"Configure\" button on the canvas header. Edit the \"Simulate Pump Data\" Stream Object and click the + button to the right of the Event Definition grid to add event definitions. Add two event definitions as follows: Name: WaterTemperature Type: Range Minimum Value: 100 Maximum Value: 160 Spike Value: 0 Name: FlowRate Type: Range Minimum Value: 14000 Maximum Value: 16000 Spike Value: 0 Ignore the Spike Value and Generate Spike options, as they are not relevant to the current scenario. Change the Events per Second to 1. Click \"Apply\" on the Simulate Pump Data configuration page. Then click \"Save\" on the Data Stream page. Add Pump Identifier We need to add a way to simulate having three different pumps. At the moment the data is not identified, so we will need to add a range of identifiers to the data. This can be achieved with the Calculated Field Agent. The \"Add Pump Identifier\" Calculated Field will add a \"PumpId\" field to the data generated with values \"A\", \"B\", and \"C\" for each subsequent row. To configure the Stream Object, double click on \"Add Pump Identifier\" to open its configuration. Or, you can also highlight the Stream Object and click on the \"Configure\" option at the top of the Data Stream. Keep \"Append to Current\" as the \"Results Returned As\" value. This will add the value calculated by the expression to each row instead of creating a new row with the identifier. Click the + button to the right of the Expressions grid to add the following expression: Calculated Field: \"PumpId\" - The field won't exist yet in the dropdown, so you must enter it yourself. Expression: ReadingNo % 2 == 0 ? \"A\" : ReadingNo % 3 == 0 ? \"B\" : \"C\" Data Type: String Press \"Apply\" on the PumpId expression and the Add Pump Identifier configuration pages, and press \"Save\" on the Data Stream page. Simulate Context Data for Assets There is often metadata associated with assets that is not part of the live data from the sensors. In this case, metadata includes whether the pump is currently under maintenance, the manufacturer, and the last service date. We must retrieve this data from elsewhere. In a production environment, this might be an SAP EAM system, but for this example, we can achieve this through the CSV Context Provider Agent. Double-click on the \"Simulate Context Data for Assets\" Stream Object to open the configuration menu. You can also highlight the Stream Object and click on the \"Configure\" option at the top of the Data Stream. Download the provided file. The contents of the file are below the download link. AssetsContext.csv PumpId,UnderMaintenance,Manufacturer,ServiceDate A,FALSE,Bosch,2020-10-12 B,FALSE,Bosch,2020-08-06 C,FALSE,Bosch,2020-01-04 Then under Data check the Use Uploaded File? checkbox and upload the file into the CSV Context Provider. The CSV Definition will be automatically detected and filled. Change UnderMaintenance from a String to a Boolean, using the options from the dropdown. Also change ServiceDate from a String to a DateTime, using the dropdown. Leave the Limit Rows, Filter Criteria, and Sort by properties as their default values. When completed, press the \"Apply\" button at the top of the configuration, and then save the Data Stream. Contextualize Data The metadata about each pump needs to be appended to each row of sensor data received from the pumps. This can be achieved with the Join Agent. The \"Contextualize Data\" Join will join together the data from the CSV Context Provider and the Calculated Field using the PumpId as the common field. Configure it as follows: Behavior: Context - we want to join some context data to our row. Context Endpoint: Right - we must tell the Stream Object which input has Context data. The Context Data is received by the Right endpoint, as shown in the image below. Select List: all fields except R_PumpId (as the same data will be in L_PumpId). Join Type: Inner Join. On: L_PumpId = R_PumpId Note You may need to maximize the page to see the grid properly. You can do this by pressing the \"Maximize\" button in the top-right corner of the page. Press the \"Restore\" button in the top-right corner to return it to the regular size. Press \"Apply\" on the Contextualize Data configuration page, and press \"Save\" on the Data Stream page. Create Analytics and Calculations In this section, we will add some analytics and calculations that will find exceptions, transform the units of the data and find the average level across 5 seconds. Ignore Pumps Under Maintenance We want to only pass data onward in the Stream if the current pump is not under maintenance. This can be achieved with the Filter Agent. To do this, drag in a Filter Agent and connect the \"Contextualize Data\" Join endpoint to the Filter. Rename the Filter to \"Ignore Pumps Under Maintenance\", and save. Double-click on the Stream Object to open the configuration menu. Click on the + symbol to add a new rule for the filter. Select \"Add Condition\", and configure the Filter to have the logic R_UnderMaintenance Equals false. The configuration and Data Stream should look like this: There are two green outputs to the Filter Stream Object, the left output is where the data is output to when the filter is true. The right output is where the data is output to when the filter is false. The left True Output should be the output that you connect to the next Stream Object. Press \"Apply\" on the Ignore Pumps Under Maintenance Data configuration page, and press \"Save\" on the Data Stream page. Change Unit to L/s The data from the Pump Data has different units than what we want to use - it is measured in L/m and we want the units to be in L/s. This can be solved with the Calculated Field Agent. To transform the data, drag in a Calculated Field Agent, and rename it to \"Change Unit to L/s\". Connect the \"Ignore Pumps Under maintenance\" Filter endpoint to the Calculated Field and Save. Make sure you connect the left True Output of the \"Ignore Pumps Under maintenance\" Stream Object to the Calculated Field's input. Configure the Calculated Field as follows: Calculated Field: L_FlowRate Expression: L_FlowRate / 60 Data Type: Double This will divide the flow rate by 60 to make the value in L/s instead of L/m. Press \"Apply\" on the Change Unit to L/S configuration page, and press \"Save\" on the Data Stream page. Average across 5 seconds The Use Case requires that engineers should be alerted if the flow rate averaged over 5 seconds falls below 250 L/s, and if the temperature averaged over 5 seconds also starts to rise above 130°C then a critical level alert should be raised. This can be achieved with the Aggregate Agent. To calculate the average temperature and flow rate over 5 seconds, drag in the Aggregate Agent and name it \"Average across 5 seconds\". Connect the \"Change Unit to L/S\" Calculated Field endpoint to the Aggregate Agent and save. Note You may need to maximize the page to see the grid properly. You can do this by pressing the \"Maximize\" button in the top-right corner of the page. Press the \"Restore\" button in the top-right corner to return it to the regular size. Configure the Aggregate Agent as follows: Attributes to group on: L_PumpId Aggregate: Average (of) L_FlowRate (as) FlowRateAvg Average (of) L_WaterTemperature (as) CoolantTemperatureAvg Unit: Second Size: 5 Press \"Apply\" on the Average across 5 seconds configuration page, and press \"Save\" on the Data Stream page. Data Conversion We want the data for the average flow rate to be in integer format to display it more easily. This can be achieved through the Data Conversion Agent. To do this, drag in a Data Conversion Agent and rename it to \"Data Conversion\". Connect the \"Average across 5 seconds\" endpoint to the Data Conversion Agent and press \"Save\" on the Data Stream page. Configure the Data Conversion Agent with the following two rows (You may need to maximize the page again). Click on the + symbol to add each row: First row: Input Column: \"FlowRateAvg\" Output Alias: \"FlowRateAvg\" Data Type: \"Int64\" Second row: Input Column: \"CoolantTemperatureAvg\" Output Alias: \"CoolantTemperatureAvg\" Data Type: \"Int64\" The input columns should already have FlowRateAvg and CoolantTemperatureAvg as options listed in the dropdown menu. This will replace the FlowRateAvg and CoolantTemperatureAvg with values converted to Integer format. Press \"Apply\" on the Data Conversion configuration page, and press \"Save\" on the Data Stream page. Output Formatting and Action Integrations In this section, we will integrate our Data Stream with the App Designer to trigger Recommendations and send data to Apps. Run Recommendation First, we want to trigger Recommendations with the data from the Data Stream. This can be achieved with the Run Recommendation Agent. To do this, drag in a Run Recommendation Agent and rename it to \"Run Recommendation\". Connect the \"Data Conversion\" endpoint to the Run Recommendation Agent and press \"Save\" on the Data Stream page Configure the Run Recommendation Stream Object as follows: Url: the URL of the App Designer site Key: the App Designer Key. Output on first occurrence Only?: true Entity Identifier: L_PumpId - this is for the Recommendation to create separate Alerts for each Entity Columns To Return: Leave empty (Return all columns) Note It is highly recommended that you use any variables that you already have that store the URL or key. You may use the variables that have already been set up if you are using the Free Trial. Otherwise, the App Designer URL and Key can be found by following these steps: Open the App Designer in a new tab by clicking the \"Waffle\" button (a.ka. \"App Launcher\") in the top left corner of the page and clicking \"App Designer\". Copy the App Designer URL from the browser's address bar and paste it into the Url field in the Run Recommendation configuration. Click the \"Settings\" button in the top bar and click the \"Copy\" button to the right of the Integration Key and paste it in the Key field in the Run Recommendation configuration. You will only be able to see this if you have Admin access. If you do not have Admin access, you can ask an Admin to share the key with you. Note If you are configuring the URL and Integration Key without using variables, make sure you uncheck the \"Use Connection Variables\" checkbox option first. This is how your Data Stream and configuration should look: Press \"Apply\" on the Run Recommendation configuration page, and press \"Save\" on the Data Stream page. XMPro App We want to send data to an App to be displayed as a decision support dashboard for the engineers. This can be achieved through the XMPro App Agent. Drag two XMPro App Agents onto the Data Stream and name them \"Post Pump Overview\" and \"Post Pump Specifics\". One will send an overview of the data for all pumps, and the other will send a large cached amount of data for each pump. Now we run into a problem; we want to connect multiple agents to the same data. To solve this, drag a Broadcast Agent into the Stream, and rename it to \"Broadcast\". Disconnect the \"Ignore Pumps Under Maintenance\" input arrow and connect it to the new Broadcast Stream Object. You can disconnect the arrow by highlighting the arrow itself and clicking on the \"Delete\" button at the top of the Data Stream. Alternatively, you can click on the green rectangle (input) on the \"Ignore Pumps Under Maintenance\" Stream Object, and drag the arrow to the green rectangle (input) of the \"Broadcast\" Stream Object. Connect the Broadcast endpoints to the two XMPro App Stream Objects and the \"Ignore Pumps Under maintenance\" Filter, as shown in the video below: Press the \"Save\" button at the top of the Data Stream. Your Data Stream should now look like this: Configure the \"Post Pump Overview\" Stream Object to store in cache and output only one row per pump as follows: (Follow the steps given for the Run Recommendation Agent above to get the Url and Key.) Url: the URL of the App Designer site Key: the App Designer Key. Cache Size: 1 Replace Cache: false Cache Per Entity: true Entity Identifier: L_PumpId Primary Key: L_PumpId Note It is highly recommended that you use any variables that you already have that store the URL or key. You may use the variables that have already been set up if you are using the Free Trial. Note If you are configuring the URL and Integration Key without using variables, make sure you uncheck the \"Use Connection Variables\" checkbox option first. Press \"Apply\" on the Post Pump Overview configuration page and press \"Save\" on the Data Stream page. Configure the \"Post Pump Specifics\" Stream Object to cache and output 20 rows per pump as follows: Url: the URL of the App Designer site Key: the App Designer Key. For more detail on how to find the key in the Site Settings, see this article. Cache Size: 20 Replace Cache: false Cache Per Entity: true Entity Identifier: L_PumpId Primary Key: L_PumpId and L_ReadingNo Note It is highly recommended that you use any variables that you already have that store the URL or key. You may use the variables that have already been set up if you are using the Free Trial. Note If you are configuring the URL and Integration Key without using variables, make sure you uncheck the \"Use Connection Variables\" checkbox option first. Press \"Apply\" on the Post Pump Specifics configuration page and press \"Save\" on the Data Stream page. Your Data Stream is now complete. To start the stream, click on the \"Publish\" button. To see the data flow at each Stream Object, press the \"Live View\" button and select all the Stream Objects. Alternatively, you can also select specific Stream Objects. For example, if you just want to see the data flowing through to the XMPro App, select the XMPro App Stream Object. Troubleshooting the Data Stream To see if data is flowing properly within the Data Stream, you will need to Publish the Data Stream. Before publishing, you want to make sure there are no errors in the configurations of the Stream Objects. Click on the \"Integrity Check\" option at the top of the Data Stream. If any errors are present, the Stream Object with the errors will turn red. Hovering over the Stream Object will show you the list of errors. Once these errors are fixed, you will need to run the Integrity Check again. Note To read more about Integrity Checks, read the Verifying Stream Integrity article. Once all Stream Objects have passed the Integrity Check, you can click on \"Publish\", then \"Live View\", on the top of the Data Stream. The Live Data will open on the side, and you can then click on \"Select Views\" to click on the Stream Objects you want to troubleshoot. If data is displaying for the Stream Object, that means the Stream Object should be working correctly. If not, you can recheck your configuration values for the Stream Object. You can also check if you have a Stream Host running. There are also other ways that you can troubleshoot Data Streams. Note For more ways on how you can troubleshoot a Data Stream, read the Troubleshoot a Data Stream article. 2. Create Event Rules & Recommendations The Use Case requires that engineers should be alerted if the flow rate averaged over 5 seconds falls below 250 L/s, furthermore, if the temperature averaged over 5 seconds also starts to rise above 130°C then a critical level alert should be raised. To achieve this we will use Recommendations. Recommendations can be found in the App Designer. Open the App Designer in a new tab by clicking the button in the top left corner of the page and clicking \"App Designer\". To access the Recommendation management section of the App Designer, click on the \"Recommendations\" button in the left menu and press the \"Manage Recommendations\" button on the page. Create Event Rule and Rule Logic To trigger the required Alerts, we will be creating a Recommendation with two Rules. First, create a Recommendation called \"Pump Flow Threshold\". The Data Stream should be the same \"Pump Condition Monitoring\" stream we created previously. To create a new Recommendation, follow the steps below after navigating to the Recommendation management page: Click \"New\". Specify a name and category for your new Recommendation. Choose a Data Stream to receive data from. Click \"Save\". Warning Make sure to click the \"Manage Access\" command and give at least yourself Run Access, otherwise, you won't be able to see any Recommendation Alerts that will be generated by this Recommendation. This Rule will notify Engineers when the Flow Rate is lower than 250 L/s and give them instructions and resources to help resolve the issue. Select the Enable Execution Order checkbox, since we want the more critical rule to override the medium rule. Create a Rule by pressing the + button to the right of the Rules list. Give the Rule the following properties: Note The tags for the Alert Heading and Alert Description fields will not work if they are copied and pasted into the field. You will need to select the tags yourself by adding an @ symbol and selecting from the tags in the list. Name Value Description Rule Name Medium - Flow rate falling The Rule Name is for identification only and will not be shown to the user in the Recommendation Alerts grid or detailed view. Alert Headline Warning @L_PumpId: Flow rate is falling This refers to the headline that the Recommendation Alert will be created with. Any tag (starting with @) will be replaced with the value output from the Data Stream. Add tags by typing @ and selecting the item. Alert Description Flow rate is reported to be falling, danger of plant overheating and shutdown. Flow Rate: @FlowRateAvg Coolant Temperature: @CoolantTemperatureAvg This refers to the description that the Recommendation Alert will be created with. Any tag (starting with @) will be replaced with the value output from the Data Stream. Alert Ranking Medium The priority level that the Recommendation Alert will be created with. Priority level determines the order in which the Alerts will be displayed. Icon An icon of your choice (hover your mouse over the default icon to upload a different one - sample icons can be found in the Icon Library) The icon that will be displayed on the Recommendation Alert in the grid and in detailed view. Impact Metric Prefix: $ Value: 15 Unit of Measurement: K The impact that the Recommendation Alert will have. For example, if the value for this was $15K, that means that the cost of the condition causing the Alert would be $15K (or $15000). This will be shown on Alerts in the Recommendation Block in App Pages. Rule Logic FlowRateAvg Is less than or equal to 250 Data sent from the selected Data Stream is passed through the Rule Logic and if the conditions created are met by the data (and if Recurrence is set to All Occurrences or First Occurrence and no Pending Alert exists), a new Recommendation Alert will be created. You can add new conditions or groups by clicking the + button. Groups can be nested within each other to create advanced logic. In an \"And\" group, all the conditions must be true, and in an \"Or\" group, only one of the conditions must be true to trigger an alert. The Rule Logic determines whether a Recommendation Alert will be created on receiving data from the Data Stream. Note For more details on Rule Logic, see this article. Create recommendations & Triage Instructions There should be some instructions for the engineers to follow to help resolve the issue when it occurs. This can be provided through the Triage Instructions. Continue creating the Rule with the following properties: Name Value Description Enable Form false A flag that determines whether the Recommendation Alert will be created with a Form. Additional Recommendation Management Column - An additional column in the Recommendation Alerts grid. Resolution Manual Resolution determines whether new data from the Data Stream will automatically resolve the Recommendation Alert if the Rule Logic is no longer true. Manual Resolution: A user must manually resolve each recommendation. Automatic Resolution: Recommendation auto resolves when trigger conditions are no longer true. This may impact performance. Recurrence First Occurrence Recurrence determines whether new data from the Data Stream will create new Recommendation Alerts if there already exists a Pending Recommendation Alert and the Rule Logic is true. Recurrence will create an Alert for each unique Entity selected by the Data Stream. For example, since there are three pumps (A, B, and C), each pump will generate its own Alert when something goes wrong, and it will need to be resolved before new Alerts for that pump are created. First Occurrence: The current recommendation must be resolved before others can be triggered for the same rule. All Occurrences: A new recommendation will be triggered every time the rule conditions are true. Recurrence will be disabled and be considered to be First Occurrence if the Recommendation has Execution Order enabled. Log Data On First Occurrence Determines whether new events from the Data Stream that satisfy the Rule Logic, after a recommendation has been triggered, will be logged or not. First Occurrence: Current recommendation will only log the initial event which triggered the recommendation. All Occurrences: Event data will be stored for every instance that satisfies the rule logic. Enable Triage Instructions true A flag that determines whether the Recommendation Alert will be created with Triage Instructions. Triage Instructions Instructions to help whoever is resolving the Recommendation Alert. Find the Triage Instructions below to copy for this use case. Possible problems causing a discharge pressure drop: Blocked Suction Pipe A partial obstruction can be caused by a piece of foreign material being drawn across the bottom of the suction pipe during the operation of the pump. Such an obstruction may not be sufficient to stop operation completely, but will result in a reduced output from the pump. It will also cause a drop in discharge pressure and amps, and will increase the vacuum reading on the pump suction. Rough running and vibration of the pump may also occur due to cavitation within the pump. Blocked Impeller Impellers are capable of passing a certain size particle. If a particle larger in size enters the suction pipe, it may become lodged in the eye of the impeller, restricting the output of the pump. Such an obstruction will usually result in a drop of amperes and a drop in both discharge pressure and suction vacuum readings. The out-of-balance effects resulting from this condition may cause pump vibration. SHUTTING DOWN PROCEDURE Before you shut down the pump, it should be allowed to operate for a short period on only clean water to clear the system. Then proceed as follows: Depress the 'STOP PUMP' push-button on the control panel. Gland seal water (if any) must be left on during all subsequent operations, namely: start-up, running, shutdown, runback and system drain. Gland water may only then be turned off. Provide additional resources for decision support You can provide the Engineers with helpful links to videos, PDFs, or websites to help resolve the issue with the Resources. Continue creating the Rule by checking Enable Resources and adding the following Resources: Resource Url Test Procedure http://xmdocsdownload.s3.amazonaws.com/Technical/WarmanETP.pdf You can see this rule in action by clicking the \"Publish\" command in the Recommendation and in the Pump Condition Monitoring Data Stream. If the average flow rate coming from the Data Stream is lower than 250 L/s the Rule will generate an Alert for each Pump that can be viewed in the Recommendation Alerts grid. Click on the \"Recommendations\" button to go back to the Recommendation Alerts grid. To see more details about the alert, click on a row in the \"Recommendation Alerts\" grid. The Recommendation Alert page provides details of the alert and allows you to monitor, discuss, and take action. Multiple Rules and Rule escalation We want to trigger new Alerts that override the Medium level alert raised before if the temperature averaged over 5 seconds also starts to rise above 130°C. To do this we will create the second Rule and configure the escalation settings. This second Rule will notify Engineers when the Coolant Temperature is higher than 130°C and Flow Rate is lower than 250 L/s and give them instructions and resources to help resolve the issue. To create another Rule, click on the Recommendations page from the left-hand menu, and click on \"Manage Recommendations\". Select the \"Pump Flow Threshold\" Recommendation that was created previously. To make amendments to the Recommendation, you will first need to unpublish the Recommendation, by clicking on the \"Unpublish\" button at the top of the Recommendation. Finally, click on the \"plus\" symbol under \"Rules\" to add the new Rule. Create the new Rule with the following properties: Name Value Rule Name Critical - Plant is overheating Alert Headline Alert @L_PumpId: Plant has started to overheat due to low flow. Alert Description Plant is overheating due to low flow rate, immediate action is required to avoid damage. Temperature: \uFEFF@CoolantTemperatureAvg\uFEFF Flow Rate: \uFEFF@FlowRateAvg\uFEFF Alert Ranking High Icon Feel free to load a suitable icon or use the default. Sample icons can be found in the Icon Library. Impact Metric Prefix: $ Value: 25 Unit of Measurement: K Rule Logic FlowRateAvg Is less than or equal to 250 CoolantTemperatureAvg\uFEFF Is greater than 130 Enable Form false Additional Recommendation Management Column - Resolution Manual Recurrence First Occurrence Log Data On First Occurrence Enable Triage Instructions false Enable Resources false We also want the Critical Rule to override the Medium Rule. To do this, ensure that the Enable Execution Order and Auto-Escalate checkboxes are ticked in the Recommendation, and reorder the Rules to put the Critical Rule at the top. You can see the full Recommendation in action by clicking the \"Publish\" command in the Recommendation. Ensure that your Data Stream is also published and running. If the average coolant temperature is higher than 130°C and the average flow rate coming from the Data Stream is lower than 250 L/s the Rule will generate an Alert for each Pump that can be viewed in the Recommendation Alerts grid. Any pending Alerts from the Medium rule will be resolved and escalated to the new Alert. 3. Create Event Boards & Apps The Use Case requires that the Engineers should be provided a view to check the history of Pump telemetry, maintenance records, and Reservoir Level in order to enable them to take necessary action. This requirement can be met through the use of an App with a couple of Pages. Layout Event Boards First, create an Application (or App) by pressing the \"New Application\" button in the left menu and clicking the \"Blank App\" template. Give the App the following properties: Name: \"Power Plant THG Event Board\" Description: \"An App to monitor assets at a power plant.\" Category: any Icon: Feel free to load a suitable icon. If you do not, the default icon will be used. Sample icons can be found in the Icon Library. Default Theme: Dark Landing Page Layout: the first item Click on the \"Save\" button. This will take you to a page where you can view the list of pages in the App or edit the App itself. Click on the Landing Page to edit it. App Layout We will want two sections on the landing page, so follow the steps to duplicate the Vertical Stacked Layout as shown in the screenshot below. Click \"Page Layers\". Click on the carets to expand the layers until you reach the second Vertical Stacked Layout. Click on the Vertical Stacked Layout. A blue toolbar will appear at the top-right corner of the block. Press the third button with a \"Clone\" symbol to duplicate the Vertical Stacked Layout and everything it contains. Note See the article on Page Layers for more information. The result should look as below: You can rename both Vertical Stacked Layouts to identify them. In the Page Layers tab, double click the Left Vertical Stacked Layout to change the text to 'Left Vertical Stacked Layout'. Double click on the text of the other Right Vertical Stacked Layout and rename that to 'Right Vertical Stacked Layout'. The left side of the page should be twice as wide as the right side, so follow the steps to change the Left Vertical Stacked Layout's Flex Grow property in the Block Styling to 2 as shown in the screenshot below. Make sure the Left Vertical Stacked Layout is still selected in the Page Layers. Click the \"Block Styling\" button to open the style manager. Click the \"Flex Layout\" accordion item to expand it. Change the Grow field to 2. Press the \"Save\" button at the top of the Application designer. Note See the articles on How to use the Style Manager and How to use Flex for more information. The result should look like this: We want to display the properties of the pumps in regularly spaced and sized cards on an App page. To do this, create one card with a Data Source, which will repeat the card for each pump. Change the Left Vertical Stacked Layout's Display property in the Block Styling to block, so that the cards will overflow to however many pumps are present. Press the \"Save\" button at the top of the Application designer. Follow the steps below to select the left Card and delete it. We will replace the default Card with a useful layout. Open the Page Layers. Expand to the Left Vertical Stacked Layout's Card. Click the Card item to select the Card element. Click the last button on the blue toolbar to delete the Card. Replace the deleted Card by dragging in a Card from the Blocks, which will include some extra items. Note See the article on Blocks for more information. We want the card to take up half the width of the left section, and overflow to the next line when there are more than 2 cards. Select the new Card using the Page Layers tab. Click on the \"Block Styling\" tab. At the top, in the \"Style Group\" field, click on the checkbox on the left of the \"card-gutter\" tag to unselect the card-gutter style group. This is because we only want to apply styles to this specific element. Under the \"General\" subsection, change \"Display\" to \"inline-block\". Under the \"Dimensions\" subsection, change the Width to 50. Under the \"Dimensions\" subsection, change the unit to %. Rename the Metric text items to \"Status\", \"Flow Rate\", and \"Coolant Temperature\". You can double-click the text items and change the text. The Status should show an Indicator (a colored circle) to display the status of the pump. Delete the top Value. Right-align the remaining two Values by expanding the Typography section and changing the Text Align property to Right. Drag two Indicator Blocks from the Blocks tab into the deleted Value text item's box. Click the Box and change the Flex Justify to End. This will align the Indicators to the right side of the box. The \"Status\" indicator should be red or green, depending on whether the pump is under maintenance or not. Change the left Indicator's Color in the Block Properties to \"#ad6363\" (red), and the right to \"#398a33\" (green). Data Source for Pump Data Add the Data Source that will be used to display our pump data. Click on the \"Page Data\" button. Click the + button next to Data Sources. Add a Data Source with Name as Pump Data, Connection as Data Streams Connector, and Entity as Post Pump Overview. Check Live Data Updates as well to keep the data constantly updated. Click on the \"Save\" button. Click the Card and set the Data Source in the Block properties tab to Pump Data. Set Show Default Row to Never, as we don't want an empty card at the end. You can also open the Page Layers tab and look at the highlighted Block to confirm that the correct Block is selected. When the data comes in for each pump, we want the cards to display the values for each pump. To do this, we will give the values, indicators, and heading dynamic or expression values. To change a property to Expression mode, follow the steps below: Select the block (in this case the Heading of the card) through the canvas or Page Layers. Click the \"Block Properties\" button. When adding an expression for the \"PumpId\", press the button on the left of the Text property field to toggle between Static, Dynamic and Expression value modes. Change the mode to Expression so you can enter an expression to display the Pump Id that is selected. Give the Heading's Text property an expression value of \"Pump \" + {L_PumpId} by clicking the button on the left side of the field twice. Note See the Dynamic and Expression Properties section of the Block Properties article for more information. Select the Value Block next to 'Flow Rate'. Click on the \"Block Properties\" tab and give the Text an expression value of ToStr(Round({L_FlowRate})) + \" L/m\". Give the Coolant Temperature Value Text Block an expression value of ToStr(Round({L_WaterTemperature})) + \"°C\". The circle Indicators' Visible property should be changed to an expression value of {R_UnderMaintenance} and !{R_UnderMaintenance} respectively. Change the text of the Title to \"Pumps at Power Plant THG\". To launch the App to see how it looks, press the \"Save\" button at the top of the Page and then press the \"Launch\" button. Each unique pump entity will have its own card, and data will be updated constantly for the Flow Rate and Coolant Temperature. To get back to editing the App, press the \"Edit\" button at the top-right of the App. This button will only be shown for users who have been granted access to the App. Note See the How to Manage Access article for more information. Drilldown Page The Engineers want to be able to see a detailed chart and history of each pump when they click on a pump's card on the landing page. To make a new drilldown Page, close the Landing Page, and add a new Page with the + button. Name the Page \"Pump Details\". To link to the newly created Pump Details Page when clicking a card, close the page and open the Landing Page again. You can click and drag the grey header of the page to the right to see the list of pages. Click on the \"Page Layers\" tab. Expand the carets until you get to \"Box Hyperlink\", and select it. Click on the \"Block Properties\" tab. Change the Navigate to property to \"Page\", the Page property to \"Pump Details\", and click the \"Edit\" button to the right of Pass Page Parameters. Press the + button on the Pass Page Parameters page to add a new Parameter to the Pump Details Page. Name the Parameter \"PumpId\" and give it the Type \"String\". Click on \"Add\". As mentioned previously, clicking on the icon on the left of the textbox field can toggle between Static, Dynamic, and Expression modes. Click on the button in the Value column once to change it to 'Dynamic' mode, which is indicated by the Database symbol. Select the value \"L_PumpId\" as this is the value we want to pass to the drill-down page. Click \"Apply\" to apply your changes to the Pump Details page's Parameters and the Box Hyperlink. Note If you are unable to see the parameters in the drop-down list, double-check that the Data Source has been applied to the correct Card block, as shown above. To see the navigation in action, launch the Landing Page and click on one of the cards. You will be navigated to the Pump Details page. Press the \"Edit\" button at the top right of the Pump Details page to edit it. We want a similar layout for this page, so follow the steps from the Landing Page to duplicate the Vertical Stacked Layout, and make the left side twice as wide as the right side. See the instructions that previously showed how to do this. We want two cards inside the Left Vertical Stacked Layout, so select the left Card and duplicate it. We want the top left card to be twice as tall as the bottom left card, so change the top left Card's Flex Grow property to 2 in the Block Styling. Remember to uncheck the card-gutter style group to make the style only apply to the selected element. We want the title of the page to be the Pump's name, so change the Title's Text property to an expression value \"Pump \" + {Parameter.PumpId}. We also want the Headings of the page to explain what is being shown, so change the top-left heading's text to \"Details\" and the bottom-left heading's text to \"Maintenance History\". We need to get the data from the Data Stream. Go back to the Page Data tab, and next to 'Data Sources', click on the \"plus\" symbol to add another Data Source. Name the new Data Source \"Pump Live Data\", with the Connection \"Data Streams Connector\", Entity as \"Post Pump Specifics\", and Live Data Updates checked. Drag a Chart into the Details card. Highlight the Chart, and in the Block Properties tab, set the Data Source of the Chart to \"Pump Live Data\". Add a Filter to the Data Source of L_PumpId Equals {Parameter.PumpId}. Click on the \"plus\" button to start adding the filter. When selecting the \"PumpId\", press the button on the left of the field to toggle between Static and Dynamic value modes. Change the mode to Dynamic so you can select a dynamic value from the dropdown. Here you can select the \"PumpId\" Parameter. This will make sure the chart is only showing data from the pump that we are looking at. Note See the Chart article for more information. We want the chart to look great and display a line series in a separate panel for flow rate and temperature. To do this, edit the Block Properties of the Chart as follows: In the Appearance accordion item set the Legend Alignment to \"Align Bottom Center\". In the Axes accordion item, change Type to \"Date Time\", Enable Pan and Zoom to \"False\" and Display Grid Lines to \"False\". In the Data accordion item, add two series with the + button to the right of the Series list as follows (leave the default value if it is not specified): Property Flow Rate Series Temperature Series Name Flow Rate Temperature Color #7ee2b5 #c46565 Type Line Line Pane Default Temperature X Axis Data L_Timestamp L_Timestamp Y Axis Data L_FlowRate L_WaterTemperature When making the 'Temperature' series, you will need to add a new Pane called 'Temperature.' To add a new Pane for the chart, click the 'Edit' button next to 'Pane' in the series property page. You can see how this looks by launching the page with the PumpId parameter \"A\", \"B\", or \"C\" On this page we want to also show the Engineers the pump maintenance history. This can be achieved through the use of a grid and a SQL Data Source. Below is a script that can be used to create the table used: CREATE TABLE [dbo].[PumpMaintenance]( [Id] [bigint] IDENTITY(1,1) NOT NULL, [PumpId] [nvarchar](10) NOT NULL, [Timestamp] [date] NOT NULL, [Comments] [nvarchar](max) NOT NULL, CONSTRAINT [PK_PumpMaintenance] PRIMARY KEY CLUSTERED ( [Id] ASC )) INSERT INTO [dbo].[PumpMaintenance] ([PumpId], [Timestamp], [Comments]) VALUES (N'A', CAST(N'2021-05-26' AS Date), N'Routine Inspection, No issues reported.') INSERT INTO [dbo].[PumpMaintenance] ([PumpId], [Timestamp], [Comments]) VALUES (N'B', CAST(N'2021-05-25' AS Date), N'Routine Inspection, No issues reported.') INSERT INTO [dbo].[PumpMaintenance] ([PumpId], [Timestamp], [Comments]) VALUES (N'C', CAST(N'2021-05-24' AS Date), N'Routine Inspection, No issues reported.') INSERT INTO [dbo].[PumpMaintenance] ([PumpId], [Timestamp], [Comments]) VALUES (N'A', CAST(N'2021-03-15' AS Date), N'High Vibration detected, main shaft replaced.') INSERT INTO [dbo].[PumpMaintenance] ([PumpId], [Timestamp], [Comments]) VALUES (N'B', CAST(N'2021-03-14' AS Date), N'Routine Inspection, bearing replaced.') INSERT INTO [dbo].[PumpMaintenance] ([PumpId], [Timestamp], [Comments]) VALUES (N'C', CAST(N'2021-03-13' AS Date), N'Routine Inspection, bearing replaced.') INSERT INTO [dbo].[PumpMaintenance] ([PumpId], [Timestamp], [Comments]) VALUES (N'A', CAST(N'2021-01-04' AS Date), N'Routine Inspection, No issues reported.') INSERT INTO [dbo].[PumpMaintenance] ([PumpId], [Timestamp], [Comments]) VALUES (N'A', CAST(N'2020-07-25' AS Date), N'Routine Inspection, bearing replaced.') Drag a Data Grid into the Maintenance History card and edit its Block Properties. Press the + button next to the Data Source select box to add a new Data Source, and name it \"Pump Maintenance.\" We want to add a SQL Data Source, but we don't have a SQL Connection yet. Press the + button next to the Connection select box and click on \"SQL Connector.\" Give the new SQL Connector a Name, enter your own connection string, User Name, and Password, and choose a Database. If you are using the Free Trial, you can get these details in your welcome email. XMPro sets up a 2GB database for you to use during the 120-day trial period. Save the Connection and select it in the New Data Source. Select the \"PumpMaintenance\" table and give the Data Source the name \"Pump Maintenance\". Save the new Data Source and select it in the Data Grid's Block Properties. This grid will show all the Pump Maintenance rows, but we want to show just the rows that this page is looking at. To do that, edit the Filter and add the filter logic: PumpId Equals {Parameter.PumpId} We want to change the Data Grid's columns around to make them look good. Open the Columns accordion item, and reorder the columns by dragging the dotted handles to the left of the list. Order them Id, Comments, Timestamp, PumpId. We don't want to show the PumpId, as it will always be the same. To hide it, click the \"PumpId\" row in the list and change the Visible property to \"False\". Apply the changes to the column. The Timestamp column should be in Date format, not Date Time. Edit the Timestamp column and change Type to \"Date\". Launch the page with the PumpId parameter \"A\", \"B\", or \"C\" to see this in action. It should look like this: Easy Access to Recommendations We want engineers to be able to see and respond to Recommendation Alerts from this App, so we should drag a Recommendations Block into the right card of both Pages. Also, rename the heading to \"Recommendations\". To filter the Recommendation Alerts to the relevant ones only, select the \"Pump Flow Threshold\" in the Block Properties of the Recommendations Block on both pages. On the Pump Details Page, we only want to show the Recommendation Alerts for the specific pump we're looking at. To do this, Change the Entity ID property to Equals Parameter.PumpId. We have now completed the requirements of the Use Case. To see the App running live, click on the \"Launch\" button. You can also publish the App by dragging the canvas to the left to open the page list, and clicking on \"Publish\". Here is how the final drill-down page looks:"
  },
  "src/how-tos/agents/README.html": {
    "href": "src/how-tos/agents/README.html",
    "title": "Agents | XMPro",
    "summary": "Agents An Agent is a reusable object which forms the building block of a Data Stream. When a number of Agents are connected together, a Data Stream is formed. Each Agent is designed to perform a specific function in the stream. For example, they can be used to retrieve data from a database in real-time, display data, filter, sort the data, or save the data somewhere else, depending on the function of that individual Agent. Note It is recommended that you read the article listed below to improve your understanding of Agents. Agent Articles Manage Agents Building Agents Packaging Agents Debugging an Agent"
  },
  "src/how-tos/agents/building-agents.html": {
    "href": "src/how-tos/agents/building-agents.html",
    "title": "Building Agents | XMPro",
    "summary": "Building Agents Overview To get started with developing a new Agent, create a new C# library project in Visual Studio and import the XMPro.IoT.Framework NuGet package. When writing the code for an Agent, you will have to implement a number of interfaces. Which interfaces to implement depends on the category under which your Agent will fall: Listeners Listeners are created by implementing IAgent and IPollingAgent interfaces. To push the events to the next receiver, the OnPublish event should be invoked and the events should be passed as arguments. Action Agents/ Functions Action Agents are created by implementing the IAgent and IReceivingAgent interfaces. The Receive method will be called every time events are received by this Agent. To publish these events again, the same logic as per the Listener Agent can be used. Context Providers Context Providers are created by implementing the IAgent, IPollingAgent interfaces. They are very similar to Listeners; however, Context Providers publish all available records/events when polled instead of only publishing the newer/changed ones. Transformations Transformations are implemented in a similar way as Action Agents, except that all Transformations should have the Require Input Map flag set to false and must not implement the GetInputAttributes method, hence it should be: public IEnumerable<XMIoT.Framework.Attribute> GetInputAttributes(string endpoint, IDictionary<string, string> parameters) { throw new NotImplementedException(); } The interfaces that can be implemented are as follows: IAgent IPollingAgent IReceivingAgent IPublishesError IAgentLogger (v4.4.19) The matrix below shows which interface needs to be implemented for which category Agent: Agent Category IAgent IPollingAgent IReceivingAgent IPublishesError IAgentLogger Listener Required Recommended Optional Optional Optional Context Provider Required Recommended Optional Optional Optional Transformation Required Optional Required Optional Optional Action Agent/ Function Required Optional Required Optional Optional AI & Machine Learning / Gen AI Required Optional Required Optional Optional Note The IPollingAgent interface is not strictly required for Listeners or Context Providers, however, it is generally used in most cases. Not implementing IPollingAgent for a Listener or Context Provider should be considered an advanced option. IAgent IAgent is the primary interface that must be implemented by all Agents as it provides the structure for the workings of the Agent. After implementing this interface, there are several methods you have to add to your project that forms part of this predefined structure. Settings/Configurations Some Agents need to be provided with configurations by the user, for example, for a CSV listener Agent to get records from a CSV file, it needs the following: Polling interval (in seconds) CSV file CSV Definition Each of these settings should be referenced in the code and must correspond to the settings template created when packaging your Agent. Note A template is a JSON representation of all the controls and their layout that will be used to capture the settings from a user. An example of the settings template (generated using the XMPro Package Manager) is shown in the image below. The settings in this example consist of the following controls: Group (Data) File Upload Group (Payload) Grid Each control has a Key, which uniquely identifies it in the template and allows the Agent code to access its value at any time. To get the value contained in a setting, use the following code: string mySetting = parameters[\"myUniqueKey\"]; Before a template is rendered on the screen, or if a postback occurs on any control in the template, the method below would be called to allow the Agent an opportunity to make any necessary runtime changes to the template, for example, verifying user credentials, displaying all tables of a selected database in a drop-down list, etc. In this example, no changes are being made to the template but, if needed, they can be added to the todo section. Note For a postback to occur after a user navigates out of a setting field, the Postback property needs to be set to true when packaging the Agent. public string GetConfigurationTemplate(string template, IDictionary<string, string> parameters) { //parse settings JSON into Settings object var settings = Settings.Parse(template); //populate the settings/configuration controls with the user selected values new Populator(parameters).Populate(settings); // ToDo: update the controls, values or the data sources here //return the updated settings xml return settings.ToString(); } Validate If a user tries to run an Integrity Check on a Data Stream in Data Stream Designer, all Agents will be requested to validate the configurations they have been provided. An Agent has to use this opportunity to inform the user about any configurations that are incorrect, for example, credentials that have expired, required values that are missing, etc. To validate the configurations/ settings in an Agent, the Validate method needs to be implemented. This method returns an array of errors that occurred. If validation was successful, an empty array would be returned. The example code below verifies if a user has specified a broker address, topic, and payload definition for an MQTT Agent: public string[] Validate(IDictionary<string, string> parameters) { int i = 1; var errors = new List<string>(); this.config = new Configuration() { Parameters = parameters }; if (String.IsNullOrWhiteSpace(this.Broker)) errors.Add($\"Error {i++}: Broker is not specified.\"); if (String.IsNullOrWhiteSpace(this.Topic)) errors.Add($\"Error {i++}: Topic is not specified.\"); var grid = new Grid(); grid.Value = this.config[\"PayloadDefinition\"]; if (grid.Rows.Any() == false) errors.Add($\"Error {i++}: Payload Definition is not specified.\"); return errors.ToArray(); } Output Payload Each Agent has the responsibility to inform the Engine about the structure of the payload that will be produced by the Agent. To do this, implement the following method: IEnumerable<Attribute> GetOutputAttributes(string endpoint, IDictionary<string, string> parameters) This method returns a collection that has an Attribute type, which is a type that represents the name and type of a given attribute in the outgoing payload. As from XMPro.IOT.Framework version 3.0.2, comparison/ equality operations are also supported in Attribute, for example: new XMIoT.Framework.Attribute(\"Name1\", Types.DateTime).Equals(new XMIoT.Framework.Attribute(\"Name2\", Types.String)); Create Each Agent needs to implement a method called Create, which will be invoked when your Agent is being hosted. User-defined configuration is passed as a parameter to this method and should be stored in a class variable as far as possible for later use. This is a good point to provide any resources needed for the working of your Agent. void Create(Configuration configuration) { this.config = configuration; // ToDo: Provision any resources or write Startup logic. } Start The Start method needs to be implemented by all Agents. This method will be invoked when your Agent is hosted and starts to work. void Start() Destroy Each Agent needs to implement a Destroy method, which will be invoked if the Create method was called successfully, when a data stream is either being unpublished or it encounters an error and fails to start. Use this method to release any resources or memory that your Agent may have acquired during its creation and lifetime. void Destroy() Publishing Events To push the events to the next Agent, your Agent should invoke the OnPublish event with the events passed as arguments: this.OnPublish?.Invoke(this, new OnPublishArgs(new JArray(), \"EndpointName\")); Note Events are represented as JSON Objects and have to be pushed as a collection, i.e. JArray. Caution Please note that OnPublishArgs(Array rtr) is obsolete from XMPro.IOT.Framework 3.0.2 onwards. You are now required to specify the endpoint name on which you would like to publish (i.e. OnPublishArgs(Array rtr, string Endpoint)) Decrypting Values If an Agent's configuration contains a Secure/Password Textbox, its value will automatically be encrypted. To decrypt the value, use the following set of instructions: var request = new OnDecryptRequestArgs(value); this.OnDecryptRequestArgs?.Invoke(this, request); var decryptedVal = request.DecryptedValue; Custom Events While building your Agent, you may need to use external libraries or third-party event subscriptions to handle custom events. If these are used, you must catch any exceptions from the event handlers yourself, to prevent uncaught exceptions that could possibly crash the Data Stream if they get through. IPolling Agent The IPollingAgent interface allows time-based operations. Implementing this interface, and opting in to Polling by returning true from the RequiresPolling method, will automatically add a PollingInterval setting to the configuration template of your Agent, which can be used by the user to specify the interval for polling. The Poll method will be invoked every time the poll interval elapses. void Poll() This method will be called at regular intervals according to the Configuration settings, and can be used to perform any work or logic you wish, for example, querying a third-party system for changes. bool RequiresPolling(IDictionary<string, string> parameters) The RequiresPolling method is an advanced option. It is expected that in most cases, this method should simply return a true value, which will not change the behaviour of the Agent. The PollingInterval setting will display as normal, and the Poll method will be called at that interval, as normal. Advanced users, however, can use this method to decide to opt-out of Polling settings, by returning false. The parameters method parameter will contain the Stream Object's Configuration, allowing you to determine whether to return true to opt-in, or false to opt out, depending on what settings the user has selected. Opting out will cause the PollingInterval setting to not appear in the configuration tab, and the Poll method to never be called when the Stream is published. This may be useful when the agent you are building can be configured to either actively query its configured third-party system for data at regular intervals, or set up a persistent connection to the third-party service and passively wait for that connection to deliver data. If the Agent does not need to query for data at regular intervals, or perform other work or logic on a specific schedule, it is recommended to not implement IPollingAgent rather than always returning false from the RequiresPolling method. IReceivingAgent If your Agent is required to receive inputs from other Agents, you should implement the IReceivingAgent interface. Input Payload Each Agent is responsible to inform the Engine about the structure of the payload it consumes. To achieve this in your Agent, implement the following method: IEnumerable<Attribute> GetInputAttributes(string endpoint, IDictionary<string, string> parameters) This method returns a collection consisting of Attribute, which is a type that represents the name and type of a given attribute in the incoming payload. Input Mapping In most cases, if an incoming payload structure is supposed to be different from what the parent is sending, i.e. the Input Payload has been specified above, the user will have to map parent outputs to the current Agent's inputs. To enable this, mark the Require Input Map flag as true in the Stream Integration Manager when packaging the Agent. Endpoint Each Agent can have a number of input and output endpoints. Endpoints are the points where incoming or outgoings arrows are connected. Each endpoint consists of a Name<String> attribute. You will be passed an endpoint name when queried for an Input payload definition. Be sure to specify the endpoint name when querying the parent's output payload definition. Parent Outputs All receiving Agents can query the structure of parent Agent outputs connected at a given endpoint by invoking an event, as demonstrated in the example below: var args = new OnRequestParentOutputAttributesArgs(this.UniqueId, \"Input\"); this.OnRequestParentOutputAttributes.Invoke(this, args); var pOuts = args.ParentOutputs; Receiving Events Events published to a receiving Agent can be received by implementing the following method: void Receive(string endpointName, JArray events) The endpointName parameter will identify which endpoint the events have been received at. Note It is not guaranteed that the Start method will be invoked before the Receive method. Use the Create method to execute any logic that needs to be executed before the Receive method is called. IPublishError An Agent can publish messages to an error endpoint by implementing the IPublishesError interface. An unhandled error in an Agent will be captured and error information will be published to the error endpoint. Implement the interface member: public event EventHandler<OnErrorArgs> OnPublishError; To push the error to the next Agent, the OnPublishError event should be invoked, and the error information should be passed as arguments: this.OnPublishError?.Invoke(this, new OnErrorArgs(AgentId, Timestamp, Source, Error, DetailedError, Data)); Note Error endpoints should be enabled in XMPro Stream Integration Manager when packaging the Agent. This can be done by selecting the \"Add On Error Endpoint?\" checkbox. See the image above for an example. IAgentLogger An Agent can output logging to the the Data Stream Logs by implementing the IAgentLogger interface. Like IPublishError, this can be used for errors, but it can also be used to log information or warning messages too. The prerequisite to use this interface are XMPro.IoT.Framework v4.4.19+ and Data Stream Designer v4.4.19+. Add an empty constructor to your Agent entry point class and another constructor that accepts an IAgentLogger. See following code for the contents of the two constructors: private readonly AgentLoggerProxy _loggerProxy; public BaseAgent { _loggerProxy = new AgentLoggerProxy(); } public BaseAgent(IAgentLogger logger) { _loggerProxy = new AgentLoggerProxy(logger); } The IAgentLogger interface contains the logging methods but a proxy class is needed to execute it to avoid compatibility issues with older SH and DS. Create the AgentLoggerProxy class with the following contents: public class AgentLoggerProxy { private readonly object? _logger; private readonly Type? _loggerType; private readonly Dictionary<string, MethodInfo?> _methods; public AgentLoggerProxy(object? logger = null) { _logger = logger; _loggerType = logger?.GetType(); _methods = new Dictionary<string, MethodInfo?>(); if (logger != null) { // Cache all method infos _methods[\"LogInfo\"] = _loggerType?.GetMethod(\"LogInfo\", new[] { typeof(string), typeof(object[]) }); _methods[\"LogErrorWithException\"] = _loggerType?.GetMethod(\"LogError\", new[] { typeof(Exception), typeof(string), typeof(object[]) }); _methods[\"LogError\"] = _loggerType?.GetMethod(\"LogError\", new[] { typeof(string), typeof(object[]) }); _methods[\"LogWarning\"] = _loggerType?.GetMethod(\"LogWarning\", new[] { typeof(string), typeof(object[]) }); _methods[\"LogDebug\"] = _loggerType?.GetMethod(\"LogDebug\", new[] { typeof(string), typeof(object[]) }); } } public void LogInfo(string messageTemplate, params object[] args) { if (_logger != null && _methods[\"LogInfo\"] != null) { _methods[\"LogInfo\"]!.Invoke(_logger, new object[] { messageTemplate, args }); } } public void LogError(Exception ex, string messageTemplate, params object[] args) { if (_logger != null && _methods[\"LogErrorWithException\"] != null) { _methods[\"LogErrorWithException\"]!.Invoke(_logger, new object[] { ex, messageTemplate, args }); } } public void LogError(string messageTemplate, params object[] args) { if (_logger != null && _methods[\"LogError\"] != null) { _methods[\"LogError\"]!.Invoke(_logger, new object[] { messageTemplate, args }); } } public void LogWarning(string messageTemplate, params object[] args) { if (_logger != null && _methods[\"LogWarning\"] != null) { _methods[\"LogWarning\"]!.Invoke(_logger, new object[] { messageTemplate, args }); } } public void LogDebug(string messageTemplate, params object[] args) { if (_logger != null && _methods[\"LogDebug\"] != null) { _methods[\"LogDebug\"]!.Invoke(_logger, new object[] { messageTemplate, args }); } } public bool HasLogger => _logger != null; } Call the logging methods of the proxy class. This will now display the logs on Stream Host. protected void LogMessage(string source, string message) { if (_loggerProxy.HasLogger) { loggerProxy.LogInfo($\"[{source}] {message}\"); } } protected void LogError(Exception? ex, string message) { if (_loggerProxy.HasLogger) { _loggerProxy.LogError(ex, message); } } Example The code below is an example of a basic MQTT Listener Agent. Take note of how the interfaces and methods have been implemented. Note Please note that this example uses the M2MqttDotnetCore 1.0.7 NuGet package. using Newtonsoft.Json.Linq; using System; using System.Collections.Generic; using System.Linq; using System.Text; using uPLibrary.Networking.M2Mqtt; using uPLibrary.Networking.M2Mqtt.Messages; using XMIoT.Framework; using XMIoT.Framework.Settings; using XMIoT.Framework.Settings.Enums;namespace XMPro.MQTTAgents { public class Listener : IAgent { private Configuration config; private MqttClient client; private string Broker => this.config[\"Broker\"]; private string Topic => this.config[\"Topic\"]; public long UniqueId { get; set; } public event EventHandler<OnPublishArgs> OnPublish; public event EventHandler<OnDecryptRequestArgs> OnDecryptRequest; public void Create(Configuration configuration) { this.config = configuration; this.client = new MqttClient(this.Broker); this.client.MqttMsgPublishReceived += Client_MqttMsgPublishReceived; } public void Start() { if (this.client.IsConnected == false) { this.client.Connect(Guid.NewGuid().ToString()); this.client.Subscribe(new string[] { this.Topic }, new byte[] { MqttMsgBase.QOS_LEVEL_EXACTLY_ONCE }); } } private void Client_MqttMsgPublishReceived(object sender, uPLibrary.Networking.M2Mqtt.Messages.MqttMsgPublishEventArgs e) { try { var message = Encoding.UTF8.GetString(e.Message); this.OnPublish?.Invoke(this, new OnPublishArgs(JArray.Parse(message), \"Output\")); } catch (Exception ex) { Console.WriteLine($\"{DateTime.UtcNow}|ERROR|XMPro.MQTTAgents.Listener|{ex.ToString()}\"); } } public void Destroy() { if (this.client?.IsConnected == true) this.client.Disconnect(); } public string GetConfigurationTemplate(string template, IDictionary<string, string> parameters) { var settings = Settings.Parse(template); new Populator(parameters).Populate(settings); return settings.ToString(); } public string[] Validate(IDictionary<string, string> parameters) { int i = 1; var errors = new List<string>(); this.config = new Configuration() { Parameters = parameters }; if (String.IsNullOrWhiteSpace(this.Broker)) errors.Add($\"Error {i++}: Broker is not specified.\"); if (String.IsNullOrWhiteSpace(this.Topic)) errors.Add($\"Error {i++}: Topic is not specified.\"); var grid = new Grid(); grid.Value = this.config[\"PayloadDefinition\"]; if (grid.Rows.Any() == false) errors.Add($\"Error {i++}: Payload Definition is not specified.\"); return errors.ToArray(); } public IEnumerable<XMIoT.Framework.Attribute> GetOutputAttributes(string endpoint, IDictionary<string, string> parameters) { var grid = new Grid(); grid.Value = parameters[\"PayloadDefinition\"]; foreach (var row in grid.Rows) { yield return new XMIoT.Framework.Attribute(row[\"Name\"].ToString(), (Types)Enum.Parse(typeof(Types), row[\"Type\"].ToString())); } } } } Further Reading Packaging Agents"
  },
  "src/how-tos/agents/debugging-an-agent.html": {
    "href": "src/how-tos/agents/debugging-an-agent.html",
    "title": "Debugging an Agent | XMPro",
    "summary": "Debugging an Agent Agents can be traced and debugged once they are added and used in a Data Stream. This is particularly useful when testing if an agent is working as intended and troubleshooting agent issues along the way. Setup Before Debugging Package the agent using this guide. Make sure that the Agent is packaged as non-virtual. If the Agent is required to be virtual, temporarily set it to non-virtual during development and just repackage it to virtual when releasing. Note Only non-virtual agents could trigger all breakpoints inside the Agent's code. This will also allow you to access any local environment (database, server, etc.) that you will use for testing. Add the Packaged Agent in the Data Stream Designer by following the Adding an Agent article. Install the XMPro Stream Host by following the Deploy a Stream Host article. Within the installation wizard, select Console Application as the Host Type. Create a new Data Stream for testing the agent and select the collection profile you used during Installation of Stream Host. Add the created Agent in the Data Stream and Save. Run the Stream Host as Admin and Publish the Data Stream for the first time. A cache folder will be created inside the Stream Host folder which will be used later on. Steps to Debug an Agent Build the Agent Project to generate a dll. If built using the Debug configuration, the dll usually would be found inside the folder [Project folder]/bin/Debug/netstandard2.1. Replace the Agent dll on the Stream Host installation folder under Cache/[Agent Id]/[Agent Version] with the one generated. To determine an Agent's id, export a JSON from the XMP file of the agent via Package Manager and determine the value from the Id property. Run Stream Host as Admin. Run Visual Studio as Admin and open Agent solution. Add a breakpoint in the Agent's code. Attach XMPro.StreamHost.Console.exe to process. By default, Visual Studio shortcut is ctrl + alt + p. Publish the test Data Stream on the Data Stream Designer to initiate debugging. Common Issues Issue: 'Access to Path is denied' when publishing a Data Stream Make sure that Stream Host is ran in Administrator Mode Issue: Breakpoint doesn't fire Make sure the Agent is packaged as Non-Virtual. This can also be an issue with testing out multiple versions of the agent. Ensure that the agent dll is copied to the folder with the correct agent id and version. Alternatively, one can refresh the Cache folder by: Deleting the Cache folder Running Stream Host Publishing the Data Stream Copying the Agent dll to the appropriate folder Potential issue can lie in dll not containing the expected changes. Cleaning and rebuilding the agent may solve this issue. Issue: 'Sorry, something went wrong.' error when configuring an agent Make sure that stream host is running for non-virtual agents. If the agent is supposedly virtual, repackage the agent as non-virtual temporarily to be able to access your local environment settings Ensure that agent settings are configured in line with the agent's code. Things to note for: Ensure that the key when packaging agents match the key used in code (case-sensitive) Ensure that all key names are unique for both group and variables. For value fields (eg. Token Box, Dropdown), ensure that default/configured values match the expected values in code. Take note that this is also case-sensitive Alternatively, adding a breakpoint and debugging in GetConfigurationTemplate can help determine the setting/property that is causing the error Issue: 'Could not complete Integrity check. undefined' when running integrity check This can be caused by missing properties within the settings when packaging an agent. Ensure that the expected configurations within the agent's code are properly configured within the settings in package manager."
  },
  "src/how-tos/agents/index.html": {
    "href": "src/how-tos/agents/index.html",
    "title": "Agents | XMPro",
    "summary": "Agents An Agent is a reusable object which forms the building block of a Data Stream. When a number of Agents are connected together, a Data Stream is formed. Each Agent is designed to perform a specific function in the stream. For example, they can be used to retrieve data from a database in real-time, display data, filter, sort the data, or save the data somewhere else, depending on the function of that individual Agent. Note It is recommended that you read the article listed below to improve your understanding of Agents. Agent Articles Manage Agents Building Agents Packaging Agents Debugging an Agent"
  },
  "src/how-tos/agents/manage-agents.html": {
    "href": "src/how-tos/agents/manage-agents.html",
    "title": "Manage Agents | XMPro",
    "summary": "Manage Agents Agents create the foundation for Data Streams, and they can be connected to other Agents to create the flow of data. Each Agent performs a specific function. They are useful as they can be used to either retrieve data in real-time, display data, filter or sort the data, or save them to another database, depending on the function of that individual Agent. Note It is recommended that you read the article listed below to improve your understanding of Agents. Agent Creating Agents Creating an Agent can be divided into two parts: Writing the code for an Agent Agents are generally written in C# as library projects that make use of the XMPro.IoT.Framework NuGet package. XMPro.IoT.Framework requires your project to be written using a predefined structure. This structure requires you to implement certain interfaces, depending on the type of Agent you are creating. To learn more about how to use this framework, refer to these instructions. Note Code for some Agents has been made available on GitHub. It might be useful to use these resources as an example when writing your own Agents. Packaging the Agent After writing your code, you need to use the XMPro Package Manager Windows 10 desktop application to package your Agent. This application allows you to specify all the properties your Agent requires, add the user settings in the form of controls, and allows you to upload the DLL of the Agent you've written. Finally, it will create a file with a \".xmp\" extension, which you can upload to Data Stream Designer and start to use to build Streams. To package the Agent, refer to these instructions. Adding an Agent After writing a new Agent and packaging it, you can upload it to Data Stream Designer by following the steps below: Open the Agents page from the left-hand menu. Click Add. Click the Select File button and browse to the .xmp file you've packaged. If the .xmp file is valid, some of the details contained in the file, such as the name of the Agent, will automatically be listed on the form. Select the category of the Agent (prepopulated if contained in the file) Click Save. Note The Metadata field allows you to add tags for the Agent. You can either select a value from the drop-down that appears when you click in the field or type a new value and press Enter. Additional information that forms part of the Agent's details will be displayed on the form, such as the version and Metadata. The newly uploaded Agent will now be available in the toolbox on the Use Case canvas page. To add an Agent to the canvas, follow the steps below: Open the Data Streams page from the left-hand menu. Select your Data Stream. Expand the category in the toolbox where your Agent is located. Click on your Agent and drag the Agent to the canvas. Click Save. Bulk Adding Agents Uploading multiple Agents begins like a single Agent (see Adding an Agent above), except a compressed (.zip) file is selected. Note A 100 MB limit applies to the decompressed file size, not the compressed one. If the .zip file is valid, a data grid is populated with the Agent name, version, ID, category, and file size. Complete the upload by following the steps below: Select the category of the Agents (prepopulated if contained in the respective .xmp file) Click on Save If any Agents fail the initial validation due to a missing category, a status column appears to identify them. To fix this, (1) select the category and (2) click on Save. Or Discard to exit the blade. The status column will advise which Agents were uploaded successfully, and which were ignored as the version already exists. Upgrading Agents To upgrade Agents in the Data Stream, visit How To Upgrade a Stream Object Version. Deleting Agent Versions To remove one or more versions of a specific Agent, first, make sure that the versions of the Agent that you're planning to remove are not being used anymore. Then, open the Agents page from the left-hand menu and follow the steps below: On the Agents page, select the Agent. Click on \"Delete Versions\". Select the versions you would like to delete. Click Delete. Deleting Agents When planning to remove multiple Agents completely at the same time, make sure they are not being used anymore. Open the Agents page from the left-hand menu and follow the steps below: Click on \"Select\". Select all the Agents you would like to remove. Click on \"Delete\". Note To cancel the selection, click on \"Select\" again. Confirm that you would like to delete all versions of the selected Agents. Finding Help for Agents Help documentation is available for every Agent. These pages provide context, configuration definitions, an example, and release notes to help if you are unsure of anything related to the Agent you are configuring. See the Integrations article for the list of Agent documentation links."
  },
  "src/how-tos/agents/packaging-agents.html": {
    "href": "src/how-tos/agents/packaging-agents.html",
    "title": "Packaging Agents | XMPro",
    "summary": "Packaging Agents Getting Started The XMPro Package Manager is a Windows 11 desktop application that enables you to package a new Agent or update details for an existing Agent. See the Agent article for more information on Agents. This application takes you through the process of specifying all the properties your Agent requires, adding or changing the controls for each of the user settings, and uploading the DLL files of the Agent code. It will provide you, upon completion, with a file that can be uploaded to Data Stream Designer after which you can build Data Streams using the Agent. You can download the software from the Microsoft Windows 10 Store or by clicking here. After installing the XMPro Package Manager, launch the application from the Microsoft Store or search for \"XMPro Package Manager\" in the Start menu and then click on \"XMPro Package Manager\". Note You can run multiple instances of Package Manager at the same time. This side-by-side comparison is helpful when developing a new Agent that is similar to another; or comparing different versions of the same Agent. New / Import On the first screen of the application, you can either create a new Agent package or import and update an existing one. Note Use the arrows at the bottom of the page section to move forward or backward in the application. When you import an existing package, you have the option to export the package as a JSON file. This is useful either to compare packages or for source control and version management. You can also import the JSON file from an existing package, which is particularly useful if you need to modify translations added through the Include Multilingual Support feature. Details The Details form allows you to configure the properties of an Agent. These properties are listed and explained below. Name The name of the Agent is what the Agent will be known as once it is uploaded to the Data Stream Designer platform, for example, \"Jupyter Notebook\". Category The category is selected based on the function the Agent performs, for example, \"AI & Machine Learning\". Description The description is a brief explanation of what the Agent does, for example, \"This Action Agent allows you to create and load Jupyter Notebook files\". Version The version of the Agent. Any real number is acceptable, for example, \"1.02\". Caution If you make a change to an existing Agent, make sure you increment the version number as Data Stream Designer will not allow you to upload two of the same Agents with the same version. Virtual Agents can be classified as either Virtual or Non-Virtual. An Agent is Virtual if it is not specific to a certain environment and can be configured remotely. Non-Virtual Agents have to be in their respective environments to be able to function correctly, e.g. the SQL Server Agent, which has to connect to SQL Server via the intranet. Entry Point The entry point is the namespace and class name of the actual Agent's DLL file. For example, if an Agent with the class name \"ActionAgent\" is located in the XMPro.JupyterNotebookAgents namespace, the Entry Endpoint for it would be \"XMPro.JupyterNotebookAgents.ActionAgent\". Isolated Loading When loading Agents to use in a Stream Host, all the libraries are put in a separate Load Context. Tick Isolated Loading to keep Agent files separate and reduce the risk of libraries clashing or conflicting together. In most cases, this option should be enabled. Icon File The icon used to represent your Agent. Click the Browse button, navigate to where you've stored the file via the Explorer and select the new image file. Note It is recommended that you upload either a JPG or PNG file with a size of 64×64 pixels to accommodate for retina displays. Require Input Map Tick Require Input Map to specify that your Agent will be receiving events in a defined structure. The arrow leading to your Agent will be configurable to allow the user to map the inputs of your Agent to incoming attributes. Note If left unticked, parent outputs will be published to this Agent as they are. Add On-Error Endpoint? Tick to add an additional Output Endpoint, called an Error Endpoint. An Error Endpoint will output error information when your stream is running and something goes wrong, making debugging easier. You can also define actions that will be executed after error data is sent to the next Agent in the stream by your Agent, for example when a certain record is not valid. Endpoints The Endpoints form allows you to specify any Input or Output Endpoints. Input Endpoints These Endpoints represent entry points to the Agent, which will allow the Agent to receive data or input from another Agent. To add an Input Endpoint, type it's name in the text field and click Add. The new Endpoint will appear in the list below the Add button. You may need to hover over the list and scroll down to see it. As per the image, an Input Endpoint named \"Input\" has been added. Caution The name of the Input Endpoints has to match what has been defined in the Agent's code. To remove an existing Endpoint, scroll down in the list until you see it, select the Endpoint and click on the Remove button. Output Endpoints Output Endpoints represent exit points from an Agent and allow you to connect your Agent to another Agent, making it possible to pass data from your Agent to another Agent. To add an Output Endpoint, type it's name in the text field, change the Endpoint Type to \"Output\", and click Add. The new Endpoint will appear in the list below the Add button. You may need to hover over the list underneath the text field and scroll down before being able to see it. In the image, an Output Endpoint named \"Output\" has been added. Caution The name of the Output Endpoints should match what has been defined in the Agent's code. To remove an existing Endpoint, scroll down in the list until you see it, select the Endpoint and click on the Delete button. References The References form is where you upload the file(s) required for the Agent to execute. Only files in the Selected File(s) list will be included in the package, and any DLLs must be created in .NET. To upload a file, click the Browse button next to the DLL File(s) field and navigate to where the files are located. Select all the files needed and click the Add button to add them to the Selected File(s) list. To remove a file from the list, click the Delete button next to the file name in the Selected File(s) list. Type Description Agent The DLL file that was generated when you built the project containing your Agent source code. Reference Additional DLL file(s) referenced by the Agent File, such as Newtonsoft.Json. You do not need to upload the XMIoT.Framework.dll file as this DLL is automatically included. Resource Additional DLL file(s) needed by the Reference File. Zip The Stream Host decompresses the file, while maintaining the folder structure, so that Agents such as the Meta Agent can run external source code and self package. Settings Depending on what your Agent does, it might require that the user provide certain information, such as a server URL, username, or password. For each of these information fields (or settings), you need to specify which control should be used and what each control represents, for example, the Jupyter Notebook Agent will require the user to add a server URL. The user should provide this value using a text-box control. Thus, you need to create a control with a type of \"TextBox\" and a caption that reads \"Server URL\" in the XMPro Package Manager application. The following controls are available to be used to capture user input: Button CheckBox CheckList DropDown EditList FileUpload Filter Grid Group HTML Editor NumberBox ScriptBox TextBox Title TokenBox VariableBox Each control has several properties that have to be set and not all properties apply to all controls. For example, options apply to a drop-down control and not a text-box control. The table below contains a list of all the available properties, their description, and to which controls they are applicable. Property Name Control Type Description Allow Custom Text Drop-Down Allows the user to type custom text in the drop-down field if checked. Allow Custom Tokens Token Box Allows the user to add custom tokens if checked. Caption All Text that will be displayed with the group or setting. The caption is usually one or two words, describing the value that should be provided by the user, for example, \"Server URL\". Default Value Title The default value of the title. Font Size Script Box Size of the font in the Script Box. Group Type Groups Appears as either a sub heading (Default) or a hyperlink (SubPage) on the Agent's configuration page. Help Text All, excluding Groups If you need to provide the user with any additional information about the purpose of the setting or helpful instructions, specify it in this field. Key All Uniquely identifies the group or setting. Keywords Script Box Define your variables or other custom keywords here, so that they will be available in the editor's IntelliSense. Options (Drop Down) Drop-Down Use the Options-area to add values to the drop-down menu by specifying the Text and Value fields and then clicking Save. You may also choose an option to be used as the default option by checking the \"Set as Default Value\" box. Options (HTML Editor) HTML Editor Allows you to specify placeholders that can be mapped to input fields in the input received by the Agent. Postback All If checked, will cause the form to do a postback to retrieve values from the server when the field loses focus (when the user clicks out of the field). Required All, excluding Groups The control will be validated to make sure that a value has been specified if this box is checked. ScriptBox Height Script Box Height of Script Box. ScriptBox Mode Script Box Language in which script has to be written. ScriptBox Theme Script Box The theme of the Script Box. Themes available include: Ambiance, Chaos, Chrome, Clouds, Clouds_midnight, Cobalt, Cromson_editor, Dawn, Dreamweaver ScriptBox Width Script Box Width of Script Box. Secure All The value of the control will be treated as a secure value if this box is checked (encrypted and not displayed on the form in plain text). An example of a secure value is a SQL Server password. Show Grid Lines Grid The grid lines of the grid will be shown if checked. Show Header Grid The header of the grid will be displayed, if checked. Sort Index All This is used to determine the group or setting's position and works with increments of 10. Adjust this value to move the group or setting up or down on the form. Unique Key Grid Mark a specific column as being unique, for example, an identity column. Visible All This field sets the initial visibility of the group or setting. Adding Settings Settings are grouped logically into one or more groups, such as authentication, criteria, and output. Create a group first, then add controls for settings to the group. To do this, follow the steps below: Click on the plus-icon (top right, next to the Settings header). A form section will open, allowing you to specify a group for the settings. Specify a unique value that can be used as the key for the group. Add the caption you would like to use. Click Save. Next, we are going to add a setting. Click on the plus-icon next to the group you've created. Choose the type of control you would like to use. Add a unique key for your control. This key must correspond to what you defined in your code. Add a caption for your control. If needed, add a default value. If required, add help text. Select the options that apply from the list of check-boxes. Click Save. Output Export as JSON file Tick the checkbox Export as JSON file too? if you would like to export the file as JSON too. It will later be saved to the same directory as the XMP file with the file name category_name_version.json. Include Multilingual Support Tick the checkbox Include Multilingual Support? if you would like to add support for languages other than English. Uncheck languages you don't want to include. This feature leverages generative AI to provide language translation. It is available only if the following requirements are met: You are connected to the internet. Open AI is configured (Click here for instructions on how to do so). Note What is Translated: The Agent description and static properties added when packaging the Agent are translated, whereas internal messages and dynamic properties added when building the Agent are not. Minimum XMPro Product Version: The tables below outline the minimum versions of XMPro Data Stream Designer (DS), XMPro Stream Host (SH), and XMPro Package Manager (PM) required for multilingual support. If Automated Translations Are Incorrect: Edit the translations in the JSON file and repackage it with an incremented version number. DS & SH Multilingual Support Pre v4.4.16 v4.4.16+ v4.5.4+ Internal messages and dynamic properties ✗ ✗ ✗ Agent description and static properties ✗ ✓ ✓ Static property drop-down options ✗ ✗ ✓ PM Multilingual Support Pre v1.3.18 v1.3.18+ v4.5.4+ Internal messages and dynamic properties ✗ ✗ ✗ Agent description and static properties ✗ ✓ ✓ Static property drop-down options ✗ ✗ ✓ Configure OpenAI Click Configure OpenAI. A form will open for you to add or modify the OpenAI Endpoint and Api Key. Click Save. Review: Details Lastly, you can navigate back through the steps to review the details that you've specified. If you are satisfied, complete the wizard by clicking the Save button below before navigating to the folder where you would like the package to be exported. Your package will be created with the file name category_name_version.xmp. Note If you imported an existing file, take care to: either click 'Save as new Agent' to generate a new Agent, or click 'Save' to generate a new version of the original Agent. ensure you select a different location folder or increment the version to avoid overwriting the original. Further Reading How to upload your new Agent to Data Stream Designer Note You need to have the correct permissions set against your user to be able to edit and upload Agents. This is a role not typically given to all users."
  },
  "src/how-tos/apps/README.html": {
    "href": "src/how-tos/apps/README.html",
    "title": "Application | XMPro",
    "summary": "Application An Application or App enables you to create Apps using a low-or-no-code canvas environment. This allows anyone including Engineers and subject matter experts to build an App in a matter of days or weeks without having to be a programmer. Note It is recommended that you read the article listed below to improve your understanding of Applications. Application Articles Manage Apps Manage Templates Manage Pages Design Pages for Mobile Navigate Between Pages Pass Parameters Between Pages Manage Connections Check Connector Logs Manage Data Sources Use Data Sources in the Page Use Dynamic Properties Use Expression Properties Use Page Layers Use Block Styling and Devices Use Flex Use Validation Use Variables and Expressions Create and Maintain Notes Manage Widgets Manage App Files Manage Themes Manage Landing Pages Page Data Import an App Page"
  },
  "src/how-tos/apps/check-connector-logs.html": {
    "href": "src/how-tos/apps/check-connector-logs.html",
    "title": "Check Connector Logs | XMPro",
    "summary": "Check Connector Logs Logs allow the composer of an App, the developer writing a new Connector, or an Administrator to view messages generated by a Connector when it is in use in an App. Log entry limits are configured per Connector but applied per App Connection. The Connection's log is cleared if it is upgraded to a newer version of the Connector or it is removed from the App. Logs are saved for Connectors that implement the logging functionality. Note It is recommended that you read the articles listed below to improve your understanding of Applications, Connections, and Connectors. Applications Connectors Connections Configuring Connector Log Limits The log entries are not stored indefinitely. The oldest will be cleared according to the combination of the number of log entries and the duration. The log entry limits apply to all versions of the Connector. A Connector that is in development or experiencing errors may need a higher number and duration during troubleshooting. Logs Allowed The number of log entries retained. The maximum is 1000, the minimum is 1, and the default is 100. Logs Duration The duration, in days, of how long the logs are retained. The maximum is 90, the minimum is 1, and the default is 7. Warning Only the Administrator can change the limits. Indicator An icon in front of the Connector indicates if there are errors logged: Icon Description Red indicates there are new logs for that Connector that no one has opened yet. Yellow indicates there are logs for that Connector that have been viewed. View Connector Logs To view the logs for a Connector, follow the steps below: Open the Connectors page from the left-hand menu. Select a Connector to view its information. Select the version that has an indicator for logs. Edit the Application that you want to see the logs. Click on App Data. Select a Connection that has logs. Open the Logs page. View Connection Logs To view the logs for a Connection, follow the steps below: Click on App Data Select the Connection Click on Logs The Logs page is automatically maximized. Adjust the timeline slider above the grid to view logs within a specific time range. Refresh Connection Logs To refresh Connection logs, follow the steps below: Click on Refresh. Logs in the grid will clear and refresh. Filter Connection Logs To filter Connection logs, follow the steps below: Click on the 'Source' filter button. Select the log source. Click on OK. Export Connection Logs To export Connection logs, follow the steps below: Click on the export icon. Export all data or export selected rows."
  },
  "src/how-tos/apps/create-and-maintain-notes.html": {
    "href": "src/how-tos/apps/create-and-maintain-notes.html",
    "title": "Create and Maintain Notes | XMPro",
    "summary": "Create and Maintain Notes Notes are a way to share information about an Application between creators of the App and for future reference. They are useful when you want to communicate and record technical or non-technical information about the Application. The Notes are for the Application, so no matter how many Pages the Application has, the Notes will always remain the same. Notes are also saved across versions. Note It is recommended that you read the article listed below to improve your understanding of Applications. Application How to Manage Apps Adding Notes To add Notes to the Notes page, follow the steps below: Open the Application page from the left-hand menu. Click on the edit button to open the Application editor page. Click on Notes. Add Notes to the page. Click on Save. Styling Notes Notes can be styled using the HTML editor and the options at the top of the note. They include the following styles: Bold Italics Underline Strikethrough Subscripts and superscripts Quotes Code blocks Numbered lists Bullet Lists Indentation Heading and paragraph styles Font size Font family Font color Font background-color Left, right, centered, and justified alignment Links to websites Images"
  },
  "src/how-tos/apps/design-pages-for-mobile.html": {
    "href": "src/how-tos/apps/design-pages-for-mobile.html",
    "title": "Design Pages for Mobile | XMPro",
    "summary": "Design Pages for Mobile When designing Pages, you may want to use responsive web design principles to support different screen sizes with the same App. This is easily accomplished with Block Styling and Devices. The default Page Layouts that you can choose from when creating a page have built-in responsive styling applied to the cards. For an example of this, see the Responsive Page Layout Example. Note It is recommended that you read the article listed below to improve your understanding of how to design pages for mobile. How to Use Block Styling and Devices How to Manage Pages How to Use Flex How to Make Responsive Card Layout To create a responsive card layout just like the default page layouts, follow the steps below: Create a Page with the first, single-card layout. Clone the Horizontal Stacked Layout, Vertical Stacked Layout, and Card until you have the layout that you desire. Please note that the order in the Page Layers will also be the order, from top to bottom, that items appear in mobile. If you want rows and columns to take up a different ratio on the page, adjust the Flex Grow of the relevant items. Make sure to uncheck Style Groups when applying styles to a specific element if you do not want the style to apply to the Style Group. More info on Flex can be found here. Switch to Mobile view with the middle Devices section of the command buttons. Adjust the heights of the elements. Any styles added in Mobile mode will apply only when the device's screen width is smaller than a threshold. In this case, change the first Horizontal Stacked Layout's Min height to 200%."
  },
  "src/how-tos/apps/import-an-app-page.html": {
    "href": "src/how-tos/apps/import-an-app-page.html",
    "title": "Import an App Page | XMPro",
    "summary": "Import an App Page App Pages can be exported as a file and imported as a template to other companies or instances of XMPro Products. This allows you to continue working on the same App Page in a different environment without having to start from scratch. The layout of the template is preserved - data sources must be configured. Note It is recommended that you read the article listed below to improve your understanding of Pages. Page Import, Export, and Clone How to Manage Pages How to Import an App Page To import an App Page, follow the steps below: Open the Applications page from the left-hand menu. Click on the edit button to edit an Application. Click the plus button to add a page. Select \"Upload Layout\" from the list of options under the \"Layout\" dropdown. Select the file containing the Page that you would like to upload. Enter the File Key. Modify any remaining details if necessary. Click on Save."
  },
  "src/how-tos/apps/manage-app-files.html": {
    "href": "src/how-tos/apps/manage-app-files.html",
    "title": "Manage App Files | XMPro",
    "summary": "Manage App Files Files can be uploaded and used within the Application. The interface for App Files allows you to use, rename, delete, and perform more actions on a file that has been uploaded to the Application. App Files are useful in many scenarios, for example, if you need specific files to integrate Unity or D3 Visualizations onto the Page. Note It is recommended that you read the article listed below to improve your understanding of App Files. App Files How to Manage Apps Uploading App Files To upload new App Files, follow the steps below: Click on the Applications page from the left-hand menu. Click on the edit button for the App. Click on App Files. Click on New Directory. Enter the name of the folder. Click on Create. Click on the folder you want to store files in to enter it. Drag and Drop Files into the file area or Click Upload Files. Copying/Moving App Files around To copy or move App Files to different folders, follow the steps below: From the edit application page, click on App Files. Navigate to the file you want to copy or move. Highlight the file. Click on Copy to or Move to. Select the new location you want to move or copy the file to. Click on Move/Copy. Renaming App Files To rename App Files, follow the steps below: From the edit application page, click on App Files. Navigate to the file you want to rename. Highlight the file. Click on rename. Enter a new name. Click on Save. Deleting App Files To delete App Files, follow the steps below: From the edit application page, click on App Files. Navigate to the file you want to delete. Highlight the file. Click on delete. Confirm you want to delete the file. Downloading App Files To download App Files, follow the steps below: From the edit application page, click on App Files. Navigate to the file you want to download. Highlight the file. Click on download. The file will appear in your downloads. Using App Files To use App Files in the application itself, follow the steps below: Add a block on the page which uses a file selector, such as Unity or D3 Visualization. Highlight the block. Click on Block Properties. Use the file selector to select the file you want to use in the application. To add more files to the file manager directly from here, click on the plus sign. Upload files, download, move, copy, rename or delete files directly from here."
  },
  "src/how-tos/apps/manage-apps.html": {
    "href": "src/how-tos/apps/manage-apps.html",
    "title": "Manage Apps | XMPro",
    "summary": "Manage Apps An Application or App enables you to create Apps using a drag-and-drop canvas environment. This allows anyone including Engineers and subject matter experts to build an App in a matter of days or weeks without having to be a programmer. Note It is recommended that you read the article listed below to improve your understanding of Applications. Application How To Manage Apps Each card on the Categories dashboard shows the Name, Description, and Icon of the Category, as well as the number of Unpublished and Published Apps in the category. Clicking on the Applications button in the menu will take you to the Applications list. The Applications list is grouped by Category. Apps that have the play icon are Published. Click on a row to view an App, or click on an edit button to edit an App. The edit button will only be shown for Apps that you have edit access to. Clicking on a Category on the App Designer Categories dashboard will take you to the Applications dashboard for that Category. Each card shows the Icon, Name, and Description of the App as well as how many users have access, the version, the time and date it was last modified, the owner's profile picture and name, and whether the App is Published - if so it will have \"Active\" in green, and if not it will have \"Draft\" in yellow. Clicking a row on the Applications list or a card on the Applications dashboard will let you view the App. An example of an App can is shown below: You can go back to the previous page by clicking the X button in the top right of the page. If you have edit access to the App there will also be an edit icon at the top right that you can click to edit the App. You can create an App by clicking the New Application button in the left menu. After navigating to the edit page for an Application, you can edit the properties and delete the App by clicking the Properties command button. You can also edit a page by clicking on it in the pages list or add a new page by clicking the plus button at the top right of the list of pages. The App Pages list is ordered with the Landing Page at the top, and the rest of the pages in alphabetical order. How to Create an App To create an App, follow the steps below: Click the New Application button to create an App. Click a Template to create an Application from that Template. Enter the name and description of the new App. Choose the category the app belongs to. Upload the icon. Sample icons can be found in the Icon Library. Choose between Light and Dark themes. You may also include tags from the drop-down that opens when you click on the field - or type a new value and press Enter. Choose the layout of the Landing (Main) page. Click on Save. How to Delete an App To delete an App, follow the steps below: Open the applications page from the left-hand menu. Click on the edit button of the application you want to delete. Click on Properties. Click on Delete. Confirm that you want to delete the Application. Versions of an App To read more about managing the versions of an App, visit How To Manage Versions. Importing, Exporting, and Cloning an App To read more about exporting, importing, and cloning an App, visit How to Import, Export, and Clone. Importing an App with Data Stream Connections When importing an App with Data Stream Connections, there is an option to map all of the App's connections to their corresponding Data Stream version and Agent. This step can be skipped during the import, but each App Page's data source will have to be updated individually. Sharing Apps To read more about sharing Apps and their managing access, visit How to Manage Access. Further Reading How to Manage Templates How to Manage Pages How to Create and Maintain Notes How to Manage App Files How to Manage Themes"
  },
  "src/how-tos/apps/manage-connections.html": {
    "href": "src/how-tos/apps/manage-connections.html",
    "title": "Manage Connections | XMPro",
    "summary": "Manage Connections The parameters defined in a Connection allow the App to connect to a source of data like a SQL Database and expose the entities as Data Sources within the Page. Connection parameters can include credentials such as a username, password, path, URL, or location identifier that you can use to make a remote connection to the Data Source. For example, Connection parameters to connect to an SQL Database would include the Server Name, Authentication type, Username, and password. Note It is recommended that you read the article listed below to improve your understanding of Data Integration. Data Integration How to Manage Pages Adding a Connection to the Application Connections can be added directly to an Application by adding it to the App Data. To add a Connection to an Application, follow the steps below: Open the Applications page from the left-hand menu. Click on the edit button to edit an application from the list. 3. Click on App Data. 4. Click on add. 5. Select a connector, for example, the SQL connector. 6. Enter the details of the Connection, including it's name. 7. Click on Save. The new Connection should appear in the list of connectors, and can now be used in the application to add Data Sources. The Connection can be used for all pages within the application it was added to. Deleting a Connection Single Connection To delete a single Connection, follow the steps below: Open the Applications page from the left-hand menu. Click on the edit button to edit an application. 3. Click on App Data. 4. Select the Connection. 5. Click on Delete. 6. Confirm that you want to delete the Connection. Multiple Connections To delete multiple Connections, follow the steps below: Open the Applications page from the left-hand menu. Click on the edit button to edit an application. 3. Click on App Data. 4. Click on Select. 5. Select multiple Connections to be deleted. 6. Click on Delete. 7. Confirm that you want to delete the Connection. Note You can cancel the multi-select by clicking on the select button again. Data Stream Connections Navigate to the Data Stream Connector to access a comprehensive inventory of the Data Stream Connections for the Application. The connections are categorized based on the respective pages where they are utilized. You can use this list to verify the current version of the Data Stream in use and make any necessary updates if required. Further Reading How to Manage Data Sources"
  },
  "src/how-tos/apps/manage-data-sources.html": {
    "href": "src/how-tos/apps/manage-data-sources.html",
    "title": "Manage Data Sources | XMPro",
    "summary": "Manage Data Sources Data Sources can be created for a Page in the Application. They are a way to link to a specific Entity in a Connection's Entities, for example, a table in a SQL database. Data Sources are managed through the Page Data tab of a Page. Data Sources allow you to display, use, manipulate or store data from a connected source of data such as an SQL Server Database. Note It is recommended that you read the article listed below to improve your understanding of Data Integration. Data Integration How to Manage Connections Creating a Data Source To create a Data Source on the Page of an Application, follow the steps below: Open the Editor for the Application. Open the Page that will have the Data Source. Click on Page Data. Click on the plus symbol to add a new Data Source. Enter a name. Add the Connection and Entity where data will be retrieved. Specify the Primary Key. Click on Save. Edit a Data Source To edit a Data Source, follow the steps below: Open the Editor for the Application. Open the Page that has the Data Source. Click on Page Data. Click on the edit button. Edit the details of the Data Source. Click on Save. Delete a Data Source To delete a Data Source, follow the steps below: Open the Editor for the Application. Open the Page that has the Data Source. Click on Page Data. Click on the edit button. Click on Delete. Confirm that you want to delete the Data Source. Further Reading How to use Data Sources in the Page"
  },
  "src/how-tos/apps/manage-pages.html": {
    "href": "src/how-tos/apps/manage-pages.html",
    "title": "Manage Pages | XMPro",
    "summary": "Manage Pages A Page is a web page built with XMPro's App Designer. Pages allow you to separate the Application into sections, navigate between the Pages, and pass data between Pages using Parameters. Note It is recommended that you read the article listed below to improve your understanding of Pages. Page Canvas How to Manage Apps Creating a Page To create a Page within an existing application, follow the steps below: Click on Applications from the left-hand menu. Click on the edit button of the Application from the list. Click on the plus button to add a new Page. Enter the details of the new Page. Choose the layout of the new Page. Click on Save. The new Page will show in the list of pages for the Application. Designing a Page Once a Page has been created, you can design your Page to meet your specifications. There are many Blocks or controls that can be added from the Blocks tab such as Text, Number, and Date Boxes, Grids, Charts, Gauges, Accordions, and Tabs. The full list of Blocks can be found here. Adding New Blocks Blocks are accessed through the Blocks tab in the page designer and can be added to the page by dragging them into the Canvas. Blocks can also be searched by typing in the search bar at the top. Moving Blocks in the Canvas Blocks can be rearranged within the Canvas in a few ways: Moving Blocks using the Canvas Click and drag the Block you want to move. Hover over where you want to move the Block to. A green line and an orange outline will appear to show where the Block will end up. Release the mouse to drop the Block. Moving Blocks using the Toolbar Sometimes the Block you want to move may be hard to click or behind other Blocks. In this case, you can move the Block by its drag handle button in the blue toolbar. Select the Block by clicking one of its children and clicking the Select Parent button in the blue toolbar or by selecting it in the Page Layers. Click and drag the drag handle button in the blue toolbar. Hover over where you want to move the Block to. A green line and an orange outline will appear to show where the Block will end up. Release the mouse to drop the Block. Moving Blocks by the Page Layers Sometimes you may need to be more precise in dragging a Block. In this case, you can move the Block by rearranging it in the Page Layers. See the Page Layers article for more information on how to use Page Layers. Expand the Block you want to move and the Block you want to put in the Page Layers. Click and drag the drag handle in the Page Layers. Hover over where you want to move the block to. A green line and an orange outline will appear to show where the block will end up. Release the mouse to drop the block. Launching a Page Once a Page has been designed, you can view the finished product of the designed Page by launching it. Click on the page you want to preview. Click on Launch. Deleting a Page To delete the Page, open the Page itself and delete it via the settings menu. Follow the steps below to delete the Page: Open the Page you would like to delete. Click on Settings. Click on Delete. Confirm that you want to delete the Page. Further Reading How to Import an App Page How to Design Pages for Mobile How to Navigate between Pages How to Manage Connections How to Use Dynamic Properties How to Use Expression Properties How to Use the Page Layers How to Use Block Styling and Devices How to Use Validation How to Use Variables & Expressions How to Manage Widgets"
  },
  "src/how-tos/apps/manage-templates.html": {
    "href": "src/how-tos/apps/manage-templates.html",
    "title": "Manage Templates | XMPro",
    "summary": "Manage Templates Templates are pre-designed Applications that can be selected when creating a new Application. Templates can be used to save time without having to build a whole new App layout from scratch, and also allow you to create a consistent theme or design that you can use across all your Applications. Note It is recommended that you read the article listed below to improve your understanding of Templates. Template How to Manage Apps Creating a Template To create a Template, make sure you already have an App that you want to use to save as a Template. Follow the steps below to create a template out of an existing App. Click on Applications from the left-hand menu. Click on the edit button of the application from the list. Click on Save Template. Enter the name, description, and category of the Template. Upload screenshots of what the Application looks like. Click on Save. Note Adding screenshots helps other users when they want to have a look at the Template to understand what the Template contains. Using a Template When creating an App, you can choose a Template as a base instead of starting the App from scratch. To use a Template: Click on the plus from the left-hand menu to create a new Application. Choose the template you would like to use. Click on Select Template. Continue creating the new Application. Click Save. Editing a Template A list of existing Templates can be viewed on the Templates page from the left-hand menu. This is where you can make changes to Templates, delete Templates, view, import, or export them. Click on Templates from the left-hand menu. Select the Template you would like to edit. Make the necessary changes. Click Save. Deleting Templates Single Template To remove a single Template, follow the steps below: Open the Templates page from the left-hand menu. Select the Template from the list. Click Delete. Confirm that you would like to delete the Template. Multiple Templates To remove multiple Templates at the same time, follow the steps below: Open the Templates page from the left-hand menu. Click Select. Select the Templates that you would like to remove. Click Delete. Confirm that you would like to delete the Templates selected."
  },
  "src/how-tos/apps/manage-themes.html": {
    "href": "src/how-tos/apps/manage-themes.html",
    "title": "Manage Themes | XMPro",
    "summary": "Manage Themes The Application can either be Light-Themed or Dark-Themed. This depends on the overall design of the Application and can be configured when creating the App, and can also be edited after the app has been created. This is useful as some users or developers prefer to have a certain consistent light or dark-colored theme across their app, and this option allows you to customize the app to fit that preference. Note It is recommended that you read the article listed below to improve your understanding of Applications. Application How to Manage Apps Default Theme when creating a new App The Default Theme is the theme that will be automatically selected when you create a new Page within the Application. For example, if the Default Theme for the overall Application is dark, when you create a new Page, the Default Theme for that Page will always be set to dark. To choose the Default Theme when creating a new Application, follow the steps below: Click on the plus button from the left-hand menu to add a new application. Select the Default Theme when creating an App. The background will either be light or dark depending on the theme. Changing the Default Theme of an App To edit the Default Theme for the overall App, follow the steps below: Open the edit page for the Application. Click on Properties. Change the Default Theme. Click on Save. Note Changing the Default Theme of the App does not change the Themes of the individual Pages that are already configured. Choosing a Theme when creating a page When creating a new page, follow the steps below: Click on the plus to add a new page. Enter the details of the new page. The theme of the new page will automatically be set to the app's default theme. This can still be changed here. Click on Save. Changing the theme for a page To edit the Theme of an existing Page, follow the steps below: Open the page from the application editor. Click on Settings. Change the Theme of the Page. Click on Save."
  },
  "src/how-tos/apps/manage-widgets.html": {
    "href": "src/how-tos/apps/manage-widgets.html",
    "title": "Manage Widgets | XMPro",
    "summary": "Manage Widgets Widgets are collections of Blocks or layouts that you can group together and re-use for other Apps and Pages. For example, if there is a common group of Blocks that is repetitive to continuously recreate, these Blocks can be selected and turned into a Widget. When a Widget is created, it is added as a Block in the Blocks toolbox and can then be dragged onto the canvas and re-used as many times as needed on any Page. Note It is recommended that you read the article listed below to improve your understanding of Widgets. UI Block (Toolbox) How to Manage Pages Creating a Widget When a Widget is created, you can specify if the Widget can only be seen and used by you, or everyone else in the company. If everyone has access to it, anyone can drag and drop your Widget into their own apps. The owner of the Widget is the only one who can edit or delete it. To create a Widget, follow the steps below: Select the Blocks you would like to save as a Widget. Click the save button to create a new Widget. Enter the name. The visibility determines who will be able to see and use your Widget. If set to everyone, anyone in your company or organization can drag and drop your Widget into their own Apps. Choose an icon. Sample icons can be found in the Icon Library. Click Create. When a Widget is created, it will show in the toolbox, under 'Blocks' in the 'Widget' category. Using Widgets The Widget can be dragged and dropped anywhere on the canvas, and this will create the same set of blocks as before. Deleting a Widget When a Widget is deleted, it will be removed from the sidebar and you will no longer be able to drag it onto the canvas. Deleting a Widget will not affect anything previously dropped onto the canvas on any Page. Select Edit. Note that you will not be able to edit the Widget unless you are the owner of it. Select Delete. Confirm that you would like to delete the Widget. Importing Widgets Widgets that were built in one Application can be imported to another Application. A single file can contain multiple Widgets that can be uploaded. To import Widgets, follow the steps below: Click on Blocks. Click on Import Widgets. Select a file. Enter a File Key. Click on upload. Select the Widgets you would like to upload. Click on Save. Note New Widgets will appear in the list of Widgets. Exporting Widgets If you want certain Widgets that were built in your Application to be used in another Application, you can export those Widgets. Click on Blocks. Click on export Widgets. Select the Widgets you would like to export. Click on Export. Note You can choose multiple Widgets to export at once. They will all be exported into one file. Enter a File Key. Click OK."
  },
  "src/how-tos/apps/navigate-between-apps.html": {
    "href": "src/how-tos/apps/navigate-between-apps.html",
    "title": "Navigate Between Apps | XMPro",
    "summary": "Navigate Between Apps It is possible to allow navigation between Apps by configuring the Action of a Block on the launching App to navigate to the destination App's URL and set it's landing page's Parameter. This allows you to separate your content into different applications that can still be easily navigated by the user. Important Considerations: The parameter name in both Apps must match exactly The destination App must be published and accessible to users of the launching App. Note We're going to achieve this by combining concepts from the following articles: How to Navigate Between Pages How to Pass Parameters Between Pages Configure the destination App Add a Parameter and a textbox to display the value when it is passed to the Page during runtime. See How to Add a Parameter to the Page for detailed steps. Add a Parameter Click Applications from the left-hand menu. Click the edit button of the destination App from the list. Click Page Data on the landing page Click the plus to add a Parameter Add the name and type of the new Parameter Click Create. Click on Save. Add a display (Optional) Add a Textbox to the Page so you can display the parameter value when it is passed from the launching App. Click Block Properties Click the 'A' button to toggle from static to dynamic text. Select the Parameter from the dropdown. Click Save. Configure the launching App Add a Button to launch the second app and populate the page parameter you just created in the URL using a dynamic expression. Add a Button Click Applications from the left-hand menu. Click the edit button of the Application from the list. Select a Page from the Application's Edit menu. Click on Blocks. Under 'Actions', select an action such as a button. Drag and drop it onto the Page of the application. Select the button. Click on Block Properties. Under 'Action,' click on the Navigate To Dropdown and select URL. Click the 'A' button to toggle the URL from static to expression mode. Click the dropdown to edit the expression value. Enter the destination App's URL with parameters (e.g., \"https://your-xmpro-instance.com/render;appId=123?assetId=\"+{Variable.AssetID}) Under 'Appearance,' give the button a name. Click Save. See How to Copy the App Link for details on how to copy the launch App's URL. Copy the App Link You can copy the App link if you want to share it. This creates a link to the published app version - or to the latest version if there is no published version. Click More. Click Copy App Link. Further Reading How to Pass Parameters between Pages"
  },
  "src/how-tos/apps/navigate-between-pages.html": {
    "href": "src/how-tos/apps/navigate-between-pages.html",
    "title": "Navigate Between Pages | XMPro",
    "summary": "Navigate Between Pages It is possible to allow navigation between Pages of an App by configuring the Action of a Block. This allows you to separate your content within the application into sections that can be easily navigated by the user. Note It is recommended that you read the article listed below to improve your understanding of Navigating between Pages. Navigation and Parameters How to Manage Pages Configuring Navigation between Pages To add Navigation between Pages, make sure the Application has more than one Page. See the Manage Pages article to read more about adding Pages. When a new Page is created, they are automatically configured to have links going back to the landing page, which can be seen at the top of the screen. Some Pages do not automatically have links to other Pages. For example, the Landing page does not have links going to other pages. To add Navigation between Pages, follow these steps: Click on Applications from the left-hand menu. Click on the edit button of the Application from the list. 3. Select a Page from the Application's Edit menu. 4. Click on Blocks. 5. Under 'Actions', select an action such as a button. 6. Drag and drop it onto the Page of the application. 7. Select the button. 8. Click on Block Properties. 9. Under 'Action,' click on the Navigate To Dropdown and select Page. 10. Select the page you want to navigate to. 11. Under 'Appearance,' give the button a name. 12. Click on Save. Navigating between Pages at Runtime After the Navigation between Pages has been added, you can Launch the App to see what it will look like at runtime. Follow the steps below to Launch and view the App: Click on Launch. The button is visible on the Page. Click on the button to navigate to the other selected Page. 3. The page will open. Deleting Navigation between Pages You can delete the navigation functionality by either deleting the Block itself or by deleting the settings under Action in the Block Properties tab. Navigating Using Back URL You can include a back URL to the current page when configuring a Navigate To URL, so that the user can return to the original page. For example, you want to open an Alert from a custom templated list and the alert drill-down needs a back URL. To append a back URL, follow these steps: Click on Block Properties. Under 'Action', click on the Navigate To Dropdown and select URL. Toggle the URL mode to Expression Mode. Click the dropdown to edit the expression value. 5. Note the current page parameters under Constants. 6. Configure the URL with back parameters, similar to the below: \"https://xmad-sample.azurewebsites.net/viewalert;id=\"+\"12345\"+\";backUrl=render;backParams=\\{\\\\\"appId\\\\\":\\\\\"\"+appId+\"\\\\\",\\\\\"pageId\\\\\":\\\\\"\"+pageId+\"\\\\\",\\\\\"categoryName\\\\\":\\\\\"\"+categoryName+\"\\\\\",\\\\\"appVersion\\\\\":\\\\\"\"+appVersion+\"\\\\\"\\\\}\" Copying App Link You can copy the App link if you want to share it. This creates a link to the published app version - or to the latest version if there is no published version. Click More. Click Copy App Link. Copying Page Link You can copy a specific App Page link if you want to share it. This will create a link to the specific app version and page. Open the Page. Click Copy Page Link. Further Reading How to Pass Parameters between Pages"
  },
  "src/how-tos/apps/page-data.html": {
    "href": "src/how-tos/apps/page-data.html",
    "title": "Page Data | XMPro",
    "summary": "Page Data You can use Page Data to update the data on the current page when an Action is performed. In the example shown below, each button is configured to update the value of the variable shown in the text control with a different value. Adding a Page Data to Control To add Page Data follow the steps below: Select the control. Click to edit Page Data. Click the Plus sign. Select a field. Enter a value or select from Dynamic values. Click Apply. Removing a Page Data from Control To remove Page Data follow the steps below: Select the control. Click to edit Page Data. Find the row that you want to be deleted and click Delete. Confirm your action. Click Apply."
  },
  "src/how-tos/apps/pass-parameters-between-pages.html": {
    "href": "src/how-tos/apps/pass-parameters-between-pages.html",
    "title": "Pass Parameters Between Pages | XMPro",
    "summary": "Pass Parameters Between Pages You can use Parameters if you want to send particular values to another Page. For example, if you have a list of machines, and a user selects one, the Application may open a new Page that displays information for that particular machine. In that case, you may want to pass the ID of the machine the user clicked on to the Page that is being opened. Note It is recommended that you read the article listed below to improve your understanding of Navigating between Pages. Navigation and Parameters How to Navigate Between Pages Adding a Parameter to the Page A Parameter needs to be added to the Page that is receiving the data. In this example, there are two Pages that exist in the Application: the main Landing Page and the secondary Page. The second page is the Page where the Parameter is made. To add a Parameter to a page, follow the steps below: Click on Applications from the left-hand menu. Click on the edit button of the Application from the list. 3. Click on the page where you want to data to be sent to. 4. Click on Page Data. 5. Click on the plus to add a Parameter. 6. Add the name and type of the new Parameter. 7. Click on Create. 8. Click on Save. Now that a Parameter has been added, create a textbox or a way to display the value when it is passed to the Page during runtime. Add a textbox to the Page so you will be able to display the value when it is passed from the main page to this page. 2. Click on Block Properties. 3. Click on the 'A' button to toggle between static and dynamic text. 4. Select the Parameter from the dropdown. 5. Click on Save. The data has to be sent from the main page to the secondary page. To pass data from the main Landing Page using the Parameter you just created, follow the steps below: Go to the page you will be sending data from. Select the button/link that navigates to the second page. Click on Block Properties. Click on the Edit button under Pass Page Parameters. Configure if the data being passed is dynamic or static. Add/Select a value that you would like to pass to the parameter on the second page. Click on Apply. Passing Dynamic Data to the Page When navigating between pages, you can also pass dynamic data - such as the Chart value - to the next page using page parameters. First, configure the Chart block then follow the steps below: Click on Block Properties. Under _'_Appearance' set Show Drilldown to True. 3. Under 'Action', click on the Navigate To Dropdown and select Page. 4. Select the page you want to navigate to. 5. Click Pass Page Parameters. 6. Pass Page Parameter blade will open. 7. Type in the name of the parameter and select the type. 8. Click Add. 9. Change the field type to Dynamic Value. 10. Select the Chart value you want to pass on the next page. 11. Click Apply. View values passed to other pages at runtime Once the Parameter has been configured, launch the application to see how the data will be passed between Pages at runtime. Click on Launch. 2. Click on the link that goes to the second page. 3. The data sent from the first page should reach the second page. Edit a Parameter To edit a Parameter, follow the steps below: Click on Page Data. Click on the pencil/edit button for the Parameter. 3. Make changes to the Parameter. 4. Click on Save. Delete a Parameter To delete a Parameter, follow the steps below: Click on Page Data. Click on the pencil/edit button for the Parameter. 3. Click on Delete. 4. Confirm that you would like to delete the Parameter."
  },
  "src/how-tos/apps/use-block-styling-and-devices.html": {
    "href": "src/how-tos/apps/use-block-styling-and-devices.html",
    "title": "Use Block Styling and Devices | XMPro",
    "summary": "Use Block Styling and Devices Block Styling includes options that allow you to change the text color, background color, borders, typography, dimensions, or other styling options of the Block. You can use it to customize the look and feel of the Application based on themes or color palettes for your specific organization. The style and position of the Blocks can also be customized for different devices, which is important in ensuring that users have a good user experience regardless of the screen size they are viewing your Application on. Note It is recommended that you read the article listed below to improve your understanding of Devices and Block Styling. Device Block Styling How to Manage Pages Adding a Style Group Style Groups can be created and customized by the user and applied to Blocks on the Canvas. To style a Block, make sure the Block you want to style is selected. Click on the Block Styling tab in the Toolbox. Add a Style Group by typing a name in the field under 'Style Group' and pressing enter. Expand any category to change styles. Add your custom style. The style of the group will change as a result. The created style group can then be applied to other Blocks. Select a different Block and enter the name of the new style Block in the field under 'Style Group'. Adding Style to States States include events such as hovering over a Block, clicking a Block, or changing the style for every second Block. To change the styling of a state, select the Block you want to style. Click on the Block Styling tab in the Toolbox. Change the state. Add your custom styling. The styling will be applied to the Block for that state. In this example, if the user hovers over the Home text, the background will change from light blue to light green. To see the hovering effect in action, no state should be selected. The background color will remain light blue, and will only change to light green when the user hovers over it. Configure styling between Desktop, Tablet, and Mobile Phones To configure the styling between devices, follow the steps below: Select Desktop. Create a style group. Change the styling. This styling will be applied to all devices automatically. Change the device to tablet. Change the styling for tablets. Changes will apply to screen sizes smaller than 1366 pixels. Change the device to mobile. Change the styling for phones. Changes will apply to screen sizes smaller than 896 pixels. Further Reading How to Design Pages for Mobile How to Use Flex"
  },
  "src/how-tos/apps/use-data-sources-in-the-page.html": {
    "href": "src/how-tos/apps/use-data-sources-in-the-page.html",
    "title": "Use Data Sources in the Page | XMPro",
    "summary": "Use Data Sources in the Page Once a Data Source has been added to a Page, it can be used on a number of Blocks. Data Sources can be bound to certain Blocks that allow you to store data or display data, such as a data grid. These can be used if you want to display data in a grid view to the user, or if you want the user to enter some details and have it stored directly into the connected Data Source, such as an SQL Server Database. Note It is recommended that you read the article listed below to improve your understanding of Data Integration. Data Integration How to Manage Data Sources Adding a Data Source to a page To add a Data Source onto the Page of an Application, follow the steps below: Open the Editor for the Application. Drag a Block that can display data, such as a Data Grid. Highlight the Block that you want to bind the Data Source to. Select Block Properties. Select a Data Source from the list. Click on Save. The block highlight color will change to yellow to show it has a Data Source. Click on Launch to launch the Application and view the data. Note If the Data Source is properly configured, the data will display and can be visible when the app is launched. Filtering records from a Data Source To filter and limit the number of records the Data Source displays, follow the steps below: Open the Editor for the Application. Highlight the block of the Data Source you want to filter. Click on the edit button to Filter. Add a filtering condition or group. Click on Apply. Click on Save. Sorting records from a Data Source To sort the records the Data Source displays, follow the steps below: Open the Editor for the Application. Highlight the block of the Data Source you want to sort. Click on the plus button to add a new field to sort by. Sort the field in ascending or descending order. Click on Save. Showing specific records from a Data Source Show # of Results To show a limited number of the records the Data Source displays, follow the steps below: Highlight the block of the Data Source. Click on Block Properties. Show the number of results. Click on Save. Skip # of Results To skip certain rows, follow the steps below: Highlight the block of the Data Source. Click on Block Properties. Skip a number of results. Click on Save. Show Default Row To change the settings for the default row, follow the steps below: Highlight the block of the Data Source. Click on Block Properties. Change the default row. Click on Save."
  },
  "src/how-tos/apps/use-dynamic-properties.html": {
    "href": "src/how-tos/apps/use-dynamic-properties.html",
    "title": "Use Dynamic Properties | XMPro",
    "summary": "Use Dynamic Properties Dynamic Properties allow you to select a dynamic value for a property from the Page Parameters, Variables, User Details, and from a column or expression of the current row of a parent Block's Data Source. Note It is recommended that you read the article listed below to improve your understanding of Properties. Block Properties How to Manage Pages How to Enable Dynamic Properties To enable Dynamic Properties, follow the steps below: Select the Block on the Canvas on which you want to add Dynamic Properties. Click the Block Properties tab or double-click the Block on the Canvas. If the property has a button on the left with an A icon, click on that icon to switch to Dynamic Property. Select the value to which you want to bind that property. In this example, it is binding to the device type so this Block will be visible if the Device is Mobile."
  },
  "src/how-tos/apps/use-expression-properties.html": {
    "href": "src/how-tos/apps/use-expression-properties.html",
    "title": "Use Expression Properties | XMPro",
    "summary": "Use Expression Properties Expression Properties allow you to create short scripts to create a custom value. This custom value can be calculated from other Variables, Parameters, user input, data from Data Sources, and various Functions, Constants, and Operators. See the Variable and Expressions article to learn more about Expressions. Note It is recommended that you read the article listed below to improve your understanding of Properties. Block Properties How to Manage Pages How to Enable Expression Properties To enable Expression Properties, follow the steps below: Select the Block on the Canvas on which you want to add Expression Properties. Click the Block Properties tab or double-click the Block on the Canvas. If the property has a button on the left with an A icon, click on that icon to switch to Dynamic Property. Click again to switch to the Expression Property. Build the Expression."
  },
  "src/how-tos/apps/use-flex.html": {
    "href": "src/how-tos/apps/use-flex.html",
    "title": "Use Flex | XMPro",
    "summary": "Use Flex Flex styles are a way of changing the layout of the page so it is responsive. When using Flex, the layout and position of the Blocks will respond to fit the screen, which is important in ensuring that users have a good user experience regardless of the screen size they are viewing your Application on. Note It is recommended that you read the article listed below to improve your understanding of Devices and the Style Manager. Device Style Manager How to Use Style Manager and Devices Enabling Flex Styles To enable Flex styles, follow the steps below: Select the parent Block of the Blocks you want to configure the position for. Click on Block Styling. Choose Flex for the display or enable the flex container. Flex Container Direction The direction determines which direction the content will go. It can either be: Row - Left to right Reverse row - right to left Column – Top to Bottom Reverse column – Bottom to Top Justify Justify determines the way the contents are laid out. It can either be: Start End Space Between (puts spaces between the Blocks) Space Around (puts an equal amount of space around each Block) Center Align-Items Determines the vertical alignment of the Blocks. It can either be: Start End Stretch Center Blocks inside the Flex Container Grow Grow will grow the item to fit the container. If multiple Blocks have a grow value greater than 0, they will take up a ratio of the available space. Shrink Shrink determines whether an item is allowed to shrink if the screen is too small or if other Blocks take up too much space. Shrink will not work if the Block has a minimum width or height. Basis This determines the default size of the object along its direction axis. Order The order will change the order of the Blocks. Blocks with no order will be displayed first, followed by the ordered Blocks going in ascending order. Align-Item Aligns the individual Blocks. They can either be: Start End Stretch Center Further Reading How to Design Pages for Mobile"
  },
  "src/how-tos/apps/use-page-layers.html": {
    "href": "src/how-tos/apps/use-page-layers.html",
    "title": "Use Page Layers | XMPro",
    "summary": "Use Page Layers Blocks are organized on the Canvas in a hierarchy. A list view of this hierarchy is visible by selecting the Page Layers tab in the toolbox. This can make selecting Blocks simpler and easier as some Applications may have many nested layers and it can be difficult to select them on the Canvas itself. Each Block that is selected also displays a list of any children Blocks if applicable. This allows you to find the exact Block you need to manipulate. Note It is recommended that you read the article listed below to improve your understanding of Page Layers. Page Layers How to Manage Pages Selecting a block Individual Blocks can be selected from the Page Layers view. To select a block on the Page using the Page Layers list, follow the steps below: Click on Page Layers. Expand layers to get to the element. Click on the Block you want to select. The Block selected will be highlighted on the Page. Moving blocks around Clicking and dragging the handle on the right of the Block will re-arrange itself in the list as well as the page. To move Blocks around, follow the steps below: Click on Page Layers. Expand layers to get to the element. Click and drag the handle on the right. Drop the Block in another place to move it around. The selected new location will be highlighted in orange on the Page. The Block will be moved on the Page. Renaming blocks Renaming Blocks will not affect what the block looks like at runtime, it will only change the text or label that will appear when you hover over the Block. To rename Blocks, follow the steps below: Click on Page Layers. Expand layers to get to the element. Double Click on the text to highlight it and change it. 4. Enter the new name of the Block. Note Changing the name will not change the content of the Block, it will only change what the Block is called. Hide and Show blocks You can press the hide on the left to hide elements on the page. This will hide the elements on the page and also in runtime view as well. Click on Page Layers. Expand layers to get to the element. Click on the eye symbol on the left to toggle the visibility of the Block."
  },
  "src/how-tos/apps/use-validation.html": {
    "href": "src/how-tos/apps/use-validation.html",
    "title": "Use Validation | XMPro",
    "summary": "Use Validation Validation is a way of making sure the user has correctly entered data when they are filling out a form. The Validation occurs when they press the submit button. This prevents the user from submitting data that is inaccurate or in the wrong format. Note It is recommended that you read the article listed below to improve your understanding of Applications. Block Properties How to Manage Pages Adding Validation to Forms To add Validation to forms, follow the steps below: Add a form control such as a Fieldset. Create your form. Add input blocks such as textboxes, number selectors, or text areas, which allow validation to be configured. Highlight the field you want to validate. Click on Block Properties. Enter if the field is required. Required means the user must enter a value for the field. If required, enter the error message the user will see if they do not enter a value. If applicable, enter a regex if the value needs to have a specific pattern. For example, if the field needs at least two words, or must have an @ symbol for an email. If applicable, enter the error message if the pattern is not provided. Highlight the submit or confirm button. Click on Block Properties. Select the Validation Groups to validate. Viewing Validation at runtime At runtime, if the 'submit' or 'confirm' button is pressed without valid inputs, the fields will be highlighted in red and the corresponding error warning will show. Once all fields are valid, all errors will disappear from the screen and the user will be able to press the submit or confirm button. Validation Groups Validation Groups can be used when there are multiple forms on the page that need to be separated. To organize validation groups, follow the steps below: Select the field for the second form. Click on Block Properties. Expand Validation. Click on the plus to create a new validation group. Enter the name of the validation group. Click on Create. Highlight each of the fields on the new form. Click on their Block Properties. Add them to the new validation group. Highlight the submit button for the new form. Click on Block Properties. Select the new validation group. The validation will only be applied to that validation group."
  },
  "src/how-tos/apps/use-variables-and-expressions.html": {
    "href": "src/how-tos/apps/use-variables-and-expressions.html",
    "title": "Use Variables & Expressions | XMPro",
    "summary": "Use Variables & Expressions Variables are placeholders used to hold and maintain certain values. In some cases, it is possible to not know some of the values that you might want to display or use within the Application. In this case, you can use Variables where the real value can be substituted in later. Expressions can also be configured and are useful for doing certain calculations and returning results which can also be used in the Application. Note It is recommended that you read the article listed below to improve your understanding of Variables and Expressions. Variables and Expressions How to Manage Pages Adding a Variable To add a Variable to the Application, follow the steps below: Open the editor for the Application. Open the page the Variable will be stored in. Click on Page Data. Click on the plus symbol to add a new Variable. Type the name of the Variable. Enter the type and whether it is a value or expression. Click on Save. The Variable should show in the list of Variables. Using a Variable To use a Variable, follow the steps below: Highlight the Block you want to bind the Variable to. In this case, it is a textbox for the user's input. Click on Block Properties. Expand Value. Select the Variable Click on Save. Adding Expressions When adding a Variable, there is an option to build an expression. The example below shows an expression that multiplies the values of two variables together. To build an expression, follow the steps below: Change the mode to expression. Select the expression box. Select from a range of parameters, Variables, and other functions to build an expression. When a value is selected it will appear in the expression box. Note Numbers are identified as integers by default. Convert to other data types using: a method e.g.ToLong(0)for the value 0 as a long 2.0for the value 2 as a double Click on Save. Deleting a Variable To delete a Variable, follow the steps below: Click on Page Data. Click on Edit to edit the Variable. Click on Delete. Confirm that you want to delete the Variable."
  },
  "src/how-tos/connectors/README.html": {
    "href": "src/how-tos/connectors/README.html",
    "title": "Connectors | XMPro",
    "summary": "Connectors A Connector is a pre-built integration plug-in for the XMPro App Designer that facilitates a no-code connection to third-party data sources. Note It is recommended that you read the article listed below to improve your understanding of Connectors. Connector Articles Manage Connectors Building Connectors Packaging Connectors"
  },
  "src/how-tos/connectors/building-connectors.html": {
    "href": "src/how-tos/connectors/building-connectors.html",
    "title": "Building Connectors | XMPro",
    "summary": "Building Connectors Overview To start developing a new Connector, create a new C# library project in Visual Studio and import the XMPro.Integration.Framework NuGet package. When writing the code for a Connector, you will have to implement one or more interfaces: Interface Necessity Description IConnector Required Provides the structure implemented by all Connectors. ILiveConnector Optional Allows the Connector to send notifications to the App Page to notify the change of entity. IConnectorError Optional Allows the Connector to publish error messages to the Connector Logs. ITSAConnector Optional Allows the Connector to advise the Time Series Analysis that the data is pre-processed and returned in buckets. ITSCConnector Optional Deprecated from v4.4.12, upgrade to the ITSAConnector. IConnector IConnector is the primary interface that all Connectors must implement as it provides the structure for the workings of the Connector. There are several methods required to implement this interface. Settings/Configurations Some Connectors need to be provided with configurations by the user. For example, for a SQL Connector to get records from a SQL Database, it needs the following: Server Instance User Name Password Database Each of these settings should be referenced in the code and must correspond to the settings template created when packaging your Connector. Note A template is a JSON representation of all the controls and their layout that will be used to capture the settings from a user. An example of the settings template (generated using the XMPro Package Manager) is shown in the image below. The settings in this example consist of the following controls: Group (Server) Textbox Checkbox Group (Database) DropDown ScriptBox Each control has a Key, which uniquely identifies it in the template and allows the Connector code to access its value at any time. To get the value contained in a setting, use the following code: string mySetting = parameters[\"myUniqueKey\"]; Before a template is rendered on the screen, or if a postback occurs on any control in the template, the method below would be called to allow the Connector an opportunity to make any necessary runtime changes to the template, for example, verifying user credentials, displaying all tables of a selected database in a drop-down list, etc. In this example, no changes are being made to the template, but they can be added to the todo section if needed. Note For a postback to occur after a user navigates out of a setting field, the Postback property needs to be set to true when packaging the Connector. public string GetConfigurationTemplate(string template, IDictionary<string, string> parameters) { //parse settings JSON into Settings object var settings = Settings.Parse(template); //populate the settings/configuration controls with the user selected values new Populator(parameters).Populate(settings); // ToDo: update the controls, values or the data sources here //return the updated settings xml return settings.ToString(); } Entities Each Connector must inform the Engine about the Entities that will be produced by the Connector. To do this, implement the following method: public IEnumerable<Entity> GetEntities(IDictionary<string, string> parameters) This method returns a collection of Entities, which represent an object or a function of the Connector. For example, an Entity can be a Table within the configured Database in the SQL Connector. Each Entity contains the following: Name Description EntityId A unique identifier for the Entity. Name The name of the entity. IsLive Indicate if the Entity supports Live Updates. Operations The operations which the Entity supports. Read Insert Update Delete new Entity(\"OpenRecommendation\") { IsLive = True, Name = \"Open Recommendation\", Operations = Operation.Read }; Entity Properties The Connector must provide a list of the Entity's properties, which describe its key, output schema, and optional inputs. To achieve this, implement the following method: public Entity GetEntity(string entityId, IDictionary<string, string> parameters) This method returns the Entity with a collection of properties for the selected Entity's entityId, which is passed as a parameter to this method. Most properties will be Output properties, which describe the Entity's data, and are indicated by setting key and isParameter to false. For example, this String property named OutputString: new Property(\"OutputString\", Settings.Enums.Types.String, key: false, isParameter: false) At least one property should be marked as the Entity's Key, indicated by setting key to true. The key uniquely identifies records when performing Update or Delete tasks, and for Application Blocks such as Grids that require a unique key per record. For example, this Long property named Id: new Property(\"Id\", Settings.Enums.Types.String, key: true, isParameter: false) Finally, we have the optional Parameter properties, indicated by setting isParameter to true. They are included in the output schema, but also exposed to the App Page as optional input to the Read operation - retrieved from its options parameter to modify the results. For example, this Int property named Input: new Property(\"Input\", Settings.Enums.Types.Int, key: false, isParameter: true); Note Few Connectors need Parameter properties - they are used when the desired outcome is not achievable through the regular Configuration settings or the data source filter. For example, the Azure Digital Twins Connector's Time Series entity includes an optional input parameter, \"$ts\", which shows up in the output as well as a Timestamp for that specific record/event. Create The Connector must implement a method called Create, which is invoked when your Connector is hosted. User-defined configuration is passed as a parameter to this method and should be stored in a class variable for later use. This is a good point to provide any resources needed for the working of your Connector. void Create(Configuration configuration) { this.config = configuration; // ToDo: Provision any resources or write Startup logic. } Read The Read method is one of the Entities' operations and is expected to return a JToken back to the Engine. This method is invoked when a Read/Refresh Action is called from a Block within an App Page. public IQueryable<JToken> Read(string entityId, OperationOptions options, out long count, JObject extraOptions = null) This method contains a list of parameters being passed from the Engine. Name Description entityId A unique identifier for the Entity OperationOptions The operation options as configured by a user: Parameters: a JObject containing the input parameters' value Filter: the data filter criteria TransactionName: the name of the transaction count The number of records extraOptions A JObject contains the following: Sort: the data sorting criteria Skip: the number of records to skip Take: the number of records to return Insert The Insert method is one of the Entities' operations and is expected to return a JObject back to the Engine with the inserted record Id. This method will be invoked when an Insert Action is called from a Block within an App Page. public JObject Insert(string entityId, JObject values, OperationOptions options) Name Description entityId A unique identifier for the Entity values A JObject of values to be inserted OperationOptions The operation options as configured by a user: Parameters: a JObject containing the input parameters' value Filter: the data filter criteria TransactionName: the name of the transaction Update The Update method is one of the Entities' operations and is expected to return a JObject back to the Engine with the updated record Id. This method will be invoked when an Update Action is called from a Block within an App Page. public JObject Update(string entityName, JObject key, JObject values, OperationOptions options) Name Description entityId A unique identifier for the Entity key A JObject containing the primary key of the record to be updated values A JObject of values to be updated OperationOptions The operation options as configured by a user: Parameter: a JObject containing the input parameters' value Filter: the data filter criteria. TransactionName: the name of the transaction Delete The Delete method is one of the Entities' operations and is expected to return back to the Engine with the number of records deleted. This method will be invoked when a Delete Action is called from a Block within an App Page. public int Delete(string entityId, JObject key, OperationOptions options) Name Description entityId A unique identifier for the Entity key A JObject containing the primary key of the record to be deleted OperationOptions The operation options as configured by a user: Parameters: a JObject containing the input parameters' value Filter: the data filter criteria TransactionName: the name of the transaction Destroy Each Connector must implement a Destroy method, which will be invoked when an App Page is closed. Use this method to release any resources or memory that your Connector may have acquired during its lifetime. void Destroy() Decrypting Values If a Connector's configuration contains a Secure/Password Textbox, its value will automatically be encrypted. To decrypt the value, use the following set of instructions: var request = new OnDecryptRequestArgs(value); this.OnDecryptRequestArgs?.Invoke(this, request); var decryptedVal = request.DecryptedValue; Custom Events While building your Connector, you may need to use external libraries or third-party event subscriptions to handle custom events. If these are used, you must catch any exceptions from the event handlers yourself, to prevent uncaught exceptions that could possibly crash the App Page if they get through. ILiveConnector The ILiveConnector interface allows the Connector to send notifications to an App Page to notify of a change to the entity. There are several methods required to implement this interface. Subscribe Subscribe is called by the Engine to inform the Connector that an App Page has been opened that uses Live Data from a given Entity (IsLive property set to true), and should be used to begin listening for changes to that entity. The Subscribe method has two overloads and can be used in the following ways: Use the first overload if you only want to pass the entity ID to the method. public void Subscribe(string entityId) Use the second overload if you want to use filtering. public void Subscribe(string entityId, OperationOptions options, JObject extraOptions) Warning The second overload is supported on App Designer v4.3.5 and XMPro.Integration.Framework v4.2 and above. UnSubscribe Unsubscribe is called by the Engine to inform the Connector that all AppPages that use Live Data from a given Entity have been closed, and should be used to stop listening for changes to that entity. public void UnSubscribe(string entityId) Publish This method can be used to allow external changes to be passed to the Connector's internal entity tracking. public void Publish(string entityId, Change[] changes, JObject options) OnChange To push the changes of entities to an App Page that subscribed to the live update, your Connector should invoke the OnChange event with the values of changes as arguments: this.OnChange?.Invoke(this, new OnChangeArgs() { EntityId = entityId, Changes = changes.ToArray() }); IConnectorError A Connector can publish messages to the Connector Logs by implementing the IConnectorError interface. To log the error, your Connector should invoke the OnConnectorError event with the error information passed as arguments: this.OnConnectorError?.Invoke(this, new OnErrorArgs(ConnectionId, Timestamp, Source, Error, DetailedError, Data)); ITSAConnector v4.4.12: replaced the ITSCConnector interface, which is now deprecated. The ITSAConnector interface notifies the Time Series Analysis to use optimized client-side querying to increase its performance. The Connector will pre-process the large volumes of data and return it in buckets. When a Connector that implements the ITSAConnector interface is used with a Time Series Analysis Block, the Block expects the Connector to implement a specialized structure for data inputs and outputs: Implement Date Buckets by organizing the data into separate partitions based on specific time intervals, such as days, weeks, or months. Below is a of sample bucketed data with an interval of 2 hours: Bucketed Timestamp Sensor1 Sensor2 Sensor3 Original Timestamp 2024-03-28 08:00:00 25.4 18.2 32.7 2024-03-28 05:36:17 2024-03-28 08:00:00 24.8 18.5 33.2 2024-03-28 07:12:45 2024-03-28 08:00:00 25.1 18.9 34.0 2024-03-28 08:58:21 2024-03-28 10:00:00 25.6 19.2 34.5 2024-03-28 09:27:54 2024-03-28 10:00:00 26.2 19.6 34.8 2024-03-28 10:44:30 2024-03-28 10:00:00 26.5 19.8 35.1 2024-03-28 11:15:01 2024-03-28 12:00:00 27.0 20.1 35.3 2024-03-28 12:21:59 2024-03-28 12:00:00 27.3 20.5 35.7 2024-03-28 13:33:42 2024-03-28 12:00:00 27.7 20.8 36.0 2024-03-28 14:07:29 2024-03-28 14:00:00 27.9 21.2 36.3 2024-03-28 15:08:11 Replace the Original Timestamp with the Bucketed Timestamp value for final results. For example: Original Timestamp Sensor1 Sensor2 Sensor3 2024-03-28 08:00:00 25.4 18.2 32.7 2024-03-28 08:00:00 24.8 18.5 33.2 2024-03-28 08:00:00 25.1 18.9 34.0 2024-03-28 10:00:00 25.6 19.2 34.5 2024-03-28 10:00:00 26.2 19.6 34.8 2024-03-28 10:00:00 26.5 19.8 35.1 2024-03-28 12:00:00 27.0 20.1 35.3 2024-03-28 12:00:00 27.3 20.5 35.7 2024-03-28 12:00:00 27.7 20.8 36.0 2024-03-28 14:00:00 27.9 21.2 36.3 Note SQL and ADX have a native function to achieve this, DATE_BUCKET() for SQL and bin() for ADX. Use the interface and implement buckets on any Connector to access the Time Series Analysis Block optimizations for your Data Source. Example The code below is an example of an empty connector. Take note of how the interfaces and methods have been implemented. using Newtonsoft.Json.Linq; using System; using System.Collections.Generic; using System.Linq; using System.Text; using XMPro.Integration.Framework; using XMPro.Integration.Framework.Connector; using XMPro.Integration.Settings; namespace XMPro.Integration.NewConnector { public class NewConnector: ILiveConnector, IUsesVariable, IConnectorError, ITSAConnector { public long UniqueId { get; set; } public event EventHandler<OnChangeArgs> OnChange; public event EventHandler<OnErrorArgs> OnConnectorError; public event EventHandler<OnDecryptRequestArgs> OnDecryptRequest; public event EventHandler<OnVariableRequestArgs> OnVariableRequest; private Configuration _config; public void Subscribe(string entityId) { // Implement script for Subscribe method } public void UnSubscribe(string entityId) { // Implement script for UnSubscribe method } public void Publish(string entityId, Change[] changes, JObject options) { // Implement script for Publish method } public string GetConfigurationTemplate(string template, IDictionary<string, string> parameters) { var settings = Settings.Settings.Parse(template); new Populator(parameters).Populate(settings); return settings.ToString(); } public IEnumerable<Entity> GetEntities(IDictionary<string, string> parameters) { this._config = new Configuration(parameters); //Implement script for GetEntities method return new List<Entity>() { { new Entity(\"0\") { Operations = Operation.Read, IsLive = false, Name = \"Name\" } } }; } public Entity GetEntity(string entityId, IDictionary<string, string> parameters) { return new Entity(entityId) { Properties = new List<Property>().ToArray(), Operations = Operation.Read, IsLive = false }; } public void Create(Configuration config) { //Implement script for Create method } public IQueryable<JToken> Read(string entityId, OperationOptions options, JObject extraOptions = null) { try { //Implement script for Read method return Enumerable.Empty<JToken>().AsQueryable(); } catch (Exception e) { this.OnConnectorError?.Invoke(this, new OnErrorArgs(123, DateTime.UtcNow, nameof(Read), e.Message, e.ToString())); return Enumerable.Empty<JToken>().AsQueryable(); } } public JObject Insert(string entityId, JObject values, OperationOptions options) { //Implement script for Insert method } public JObject Update(string entityId, JObject key, JObject values, OperationOptions options) { //Implement script for Update method } public int Delete(string entityId, JObject key, OperationOptions options) { //Implement script for Delete method } public void CommitTransaction(string transactionName) { //Implement script for CommitTransaction method } public void Destroy() { //Implement script for Destroy method } } } Further Reading Packaging Connectors"
  },
  "src/how-tos/connectors/manage-connectors.html": {
    "href": "src/how-tos/connectors/manage-connectors.html",
    "title": "Manage Connectors | XMPro",
    "summary": "Manage Connectors Connectors allow you to connect to third-party sources of data. Examples of these Data Sources include databases, Data Streams, or Recommendations, which can be integrated into the Application and are needed if you want to display any real-time or context data to the user on a Page of an Application. Note It is recommended that you read the article listed below to improve your understanding of Connectors. Connector Creating Connectors Creating a Connector can be divided into two parts: Writing the code for a Connector Connectors are generally written in C# as library projects that make use of the XMPro.Integration.Framework NuGet package. XMPro.Integration.Framework requires your project to be written using a predefined structure. This structure requires you to implement certain interfaces. To learn more about how to use this framework, refer to these instructions. Note Code for some Connectors has been made available on GitHub. It might be useful to use these resources as an example when writing your own Connectors. Packaging the Connector After writing your code, you need to use the XMPro Package Manager Windows 10 desktop application to package your Connector. This application allows you to specify all the properties your Connector requires, add the user settings in the form of controls, and allows you to upload the DLL of the Connector you’ve written. Finally, it will create a file with a “.xmp” extension, which you can upload to App Designer and start to use to build Applications. To package the Connector, refer to these instructions. Adding a Connector Connectors can be added via the Connectors page before being used in any of the Applications. Click on the Connectors page from the left-hand menu. Click on Add. Upload the xmp file of the Connector. The unique ID, name, version, and description are re-filled based on details from the file uploaded. Add the category. Click on Save. Selecting an existing Connector opens the configuration panel where details for the Connector can be viewed. The category can also be changed here. Deleting Connectors Connectors can be removed via the Connectors page. To remove Connectors: Open the Connectors page from the left-hand menu. Click Select. Select the Connectors that you would like to remove. Click Delete. 5. Confirm that you would like to delete the Connectors selected. Versions of a Connector When a new version of a Connector is added, the Connector will be updated to the new version. The old version will remain and Applications using the old version of the Connector will continue to use that version until it is upgraded manually. Open the Connectors page from the left-hand menu. Select a Connector to view its information. Each version is shown along with the number of Applications still using that version. Select the version to view the complete list of Applications still using that version. Note Users with DeleteConnector rights and Admins see the usage count for all Applications, whereas other users see the usage count of Applications to which they have access. Categories Connectors can be organized into categories. These categories are separate from the App and Data Stream Categories. Click on the Connectors page from the left-hand menu. Click on Manage Categories. The list of existing categories is shown. Click on Add. 5. Name the category. 6. Click on Add. Categories for Connectors can also be edited or removed. To edit or remove a category for Connectors, select the category from the list of existing categories to enable the edit and remove options. Finding Help for Connectors Help documentation is available for every Connector. These pages provide context, configuration definitions, an example, and release notes to help if you are unsure of anything related to the Connector you are configuring. See the Integrations article for the list of Connector documentation links."
  },
  "src/how-tos/connectors/packaging-connectors.html": {
    "href": "src/how-tos/connectors/packaging-connectors.html",
    "title": "Packaging Connectors | XMPro",
    "summary": "Packaging Connectors Getting Started The XMPro Package Manager is a Windows 11 desktop application that enables you to package a new Connector or update details for an existing Connector. See the Connector article for more information on Connectors. This application takes you through the process of specifying all the properties your Connector requires, adding or changing the controls for each user setting, and uploading the DLL files of the Connector code. It will provide you, upon completion, with a file that can be uploaded to Application Designer after which you can use the Connector in App Pages. You can download the software from the Microsoft Windows 10 Store or clicking here. After installing the XMPro Package Manager, launch the application from the Microsoft Store or search for “XMPro Package Manager” in the Start menu and then click on “XMPro Package Manager”. New / Import On the first screen of the application, you can either create a new Connector package or import and update an existing one. Note Use the arrows at the bottom of the page section to move forward or backward in the application. When you import an existing package, you have the option to export the package as a JSON file. This is useful either to compare packages or for source control and version management. You can also import the JSON file from an existing package, which is particularly useful if you need to modify translations added through the Include Multilingual Support feature. Details The Details form allows you to specify or edit the properties of a Connector. These properties are listed and explained below. Name The name of the Connector is what the Connector will be known as once it is uploaded to the Application Designer platform, for example, “SQL Connector”. Description The description is a brief explanation of what the Connector does, for example, “This Connector allows you to read/update a SQL Database table“. Version The version of the Connector. Any real number is acceptable, for example, \"1.02\". Warning If you make a change to an existing Connector, make sure you increment the version number as Application Designer will not allow you to upload two of the same Connectors with the same version. Entry Point The entry point is the namespace and class name of the actual Connector’s DLL file. For example, if a Connector with the class name “Connector” is located in the XMPro.AzureSQLConnectors namespace, the Entry Endpoint for it would be “XMPro.AzureSQLConnectors.Connector”. Icon File The icon used to represent your Connector. Click the Browse button, navigate to where you’ve stored the file via the Explorer and select the new image file. Note It is recommended that you upload either a JPG or PNG file with a size of 64×64 pixels to accommodate for retina displays. References The References form is where you upload the file(s) required for the Connector to execute. Only files in the Selected File(s) list will be included in the package, and any DLLs must be created in .NET. To upload a file, click the Browse button next to the DLL File(s) field and navigate to where the files are located. Select all the files needed and click the Add button to add them to the Selected File(s) list. To remove a file from the list, click the Delete button next to the file name in the Selected File(s) list. Type Description Plugin The DLL file that was generated when you built the project containing your Connector source code. Reference Additional DLL file(s) referenced by the Plugin File, such as Newtonsoft.Json. You do not need to upload the XMIoT.Framework.dll file as this DLL is automatically included. Resource Additional DLL file(s) needed by the Reference File. Settings Depending on what your Connector does, it might require that the user provide certain information, such as a server URL, username, or password. For each of these information fields (or settings), you need to specify which control should be used and what each control represents, for example, the SQL Connector will require the user to add a server URL. The user should provide this value using a text-box control. Thus, you need to create a control with a type of “TextBox” and a caption that reads “Server URL” in the XMPro Package Manager application. The following controls are available to be used to capture user input: Button CheckBox CheckList DropDown EditList FileUpload Filter Grid Group HTML Editor NumberBox ScriptBox TextBox Title TokenBox VariableBox Each control has several properties that have to be set and not all properties apply to all controls. For example, options apply to a drop-down control and not a text-box control. The table below contains a list of all the available properties, their description, and to which controls they are applicable. Property Name Control Type Description Allow Custom Text Drop-Down Allows the user to type custom text in the drop-down field if checked. Allow Custom Tokens Token Box Allows the user to add custom tokens if checked. Caption All Text that will be displayed with the group or setting. The caption is usually one or two words, describing the value that should be provided by the user, for example, “Server URL”. Default Value Title The default value of the title. Font Size Script Box Size of the font in the Script Box. Help Text All, excluding Groups If you need to provide the user with any additional information about the purpose of the setting or helpful instructions, specify it in this field. Key All Uniquely identifies the group or setting. Keywords Script Box Define your variables or other custom keywords here, so that they will be available in the editor’s IntelliSense. Options (Drop Down) Drop-Down Use the Options-area to add values to the drop-down menu by specifying the Text and Value fields and then clicking Save. You may also choose an option to be used as the default option by checking the “Set as Default Value” box. Options (HTML Editor) HTML Editor Allows you to specify placeholders that can be mapped to input fields in the input received by the Agent. Postback All If checked, will cause the form to do a postback to retrieve values from the server when the field loses focus (when the user clicks out of the field). Required All, excluding Groups The control will be validated to make sure that a value has been specified if this box is checked. ScriptBox Height Script Box Height of Script Box. ScriptBox Mode Script Box Language in which script has to be written. ScriptBox Theme Script Box The theme of the Script Box. Themes available include the following: Ambiance Chaos Chrome Clouds Clouds_midnight Cobalt Cromson_editor Dawn Dreamweaver ScriptBox Width Script Box Width of Script Box. Secure All The value of the control will be treated as a secure value if this box is checked (encrypted and not displayed on the form in plain text). An example of a secure value is a SQL Server password. Show Grid Lines Grid The grid lines of the grid will be shown if checked. Show Header Grid The header of the grid will be displayed, if checked. Sort Index All This is used to determine the group or setting’s position and works with increments of 10. Adjust this value to move the group or setting up or down on the form. Unique Key Grid Mark a specific column as being unique, for example, an identity column. Visible All This field sets the initial visibility of the group or setting. Adding Settings Settings are grouped logically into one or more groups, such as authentication, criteria, and output. Create a group first, then add controls for settings to the group. To do this, follow the steps below: Click on the plus-icon (top right, next to the Settings header). A form section will open, allowing you to specify a group for the settings. Specify a unique value that can be used as the key for the group. Add the caption you would like to use. Click Save. Next, we are going to add a setting. Click on the plus-icon next to the group you’ve created. Choose the type of control you would like to use. Add a unique key for your control. Please note that this key needs to correspond to what you defined in your code. Add a caption for your control. If needed, add a default value. If required, add help text. Select the options that apply from the list of check-boxes. Click Save. Output Export as JSON file Tick the checkbox Export as JSON file too? if you would like to export the file as JSON too. It will later be saved to the same directory as the XMP file with the file name category_name_version.json. Include Multilingual Support Tick the checkbox Include Multilingual Support? if you would like to add support for languages other than English. Uncheck languages you don't want to include. This feature leverages generative AI to provide language translation. It is available only if the following requirements are met: You are connected to the internet. Open AI is configured (Click here for instructions on how to do so). Note What is Translated: The Connector description and static properties added when packaging the Connector are translated, whereas internal messages and dynamic properties added when building the Connector are not. Minimum XMPro Product Version: The tables below outline the minimum versions of XMPro App Designer (AD) and XMPro Package Manager (PM) required for multilingual support. If Automated Translations Are Incorrect: Edit the translations in the JSON file and repackage it with an incremented version number. AD Multilingual Support Pre v4.4.16 v4.4.16+ v4.5.4+ Internal messages and dynamic properties ✗ ✗ ✗ Connector description and static properties ✗ ✓ ✓ Static property drop-down options ✗ ✗ ✓ PM Multilingual Support Pre v1.3.18 v1.3.18+ v4.5.4+ Internal messages and dynamic properties ✗ ✗ ✗ Agent description and static properties ✗ ✓ ✓ Static property drop-down options ✗ ✗ ✓ Configure OpenAI API Click Configure OpenAI. A form will open for you to add or modify the OpenAI Endpoint and Api Key. Click Save. Review: Details Lastly, you can navigate back through the steps to review the details that you’ve specified. If you are satisfied, complete the wizard by clicking the Save button below before navigating to the folder where you would like the package to be exported. Your package will be created with the file name category_name_version.xmp. Note If you imported an existing file, take care to: either click 'Save as new Connector' to generate a new Connector, or click 'Save' to generate a new version of the original Connector. ensure you select a different location folder or increment the version to avoid overwriting the original. Further Reading How to upload your new Connector to Application Designer Note You need to have the correct permissions set against your user to be able to edit and upload Connectors. This is a role not typically given to all users."
  },
  "src/how-tos/data-streams/README.html": {
    "href": "src/how-tos/data-streams/README.html",
    "title": "Data Streams | XMPro",
    "summary": "Data Streams A Data Stream allows you to view the flow of data between Agents, which are connected using arrows that allow data to flow from one Agent to the next. This allows you to view data from multiple Data Sources in one place, and complete certain actions on the data such as aggregating, filtering, displaying, or re-saving the data into another database. Note It is recommended that you read the article listed below to improve your understanding of Data Streams. Data Stream Articles Manage Data Streams Manage Collections Use Remote Receivers and Publishers Manage Recurrent Data Streams Use Business Case and Notes Run an Integrity Check Check Data Stream Logs Use Live View Use Stream Metrics Troubleshoot a Data Stream Upgrade a Stream Object Version Setup Input Mappings Use Error Endpoints Use the Timeline Context Menu"
  },
  "src/how-tos/data-streams/check-data-stream-logs.html": {
    "href": "src/how-tos/data-streams/check-data-stream-logs.html",
    "title": "Check Data Stream Logs | XMPro",
    "summary": "Check Data Stream Logs A Stream Host is an application that can either be installed as a Windows Service or as a Console Application. Stream Hosts enable Data Streams to run, and you can check any status updates, messages, or errors from the Stream Host directly from the Data Stream you are running. Note It is recommended that you read the article listed below to improve your understanding of Stream Hosts and Data Streams. Data Stream Collection and Stream Host How to Manage Data Streams Stream Host logs can be checked by going to the 'Collection' page of Data Stream Designer and viewing the logs there. However, you can also view Logs that are specific to a Data Stream directly from the Data Stream canvas. Note To find out more about viewing Stream Host logs, visit the How to Manage Stream Hosts article. View Data Stream Logs To view Data Stream logs from the canvas, follow the steps below: Publish a Data Stream. Click on Logs. Select the Stream Host Device to view logs for. Logs will display in the grid. You can also maximize the grid to view the data more clearly. To view logs within a specific time range, adjust the timeline slider above the grid. Refresh Data Stream Logs To refresh Stream Host logs, follow the steps below: Publish a Data Stream. Click on Logs. Click on refresh. Logs in the grid will clear and refresh. Filter Data Stream Logs To filter Data Stream logs, follow the steps below: Publish a Data Stream Click on Logs. Click on the 'Level' filter button. Select the log level. Click on OK. Export Data Stream Logs To export Data Stream logs, follow the steps below: Publish a Data Stream Click on Logs. Click on the three dots. Export all data or export selected rows."
  },
  "src/how-tos/data-streams/context-menu.html": {
    "href": "src/how-tos/data-streams/context-menu.html",
    "title": "Context Menu | XMPro",
    "summary": "Context Menu The Right Click Menu or the Context Menu is the menu, which appears when you right-click on the Stream Object in Data Stream. This menu gives you added functionality by offering you actions you can take with the Stream Object. Configure You can configure the Stream Object through the Context Menu. See the Stream Object Configuration article for more details on Agent Configuration. Integrity Check You can run an Integrity Check on the agent through the Context Menu. See Verifying Stream Integrity article for more details on Integrity Check. Disable/Enable You can disable/enable a Stream Object through the Context Menu. Disable a Stream Object Stream Objects can be disabled in a Data Stream. Disabled Stream Objects will be excluded from the output when the Data Stream is published. Observe that the Disabled Stream Object is now greyed out. Warning Agents with no entry points and multiple entry points cannot be disabled. Enable a Stream Object Disabled Stream Objects can again be enabled in a Data Stream. Enabled Stream Objects will be Included in the output when the Data Stream is published. Observe that the Stream Object is not greyed out. Copy You can copy a Stream Object and Paste it on the canvas. Click anywhere on the canvas and right-click. Delete You can Delete a Stream Object using the Context Menu."
  },
  "src/how-tos/data-streams/manage-collections.html": {
    "href": "src/how-tos/data-streams/manage-collections.html",
    "title": "Manage Collections | XMPro",
    "summary": "Manage Collections Stream Hosts are grouped into different Collections, which are created and maintained in Data Stream Designer. A Collection can be defined as a category that contains a set of Stream Hosts that run the same Data Streams. Collections are used to prevent you from having to redeploy a Data Stream to multiple Stream Hosts, devices, and assets. When a Data Stream is published for a Collection, the devices themselves can just subscribe to that Collection. Note It is recommended that you read the article listed below to improve your understanding of Collections. Collection and Stream Host Video 1: How To Use Collections Create a Collection Collections are an important concept in the Data Stream Designer. You might have to create a Collection soon after starting to use the Application as they are crucial to the workings of use cases and Streams. A Collection also has to be created before installing a Stream Host as the Stream host is dependent on the information contained in a Collection. To create a Collection, follow the steps below: Open the Collections page from the left-hand menu. Click on New. Choose a name for the new Collection. You may also include tags if needed by choosing tags from the drop-down that will open as soon as you click on the field or by typing a new value and pressing Enter. Click Ok. Change a Collection key It might be needed to replace or change the key that is associated with a Collection from time to time. To replace a key with a new one, follow the steps below: Open the Collections page from the left-hand menu. Select the Collection from the list. Click on Revoke Key. Confirm that you would like to revoke the key. After clicking Revoke, the key will be replaced with a new key. Delete a Collection To remove a Collection, follow the steps below: Open the Collections page from the left-hand menu. Select the Collection you would like to remove. Click on the Delete button. Confirm that you would like to delete the selected Collection. Further Reading How to Use Remote Receivers and Publishers"
  },
  "src/how-tos/data-streams/manage-data-streams.html": {
    "href": "src/how-tos/data-streams/manage-data-streams.html",
    "title": "Manage Data Streams | XMPro",
    "summary": "Manage Data Streams A Data Stream is a visual representation of a flow of data, which is depicted by the use of Agents that are connected by arrows that allow data to flow from one Agent to the next. Data streams are built in an interactive canvas environment that allows you to drag Agents from the toolbox to a drawing area. These Agents allow you to complete certain actions on the data. This includes aggregating, filtering, displaying, or re-saving the data into another database. Note It is recommended that you read the article listed below to improve your understanding of Data Streams. Data Stream Creating a Data Stream To create a Data Stream, follow the steps below: Open the New Data Streams page from the left-hand menu. Give the Data Stream a name. Enter a description. Enter the type (streaming or recurring). Enter the category under which the Data Stream is found in the Data Stream list. Give the Data Stream an icon. Sample icons can be found in the Icon Library. Enter the Collection the Data Stream will have. Click Save. Fig 1: Creating a Data Stream Fig 2: A newly created Data Stream Opening a Data Stream Data Streams can be opened via the Data Streams Page on the left-hand menu, or via the main page that contains the list of Categories. To open Data Streams from the left-hand menu: Open the Data Streams page from the left-hand menu. Select the Data Stream you want to open. Fig 3: Opening a Data Stream from the left-hand menu To open Data Streams from the list of categories: Click the Logo to open the landing page. Click the Category of the Data Stream. Fig 4: Finding a Data Stream from the landing page of categories Click the Data Stream you want to open. Fig 5: Opening a Data Stream from a category Adding an Agent to the Canvas To add Agents to the canvas, drag and drop Agents from the left-hand toolbox to make up the data flow for your Data Stream. An Agent that has been added to the canvas is called a Stream Object. See the Agents article for more information on Agents. Enter part of the Agent name to filter the toolbox (or expand a category to view the list of Agents). Click and drag an agent onto the Canvas. Click the output endpoint and drag it to an input endpoint to connect two Stream Objects. Fig 6: Adding an Agent to the Canvas Fig 7: Connecting two Agents Copying and Pasting Stream Objects Stream Objects that are in the Data Stream can be copied and pasted using keyboard shortcuts. To copy a Stream object: Select a Stream Object to highlight it. To highlight multiple Stream Objects, hold the ctrl key while you are selecting them. Once the Stream Object(s) are highlighted in yellow, press and hold ctrl + C. To paste the Stream Object that was just copied, press and hold ctrl + P. Note You can also copy a Stream Object from one Data Stream and paste it into a different Data Stream. Fig 8: Copying a Stream Object Deleting a Stream Object To delete a Stream Object on the canvas, follow the steps below: Click a Stream Object to select it. Click Delete. Fig 9: Deleting a Stream Object using the Delete Button You can also delete Stream Objects that are on the Data Stream canvas by using the 'delete' keyboard shortcut. Select an Agent to highlight it. To highlight multiple Agents, hold the ctrl key while you are selecting them. Once the Stream Object/s are highlighted in yellow, click on the delete key on the keyboard. Fig 10: Deleting a Stream Object using the keyboard Deleting a Data Stream To delete a Data Stream, follow the steps below: Click Properties. Click Delete. Fig 11: Deleting a Data Stream Sharing Access to a Data Stream Data Streams can be shared between users with differing permisson. See the Manage Access article to read more about managing access to users. To share a Data Stream, follow the steps below: Click Manage Access. Click Add. Enter the user to which you want to grant access. Choose between read, write, or co-owner permissions. Click Ok. Fig 12: Sharing Access to a Data Stream Changing Access to a Data Stream To change permissions of existing users, follow the steps below: Click on Manage Access. Select the user. Fig 13: Changing Access to a Data Stream Change their permissions.\\ Or, delete permissions for the user. Fig 14: Changing or deleting permission to a Data Stream Removing Access to a Data Stream To remove the permissions for multiple users, follow the steps below: Click Manage Access. Click Select. Select multiple users. Click Delete. Fig 15: Removing Access to a Data Stream for multiple users Cloning a Data Stream To clone a Data Stream, follow the steps below: From within the Data Stream canvas, click Properties. Click Clone. This button may not initially be visible on the Properties page but can be found in the menu that appears if you hover with your mouse cursor over the \"More\" button. Specify the name for the cloned Data Stream. Choose a category to copy the Data Steam to. Please note that this should not be the same as the category of the original Data Stream. Click Save. Fig 16: Closing a Data Stream Fig 17: The cloned Data Stream Further Reading How to Manage Recurrent Data Streams How to Use Business Cases and Notes How to Run an Integrity Check How to Manage Live View How to Troubleshoot a Data Stream How to Upgrade a Stream Object Version How to Setup Input Mappings How to Use Error Endpoints How to Use the Timeline"
  },
  "src/how-tos/data-streams/manage-recurrent-data-streams.html": {
    "href": "src/how-tos/data-streams/manage-recurrent-data-streams.html",
    "title": "Manage Recurrent Data Streams | XMPro",
    "summary": "Manage Recurrent Data Streams Data Streams of the Streaming type will run polling Agents at a set interval, for instance, every 10 seconds, whereas Recurrent Data Streams run on a customizable schedule, for instance, once a day at 12 AM. This may be useful if you only want to read data or perform an action with the data at certain points during the day, or if you want to perform actions on the data once a week, month or year. Note It is recommended that you read the articles listed below to improve your understanding of Data Streams. Data Stream How to Manage Data Streams Creating Recurrent Data Streams The streaming type of the Data Stream can be configured at the time of the Data Stream's creation. Click on add Data Stream from the left-hand menu. Change the Type to be Recurring. Click on Save. To change an existing Data Stream to recurring, go into the properties menu and change the type to be recurring. Click on Properties. Change the Type to be Recurring. Click on Save. Configuring Recurrence for Agents When a Data Stream is set to be recurring, opening the configuration menu for listeners or context providers will allow you to make changes to the schedule for when they occur. To configure recurrence for Agents, follow the steps below: Add Agents to the Data Stream Canvas. Click on Configure for an Agent. Instead of polling intervals, the configuration menu will ask you to configure recurrence. Configure the schedule for the Agent. Recurrence The following table describes the Recurrence configuration properties: Property Description Start Repeat Specify whether the Agent's schedule should start Immediately when the Data Stream is published or On a configured date and time. Note: If the Start Repeat (On) is already in the past at the time the Data Stream is published, the Agent waits to execute on the next scheduled Repeat. Repeat The schedule's unit of time. The available options are: Seconds, Minutes, Hourly, Daily, Weekly, Monthly, or Yearly. Repeat Every How frequently the repeat interval occurs. For example, every 30 seconds, every 2 weeks, etc. Repeat On Specify when the Repeat occurs (applies to Weekly, Monthly, and Yearly): • For Weekly, select one or more days of the week (e.g., Monday, Wednesday, Friday). • For Monthly, choose the day of the month (1-31). • For Yearly, select the month and day. Repeat At The time of day that the Agent executes (applies to Daily, Weekly, Monthly, and Yearly). End Repeat Choose for the recurrence to Never end, end On the specified date, or end After the specified number of occurrences. Note: If the Data Stream is published and the End Repeat conditions are already met (the On date is in the past, or the Start Repeat On date is in the past and calculated occurrences up to the current date have reached the set After value), the Agent will not execute. Warning Execution Behavior Examples: We always execute first on the configured Start Repeat. When Start Repeat and the scheduled Repeat fall on the same day, the Agent executes at the Start Repeat time but skips the Repeat At time to avoid duplicate execution on the same day. The regular schedule resumes on the next occurrence on a different day. Example 1: If you configure Start Repeat On 15 January at 9:00 AM, Repeat Daily at 2:00 PM, and publish the Data Stream on 15 January at 8:00 AM, the Agent executes on 15 January at 9:00 AM, skips the 2:00 PM execution that same day, and then resumes the regular daily schedule at 2:00 PM on 16 January. Example 2: If the Start Repeat is on Monday, and the Repeat is Weekly on Wednesday and Friday, publishing the Data Stream on a Sunday first executes on Monday, and proceed with the scheduled repeats on Wednesday and Friday. Recommendation: To ensure predictable behavior, set the Start Repeat On date and time to match the next scheduled Repeat when using Daily or less frequent intervals."
  },
  "src/how-tos/data-streams/remote-receivers-and-publishers.html": {
    "href": "src/how-tos/data-streams/remote-receivers-and-publishers.html",
    "title": "Use Remote Receivers and Publishers | XMPro",
    "summary": "Use Remote Receivers and Publishers Sometimes it is necessary to run the same Data Stream on two or more different systems. It may be that one system is low-powered and does not have enough resources to handle the integrations or analytical tasks of the Data Stream, or some integrations may not even be accessible on a system that is outside a corporate network or behind a firewall. The solution to these problems is found by using Remote Receivers and Publishers. Two Collections are set up, and half of the Data Stream is run on one Collection while the other half runs on the other Collection. The Stream Host can automatically detect where data has to flow from one Collection to the other (a Collection Hop). Note It is recommended that you read the article listed below to improve your understanding of Live Data. Remote Receivers and Publishers How to Manage Data Streams How to Manage Collections Each Collection allows you to configure a Remote Publisher and a Remote Receiver. Every time a Collection Hop is detected the Stream Hosts will automatically set up the configured Remote Publisher, which will put the data on a central store. The receiving Collection will also automatically set up a Remote Receiver which will receive data from the store and pass it on to the Data Stream on the other side. It is also possible to set up multiple Stream Hosts to funnel data from tens or hundreds of devices into the data store, which will then be redirected to a single Stream Host with a Remote Receiver. Set Up Remote Receivers and Publishers To set up a Remote Receiver and a Remote Publisher, follow the steps below: Create two collections, one for each system. Click the Collection that will be sending data. Choose a Remote Publisher Agent and Version. Configure the Remote Publisher. Each Agent has specific configuration settings. For the MQTT Agent as a Remote Publisher, set up a broker. Click on Apply. Save the Collection. Click the Collection that will be receiving data. Choose a Remote Receiver Agent and Version. Configure the Remote Receiver. Each Agent has specific configuration settings. For the MQTT Agent as a Remote Publisher, Set up a broker and payload definition. In your Data Stream, set the Stream Objects' Collections to the desired Stream Host's Collection."
  },
  "src/how-tos/data-streams/run-an-integrity-check.html": {
    "href": "src/how-tos/data-streams/run-an-integrity-check.html",
    "title": "Run an Integrity Check | XMPro",
    "summary": "Run an Integrity Check When running an Integrity Check on a Data Stream, each Stream Object is checked to verify that it is configured correctly. Errors for the Agent will be displayed if there are any issues found with their configurations. This is done to ensure the integrity of your Data Stream and to make sure all input fields are valid and accurate. Note It is recommended that you read the article listed below to improve your understanding of an Integrity Check. Agent Verifying Stream Integrity How to Manage Data Streams Running an Integrity Check To run an Integrity Check on a Data Stream, follow the steps below: Click on Integrity Check. Wait for the Integrity Check to complete. This can be seen by watching the loading bar on each Agent. When the Integrity Check is completed, Agents will show their errors if they exist. Tip ✅ SUCCESS: Agents with a blank background have passed their Integrity Check with no errors. ❌ERROR: Agents with a red background have reported back some errors in their configuration. Hover over the Agent with errors to view a list of errors. Note An Integrity Check cannot be run on Agents that have unsaved changes. To run an Integrity Check, discard or save all changes made. Fixing Integrity Check errors The errors are saved to the Stream Object and are not removed until another Integrity Check is performed. Open the configuration panel for the Agents that are showing errors, and fix any errors in the inputted values. In this case, the text file Agent did not have a file path specified. Double click on the Agent with the errors to open its configuration menu. Fix any errors in configuration. Click on Apply. Click on Save. Click on Integrity Check to run it again. Check if the background is no longer red."
  },
  "src/how-tos/data-streams/setup-input-mappings.html": {
    "href": "src/how-tos/data-streams/setup-input-mappings.html",
    "title": "Setup Input Mappings | XMPro",
    "summary": "Setup Input Mappings Input Mappings allow you to specify that an Agent receives its input in a specific structure. This is possible by configuring the arrows between the two Agents, which allow the user to map the inputs of the Agent to incoming attributes. This functionality is beneficial if you want to map any incoming data from a preceding Agent to specific attributes that can be saved in rows or columns in a database using an Action Agent, such as an SQL Server Writer. Note It is recommended that you read the article listed below to improve your understanding of Input Mappings. Stream Object Configuration How to Manage Data Streams Adding Input Mappings To add Input Mappings between two Agents, follow the steps below: Click on the arrow between the two Agents you want to map. Click on Configure. The left side lists all the properties the first Agent is sending. The right side is listing all the inputs the receiving Agent is expecting. Select the property you want to map for each field. If the value is greyed out, it means it does not match the type (number, text, etc) that the receiving Agent is expecting for that field. Click on Apply. Automap To map via Automap, follow the steps below: Click on the arrow between the two Agents you want to map. Click on Configure. Click on Automap. Click on Apply. Match by Expression To map via Match by Expression, follow the steps below: Click on the arrow between the two Agents you want to map. Click on Configure. Click on Match by Expression. Enter a prefix, postfix, or Expression. For example, 'num' as a prefix will match 'numApples' with 'Apples'. Click on Apply. Show Unmapped To show Unmapped fields, follow the steps below: Click on the arrow between the two Agents you want to map. Click on Configure. Click on Show Unmapped. The list will change to only show the list of fields that have not yet been mapped."
  },
  "src/how-tos/data-streams/troubleshoot-a-data-stream.html": {
    "href": "src/how-tos/data-streams/troubleshoot-a-data-stream.html",
    "title": "Troubleshoot a Data Stream | XMPro",
    "summary": "Troubleshoot a Data Stream When creating and configuring a Data Stream, there is a chance it may not be working as expected, and you may have to find out more information as to why it is not behaving the way it should. There are a few options available on how to troubleshoot a Data Stream. Troubleshooting is required if you want to make sure the flow of data is accurate. Note It is recommended that you read the article listed below to improve your understanding of Data Streams. Data Stream How to Manage Data Streams Troubleshoot using Live View To troubleshoot using the Live View, follow the steps below: Click on Publish. Click on Live View. Select the Agent/s to view the Live Data for. Click Save. Note If data is not being displayed when it should be, or if the values are not being displayed as expected, something may be going wrong with the Agent. Troubleshooting using Error Endpoints To Troubleshoot using the Error Endpoints, follow the steps below: Drag an Event Printer agent onto the canvas. They can be found under 'Action Agents.' Add an arrow from the error endpoint connected to the Event Printer. Click on Publish. Click on Live View. Select the Event Printer. Click Save. Troubleshooting when there is no data visible In some cases, the Event Printer does not show any data when trying to troubleshoot the Data Stream. If this is the case, the Collections Stream Host may be able to give some information. Open the Collections page from the left-hand menu. Click on the Collection. Click on Stream Hosts. Select the Stream Host. View the logs from the Stream Host. Note Any errors that are generated from an Agent which are printed from the error endpoint are also printed in the Stream Host logs. Troubleshooting when there are no Stream Hosts If the Stream Host is not running at all, you can view the logs from the install directory of the Stream Host on your computer. The install folder is named XMPro Stream Host and is usually found in the Program Files in the C Drive."
  },
  "src/how-tos/data-streams/upgrade-a-stream-object-version.html": {
    "href": "src/how-tos/data-streams/upgrade-a-stream-object-version.html",
    "title": "Upgrade a Stream Object Version | XMPro",
    "summary": "Upgrade a Stream Object Version If an Agent has been updated and you want to use the latest version, you can upgrade the Agent using the top menu to get the latest version. It is beneficial to upgrade the Agent especially if there are known errors for that Agent or if the Agent has been improved and provides more functionalities or settings. Note It is recommended that you read the article listed below to improve your understanding of Agents. Agent How to Manage Data Streams Upgrading Agents To upload a new version of an Agent, you should follow the same steps as when uploading an Agent for the first time. For instructions on how to upload an Agent, see the Manage Agents article. The new version of the Agent will appear in the Versions section of your Agent's detail page. The Agents in the toolbox will always be the latest version available; however, the versions of the Agents in your existing Streams will have to be upgraded as this is not done automatically. On the canvas, any Agent that is not the latest version will display its version underneath its icon. To upgrade the version of an Agent in a stream, open your stream and select the Agent. Select the Agent Click \"Upgrade\" Click \"Apply\" Click \"Save\" The latest version is selected by default and this is the most common action. You can opt to select a different version. This is useful during agent development if you wish to roll back from the current version."
  },
  "src/how-tos/data-streams/use-business-case-and-notes.html": {
    "href": "src/how-tos/data-streams/use-business-case-and-notes.html",
    "title": "Use Business Case and Notes | XMPro",
    "summary": "Use Business Case and Notes A Business Case is usually written before a Data Stream is created, and is used to communicate why the users are using that particular Data Stream. They are used to quantify the financial impact, explain why the Data Stream was created and the value that was gained from using it. Business cases allow you to provide descriptions and non-technical explanations that can be communicated to other users in the organization. Notes are another area where you can communicate and record technical information about the Data Stream. From v4.4.7 onwards, Notes are per Version rather than per Data Stream - allowing the use of notes to track the differences between versions. Note It is recommended that you read the article listed below to improve your understanding of Business Cases. How to Manage Data Streams Adding Notes To add a Note to the Data Stream, follow the steps below: Click on Notes. Enter the Notes in the available text field. Customize the text using the text editor options. This includes adding headings, font formats, or images. Click on Save. Adding a Business Case To add a Business Case to the Data Stream, follow the steps below: Click on Business Case. Enter the details for the Business Case. Click on Save. Viewing or Editing a Business Case To view or edit a Business Case, follow the steps below: Click on Business Case. View the date the Business Case was last created or modified. Edit any details. Click on Save."
  },
  "src/how-tos/data-streams/use-error-endpoints.html": {
    "href": "src/how-tos/data-streams/use-error-endpoints.html",
    "title": "Use Error Endpoints | XMPro",
    "summary": "Use Error Endpoints When data flows from one Agent to another, a particular Agent may fail to process a certain data point during runtime. When this happens, the data point that failed and the reason why it failed will be passed through the error endpoint instead of going forward to the output endpoint. Each Agent displays its own errors, and therefore this can be a useful tool for debugging particular Agents. Note It is recommended that you read the article listed below to improve your understanding of Agents. Agent How to Manage Data Streams How to Use Error Endpoints To use an error endpoint, follow the steps below: Click on the red endpoint and drag the arrow to where you want to error data to flow. In this example, the error endpoints are going to be printed using an Event Printer Agent. Click on Save. To view the error data, click on Publish. Click on Live View. Click on the Event Printer to display errors that occur during runtime. Click on Save. The data printed for the Error Endpoint includes the AgentID of the Agent that had the error, as well as the timestamp of when the error occurred. The message of the error is also printed. The exact data from the data points are also printed. Instead of using the Event Printer to print errors, Error Endpoints can also connect to actions that trigger at the time of the error. For example, the following will send an email to a configured email address if an error occurs. Handling multiple errors from Error Endpoints A Union can be used to handle multiple errors at a time. To use the union Agent to do this, follow the steps below: Under the Transformation Agents, drag and drop a Union Agent onto the Data Stream. Connect the error endpoints of multiple Agents to the union. Add another Agent to deal with all the errors at the same time."
  },
  "src/how-tos/data-streams/use-live-view.html": {
    "href": "src/how-tos/data-streams/use-live-view.html",
    "title": "Use Live View | XMPro",
    "summary": "Use Live View When a Data Stream is published, the Live View option becomes visible to allow you to view the data that is being processed by the Agents in the Stream. The way the data is displayed can be changed from a grid view to a gauge or a chart. This is useful for viewing the flow of data in real time and is also, therefore, a good tool to use when debugging. Note It is recommended that you read the article listed below to improve your understanding of Live Data. Running Data Streams How to Manage Data Streams Viewing Live Data To view this data, publish your Stream first, then select the \"Live View\" button. Follow the steps below: Select Live View after publishing your Stream. Select the Agents you would like to view data for. Note Make sure your Data Stream is published before trying to open the Live View. Prior to v4.3.7, it was important to always close the Live View before navigating away. Otherwise, connections were left open. If these build up over time and affect performance, an admin can reset them here. Change Live Data Display To change the type of control the live data is displayed in, follow the steps below: Select the settings icon from the Live View page. Choose the type of control you would like to use. Configure the values of the control. Click Save."
  },
  "src/how-tos/data-streams/use-stream-metrics.html": {
    "href": "src/how-tos/data-streams/use-stream-metrics.html",
    "title": "Use Stream Metrics | XMPro",
    "summary": "Use Stream Metrics When a Data Stream is published, the Stream Metrics become visible and allow you to view the number of Stream Hosts on which the Data Stream successfully started, the amount of data and errors that are being processed per minute in the Data Stream, and the number of active Stream Hosts per Collection. Note It is recommended that you read the article listed below to improve your understanding of Stream Metrics. Running Data Streams How to Manage Data Streams Stream Metrics Components The Stream Metrics has four parts: Started On, Stream Load, Stream Errors, and Stream Hosts per Collection. Warning Stream metric components (Stream Load and Stream Errors) do affect performance. See the Data Stream Designer Settings article for more information on how to toggle this feature on and off. Started On Started On shows the number of Stream Hosts on which the Data Stream started vs the total number of Stream Hosts online across all Collections. The indicator is: green if the Data Stream started on all Stream Hosts amber if some started (indicates an error on the Stream Host) red if the Data Stream failed to start on all Stream Hosts (likely an error on the Data Stream) Note This is useful to alert the composer when the Data Stream is first published that the Data Stream failed to start. ![Started On status indicator showing stream host start status](../../images/data-streams/Started On.png) Stream Load Stream Load represents the amount of data that is being processed by the agents in the Data Stream. The left side of the Stream Load card shows the amount of data that has been processed in the last minute and the right side has a sparkline with a 5-minute history. Hovering over the sparkline will display the amount of data that was processed for the selected minute. ![Stream Load card showing data processing metrics](../../images/data-streams/Stream Load.png) Stream Errors Stream Errors represent the number of errors that are being generated by the agents in the Data Stream. The left side of the Stream Errors card shows the amount of errors that are generated in the last minute and the right side has a sparkline with a 5-minute history. Hovering over the sparkline will display the number of errors that were generated for the selected minute. Stream Hosts per Collection The Stream Hosts per Collection card shows the name and the number of active Stream Hosts in each Collection. If the Data Stream has objects that are in different Collections it will show a card for each Collection."
  },
  "src/how-tos/data-streams/use-the-timeline.html": {
    "href": "src/how-tos/data-streams/use-the-timeline.html",
    "title": "Use the Timeline | XMPro",
    "summary": "Use the Timeline The Timeline displays a record of all the changes users have made to the Data Stream, including any notes made about particular issues. This can therefore be used as a collaboration tool to see the changes users make (even if it's only a single user), as well as notes about things that need to be addressed. Note It is recommended that you read the article listed below to improve your understanding of Timelines. Timeline How to Manage Data Streams Viewing the Timeline To open the Timeline, click \"Timeline\". Adding a note To add Notes to the Timeline, follow the steps below: Click \"Timeline\". Click the \"Note\" button. Type the notes you would like to add. Click \"Ok\". Filtering the Timeline To apply filtering on the Timeline, follow the steps below: Click on Filter. Select the type of items you would like to display. Click OK. Version filtering the Timeline To apply the version filtering on the Timeline, follow the steps below: Click on the Context dropdown. Select the Version that you would like to see the events."
  },
  "src/how-tos/import-export-and-clone.html": {
    "href": "src/how-tos/import-export-and-clone.html",
    "title": "Import, Export, and Clone | XMPro",
    "summary": "Import, Export, and Clone All XMPro Objects allow you to export them as a file and import them to other companies or instances of XMPro Products. This allows you to continue working on the same XMPro Object such as a Data Stream or Application in a different environment without losing all your work or having to start from scratch. Exporting All XMPro Objects (Agents, Applications, Data Streams, and Recommendations) can be exported as a file with a corresponding file extension. XMPro Object Extension Agents .xmp Connectors .xmp Applications .xapp App Pages .xapg Data Streams .xuc Recommendations .xr Forms .xfm This functionality is made available on an XMPro Object's corresponding page, by selecting the \"export\" option. When an XMPro Object is exported, only the latest version will be exported. Thus, if someone imports an XMPro Object, it will be assigned a new ID and contain only one version – the latest version that was exported. Before the exported file is created and downloaded, you will be asked for a password to encrypt the file. The person that imports the Data Stream will have to enter the correct password in order to import it. The App export has an advanced option that allows you to choose which files are included - by default files design time files are included and the uploads folder (runtime files) are excluded. When ticked, you can choose whether to include files that were added at runtime or exclude all files. To export any XMPro Object, follow the steps below: Navigate to the page of the XMPro Object you would like to export. Click on _Export (_For the Data Stream Designer, click on Properties first, then click on Export). Choose a strong password to encrypt the file. The person importing the file must enter the same password. Click on Ok. The exported file will appear in your downloads. Note To export a Widget, follow the steps in Manage Widgets. Importing All XMPro Objects (Agents, Applications, Data Streams, and Recommendations) can also be imported into other companies or instances of XMPro, to avoid needing to replicate a particular Data Stream or Application from scratch. Importing is done from a different location as exporting, which is on the page for the corresponding feature. To import any XMPro Object, follow the steps below: Navigate to the page of the XMPro Object you would like to import. Click on Import. Upload the corresponding import file for the XMPro Object. Enter the password. Click on Upload. 6. Configure any details. 7. When finished, select Save. Note To import an App Page, follow the steps in Import an App Page. Note To import a Widget, follow the steps in Manage Widgets. Cloning To clone any XMPro Object, follow the steps below: Navigate to the page of the XMPro Object you would like to clone. Click on Clone. 3. Give the cloned XMPro Object a new name. 4. Select the version of the app you would like to clone. 5. Click on Ok. The XMPro Object will be cloned and you will be able to see it in the list of Applications, Data Streams, or Recommendations, etc."
  },
  "src/how-tos/index.html": {
    "href": "src/how-tos/index.html",
    "title": "How-Tos | XMPro",
    "summary": "How-Tos This section provides step-by-step guides for common tasks in XMPro. Whether you're creating an application, setting up a data stream, or managing recommendations, you'll find detailed instructions here. Sections Agents Learn how to create, configure, and manage agents in XMPro. Applications Discover how to build and manage applications using XMPro's low-code canvas environment. Connectors Find out how to set up and use connectors to integrate with external systems. Data Streams Learn how to create and manage data streams for real-time data processing. Publish Understand the process of publishing your applications and data streams. Recommendations Explore how to create and manage recommendations in XMPro. General Management Import, Export, and Clone Manage Access Manage Categories Manage Landing Pages Manage Site Settings Manage Variables Manage Versions Stream Host"
  },
  "src/how-tos/manage-access.html": {
    "href": "src/how-tos/manage-access.html",
    "title": "Manage Access | XMPro",
    "summary": "Manage Access XMPro Objects such as Data Streams, Recommendations, Applications, and more can be shared with different users. The person that originally created the XMPro Object will be listed as the owner. When sharing the XMPro Object with other users, users can either be given Co-owner, read, or write access. Note It is recommended that you read the article listed below to improve your understanding of Managing Access. Manage Access Giving permissions to users To share XMPro Objects with users, follow the steps below: Go to the page of the XMPro Object you would like to manage the access for. Click on Manage Access. Open the Design Access Tab. Click Add. 5. Add the user to give them access. 6. Choose read, write, or co-owner permissions. 7. Click Ok. Editing User permissions To edit the permissions of an existing user, follow the steps below: Go to the page of the XMPro Object you would like to manage the access for. Click on Manage Access. Open the Design Access Tab. Click on a user. 5. Edit their permissions. 6. Click on Save. Deleting permissions from Users To delete the permissions of an existing user, follow the steps below: Go to the page of the XMPro Object you would like to manage the access for. Click on Manage Access. Open the Design Access Tab. Click on a user. 5. Click on Delete. 6. Confirm that you really want to delete all permissions for the selected user. Deleting permissions of multiple Users To delete the permissions of multiple existing users, follow the steps below: Go to the page of the XMPro Object you would like to manage the access for. Click on Manage Access. Open the Design Access Tab. Click on Select. Select from the list of users. 6. Click on Delete. 7. Confirm that you really want to delete all permissions for the selected users. Editing Permissions on the Run Access To edit Run Access permissions, follow the steps below: Go to the page of the XMPro Object you would like to manage the access for. Click on Manage Access. Open the Run Access Tab. Select from the list of users. Click on Save. Further Reading How to Subscribe to Notifications"
  },
  "src/how-tos/manage-categories.html": {
    "href": "src/how-tos/manage-categories.html",
    "title": "Manage Categories | XMPro",
    "summary": "Manage Categories A Category is a container that groups related Data Streams and Applications, which are shared between core XMPro Products to provide a homogenous environment. Note It is recommended that you read the article listed below to improve your understanding of Categories. Category Adding a new Category To create a new Category or use case group, follow the steps below: Open the Categories page from the left-hand menu. Click New. Specify a name and description for your new Category. Upload an icon by clicking on the plus-image and browsing to the correct file. Sample icons can be found in the Icon Library. Click Save. Reordering Categories The order of the categories that can be seen on the landing page can be changed using the Categories page. Please note that the order in which the categories appear on this page is the same as the order in which categories are displayed on the landing page. Follow the steps below to reorder the categories on the landing page: Open the Categories page from the left-hand menu. 2. Click Reorder. 3. Drag an item on the list to move it before or after another item. 4. When satisfied with the order of the categories, click on \"Save\". Note If you change your mind about reordering the categories, click Cancel. None of the changes you've made will be saved. Removing Categories Single Category To remove a single category, follow the steps below: Open the Categories page from the left-hand menu. Select the category from the list. Click Delete. Confirm that you would like to delete the category. Multiple Categories To remove multiple categories at the same time, follow the steps below: Open the Categories page from the left-hand menu. Click Select. 3. Select the categories that you would like to remove. 4. Click Delete. 5. Confirm that you would like to delete the categories selected."
  },
  "src/how-tos/manage-landing-pages.html": {
    "href": "src/how-tos/manage-landing-pages.html",
    "title": "Manage Landing Pages & Favorites | XMPro",
    "summary": "Manage Landing Pages & Favorites In App Designer, the Landing Page can be set for what Application Landing Page all users in the company will see when they first open App Designer. Apps and Data Streams can be favorited for fast access in future from Subscription Manager. Favorite commonly used Blocks for fast access when building Apps in App Designer. Note It is recommended that you read the article listed below to improve your understanding of Applications. Application Landing Pages & Favorites How to Manage Apps Set a Landing Page To set the Company's Landing Page for either Mobile or Desktop, follow the steps below: Click on Settings Select from the list of available Applications. Click on Save. Note You can only select Applications that are already published. Favorite an App To Favorite Apps, follow the steps below: Click on the star to favorite an App. Go to Subscription manager. Favorited Apps will show on the main page of Subscription Manager. Note Apps can only be favorited using the category tiles list. Favorite a Data Stream To Favorite Data Streams, follow the steps below: Click on the star to favorite a Data Stream. Go to Subscription manager. Favorited Data Streams will show on the main page of Subscription Manager. Note Data Streams can only be favorited using the category tiles list. Favorite a Block Added in v4.4.11 To Favorite a Block, including Widgets, follow the steps below. Click on the star to favorite a Block (hover over the block to reveal the star). Go to the Favorites category. Favorited blocks will appear under Favorites section as well as their original section. Favorite an Agent Added in v4.4.17 To Favorite an Agent, follow the steps below. Click on the star to favorite an Agent (hover over the block to reveal the star). A solid star is the visual indicator for favorited Agents."
  },
  "src/how-tos/manage-site-settings.html": {
    "href": "src/how-tos/manage-site-settings.html",
    "title": "Manage Site Settings | XMPro",
    "summary": "Manage Site Settings These settings are used to configure each XMPro Product. To open the settings page, click on the gears icon in the grey bar at the top of the screen. Note Please note that the settings that you will see on this page depend on the role and access rights that have been assigned to you. App Designer Settings Security Enable Audit Trail Enabling this setting would cause logs to be created whenever changes are made to Recommendations, Connectors, and components of Applications. The logs will contain details about who made the change and when it was applied. Encryption Key The encryption key is used to encrypt and decrypt sensitive data configured in the user settings when they are stored or retrieved from the database, for example, passwords. Integration Integration Key This key is used to verify Agents that integrate with the App Designer. The Integration Key will need to be copied into the Agent's configuration settings. User Interface Desktop Landing Page Optionally override the default landing page to use a published Application for the whole company when using a desktop computer. Mobile Landing Page Optionally override the default landing page to use a published Application for the whole company when using a mobile device. Enable Mobile App Optionally override the default landing page to use a published Application for the whole company when using a desktop computer. Mobile Landing Page Optionally override the default landing page to use a published Application for the whole company when using a mobile device. Enable Mobile App Added v4.4.4 This defaults to true on new installations. Toggle it off to hide the mobile app icon on the toolbar. This defaults to true on new installations. Toggle it off to hide the mobile app icon on the toolbar. Metablocks Added v4.4.0 Enable Metablocks Enabling this setting results in Metablocks appearing in the Blocks blade. Reports Added v4.3.7 Standard reports give the administrator a view into where (which Applications) and how (which version) Connectors have been used. The information is presented in a grid that can be sorted, filtered, reorganized, and grouped. It can also be exported as an XLSX file. Connector Usage Report This report shows all loaded Connectors, their versions, and how many times each version is used in an Application, if any. This master list shows the administrator which Connectors are installed and their utilization. This assists in identifying new Connectors or versions not yet added. Connector Usage Details Report This report shows the Applications in which a Connector version has been used. Additional information includes the Application's owner and category. This detailed report assists in gauging the impact of upgrading one or more Connector versions. Scripts Embed Script Added in v4.4.17, the supplied html script tag is inserted into every App Designer html page. Use this to load an external JavaScript script, such as to provide localized support or track user usage. For example, the below script embeds a chatbot into App Designer. // example script to embed a fastbot trained on appropriate documentation <script defer src=\"https://app.fastbots.ai/embed.js\" data-bot-id=\"abc\"></script> To improve performance and ensure users always have the latest version of your script: Use version parameters in your script URL to control caching: <script defer src=\"https://example.com/your-script.js?v=1.0.2\"></script> Note Update the version number whenever you modify the script. This ensures: Returning users get the new version immediately Users benefit from browser caching between sessions You control exactly when cache invalidation occurs Consider using content delivery networks (CDNs) for faster loading and improved caching. Use appropriate loading attributes like defer or async to optimize page rendering: defer: Script executes after HTML parsing is complete (recommended for most cases) async: Script executes as soon as it's available, potentially during HTML parsing For guidance on how to use this setting effectively, please contact your XMPro representative. Data Stream Designer Settings Security Encryption Key The encryption key is used to encrypt and decrypt sensitive data configured in the user settings of an Agent when they are stored or retrieved from the database, for example, passwords. Enable Audit Trail Enabling this setting would cause logs to be created whenever changes are made to Agents, Collections, and components of Data Streams. The records will contain details about who made the change and when it was applied. User Interface Enable InputMap Highlights Enables the Canvas arrow highlight which is shown if the arrow's configuration doesn't have mappings. This is useful for demos where the complete configuration has intentionally not been provided. Enable Stream Metrics Enables the logging and display of stream metrics (Stream Load and Stream Errors) in Data Streams. Refresh the page for the setting to be applied to the Data Stream Canvas. Behavior Default Polling Interval (seconds) Added v4.3.7 The default value that is used for the polling interval when a Polling Agent is added to a Streaming type Data Stream. If there is no value provided for this setting, the polling interval defaults to 3600 seconds (1 hour). Note The default is applied when the Agent is added to the canvas. A change to this site setting will only take effect for Agents added afterward. Live View Usage Added v4.3.6 Over time, if users did not close the Live View, these open connections placed an additional load on the Data Stream Designer (DS) as the Stream Hosts continued to send live data back to DS. This reduced overall performance and reliability, and increased infrastructure costs. We recommend that users always close the Live View of a published Data Stream before navigating away. When in doubt, an administrator can force a reset to close all open Live View connections. The Live View Usage includes the following: The number of Stream Objects (Agents) with Live View enabled and the number of Data Streams affected. A button to reset the Live View usage. Resetting the Live View will close any connections that may have been left open if a user closes the Data Stream canvas without first closing the Live View. It will also stop any open Live View blades from receiving data. To start receiving data again, re-open the Live View and reselect the Stream Objects. Refer to the Live View Usage Report for a list of Stream Objects and Data Streams that are preselected for Live View. Note A Stream Object with Live View enabled is an indicator that a user has viewed the data - it is not confirmation whether the user closed the connection. Tip The Live View issue is addressed in the v4.3.7 release: Open connections are closed regardless of how the Live View is closed (e.g. navigating away or closing the tab). All connections are closed when the Data Stream Designer app service is restarted. If you've upgraded to v4.3.7, use the Reset Live View button once to ensure all connections are closed. Reports Added v4.3.7 Standard reports give the administrator a view into where (which Data Stream) and how (which version) Agents have been used. The information is presented in a grid that can be sorted, filtered, reorganized, and grouped. It can also be exported as an XLSX file. Live View Usage Report This report shows all Agents that have Live View enabled. Additional information includes the Data Stream name, Data Stream version, Data Stream owner, the Collection name, the Stream Object name, and whether the Data Stream is published. This report along with the Reset option was useful prior to v4.3.7, to determine where connections may have been left open. Agent Usage Report This report shows all loaded Agents, their versions, their categories, and how many times a version is used in a Data Stream, if any. This master list shows the administrator which Agents are installed and their utilization. This assists in identifying new Agents or versions not yet added. Agent Usage Details Report This report shows Data Streams in which an Agent version has been used. Additional information includes the Data Stream version, its owner, the Collection, and the Stream Object name. This detailed report assists in gauging the impact of upgrading one or more Agent versions. Agent Polling Interval Report This report shows the polling intervals configured on all Agents that have the Polling Interval option. Additional information includes the Agent Name, Agent Category, Data Stream name, Data Stream version, Data Stream owner, the Collection name, the Stream Object name, and whether the Data Stream is published. This master list empowers the administrator to locate those set too short (1s) that may be causing performance issues. 10 seconds may be appropriate during initial testing, but ill-advised in a QA or Production environment. Subscription Manager Settings Security Hide Users Outside Business Role Branch When enabled, users can see the information of users in their business role and any of its parent business roles up to the root. They cannot see any child or sibling business roles and their users. For example, a user cannot tag/search users outside their business role tree path in a comment on a recommendation alert. This defaults to true on new installations. Toggle it off to make all user information visible to all users in the company. Warning The exception for this setting is a user with an Administrator role for the Subscription Manager product. They can assign access to XMPro objects to any user or business role in the company. Global Notification Added v4.4.0 Global Administrators can display a global notification across the top of all products in the XMPro suite for a specific period. This aids in communicating important information to users, such as a notice advising of planned maintenance downtime and a hyperlink to release notes. Choose a type of hint, warning, or error to set the notification icon and banner color. The banner can be dismissed for a session. Discard \"Global Notification\" Settings Clears all Global Notification settings and hides the current message, if any. Type This determines the icon and color of the notification banner. The options are a hint, warning, or error. Message A message of up to 500 characters is displayed in the notification banner. Basic text formatting, lists, and links are supported. Show Now Enabling this setting results in the notification banner being immediately shown across all products, and disables the Show On property. Show On (your local time) The date and time when the notification will be shown to users. It is stored as UTC, but displayed in the administrator's local time zone. This setting is not available when Show Now is enabled. Hide On (your local time) An optional date and time when the notification should no longer be shown to users. It is stored as UTC, but displayed in the administrator's local time zone. Leave blank if you want the message to be shown until it is manually cleared - either by clicking Discard \"Global Notifications\" Settings, clearing the Message or Show option. Support Email The email to which notifications will be sent if a user signs up to XMPro or makes a request, for instance, a request for a Subscription to a Product, or a request for a License. Disable Email Notifications Disables emails sent to the email address above for any reason. If email notifications are disabled then the Global Administrator will need to log in to Subscription Manager to check whether there are any pending requests."
  },
  "src/how-tos/manage-variables.html": {
    "href": "src/how-tos/manage-variables.html",
    "title": "Manage Variables | XMPro",
    "summary": "Manage Variables XMPro Variables are placeholders used to hold and maintain certain values. If you may not know some of the values that you might want to use within an XMPro Object, such as credentials or passwords, you can use Variables where the real value can be substituted later. Note It is recommended that you read the article listed below to improve your understanding of Variables. Variable Adding a new Variable Variables can be added via the Variables page before being used in any of the Data Streams or Applications. Click on the Variables page from the left-hand menu. Click on Add. Enter the details of the new Variable. Choose if the value is encrypted. This determines whether or not the value can be seen by the user. Click on Save and Close. Using Variables Variables can be used in Data Streams or Applications to authenticate users or to access certain data sources. Consider having the following agents in a stream: Azure SQL Listener When the Azure SQL Listener is configured the user needs to enter the server details and password in order to access the available tables and columns. In this case, variables that already store the passwords and credentials can be used in the input fields. For example: Add an SQL Listener from the list of Agents. Click on Configure. Select the Server and user details from the list of variables (ensure that the 'Use Connection Variables' option is selected). 4. Select the correct encrypted password variable for the server. 5. If selected correctly, tables and columns can now be accessed. Removing Variables Single Variable To remove a single variable, follow the steps below: Open the Variables page from the left-hand menu. Select the variable from the list. Click Delete. 4. Confirm that you would like to delete the variable. Multiple Variables To remove multiple variables, follow the steps below: Open the Variables page from the left-hand menu. Click Select. Select the variables from the list. Click Delete. 5. Confirm that you would like to delete the selected variables. Overriding Variables The Variables defined can be overridden by the individual Stream Host to provide the unique configuration e.g. per Asset, site, or OPC IP Address. See How to Override Variables for more information."
  },
  "src/how-tos/manage-versions.html": {
    "href": "src/how-tos/manage-versions.html",
    "title": "Manage Versions | XMPro",
    "summary": "Manage Versions Versions can be managed for different XMPro Objects, including Data Streams, Agents, Applications, and Recommendations. Copying a Version allows you to continue working and making changes to the XMPro Object while maintaining a Version of it before you made changes, which can also act as a backup mechanism. Note It is recommended that you read the article listed below to improve your understanding of Versions. Version Opening a specific Version Any of the major Versions of an XMPro Object can be viewed at any point in time. To open a specific Version, follow the steps below: Click on \"Versions\". Select the Version you would like to view. Click \"Open\". The images below show how to view the Versions of an Application in the App Designer. The Version you are currently editing is displayed as a subtitle below the name. If you viewed a Version that is not the latest version available and the page is closed, it will not be saved. Thus, if re-opened, the latest version will be displayed, even if an older version is running. You may run any of the Versions available, even if they are not the latest Version. If you are making changes, always make sure you are working on the correct version. Copying Versions To copy a Version, select the Version and click on \"Copy\". The new copy will be created, set as the current version, and will have a version number higher than all the other versions. Thus, a major version increase will be done, e.g. if the version you copied is Version 2.35, but the latest version is Version 3.80, the newly copied version will be Version 4.0. Click on \"Versions\". Select the Version you would like to view. Click on Copy to create a new copy of the selected Version and set the copy to the current Version. Deleting Versions To delete a Version, select the version from the list and click \"Delete\". To delete an XMPro Object completely, the XMPro Object must be deleted itself, rather than the Version. Click on \"Versions\". Select the Version you would like to view. Click on Delete."
  },
  "src/how-tos/publish/admin-unpublish-override.html": {
    "href": "src/how-tos/publish/admin-unpublish-override.html",
    "title": "Admin Unpublish Override | XMPro",
    "summary": "Admin Unpublish Override Apps and Data Streams can be published and unpublished in other parts of App Designer and Data Stream Designer In App Designer, you can publish or unpublish an App via the Connectors page. In Data Stream Designer, you can publish or unpublish a Data Stream via the Agents or Collections page. Admins are able to see all Apps or Data Streams, whereas users can only see the Apps or Data Streams to which they have access. This can be useful for Admins if they need to unpublish an App or Data Stream if they do not have access to it. Tip It is recommended that you read the article listed below to improve your understanding of Applications. Application Data Stream How to Publish Publish or Unpublish an App From the Connectors Page To publish or unpublish an App via the Connectors page, follow the steps below: Open the Connectors page from the left-hand menu. Click on a Connector. Select a version of the Connector to view Apps that are using it. Select the App. Select Publish or Unpublish. Tip The number of Apps being used will be displayed for each Connector version. Publish or Unpublish a Data Stream From the Agents page To publish or unpublish an App via the Agents page, follow the steps below: Open the Agents page from the left-hand menu. Click on an Agent. Select a version of the Agent to view Data Streams that are using it. Select the Data Stream. Select Publish or Unpublish. Tip The number of Data Streams being used will be displayed for each Agent version. From the Collections page To publish or unpublish an App via the Collections page, follow the steps below: Open the Collections page from the left-hand menu. Click on a Collection. Click on More. Click on Data Streams. Select the Data Stream. Select Publish or Unpublish."
  },
  "src/how-tos/publish/index.html": {
    "href": "src/how-tos/publish/index.html",
    "title": "Publish | XMPro",
    "summary": "Publish Publishing will finalize the XMPro asset and make it available for all users with Run Access. To configure the run access and who can see the asset once it is published, visit How to Manage Access. Versions of XMPro Objects that are already published cannot be edited or deleted by any user, and must be unpublished before they can be edited. Only one version of an XMPro Object can be published at a time. How to Publish To publish an XMPro asset, follow the steps below: Open the page for the XMPro asset you would like to publish and select the data stream/recommendation/application. Click on Publish. Tip The Publish button will only be available if the version you are currently viewing is not published. If another version is published clicking the button will change the published version to the current version. Data Streams For Data Streams, the publish option can be seen in the top menu. After publishing a Data Stream, the Live View option will become available and Stream Metrics will appear on the canvas. Visit the Use Live View article to read more about displaying data in Live View or visit the Use Stream Metrics article to read more on Stream Metrics. Recommendations For recommendations, click on Recommendations from the left-hand menu. In the top-right corner, click on Manage Recommendations. Select the recommendation you want to publish, then click on Publish. Applications For Applications, click on the applications page from the left-hand menu. Click on the edit button for the application you want to publish to open the edit page for that application. Then, click on publish. How to Unpublish Unpublishing is done in the same location where you publish the asset. Navigate to the same place that you published the asset. Open the page for the XMPro asset you would like to unpublish and select the data stream/recommendation/application. Click on Unpublish. Tip You can unpublish an XMPro Object even if you are currently viewing another version. The Unpublish button will only be available if any version of that XMPro Object is currently published. Clicking the button will unpublish the version that is published."
  },
  "src/how-tos/recommendations/README.html": {
    "href": "src/how-tos/recommendations/README.html",
    "title": "Recommendations | XMPro",
    "summary": "Recommendations Recommendations are created and managed in the App Designer. They allow you to monitor and observe live data and respond to any events through Recommendation Alerts. Note It is recommended that you read the article listed below to improve your understanding of Recommendations. Recommendation Articles Manage Recommendations Create Rules Manage Notifications Manage Notification Templates Subscribe to Notifications Manage Forms Manage Variables Manage Alerts Manage Alerts on Mobile Manage Deleted Recommendation Items"
  },
  "src/how-tos/recommendations/create-rules.html": {
    "href": "src/how-tos/recommendations/create-rules.html",
    "title": "Manage Rules | XMPro",
    "summary": "Manage Rules A Rule is a condition that helps the Recommendation determine whether Recommendation Alerts should be created, and what created Alerts should look like. This is needed for you to create the condition(s) that the Recommendation needs to look for. An example of a Rule is \"If the temperature is greater than 50\". This catches any data that does not stay within the safe parameters. Note It is recommended that you read the articles listed below to improve your understanding of Recommendations. Rule Manage Recommendations Create Rules To create a Rule, follow the steps below: Select the Recommendation in the list that you want to add a Rule to. Click the + button at the top-right of the Rules list. Enter the Rule Name. Enter the Alert Headline and Alert Description. If you wish for the values received from the Data Stream to be added to the Headline or Description of the Alerts this Rule will generate, add a tag with the @ symbol and select the Data Stream output. Select the Rule Factor. (Optional) Select an Optional Factor. Select an Alert Ranking. (Optional) Select an Icon. Sample icons can be found in the Icon Library. (Optional) Choose an Impact Metric. Design the Rule Logic that decides when this Rule should generate a Recommendation Alert based on the data received from the Data Stream (Optional) Enable Form and Choose a Form and Form Version Add an Additional Recommendation Management Column. If you wish for the values entered into the Form to be added to the Additional Information column of the Alerts this Rule will generate, add a tag with the @ symbol and select a Field from the Form. Choose a Resolution value. If you want the Alerts generated to automatically resolve themselves if new data is received that doesn't match the Rule Logic, choose Automatic. Choose a Recurrence value. If you want a new Alert to be generated every time data is received that matches the Rule Logic, choose All Occurrences. Choose a Log Data On value. If you want the Event Data of the Alert to be replaced every time data is received that matches the Rule Logic, choose All Occurrences. (Optional) Enable and enter Triage Instructions to be followed in order to resolve the Alert. (Optional) Enable and add Resources to link in the Alert for help in resolving the Alert. View Timeline To view the timeline for a rule, follow the following steps: Select Recommendation Click More Click Timeline Select Rule Delete Rules To delete existing Rule, follow the steps below: Select the Recommendation in the list that you want to delete a Rule from. Select the Rule. Click the Delete button. Confirm the action. Note Deleting a Rule will not permanently delete it or any Recommendation Alerts generated by it. Deletion can be undone or made permanent from Deleted Items. Further Reading How to Manage Categories How to Manage Notifications"
  },
  "src/how-tos/recommendations/manage-alerts-on-mobile.html": {
    "href": "src/how-tos/recommendations/manage-alerts-on-mobile.html",
    "title": "Manage Alerts on Mobile | XMPro",
    "summary": "Manage Alerts on Mobile Recommendation Alerts are advanced Alerts that get triggered when real-time data meets the criteria defined in a Recommendation Rule. They notify you when certain conditions occur in your data and provide decision support for how to take action. Recommendations create new Recommendation Alerts based on Business Rules, and the Alerts recommend the best next actions based on expert suggestions. Recommendation Alerts monitor the actions taken and outcomes to close the loop on event response. Note It is recommended that you read the article listed below to improve your understanding of Recommendations Alerts. Recommendation Alert Manage Recommendations How to Use the Alert Details Page The Recommendation Alert page provides details of the Alert and allows you to monitor, discuss, and take action. How to Add Notes Type in designated area for Notes. Tap the three dots to open the menu. 3. Tap Save. How to Fill Out a Form Tap the Form tab. Fill out the form fields. Tap the Create Work Request button in the form to save the changes. How to Contribute to a Discussion Tap the Discussion tab. Write your message. Tap the Send button. How to Save, Resolve, and Mark as False Positive Tap the three dots to open the menu. Save - Changes will be saved and Alert Details Page will stay open. Mark as False Positive - Will mark the Alert as False Positive and will close the Alert Details Page. Mark as Resolve - Will resolve the Alert and close the Alert Details Page."
  },
  "src/how-tos/recommendations/manage-alerts.html": {
    "href": "src/how-tos/recommendations/manage-alerts.html",
    "title": "Manage Alerts | XMPro",
    "summary": "Manage Alerts Recommendation Alerts are advanced Alerts that get triggered when real-time data meets the criteria defined in a Recommendation Rule. They notify you when certain conditions occur in your data and provide decision support for how to take action. Recommendations create new Recommendation Alerts based on Business Rules, and the Alerts recommend the best next actions based on expert suggestions. Recommendation Alerts monitor the actions taken and outcomes to close the loop on event response. Note It is recommended that you read the article listed below to improve your understanding of Recommendations Alerts. Recommendation Alert Manage Recommendations Finding Recommendation Alerts The search bar can be used to find any specific Recommendation Alerts that you may be looking for. There is a dropdown option where you can specify to search through everything in App Designer, or only for Recommendation Alerts. How to Use the Recommendation Alerts Grid How to Filter the Grid Open the Recommendation Alerts page. Click the filter icon next to the column that you want to filter on. Tick the desired checkbox. Click OK. The Grid with Alerts will be updated. How to Search the Grid Open the Recommendation Alerts page. Start typing in the search bar. The Grid with Alerts will be automatically updated. How to Resolve Alerts From the Grid Open the Recommendation Alerts page. Tick the checkbox of the Alerts that you want to Resolve. Click the Mark As Resolved button. How to Show Archived Alerts Open the Recommendation Alerts page. Tick the Show Archived checkbox. The Grid with Alerts will be updated with archived Alerts. How to Use the Alert Details Page The Recommendation Alert page provides details of the alert and allows you to monitor, discuss, and take action. How to Add a Notes Type in the designated area for Notes. Click Save. How to Fill Out a Form Click the Form tab. Fill on the form fields. Click the Create Work Request button in the form to save the changes. How to Contribute to a Discussion Click the Discussion tab. Write your message. Click the Send button. How to Share an Alert Click the Share button. 2. Select Users from the dropdown. 3. Add a Note. 4. Click the Share button. How to Save, Resolve, and Mark as False Positive Clicking the Save button - Changes will be saved and Alert Details Page will stay open. Mark as False Positive - Will mark the Alert as False Positive and will close the Alert Details Page. Mark as Resolve - Will resolve the Alert and close the Alert Details Page."
  },
  "src/how-tos/recommendations/manage-categories.html": {
    "href": "src/how-tos/recommendations/manage-categories.html",
    "title": "Manage Categories | XMPro",
    "summary": "Manage Categories Recommendations can be grouped into categories. This refers to the category under which the Recommendation is found in the Recommendations list Create a Category To create a new Category, follow the steps below after navigating to the Recommendation management page: Click Manage Categories. Click the plus sign. Specify the name of the new Category. Specify the Score Factor for the Category. Click Add. Please see images below. View Category Timeline The Category Timeline shows the changes that occur when a category is being edited. Follow the steps below to view the timeline: Select the Category Click Timeline Delete a Category To delete an existing Category, follow the steps below: Select the Category. Click Delete. Click Yes."
  },
  "src/how-tos/recommendations/manage-deleted-recommendation-items.html": {
    "href": "src/how-tos/recommendations/manage-deleted-recommendation-items.html",
    "title": "Manage Deleted Recommendation Items | XMPro",
    "summary": "Manage Deleted Recommendation Items When a Recommendation is deleted, it is moved to the Deleted Items. This is because there may still be archived Recommendation Alerts created by that Recommendation that you don't want to delete. Once Recommendations are moved to Deleted Items, they can be restored. This ensures nothing is deleted by mistake and allows you to retrieve deleted Recommendations again in the future if you realize they are still needed. Note It is recommended that you read the article listed below to improve your understanding of deleting Recommendations. Deleted Items Manage Recommendations Restore Deleted Recommendation Items To restore deleted Recommendations, follow the steps below: Hover over More. Click the Deleted Items button. Tick the checkbox for the desired Recommendations, Recommendation Versions, or Rules. Click the Restore Button. 5. Confirm the action. Permanent Deletion of Recommendations Warning Recommendation Alerts will also be permanently deleted when permanently deleting items. To permanently delete a Recommendations, follow the steps below: 1. Hover over More. 2. Click the Deleted Items button. 3. Tick the checkbox for the desired Recommendations. 4. Click the Delete Button. 5. Confirm the action."
  },
  "src/how-tos/recommendations/manage-forms.html": {
    "href": "src/how-tos/recommendations/manage-forms.html",
    "title": "Manage Forms | XMPro",
    "summary": "Manage Forms A Form is a collection of fields that appear on Recommendation Alerts. Forms can be created and customized to suit the situation, depending on the Recommendation Alert. Forms are useful if you want relevant information, data, comments, or notes to be entered and changed over the course of resolving an Alert and while it is being actioned. Note It is recommended that you read the articles listed below to improve your understanding of Recommendations. Form Manage Recommendations Creating a Form To create a Form, follow the steps below: Open the Recommendations page from the left-hand menu. Click on Forms. Click on New. Enter new Form details. Click on Save. Drag the appropriate blocks onto the canvas to create the Form's labels and input fields. Highlight the block. Click on Field Properties. Change details for the block such as the label. Continue adding blocks until the Form is complete. Click on Save. Highlighting any of the blocks also gives you the option to delete the block. Blocks can also be reordered. Using the Form with a Recommendation To get the Form to appear on Recommendation Alerts, add the Form to the applicable rule that will trigger the alert. Open the Recommendations page from the left-hand menu. Select the Recommendation. Select the Rule. Enable the Form. Select which Form should show with the Recommendation Alert. Select the version of the Form. Click on Save. Deleting the Form To delete the Form, follow the steps below: Open the Recommendations page from the left-hand menu. Click on Forms. Click on the Form you want to delete. Click on Settings. Click on Delete. Actions on the Form Additional actions on the Form include: Managing versions for the Form Manage who has access to the Form Import, Export, or Clone a Form"
  },
  "src/how-tos/recommendations/manage-notification-templates.html": {
    "href": "src/how-tos/recommendations/manage-notification-templates.html",
    "title": "Manage Notification Templates | XMPro",
    "summary": "Manage Notification Templates When a Recommendation Alert is triggered by a critical event, the user can receive a notification via text message or email. The notification contains a message that notifies the user of the Recommendation Alert. You can choose to create a custom message template for when a notification is triggered, or use a default template provided. Note It is recommended that you read the articles listed below to improve your understanding of Recommendations: Notification Manage Notifications Add a Recommendation Notification Template To change what message template is used when users are notified to a Recommendation Alert, follow the steps below: Click on Manage Recommendations. 2. Click on a Recommendation. 3. Select a Rule. 4. Scroll down and select a Notification. 5. Select a Notification channel (Email or SMS). 6. Click on Edit Templates. 7. Choose from the list of notification templates. 8. Choose between Default or Custom. 9. Press Save. Add Custom HTML Templates for Email By default, each notification template is set to 'default'. You can add a custom email template instead that includes different styling. The HTML file can also include placeholders for certain data that you would like to show on the notification. Here is an example of an HTML Template file: Download Recommendation Notification Template To upload a custom email template, follow the steps below: 1. Click on Edit Templates on any selected notification. 2. Choose from the list of notification templates for Email. 3. Choose Custom. 4. Upload an HTML template file. 5. If you have any custom placeholders, select the values that will be in those fields. 6. Press Save. Note Add capitalized placeholders for data within the HTML file between curly bracket symbols. For example, {{ALERTID}}. Note This list of predefined placeholders can be used in the template without mapping: ALERTID HREF TITLE DESCRIPTION NOTE PENDINGTIME RULENAME RECNAME (Recommendation Name) Click the link to see a preview of the email. Custom Templates for SMS By default, each notification template is set to 'default'. To use a custom SMS template instead, follow the steps below: 1. Click on Edit Templates on any selected notification. 2. Choose from the list of notification templates for SMS. 3. Choose Custom. 4. Enter a custom notification message. 5. Press Save. Note Use the '@' symbol to choose tags from your Data Stream. Examples Default Template Example If ‘Default’ is selected, a default notification message will be sent to your email address or mobile. This is an example of an email notification using a Default Template: Custom Template Example This is an example of an email notification using a Custom Template:"
  },
  "src/how-tos/recommendations/manage-notifications.html": {
    "href": "src/how-tos/recommendations/manage-notifications.html",
    "title": "Manage Notifications | XMPro",
    "summary": "Manage Notifications A Notification defines how users will be notified when a Recommendation Alert is triggered by a critical event that meets the conditions set in a Rule. This is useful when you want to send a text, email, or another form of communication to users when something goes wrong and is caught by the Rule's condition. Note It is recommended that you read the articles listed below to improve your understanding of Recommendations. Notification Manage Rules Creating Notifications To create a Notification, follow the steps below: Open existing or Create a new Rule. Click the + button at the top-right of the Notifications list. Enter Notification Name. Select the desired Triggers. Select the Channels for the Notification. Save. Clone Notifications To clone an existing Notification, follow the steps below: Open existing Rule. Select the desired Notification. Click the Clone button. Enter Notification name. Confirm the action. Delete Notifications To delete an existing Notification, follow the steps below: Open existing Rule. Select the desired Notification. Click the Delete button. Confirm the action."
  },
  "src/how-tos/recommendations/manage-recommendations.html": {
    "href": "src/how-tos/recommendations/manage-recommendations.html",
    "title": "Manage Recommendations | XMPro",
    "summary": "Manage Recommendations If a Run Recommendation Agent is added to a Data Stream, the Recommendation will read the live data in real-time and compare it to the conditions and Rules configured. If any data falls into a Rule's condition then a Recommendation Alert is created. A Recommendation Alert notifies specific users of pending issues or dangers associated with the data and allows them to act upon them. Note It is recommended that you read the article listed below to improve your understanding of Recommendations. Recommendation Manage Recommendations To access the Recommendation management page, follow the steps below: In the App Designer, click the Recommendations button in the left-hand menu. Click the Manage Recommendations button. Note If you do not have the right to view Recommendation Alerts, the Recommendation Alerts grid will not be shown and the second step can be skipped. Create a Recommendation To create a new Recommendation, follow the steps below after navigating to the Recommendation management page: Click New. Specify a name for your new Recommendation. Select or create a new Category. a. Click the Plus button. b. Specify the Name. c. Specify the Score Factor for Category c. Click Save. Specify the Score Factor for the Recommendation Choose a Data Stream to receive data from Click Save Note A Recommendation needs Rules. See the Manage Rules article to find out how to create a Rule. View Recommendation Timeline The Timeline shows the changes that occur when details in the recommendation is being edited. Follow the steps below to view the timeline: Select Recommendation Click More Click Timeline Delete a Recommendation To delete an existing Recommendation, follow the steps below: Select the Recommendation. Hover over More. Click the Delete button. Confirm the action. Note Deleting a Recommendation will not permanently delete it or any Recommendation Alerts generated by it. Deletion can be undone or made permanent from Deleted Items. Further Reading How to Manage Rules How to Manage Categories How to Subscribe to Notifications How to Manage Forms How to Manage Variables How to Manage Alerts How to Manage Alerts on Mobile How to Manage Deleted Recommendation Items"
  },
  "src/how-tos/recommendations/manage-variables.html": {
    "href": "src/how-tos/recommendations/manage-variables.html",
    "title": "Manage Variables | XMPro",
    "summary": "Manage Variables Variables are placeholders used to hold and maintain certain values. In some cases, it is possible to not know some of the values that you might want to compare within rules or conditions. In this case, you can use Variables where the real value can be substituted in later. Expressions can also be configured and are useful for doing certain calculations and returning results which can also be used within Recommendation Rules. Note It is recommended that you read the articles listed below to improve your understanding of Recommendations. Recommendations Manage Recommendations Create Variables To create a Variable, follow the steps below: Select the Recommendation in the list that you want to add a Variable to. Click the plus button at the top-right of the Variables list. Enter the Variable Name. Select the Type from the dropdown. The Expression Editor is where an Expression is built. At the top is a text area in which you can type the Expression. Below the text area are three sections - the categories, the Expression terms, and the description areas. Clicking on a category will show different items in the Expression terms area, and clicking on an Expression term will show a description of the term in the description area.‌ Double-clicking an Expression Term will enter that term in the text area at the position of the cursor. Delete Variables To delete a Variable, follow the steps below: Select the Recommendation in the list where you want to delete a Variable. Select the desired Variable. Click the Delete button. Confirm the action."
  },
  "src/how-tos/recommendations/subscribe-to-notifications.html": {
    "href": "src/how-tos/recommendations/subscribe-to-notifications.html",
    "title": "Subscribe to Notifications | XMPro",
    "summary": "Subscribe to Notifications Subscribing to Notifications allows you to receive email or SMS messages for Recommendation Alerts that are relevant to you or your organization. This is useful if you want to keep track of certain Recommendations. Note It is recommended that you read the article listed below to improve your understanding of Notifications. Notification Editing Permissions on the Run Access Manage Recommendations Subscribe to a Notification To subscribe to a Notification, follow the steps below: Hover over your user profile in the top-right of the page in App Designer, and click \"Notification Settings\". Tick the checkbox to subscribe to that Notification. Click the Save button."
  },
  "src/how-tos/stream-host.html": {
    "href": "src/how-tos/stream-host.html",
    "title": "Stream Host | XMPro",
    "summary": "Stream Host A Stream Host is an application that can either be installed as a Docker container, a Windows Service, or a Console Application. Stream Hosts enable Data Streams to run and execute actions and are also responsible for getting the configurations of Non-Virtual Agents. Note It is recommended that you read the article listed below to improve your understanding of Stream Host. Stream Host How to Deploy a Stream Host The recommended Stream Host deployment is as a Docker container - see the Docker instructions. For installation instructions, see Deploy Stream Host. Logs How to Check Logs To check the logs for a Steam Host, follow the steps below: Open the Collection page. Select the Collection. Click the Stream Hosts button. Select the desired Stream Host. How to Set the Log Level You can change the Log level to either Info or Trace. To change the Log Level, follow the steps below: Open the Collection page. Select the Collection. Click the Stream Hosts button. Select the desired Stream Host. Note See the Collection and Stream Hosts article for more information on the Log Level. 5. Click on Set Log level. 6. From the dropdown, select either Info or Trace. 7. Click on OK. How to Filter Log Levels You can filter and narrow down the errors and messages that have already been logged in the table. For example, if you filter for Info errors, only info level errors will be displayed. To filter the log level for a Steam Host, follow the steps below: Open the Collection page. Select the Collection. Click the Stream Hosts button. Select the desired Stream Host. 5. Click the icon next to the Level column. 6. Select the Log Level. 7. Click OK. How to Clean the Logs To clean the logs for a Steam Host, follow the steps below: Open the Collection page. Select the Collection. Click the Stream Hosts button. Select the desired Stream Host. 5. Click the Delete Logs button. 6. Confirm your action. How to Export Logs To export the logs for a Steam Host, follow the steps below: Open the Collection page. Select the Collection. Click the Stream Hosts button. Select the desired Stream Host. Click the \"three dots\" button. Click Export all data or Export Selected rows. How to Find Online Hosts To find online Stream Hosts, follow the steps below: Open the Collection page. Select the Collection. Click the Stream Hosts button. How to Override Variables Although each Stream Host in a given Collection downloads the same definition of a Data Stream, the Variables defined in Data Stream Designer can be overridden by the individual Stream Host to provide the unique configuration e.g. per Asset, site, or OPC IP Address. The options to override variables for a Stream Host are: Using Environment Variables - enables the scalable and efficient creation of multiple Docker Stream Hosts through scripting. Using Variables.xv files - requires manual edits for each Stream Host. In practice you'd use one or the other, but it may be helpful that the Stream Host The Stream Host retrieves variable values in the following order: Environment Variable, if no match then... Variables.xv File, if no match then... Variables (i.e. as detailed in Using a Variable) Using Environment Variables v4.4.2 This option can be applied to any Stream Host install scenario, although it is better suited for when running Stream Host on Docker. Create an environment variable that is applied to a running Stream Host instance, prefixing the name of the variable that should be overridden with xmvariable__ xmvariable__NameOfVariable1=foo xmvariable__NameOfVariable2=bar xmvariable__NameOfVariable3=noop Using Variables.xv files Note This option is not supported when running Stream Host on Docker. Open the Collection page. Select the Collection. Hover on More. Click Variables. Click Select file and upload the encrypted variables.xv file, found in the Data folder of the Stream Host's installation directory e.g. \"C:\\Program Files\\XMPro Stream Host\\Data\". You can enter overrides for any Variables. Click Download to get the updated file. Replace the original file in your Stream Host folder with the new one. Restart your Stream Host to load the updated variables."
  },
  "src/installation/complete-installation/index.html": {
    "href": "src/installation/complete-installation/index.html",
    "title": "Post-deployment | XMPro",
    "summary": "Post-deployment After deploying the XMPro Platform, several additional steps are required to complete the installation and optimize your environment. This section covers the post-deployment configuration and setup tasks. Configuration Steps The following steps complete your XMPro installation: Set Up a Tenant Company - Create and configure your first tenant company Deploy Additional Stream Hosts - Add more Stream Hosts to scale data processing (optional) Uploading Connectors and Agents A critical part of the installation process is uploading the connectors and agents that enable XMPro to integrate with various data sources and systems. Upload Agents & Connectors - Upload and configure the necessary agents and connectors for your environment Follow the guides in this section to complete your XMPro installation and prepare your environment for use."
  },
  "src/installation/complete-installation/install-connectors.html": {
    "href": "src/installation/complete-installation/install-connectors.html",
    "title": "Upload Agents and Connectors | XMPro",
    "summary": "Upload Agents and Connectors After you have installed App Designer and Data Stream Designer and set up a new Company, you will want to add Connectors and Agents to the Company. This article will show you step-by-step how to upload the default set of Connectors and Agents. Data Stream Designer - Agents Log into XMPro as a Company Administrator and navigate to the Data Stream Designer Click the Agents button in the menu on the left to open the Agents page Click the Add button Download the files from each of the following links: Tier 5 - Agents (1 of 2) Tier 5 - Agents (2 of 2) Tier 6 - XMPro Internal Click Select file and upload the Tier 5 - Agents (1 of 2).zip file found in the link above Click Save Click Discard and repeat the above steps for the other 2 files App Designer - Connectors Navigate to the App Designer Click the Connectors button in the menu on the left to open the Connectors page Click the Add button Download the file from the following link: Connectors Click Select file and upload the zip file found in the link above Click Save"
  },
  "src/installation/complete-installation/install-stream-host/azure-terraform.html": {
    "href": "src/installation/complete-installation/install-stream-host/azure-terraform.html",
    "title": "Stream Host Azure Terraform | XMPro",
    "summary": "Stream Host Azure Terraform Introduction This guide covers deploying XMPro Stream Host using the Azure Terraform module. You can deploy Stream Host either as part of the full XMPro platform or as a standalone container that connects to an existing Data Stream Designer instance. Prerequisites Ensure you have completed the Azure Terraform prerequisites, which cover: Terraform installation Azure CLI setup and authentication Azure subscription requirements For Standalone Deployment An existing XMPro Data Stream Designer instance Collection ID and Secret from your DS instance Sizing Recommendations The Terraform module allows you to configure Stream Host resources based on your workload: Workload Type CPU Cores Memory (GB) Use Case Small (Default) 1 4 Light data processing, few agents Medium 2 8 Moderate workloads, multiple agents Large 4 16 Heavy processing, complex transformations Configuration Limits: CPU: 0.25 to 4 cores Memory: 0.5 to 16 GB Tip Start with the default configuration (1 CPU, 4 GB RAM) and scale up based on monitoring metrics. Deployment Options Option 1: With Full XMPro Platform When deploying the complete XMPro platform, Stream Host is automatically included. See the basic example in the terraform-xmpro-azure repository. Option 2: Standalone Stream Host To deploy only Stream Host to connect to an existing DS instance, use the dedicated Stream Host example from the terraform-xmpro-azure repository. The example includes: Complete Terraform configuration files Variable definitions with defaults Step-by-step deployment instructions Troubleshooting guide Quick Start Clone the repository git clone https://github.com/XMPro/terraform-xmpro-azure.git cd terraform-xmpro-azure/examples/stream-host Configure your deployment # Copy the example variables file # Linux/Mac: cp terraform.tfvars.example terraform.tfvars # Windows: copy terraform.tfvars.example terraform.tfvars # Edit with your specific values nano terraform.tfvars # Linux/Mac notepad terraform.tfvars # Windows Deploy terraform init terraform plan terraform apply For detailed configuration options and examples, refer to the Stream Host example README. Getting Collection Credentials For standalone deployments, you need collection credentials from Data Stream Designer: Open your XMPro Data Stream Designer Navigate to Collections Select or create a collection for the Stream Host Go to Settings tab Copy the Collection ID and Collection Secret Key Configuration Variables The Stream Host module supports various configuration options. Here are the most important ones: Resource Allocation stream_host_cpu: CPU cores (0.25 to 4) stream_host_memory: Memory in GB (0.5 to 16) Docker Image Variants stream_host_variant: Choose the Docker image variant (default: \"\" which is the same as \"bookworm-slim\", other options: \"bookworm-slim-python3.12\", \"alpine3.21\") Environment Variables SH_PIP_MODULES: Python packages to install (only available with bookworm-slim-python3.12 variant) ADDITIONAL_INSTALLS: System packages to install (works with all variants - APT for Debian, APK for Alpine) Custom variables: Any additional environment variables (works with all variants) For a complete list of variables and configuration options, see the module documentation. Common Configuration Examples Python Package Installation Install Python packages for data processing: # In your terraform.tfvars # First, specify the Python variant stream_host_variant = \"bookworm-slim-python3.12\" # Then configure pip packages (only works with Python variant) environment_variables = { \"SH_PIP_MODULES\" = \"pandas numpy scikit-learn\" } System Dependencies Install additional system packages: # In your terraform.tfvars # Use Python variant if you need both Python and system packages stream_host_variant = \"bookworm-slim-python3.12\" environment_variables = { \"ADDITIONAL_INSTALLS\" = \"git build-essential python3-dev\" # Works with all variants \"SH_PIP_MODULES\" = \"pandas numpy scikit-learn tensorflow\" # Only works with Python variant } Important The SH_PIP_MODULES and PIP_REQUIREMENTS_PATH environment variables only work with the bookworm-slim-python3.12 variant. The ADDITIONAL_INSTALLS variable works with all variants (APT for Debian variants, APK for Alpine). See Docker Variants documentation for details. Resource Scaling Adjust resources based on your workload requirements: # In your terraform.tfvars # Medium workload stream_host_cpu = 2 stream_host_memory = 8 # Large workload stream_host_cpu = 4 stream_host_memory = 16 For more advanced configurations including: Volume mounts Monitoring integration Multiple Stream Host deployments Custom networking See the comprehensive examples in the terraform-xmpro-azure repository. Troubleshooting Stream Host Not Connecting If the Stream Host doesn't appear in Data Stream Designer: Check container logs az container logs --resource-group <rg-name> --name <container-name> Verify environment variables az container show --resource-group <rg-name> --name <container-name> --query \"containers[0].environmentVariables\" Check network connectivity Ensure DS server URL is accessible Verify no firewall blocking outbound connections Other Common Issues For comprehensive troubleshooting including: Python package installation failures (ensure you're using bookworm-slim-python3.12 variant) Resource allocation problems Network connectivity issues Container restart loops Refer to the troubleshooting section in the Stream Host example. Best Practices Start Simple Use the example configuration as a starting point Test with minimal configuration first Add complexity incrementally Version Control Store your Terraform configurations in version control Use .gitignore for sensitive files Tag deployments for easy rollback Security Never commit credentials to version control Use Azure Key Vault for secrets Enable managed identities where possible Monitoring Always configure Application Insights Set up alerts for critical metrics Review logs regularly Complete Example Repository All the code examples, configuration files, and detailed documentation for Stream Host deployment are available in the terraform-xmpro-azure repository: Stream Host Example - Complete standalone deployment Basic Platform Example - Full platform with Stream Host Module Documentation - Detailed variable reference Related Documentation Stream Host Docker Installation - For standalone Docker deployments Collection and Stream Host Concepts - Understanding Stream Host architecture Azure Terraform Deployment Guide - Complete platform deployment guide Next Steps After deployment: Access Data Stream Designer to verify Stream Host connection Create your first data stream Configure agents and connectors Monitor performance and adjust resources as needed"
  },
  "src/installation/complete-installation/install-stream-host/docker.html": {
    "href": "src/installation/complete-installation/install-stream-host/docker.html",
    "title": "Stream Host Docker | XMPro",
    "summary": "Stream Host Docker Introduction This guide covers the XMPro Stream Host Docker image available from version 4.4.19 onwards. The latest Stream Host images have been redesigned for improved security and usability. Prerequisites Software Requirements A container runtime such as Docker Desktop. Hardware Requirements Component Small Medium Large Stream Host 1 CPU, 4 GB RAM 2 CPU, 8GB RAM 4 CPU, 16GB RAM Note Actual resource requirements depend on your specific data streams. Monitor performance and adjust resources accordingly. Configuration Essential Environment Variables Key Required Description xm__xmpro__Gateway__Id Optional Unique GUID identifier for this Stream Host instance. Default: A new GUID xm__xmpro__Gateway__Name Optional Display name in Data Stream Designer. Default: \"[Image-Version]-[Gateway Id]\", e.g. \"alpine3.21-python3.12-3bd462d4-4f1f-4cda-b6c5-d02f986beb6f\" xm__xmpro__Gateway__CollectionId Required ID of your Collection (available in Data Stream Designer) xm__xmpro__Gateway__Secret Required Secret key of your Collection (available in Data Stream Designer) xm__xmpro__Gateway__ServerUrl Required The server URL for where Data Stream Designer is hosted. E.g. \"https://dsserver/datastreamdesigner/\". Please note that this URL needs to end in a forward slash. xm__xmpro__Gateway__Rank Optional An integer, by default is \"0\". See Stream Host Rank for further details. These settings can be found in Data Stream Designer: Docker Repository Below is the XMPro Docker Stream Host repository. {{ACR_URL}}/stream-host Image Variants Version Tagging All images are tagged with their version number. For example: {{ACR_URL}}/stream-host:{{VERSION}} The latest tag points to the most recent release: {{ACR_URL}}/stream-host:latest Warning Using the latest tag caches the image locally. For guaranteed latest version, specify the exact version number or re-pull the image. Available Variants A Stream Host running a Data Stream must provide the capabilities to run each Agents in the Data Stream. Choose your image depending on the capabilities that are required. Image Name Description {{ACR_URL}}/stream-host:{{VERSION}}-bookworm-slim Debian (Default) {{ACR_URL}}/stream-host:{{VERSION}}-bookworm-slim-python3.12 Debian with Python {{ACR_URL}}/stream-host:{{VERSION}}-alpine3.21 Alpine Choosing the Right Image Alpine-based images offer a smaller footprint, ideal for environments where size matters Debian-based images (Bookworm Slim) provide more comprehensive tools and libraries for general use Python-enabled images come with Python pre-installed for running Python-based Agents and Connectors Python Package Installation For Python-enabled images, you can install packages using: Either a requirements.txt file, pandas==2.1.4 numpy==1.26.3 Or the SH_PIP_MODULES environment variable: SH_PIP_MODULES = pandas==2.1.4 numpy==1.26.3 Requirements.txt Location Specify the location of your requirements.txt file using the PIP_REQUIREMENTS_PATH environment variable: # Powershell and Bash Terminal -v \"<path_to_your_solution>:/opt/\" -e PIP_REQUIREMENTS_PATH=\"/opt\" # Docker compose - PIP_REQUIREMENTS_PATH=/opt volumes: - \"<path_to_your_solution>:/opt/\" Note If not specified, the system will look for requirements.txt in the default path /app. Installing System Dependencies To install additional system packages (APK/APT), you can install it using environment variables: ADDITIONAL_INSTALLS=git Deployment Docker Replace <values> with your actual configuration settings. PowerShell docker run ` --name stream-host ` --restart on-failure ` -e \"XM__XMPRO__GATEWAY__COLLECTIONID=<Collection ID>\" ` -e \"XM__XMPRO__GATEWAY__SECRET=<Collection Secret>\" ` -e \"XM__XMPRO__GATEWAY__SERVERURL=<Server URL>\" ` {{ACR_URL}}/stream-host:latest With optional environment variables: docker run ` --name stream-host ` --restart on-failure ` --pull always ` -e \"XM__XMPRO__GATEWAY__COLLECTIONID=<Collection ID>\" ` -e \"XM__XMPRO__GATEWAY__SECRET=<Collection Secret>\" ` -e \"XM__XMPRO__GATEWAY__SERVERURL=<Server URL>\" ` -e \"XM__XMPRO__GATEWAY__ID=<Stream Host Id>\" ` -e \"XM__XMPRO__GATEWAY__NAME=<Stream Host Name>\" ` -e \"XM__XMPRO__GATEWAY__RANK=<Stream Host Rank>\" ` -e \"SH_PIP_MODULES=pandas scikit-learn numpy\" ` -v \"<path_to_your_solution>:/opt/\" ` -e \"PIP_REQUIREMENTS_PATH=/opt\" ` -e \"ADDITIONAL_INSTALLS=git\" ` {{ACR_URL}}/stream-host:latest Note Remove optional variables that are NOT needed. Bash/Terminal docker run \\ --name stream-host \\ --restart on-failure \\ -e \"XM__XMPRO__GATEWAY__COLLECTIONID=<Collection ID>\" \\ -e \"XM__XMPRO__GATEWAY__SECRET=<Collection Secret>\" \\ -e \"XM__XMPRO__GATEWAY__SERVERURL=<Server URL>\" \\ {{ACR_URL}}/stream-host:latest With optional environment variables MSYS_NO_PATHCONV=1 docker run \\ --name stream-host \\ --restart on-failure \\ --pull always \\ -e \"XM__XMPRO__GATEWAY__COLLECTIONID=<Collection ID>\" \\ -e \"XM__XMPRO__GATEWAY__SECRET=<Collection Secret>\" \\ -e \"XM__XMPRO__GATEWAY__SERVERURL=<Server URL>\" \\ -e \"XM__XMPRO__GATEWAY__ID=<Stream Host Id>\" \\ -e \"XM__XMPRO__GATEWAY__NAME=<Stream Host Name>\" \\ -e \"XM__XMPRO__GATEWAY__RANK=<Stream Host Rank>\" \\ -e \"SH_PIP_MODULES=pandas scikit-learn numpy\" \\ -v \"<path_to_your_solution>:/opt/\" \\ -e \"PIP_REQUIREMENTS_PATH=/opt\" \\ -e \"ADDITIONAL_INSTALLS=git\" \\ {{ACR_URL}}/stream-host:latest Note Remove optional variables that are NOT needed. Docker Compose Create a compose.yaml file in your working directory: services: stream-host: image: {{ACR_URL}}/stream-host:latest pull_policy: always container_name: 'stream-host' environment: - XM__XMPRO__GATEWAY__COLLECTIONID=<Collection ID> - XM__XMPRO__GATEWAY__SECRET=<Collection Secret> - XM__XMPRO__GATEWAY__SERVERURL=<Server URL> restart: on-failure With optional environment variables services: stream-host: image: {{ACR_URL}}/stream-host:latest pull_policy: always container_name: 'stream-host' environment: - XM__XMPRO__GATEWAY__COLLECTIONID=<Collection ID> - XM__XMPRO__GATEWAY__SECRET=<Collection Secret> - XM__XMPRO__GATEWAY__SERVERURL=<Server URL> # Optional: Uncomment if needed # - XM__XMPRO__GATEWAY__ID=<Stream Host Id> # - XM__XMPRO__GATEWAY__NAME=<Stream Host Name> # - XM__XMPRO__GATEWAY__RANK=<Stream Host Rank> # - SH_PIP_MODULES=pandas scikit-learn numpy # - PIP_REQUIREMENTS_PATH=/opt # - ADDITIONAL_INSTALLS=git # volumes: # - \"<path_to_your_solution>:/opt/\" restart: on-failure Replace <values> with your actual configuration settings. Managing Your Docker Compose Container Start the Stream Host: docker-compose up -d stream-host Stop the Stream Host: docker-compose down Note For more information on Docker Compose, see the Docker Compose Overview. Your Stream Host installation is now complete."
  },
  "src/installation/complete-installation/install-stream-host/index.html": {
    "href": "src/installation/complete-installation/install-stream-host/index.html",
    "title": "Deploy Stream Host | XMPro",
    "summary": "Deploy Stream Host Note Want to run Stream Host in Docker? Please jump to \"Docker instructions for Stream Host\". Deploying XMPro with Azure Terraform? Stream Host is automatically included in the deployment. To add more Stream Hosts to your Azure environment, see \"Azure Terraform Stream Host configuration\". Download the Connection Profile Each Data Stream created in Data Stream Designer must belong to a Collection. You can download the information in a Collection as a file, known as a Connection Profile. This profile includes the device name, collection ID, server URL, secret, and key. To simplify installing a Stream Host (also called a device), download the Connection Profile to avoid manually copying Collection details from Data Stream Designer to the installer. To obtain a Connection Profile, follow the steps below. Log into Data Stream Designer and open the Collections page from the left-hand menu. Select the Collection you wish to use. If there isn't a Collection available, you can create one by clicking the New button, choosing a name for the collection, and clicking Ok. Click on Connection Profile. Choose a name for the device. Enter the File Key. Click Ok. The Connection Profile will automatically begin to download. Download the Installer Follow the steps below to download the XMPro Stream Host installer. From v4.4.7 onwards, ensure your network policy allows access to the download.app.xmpro.com domain. Log into Data Stream Designer and open the Collections page from the left-hand menu. Select the collection you wish to use. Click on Download Host. Select your desired platform. Click on the Download button to begin the download. Choose your Platform Choose the platform where you will install the Stream Host: Windows (x64) Docker Azure Terraform Troubleshooting If your Stream Host is not appearing in a Data Stream Collection, follow these steps to troubleshoot: Check the Stream Host logs: By default, the Stream Host writes logs to STDOUT on the platform where it's running. Review these logs for details on why your Stream Host is unable to connect. Configure additional logging: For more detailed information, you can configure additional logging for the Stream Host. Verify Stream Host settings: Ensure the Stream Host is properly configured with the correct endpoint and credentials. Check system requirements: Confirm that your system meets the minimum requirements for running the Stream Host. Ensure accurate date and time settings: Verify that the date and time on the Stream Host platform are exactly synchronized with the XMPro server time. Even a one-minute discrepancy can cause authorization issues and prevent the Stream Host from connecting. Common issues to look for: Network connectivity problems Incorrect configuration settings Authentication issues Time synchronization errors If issues persist: If you're still experiencing problems after checking these points, contact XMPro support for further assistance."
  },
  "src/installation/complete-installation/install-stream-host/windows-x64.html": {
    "href": "src/installation/complete-installation/install-stream-host/windows-x64.html",
    "title": "Windows x64 | XMPro",
    "summary": "Windows x64 Prerequisites Downloads Follow the instructions in the Deploy Stream Host guide to download the connection profile and installer. Hardware and Software XMPro Stream Host requires certain hardware and software specifications in order to install and run. Complete these steps in the 1. Preparation guide: Meet the hardware requirements Install the software requirements Initial Steps Run the executable installer file that you've downloaded as administrator When the installation wizard opens, click Next Read and accept the license agreement by ticking the check box at the bottom and click Next Click the Change button to choose the location for the Stream Host to be installed Browse to the directory you would like to use, or use the default, and click Next Host Type Selection Select the host type and click Next Note Console Application is recommended for testing purposes. It will be listed in the Start menu under the name \"XMPro Stream Host\" and must be manually run as administrator from the Start menu. Note Windows Service is recommended for production environments. It will automatically start after installation completes and the name of the service will be the same as the \"Device Name\" you specified when you downloaded the Connection Profile file or manually added the name to the installer. Connection Profile Select your preferred setup mode and click Next Upload a Collection Profile Follow these steps if you selected Connection Profile: Click Browse and select the Connection Profile file you downloaded earlier in the guide In the File Key textbox enter the key used to create the Connection Profile Click Next and let the wizard install the Stream Host Note If you selected Manual, see the section below for instructions on how to set it up. Manual Settings If you decide to manually set up the connection settings for the Stream Host, you can find the values you need by following the steps below. Choose a name for the device Log into Data Stream Designer and open the Collections page from the left-hand menu Select the Collection you wish to use Copy the ID of the Collection from Data Stream Designer to your clipboard by clicking on the copy button and paste it into the Collection ID field in the installer Copy the Key of the Collection from Data Stream Designer to your clipboard by clicking on the copy button and paste it into the Collection Secret field in the installer Add the Server URL for Data Stream Designer in the installer, for example, \"http://localhost/DataStreams\" Add an encryption key that can be used in the Encryption Key field in the installer Click Next and let the wizard install the Stream Host Your Stream Host installation is now complete."
  },
  "src/installation/complete-installation/set-up-a-tenant-company.html": {
    "href": "src/installation/complete-installation/set-up-a-tenant-company.html",
    "title": "Set up your First Tenant | XMPro",
    "summary": "Set up your First Tenant Create Base Company Create a company subscription Browse to the XMPro Subscription Manager website and click on Sign up for an account. Complete the form, checking the Create new company checkbox, and press Agree Browse to the XMPro Subscription Manager website Log in using the XMPro credentials (admin@xmpro.onxmpro.com) Note The username and password displayed on the final step of the Subscription Manager deployment. Open the Companies page from the left-hand menu Click the Company you have just requested to be added (in this example, \"Company\") Click the Subscription Requests button in the command bar, click the request and click Save Note The requested Company has been approved and subscribed to XMPro Subscription Manager. The user you applied with above can now log in. Press Ok Request a license Next we add subscriptions for Data Stream Designer and App Designer to the new Company: Click the Subscriptions gauge in the Company to open the Company's Subscriptions Click the Add button in the command bar to add a new Subscription Select the Data Stream Designer product Note The exact name will depend on your installation, in this example, it is \"DataStreams\". Click Request a new License Note This sends a request to XMPro for a Data Stream Designer license for this Company. Change the Product to App Designer and request another license Note Licenses are given on an individual basis by the XMPro support team. When you have received a license for each product through an email sent to the email address used to create this account, return to this page. Upload the license Select the Data Stream Designer product, upload its corresponding license and click Save Click Add on the Subscriptions page and repeat the steps above for the App Designer product Add the user Now we will add the user to each subscription: Click the Data Stream Designer product and click the Add button Select the user, role, any permissions the user should have in the product and click Save Repeat the above steps for the App Designer."
  },
  "src/installation/deployment/azure-terraform/advanced-configuration.html": {
    "href": "src/installation/deployment/azure-terraform/advanced-configuration.html",
    "title": "Advanced Configuration | XMPro",
    "summary": "Advanced Configuration This page covers optional features that are automatically configured in your XMPro deployment. Most users don't need to change these settings. Health Monitoring (Automatically Configured) Health monitoring is automatically enabled for all XMPro services. No configuration needed! What's Included ✅ Real-time health checks - Services monitor each other automatically ✅ Health dashboard - Visual status at /health-ui on App Designer and Data Stream Designer ✅ Application Insights - Full monitoring and alerting in Azure Portal Viewing Health Status Option 1: Health Dashboard (Recommended) Access the built-in health dashboard UI: App Designer: https://ad-yourcompany.azurewebsites.net/health-ui Data Stream Designer: https://ds-yourcompany.azurewebsites.net/health-ui This provides a visual dashboard showing the real-time status of all components. Option 2: Application Insights For detailed monitoring and historical data: Go to Azure Portal Open your resource group Click on Application Insights View the Application Map to see all services and dependencies Option 3: Direct API Endpoints For programmatic access or troubleshooting: App Designer: https://ad-yourcompany.azurewebsites.net/health Data Stream Designer: https://ds-yourcompany.azurewebsites.net/health Subscription Manager: https://sm-yourcompany.azurewebsites.net/version Logging (Automatically Configured) All logging is automatically set up. No configuration needed! What's Included ✅ Application Insights - Logs and metrics for App Designer (AD) and Data Stream Designer (DS) ✅ File-based logging - Subscription Manager (SM) logs to files via Serilog ✅ Log Analytics - Query and analyze Application Insights data Viewing Logs For AD and DS (Application Insights): Go to your resource group in Azure Portal Click on Application Insights Click \"Logs\" to search logs Click \"Failures\" to see errors For SM (File Logs): Go to your SM App Service in Azure Portal Navigate to Advanced Tools (Kudu) Browse to C:\\home\\LogFiles\\Application\\ View the sm-log-*.txt files Tip Need help with specific log types? See: Data Stream Logs Connector Logs Production Considerations For production deployments, you may want to: Set up alerts in Application Insights for errors or performance issues Configure backups for your SQL databases Review security settings in Azure Portal Set up custom domains (see GitHub documentation) Note For all other advanced configurations like SMTP, custom domains, and production settings, see the complete module documentation."
  },
  "src/installation/deployment/azure-terraform/azure-sizing.html": {
    "href": "src/installation/deployment/azure-terraform/azure-sizing.html",
    "title": "Sizing Recommendations | XMPro",
    "summary": "Sizing Recommendations This guide provides recommendations for Azure resource sizing when deploying XMPro. Overview Small, medium, and large sizing estimates are provided. The small option starts with the minimum recommended resources and, generally, each subsequent size doubles the number of CPU cores and available RAM. Not all components experience the same increase in load, so the estimates may not increase at the same rate for all components. Many factors influence the number of Apps and Data Streams a deployment can effectively run. These factors include: the number of data streams, how frequently the streams process data, the size of the data payload, the number of recommendations to be monitored, the number of apps and event boards being served, the complexity of apps and event boards (the number of elements and integration points), and the number of concurrent users accessing the apps and event boards. As a rough guide, an example workload for a Medium-sized deployment would be: ~200 Data Streams running across ~15 Stream Hosts, serving data and triggering recommendations for ~10 Apps Azure App Service Plans and Database Sizing Estimates for Azure target the Premium v3 and v4 service plans for applications, and Azure SQL Database for the databases. Azure SQL database estimates are based on the General-Purpose service tier and use the DTU-based purchasing model (a blended measure of compute, storage, and IO resources). Component Small Medium Large Subscription Manager (SM) App Service Plan 1 P1v3 or P0v4 P1v3 or P1v4 P2v3 or P1v4 Application Designer (AD) App Service Plan P1v3 or P0v4 P2v3 or P1v4 P3v3 or P2v4 Data Stream Designer (DS) App Service Plan P1v3 or P0v4 P1v3 or P1v4 P2v3 or P2v4 Stream Host (SH) Container Instances 2,3 1 CPU, 4GB RAM 2 CPU, 8GB RAM 4 CPU, 16GB RAM Azure SQL Database (For each of SM, AD, DS) 4 Standard – 20 DTUs Standard – 50 DTUs Standard – 100 DTUs Note Footnotes 1 High volumes of concurrent users may require additional compute. 2 Multiple Stream Hosts can be deployed as separate container instances. 3 If the Stream Host needs more resources, consider increasing the RAM before adding additional CPU cores as Stream Hosts perform in-memory processing of events. 4 High volumes of recommendations may require additional compute and storage. Premium v3 vs v4 Service Plans Azure offers both Premium v3 (Pv3) and Premium v4 (Pv4) App Service Plans: Premium v3: Standard tier with good performance Premium v4: Latest generation with better price-performance ratio Both are suitable for XMPro deployments. The v4 plans generally offer better value. Default Configuration The example Terraform infrastructure module uses B2 SKU for all App Service Plans by default, which provides: 2 vCPU cores 3.5 GB RAM Suitable for development and evaluation workloads For production deployments, we recommend upgrading to Premium v3 or v4 plans. You can customize the SKU for each service independently in the infrastructure layer configuration. Additional Resources For detailed Azure pricing information, see: Azure App Service Pricing Azure SQL Database Pricing Azure Container Instances Pricing"
  },
  "src/installation/deployment/azure-terraform/index.html": {
    "href": "src/installation/deployment/azure-terraform/index.html",
    "title": "Deploy XMPro on Azure | XMPro",
    "summary": "Deploy XMPro on Azure Introduction Get your XMPro intelligent digital twin platform running on Microsoft Azure quickly and reliably with Terraform automation. You'll deploy in two simple steps - first the infrastructure (databases, storage, networks), then the applications. This two-step approach lets you update applications without touching your infrastructure. Note This guide works on Windows, Mac, and Linux. Windows users should use Command Prompt or PowerShell. Provision Infrastructure Your Own Way? Note Infrastructure provisioning is your responsibility. The Terraform module in this guide is provided as an example only and is not officially supported by XMPro. You are responsible for infrastructure configuration, maintenance, and support. See the Deployment Responsibility Matrix for details. Tip The example Terraform infrastructure module uses B2 App Service Plans (2 vCPU, 3.5GB RAM) and Basic SQL databases by default. This sizing is suitable for development and evaluation. For production sizing recommendations based on your workload, see the Azure Sizing Guide. You can provision the required infrastructure using: The example Terraform module (community-supported) Azure Portal (ClickOps) Your organization's infrastructure-as-code tools If you provision infrastructure yourself, you'll need to create these resources before deploying applications: Required Infrastructure: [ ] Resource Group - 1 logical grouping for all XMPro resources [ ] Azure SQL Server - 1 server with 3-4 databases (SM, AD, DS, and optionally AI) [ ] Storage Account - 1 account for deployment artifacts and application files [ ] App Service Plans - 3-4 separate Linux plans (one for SM, AD, DS, and optionally AI) [ ] Key Vaults - 3-4 separate vaults (one for SM, AD, DS, and optionally AI) [ ] Application Insights - 1 instance for monitoring (recommended) [ ] Log Analytics Workspace - 1 workspace for centralized logging (recommended) Optional Infrastructure (for production environments): [ ] Master Data SQL Server - Separate SQL server and database for master data (create_masterdata = true) [ ] Virtual Network (VNet) - For network isolation and security (prod_networking_enabled = true) [ ] Subnets - Presentation, application, and data tiers (required if VNet enabled) [ ] Network Security Groups (NSGs) - Firewall rules for each subnet (created with VNet) [ ] Private DNS Zones - For private endpoint name resolution: privatelink.database.windows.net, privatelink.blob.core.windows.net, privatelink.file.core.windows.net, privatelink.redis.cache.windows.net, privatelink.vaultcore.azure.net (created with VNet) [ ] Private Endpoints - Secure private connections to SQL Server, Storage Account, Redis Cache, and Key Vault (created with VNet) [ ] Redis Cache - For distributed caching and auto-scaling (create_redis_cache = true, requires VNet) [ ] Public DNS Zone - For custom domain management (enable_custom_domain = true) [ ] DNS Records - A records for each service (SM, AD, DS, AI) pointing to App Services [ ] Azure AD Authentication for SQL (enable_sql_aad_auth = true) - Requires: [ ] User-Assigned Managed Identities - One for each service (SM, AD, DS, AI) [ ] SQL Server AAD Admin - Configured with appropriate permissions [ ] Azure Monitor Alerting - For Stream Host container monitoring Once you've created these resources, you can skip to Step 5: Deploy Application Layer and provide the infrastructure details in your configuration. Prerequisites You need: An Azure account with a subscription A computer with internet access Quick Deployment 1. Install Required Tools Install these on your computer: Git: Download here Terraform: Download here Azure CLI: Download here Verify they work: Windows (Command Prompt or PowerShell): git --version terraform version az version Mac/Linux: git --version terraform version az version 2. Login to Azure All platforms: # Login to your Azure account az login # Set your subscription (if you have multiple) az account set --subscription \"YOUR-SUBSCRIPTION-NAME-OR-ID\" Tip Terraform will automatically use your Azure CLI credentials. If you prefer using environment variables or service principals, see the advanced setup below. Optional: Use ARM environment variables instead If you can't use az login (e.g., in CI/CD pipelines), set these environment variables: Windows (PowerShell): $env:ARM_SUBSCRIPTION_ID = \"your-subscription-id\" $env:ARM_TENANT_ID = \"your-tenant-id\" $env:ARM_CLIENT_ID = \"your-service-principal-id\" $env:ARM_CLIENT_SECRET = \"your-service-principal-password\" Mac/Linux: export ARM_SUBSCRIPTION_ID=\"your-subscription-id\" export ARM_TENANT_ID=\"your-tenant-id\" export ARM_CLIENT_ID=\"your-service-principal-id\" export ARM_CLIENT_SECRET=\"your-service-principal-password\" For more details, see Microsoft's Terraform on Azure documentation. 3. Get the Deployment Files Windows (PowerShell): # Download the deployment configuration git clone {{TERRAFORM_MODULE_URL}}.git cd terraform-xmpro-azure\\examples\\layered\\infra # Create your configuration Copy-Item terraform.tfvars.example terraform.tfvars Windows (Command Prompt): # Download the deployment configuration git clone {{TERRAFORM_MODULE_URL}}.git cd terraform-xmpro-azure\\examples\\layered\\infra # Create your configuration copy terraform.tfvars.example terraform.tfvars Mac/Linux: # Download the deployment configuration git clone {{TERRAFORM_MODULE_URL}}.git cd terraform-xmpro-azure/examples/layered/infra # Create your configuration cp terraform.tfvars.example terraform.tfvars The infrastructure layer uses sensible defaults. You can deploy as-is or customize settings in terraform.tfvars.example - see the GitHub documentation for all available options. 4. Deploy Infrastructure Layer All platforms: terraform init # Prepare Terraform terraform apply # Deploy infrastructure (type 'yes' when asked) This creates the foundation: databases, storage, networks, and App Service Plans. Deployment takes about 10-15 minutes. 5. Deploy Application Layer Now deploy the XMPro applications on top of the infrastructure: Windows (PowerShell): cd ..\\app Copy-Item terraform.tfvars.example terraform.tfvars Windows (Command Prompt): cd ..\\app copy terraform.tfvars.example terraform.tfvars Mac/Linux: cd ../app cp terraform.tfvars.example terraform.tfvars First, get the infrastructure values: All platforms: # Go back to infra folder cd ..\\infra # Windows cd ../infra # Mac/Linux # Get the values you need terraform output Copy the resource_group_name and sql_server_fqdn values shown. Then edit terraform.tfvars in the app folder with your values: # Infrastructure references (use the actual values from \"terraform output\" above) resource_group_name = \"rg-mycompany-dev001\" # Replace with your value sql_server_fqdn = \"sql-mycompany-dev001.database.windows.net\" # Replace with your value # Application passwords - Change these! site_admin_password = \"YourStrongPassword123!\" company_admin_password = \"YourCompanyPassword123!\" # Company admin details - Change these! company_admin_email_address = \"admin@yourcompany.com\" company_admin_first_name = \"John\" company_admin_last_name = \"Doe\" # Evaluation mode - Set to true for testing/demo (includes licenses) is_evaluation_mode = true Deploy the applications: All platforms: terraform init # Prepare Terraform terraform plan # Review what will be deployed and check for errors terraform apply # Deploy applications (type 'yes' when asked) Tip The terraform plan step validates your configuration and shows exactly what will be created. If there are errors in your inputs (like incorrect infrastructure references), you'll see them here before deploying. This deploys all XMPro applications and takes about 5-10 minutes. 6. Access XMPro After deployment completes: All platforms: terraform output # Shows your URLs Login to Subscription Manager with either account: Account Type Username Password Purpose Site Admin admin@xmpro.onxmpro.com Your site_admin_password Full system access, license management Company Admin firstname.lastname@yourcompany.onxmpro.com Your company_admin_password Company management, normal operations Note Replace firstname.lastname and yourcompany with the values you set in terraform.tfvars. That's It! XMPro is now running on Azure with this architecture: Your deployment includes: ✅ All XMPro applications (SM, AD, DS, Stream Host) ✅ SQL databases for each component ✅ Key Vault for secret management ✅ Application Insights monitoring ✅ Storage accounts for files ✅ SSL certificates automatically configured What's Next? For guides in setting up your first tenant, uploading agents and connectors, or deploying additional stream hosts, refer to the Post Deployment Guide Need Help? Common Issues \"terraform: command not found\" → You haven't installed Terraform yet. Go back to step 1. \"Please ensure you have logged in\" → Run az login again \"Resource already exists\" → Add prefix = \"unique123\" to your terraform.tfvars Takes longer than 20 minutes? → First deployment can take up to 30 minutes. Check Azure Portal to see progress. More Resources Troubleshooting Guide - Fix common problems Advanced Configuration - Production settings Complete Documentation Next Steps After completing your infrastructure deployment, proceed to: Post-deployment - Complete the setup and configuration of your XMPro environment. Cleanup To remove everything and stop Azure charges: All platforms: terraform destroy Note For advanced features like custom domains, SMTP, existing databases, and multiple stream hosts, see the Advanced Configuration Guide or the GitHub documentation."
  },
  "src/installation/deployment/azure-terraform/troubleshooting.html": {
    "href": "src/installation/deployment/azure-terraform/troubleshooting.html",
    "title": "Troubleshooting | XMPro",
    "summary": "Troubleshooting This guide helps you fix common issues when deploying XMPro on Azure. Tip Most issues are solved by: Running az login to refresh your Azure authentication Making sure you're in the right directory (terraform-xmpro-azure/examples/layered/infra or .../app) Using a different Azure region if you get \"quota exceeded\" errors Most Common Issues 1. \"Terraform command not found\" Solution: # You haven't installed Terraform yet. Download it from: # https://developer.hashicorp.com/terraform/install # After installing, restart your terminal and try: terraform version 2. \"Error: building account... Please ensure you have logged in\" Solution: # Login to Azure: az login # If that doesn't work, try: az logout az login --use-device-code 3. \"Subscription not found\" or wrong subscription Solution: # List your subscriptions: az account list --output table # Switch to the right one: az account set --subscription \"Your Subscription Name\" # Verify you're on the right subscription: az account show 4. \"Resource already exists\" errors Problem: Azure resource names must be globally unique. Solution: Edit your terraform.tfvars and add a unique prefix: prefix = \"mycompany123\" # Add this line with a unique value 5. Deployment takes forever (more than 30 minutes) Common causes: Azure is slow in your region - this is normal for first deployment Database creation can take 10-15 minutes alone What to check: Look at the Azure Portal - are resources being created? Check terraform output - is it progressing? If stuck for over 45 minutes, try: # Cancel with Ctrl+C, then: terraform destroy # Clean up partial deployment terraform apply # Try again 6. \"Insufficient quota\" or \"SubscriptionIsOverQuotaForSku\" Problem: Your Azure subscription has limits on resources. Quick Solution: Use smaller resource sizes in terraform.tfvars: app_service_sku_name = \"B1\" # Instead of B2 sql_sku_name = \"Basic\" # Instead of S0 Long-term Solution: Request a quota increase in Azure Portal under \"Quotas\". 7. Login problems after deployment Can't login with admin credentials? Check your passwords in terraform.tfvars: Must be at least 8 characters Must have uppercase, lowercase, number, and special character No spaces or quotes in the password Forgot what you set? Look in your terraform.tfvars file for: site_admin_password company_admin_password 8. Application layer errors (Step 5 - terraform plan/apply failures) Problem: Errors during application deployment, often related to infrastructure references. Common errors and solutions: \"Resource group not found\" # Problem 1: resource_group_name in terraform.tfvars doesn't match infrastructure output # Solution: Get the correct name from infrastructure layer: cd ../infra terraform output resource_group_name # Copy the exact output to your app/terraform.tfvars # Problem 2: You're in a different Azure subscription # Solution: Check which subscription you're using: az account show # If wrong, switch to the same subscription used for infrastructure: az account set --subscription \"Your Subscription Name\" \"SQL Server not found\" or \"cannot connect to database\" # Problem: sql_server_fqdn is incorrect or database not ready # Solution 1: Get correct SQL server name: cd ../infra terraform output sql_server_fqdn # Copy to app/terraform.tfvars # Solution 2: Verify SQL server exists in Azure Portal # Check your resource group for the SQL server resource \"Storage account not found\" # Problem: storage_account_name doesn't match infrastructure # Solution: cd ../infra terraform output storage_account_name # Update in app/terraform.tfvars \"App Service Plan not found\" # Problem: Referenced App Service Plan names don't exist # Solution: Get all infrastructure outputs and verify names match: cd ../infra terraform output # Check that ad_service_plan_name, ds_service_plan_name, sm_service_plan_name match Best practice: Always run terraform plan in the app layer before apply. This validates all your infrastructure references are correct. 9. Applications won't start (App Service issues) Quick fixes to try: Restart the services in Azure Portal: Go to your resource group Click on each App Service (SM, AD, DS) Click \"Restart\" Check the logs in Azure Portal: Go to your App Service Click \"Log stream\" in the left menu Look for error messages Wait a bit longer: First startup can take 5-10 minutes Check the /version endpoint: curl \"$(terraform output -raw sm_app_url)/version\" Getting More Help Check Your Setup Run this to verify everything is working: # Check Terraform: terraform version # Check Azure login: az account show # Check your configuration: terraform validate Collect Information for Support If you need to contact support, run: # Save all outputs: terraform output > terraform-outputs.txt # Get resource group name: terraform output resource_group_name # List what was created: az resource list --resource-group $(terraform output -raw resource_group_name) --output table View Logs in Azure Portal Go to Azure Portal (portal.azure.com) Find your resource group (named like rg-yourcompany-dev-xmpro) Click on Application Insights resource Click \"Logs\" to see application logs Click \"Failures\" to see errors Common Error Messages Explained Error What it means Solution \"terraform: command not found\" Terraform isn't installed Install Terraform \"Error: building account\" Not logged into Azure Run az login \"SubscriptionIsOverQuotaForSku\" Azure limits exceeded Use smaller SKUs or request quota increase \"Resource already exists\" Name conflict Add unique prefix in terraform.tfvars \"Container image not found\" Wrong version specified Use imageversion = \"latest\" in terraform.tfvars \"SSL/TLS connection error\" Network/firewall issue Check corporate firewall or try different network Still Stuck? Double-check the basics: Are you in the right directory? (terraform-xmpro-azure/examples/layered/infra or .../app) Did you run terraform init first? Is your terraform.tfvars file saved? Try a clean deployment: terraform destroy # Remove everything terraform apply # Start fresh Use a different Azure region: # In terraform.tfvars, try: location = \"eastus2\" # or \"westeurope\", \"southeastasia\" Contact Support: Use the XMPro Support Portal Include your error messages Describe what step failed Note For advanced troubleshooting and detailed technical issues, see the complete module documentation."
  },
  "src/installation/deployment/index.html": {
    "href": "src/installation/deployment/index.html",
    "title": "Deploy XMPro | XMPro",
    "summary": "Deploy XMPro XMPro Platform can be installed using a range of Infrastructure, please choose the option below that best suits your requirements: Container-Based Deployments Azure Terraform Deployment Tip Full Platform: Complete XMPro deployment with all components (includes Stream Host by default) Note The following features are not yet available in Azure Terraform Deployment: SMTP OAuth configuration Redis/Autoscale setup SSO Azure Entra ID integration SSO ADFS integration Custom environment variables Custom health checks configuration Windows Server 2022 Deployment Tip On-Premises: Native IIS deployment for Windows Server environments with full control over infrastructure AWS Terraform Deployment Note AWS container deployment is coming soon for XMPro v4.5+. Legacy Installers Traditional installation methods for XMPro v4.4 and earlier versions. Azure ARM Template Deployment Traditional ARM template deployment approach for existing v4.4 installations. AWS Deployment Deploy XMPro on Amazon Web Services using Kubernetes and Helm charts. Windows Server 2022 Deployment On-premises deployment for Windows Server environments. Next Steps After completing your infrastructure deployment, proceed to: Post-deployment - Complete the setup and configuration of your XMPro environment."
  },
  "src/installation/deployment/windows-server-2022/airgapped-deployment.html": {
    "href": "src/installation/deployment/windows-server-2022/airgapped-deployment.html",
    "title": "Airgapped Deployment | XMPro",
    "summary": "Airgapped Deployment Introduction Deploy XMPro in restricted environments without internet access using offline installation packages. This approach is essential for high-security facilities, air-gapped networks, or environments with strict compliance requirements that prohibit external connectivity. All installation files are pre-downloaded and transferred to the isolated environment before deployment. Note For general installation concepts and detailed configuration options, see the main installation guide. Prerequisites Each server in your airgapped deployment must meet the standard prerequisites. See Prerequisites for complete requirements including: Windows Server 2022 IIS with required features SQL Server 2022 with Mixed Mode authentication Certificates (signing and SSL) .NET Framework and .NET 8 Hosting Bundle Download Required Files From a machine with internet access, download these files: Installer scripts: {{INSTALL_URL_PREFIX}}{{VERSION}}/install-xmpro-application.ps1 {{INSTALL_URL_PREFIX}}{{VERSION}}/manifest.json (Optional) {{INSTALL_URL_PREFIX}}{{VERSION}}/install-xmpro-prerequisites.ps1 Product packages: Open manifest.json in a text editor Download all URLs listed in the manifest (includes SM.zip, AD.zip, DS.zip, StreamHost.zip, and other dependencies) Optional: Automated Download Script Use this PowerShell script to automatically download all files from manifest.json: # Download manifest.json first $manifestUrl = \"{{INSTALL_URL_PREFIX}}{{VERSION}}/manifest.json\" $outputDir = \"C:\\XMPro-Install\" New-Item -Path $outputDir -ItemType Directory -Force | Out-Null curl.exe -L -o \"$outputDir\\manifest.json\" $manifestUrl --silent --show-error # Read manifest and download all files $manifest = Get-Content \"$outputDir\\manifest.json\" | ConvertFrom-Json foreach ($file in $manifest.PSObject.Properties) { $url = $file.Value $filename = Split-Path $url -Leaf Write-Host \"Downloading $filename...\" curl.exe -L -o \"$outputDir\\$filename\" $url --silent --show-error } Write-Host \"All files downloaded to $outputDir\" Installation Steps Step 1: Prepare Installation Directory On the Windows Server (offline), create a directory and place all files together: C:\\XMPro-Install\\ ├── install-xmpro-application.ps1 ├── manifest.json ├── SM-v{{VERSION}}.zip ├── AD-v{{VERSION}}.zip ├── DS-v{{VERSION}}.zip ├── SM.Database.Console-v{{VERSION}}.exe ├── AD.Database.Console-v{{VERSION}}.exe ├── DS.Database.Console-v{{VERSION}}.exe └── StreamHost-win-x64-v{{VERSION}}.exe Step 2: Run Installer cd C:\\XMPro-Install powershell.exe -ExecutionPolicy Bypass -File install-xmpro-application.ps1 What happens: Installer detects local product zip files in same directory Skips download step (uses local files instead) Proceeds with normal installation process No internet connection required Tip How it works: The installer looks for manifest.json and product files in the same directory as install-xmpro-application.ps1. If found, it uses them directly instead of downloading. Next Steps After completing your Airgapped deployment, proceed to: Post-deployment - Complete the setup and configuration of your XMPro environment. Need Help? Main Installation Guide - Standard deployment process Multi-Server Deployment - Distributed deployments Troubleshooting Guide - Fix common issues"
  },
  "src/installation/deployment/windows-server-2022/index.html": {
    "href": "src/installation/deployment/windows-server-2022/index.html",
    "title": "Deploy XMPro on Windows Server 2022 | XMPro",
    "summary": "Deploy XMPro on Windows Server 2022 Introduction Deploy the XMPro platform on Windows Server 2022 using native IIS hosting in under 30 minutes with our interactive installer. This guide walks you through a single-server installation where all XMPro products run on one server using IIS web applications and Windows services. Note This guide uses native IIS deployment - not containers. XMPro applications run as IIS web applications and Windows services. Single-Server Architecture Prerequisites Before installing XMPro applications, ensure your Windows Server has the following components installed. Software Requirements Component Version Details Operating System Windows Server 2022 Standard or Datacenter edition, updated with the latest Windows Updates. SQL Server 2022 (Standard) Mixed Mode authentication enabled. Database Account: Create a dedicated user account (e.g., xmadmin) with only required permissions (dbcreator and securityadmin roles) instead of using the built-in sa account. • dbcreator allows creating databases • securityadmin allows managing database logins Certificate Trust: In production, configure the Windows Server to trust the SQL Server certificate. For non-production environments, answer Y (Yes) when prompted \"Trust SQL Server Certificate?\" during installation (less secure). See Troubleshooting for detailed setup instructions. IIS 10.0+ Web Server role with required features: • Common HTTP Features (Default Document, Static Content) • Application Development (ASP.NET 4.8, .NET Extensibility 4.8) • Health and Diagnostics (HTTP Logging) • Security (Request Filtering) • Management Tools (IIS Management Console) IIS URL Rewrite Module 2.1+ Required for application routing. .NET Framework 4.8 Required for legacy compatibility. .NET 8 Hosting Bundle 8.0+ Critical: Must install the Hosting Bundle. HTTP.sys Configuration Registry settings Increase max header size to prevent HTTP 400 errors. MaxFieldLength = 65536 MaxRequestBytes = 65536 See Troubleshooting Guide for configuration steps. Certificate Requirements Certificate Type Purpose File Format Notes Signing Certificate JWT token signing for inter-product authentication. .pfx with password Self-signed or CA-issued. 4096-bit RSA key recommended. See Troubleshooting Guide for creation example. SSL Certificate HTTPS encryption for web traffic. .pfx with password Production: Use certificate from trusted CA. Testing: Self-signed acceptable. Must include hostname in Subject Alternative Names (SAN). Quick Deployment Run the Installer Open CMD (Command Prompt as Administrator) on your Windows Server and run: powershell.exe -ExecutionPolicy Bypass -Command \"$env:SCRIPT_URL='{{INSTALL_URL_PREFIX}}{{VERSION}}/install-xmpro-application.ps1'; iex (irm $env:SCRIPT_URL)\" This command downloads and runs the interactive installer in one step. The installer will launch a configuration wizard that guides you through setup. Configuration Prompts The installer will ask you several questions. Here's what each prompt means: 1. Product Selection The following prompts will ask you sequantially on which of the XMPro components you want to install. The default value for each prompt is \"Y\" for yes but you are open to choose no (by typing \"N\") if you only want to install select XMPro Components. However, some components might require existing installation of other components which is also detailed on the table below: Prompt What It Means Default Value Install SM? (y/n) Whether to install Subscription Manager. A non-Y/y input means installation of Subscription Manager will be skipped. Required first when installing AD/DS. y Install AD? (y/n) Whether to install App Designer. A non-Y/y input means installation of App Designer will be skipped. Requires an existing SM Installation. y Install DS? (y/n) Whether to install Data Stream Designer. A non-Y/y input means installation of Data Stream Designer will be skipped. Requires an existing SM Installation. y Install SH? (y/n) Whether to install Stream Host. A non-Y/y input means installation of Stream Host will be skipped. y 2. Database Configuration Prompt What It Means Default Value Database Server SQL Server instance to connect to. Examples: • Local: localhost or hostname • External: sql-server.yourcompany.com • Custom port: hostname,1433 External SQL Server requirements: • TCP/IP enabled on port 1433 • Mixed authentication mode enabled • Firewall allows connections from Windows Server hostname Database Username The dedicated SQL Server user account created in prerequisites. xmadmin Database Password The SQL Server password you want to set for the created SQL Account. (required - no default) Database Protocol SQL Server connection protocol. tcp = standard for network connections np = named pipes (local only) tcp Trust SQL Server Certificate Whether to trust SQL Server certificate without validation. Production: Select N (No) and configure Windows Server to trust the SQL Server certificate. Non-Production: Select Y (Yes) for quick setup (less secure). See Troubleshooting for certificate setup instructions. N SM Database Name Subscription Manager database name (always required as central registry). SM AD Database Name App Designer database name. Only asked if AD is selected. AD DS Database Name Data Stream Designer database name. Only asked if DS is selected. DS Company Name Your company name for company admin account (no spaces). Only asked if SM is selected. Company Company Admin First Name First name for company admin account. Only asked if SM is selected. System Company Admin Last Name Last name for company admin account. Only asked if SM is selected. Administrator Company Admin Email Email address for company admin account. Only asked if SM is selected. site.admin@yourcompany.com Company Admin Password Password for company admin account. Only asked if SM is selected. (required - no default) Site Admin Password Password for site admin account: admin@xmpro.onxmpro.com. Only asked if SM is selected. (required - no default) Use separate SM database credentials? (y/n) Use different database credentials for SM. Only asked if SM is selected. n Use separate AD database credentials? (y/n) Use different database credentials for AD. Only asked if AD is selected. n Use separate DS database credentials? (y/n) Use different database credentials for DS. Only asked if DS is selected. n Enable SMTP configuration? (y/n) Enable email for password resets, notifications, invitations. Only asked if SM or AD is selected. n Tip Username Format: Your company admin username will be automatically created as FirstName.LastName@CompanyName.onxmpro.com Example: If Company Name = \"Acme\", First Name = \"John\", Last Name = \"Smith\", your username will be: John.Smith@Acme.onxmpro.com Important SMTP is required for password resets and user invitations. Without SMTP configured, users cannot reset forgotten passwords or receive invitation emails. Configure SMTP now or add it later by editing configuration files. SMTP Configuration (if enabled) If you choose to enable SMTP, you'll be prompted for these additional settings: Prompt What It Means Default Value SMTP Server SMTP server address (e.g., smtp.gmail.com). (required - no default) SMTP Port SMTP port number (usually 587 for TLS or 465 for SSL). 587 Enable SSL? (y/n) Enable SSL/TLS encryption for SMTP connection. y SMTP Username SMTP authentication username (e.g., notifications@yourcompany.com). (required - no default) SMTP Password SMTP authentication password (or app password). (required - no default) From Email Address Email address to use as sender for system notifications. (required - no default) 3. Product Configuration Basic Configuration Note Hostname: Enter the DNS name users will use to access XMPro (e.g., xmpro.yourcompany.com). Use localhost for local-only access. Internal Base URL: Only needed if using a reverse proxy or load balancer where internal server URLs differ from external URLs. Leave default for most installations. Prompt What It Means Default Value SM Hostname DNS name where SM will be accessed. localhost SM Listen Port Port for SM web application. 5201 SM Internal Base URL (if different) (optional) Internal URL for SM (if different from external). https://hostname AD Hostname DNS name where AD will be accessed. localhost AD Listen Port Port for AD web application. 5202 AD Internal Base URL (if different) (optional) Internal URL for AD (if different from external). https://hostname:5202 DS Hostname DNS name where DS will be accessed. localhost DS Listen Port Port for DS web application. 5203 DS Internal Base URL (if different) (optional) Internal URL for DS (if different from external). https://hostname:5203 SSL Certificates Prompt What It Means Default Value SM SSL Certificate Path Path to SSL certificate file for SM (e.g., C:\\XMPro\\Certificates\\ssl.pfx). Only asked if SM is selected. (required - no default) SM SSL Certificate Password Password for SM SSL certificate. Only asked if SM is selected. (required - no default) Token Certificate Path Path to JWT signing certificate file (e.g., C:\\XMPro\\Certificates\\sign.pfx). Only asked if SM is selected. (required - no default) Token Certificate Password Password for JWT signing certificate. Only asked if SM is selected. (required - no default) AD SSL Certificate Path Path to SSL certificate file for AD. Only asked if AD is selected. (required - no default) AD SSL Certificate Password Password for AD SSL certificate. Only asked if AD is selected. (required - no default) DS SSL Certificate Path Path to SSL certificate file for DS. Only asked if DS is selected. (required - no default) DS SSL Certificate Password Password for DS SSL certificate. Only asked if DS is selected. (required - no default) Stream Host Configuration (if SH selected) Prompt What It Means Default Value Stream Host Install Path Directory where Stream Host will be installed. C:\\XMPro\\StreamHost Device Name Unique name for this Stream Host instance (will appear in Data Stream Designer). StreamHost-hostname Data Stream Designer URL DS URL for Stream Host to connect to. https://hostname:5203 Note Configuration is saved to C:\\XMPro\\ - you'll see these as defaults if you reinstall. Installation Process After answering the prompts, the installer will: ✅ Validate configuration - Tests SQL Server connection to the database and validates certificates If validation fails, you'll see the specific error and be prompted to: (r) Retry - Re-enter your credentials (s) Skip - Continue anyway (may cause installation to fail later) ✅ Migrate databases - Create and populate SM, AD, DS databases (takes 5-10 minutes) ✅ Download products - Get latest XMPro application packages ✅ Deploy to IIS - Create application pools and websites ✅ Install Stream Host - Set up Windows service (if selected) ✅ Configure applications - Apply settings and start services Installation time: 15-30 minutes depending on download speed and server performance. Note The installer shows progress for each step. Access XMPro After installation completes, the installer displays your access URLs: Subscription Manager (SM): https://localhost:5201 App Designer (AD): https://localhost:5202 Data Stream Designer (DS): https://localhost:5203 Login Credentials Account Type Username Password Purpose Site Admin admin@xmpro.onxmpro.com Your site admin password Full system access, license management. Company Admin FirstName.LastName@CompanyName.onxmpro.com Example: John.Smith@Acme.onxmpro.com Your company admin password Company operations, user management. Tip Cannot access? Check Windows Firewall allows ports 5201, 5202, 5203 Verify IIS applications are running: Open IIS Manager → Application Pools Check certificate trust: See Troubleshooting for certificate issues What Gets Installed IIS Websites XMPro-SM: Subscription Manager (C:\\inetpub\\wwwroot\\XMPro-SM) XMPro-AD: App Designer (C:\\inetpub\\wwwroot\\XMPro-AD) XMPro-DS: Data Stream Designer (C:\\inetpub\\wwwroot\\XMPro-DS) Database Migration Results SM Database: Identity, licensing, company data AD Database: Applications, pages, dashboards DS Database: Data streams, agents, collections Windows Services StreamHost-{hostname}: Data stream execution service Configuration Files C:\\XMPro\\Global-variables.json: Main configuration C:\\XMPro\\Global-settings.json: Auto-generated settings (Product IDs, Collection secrets) C:\\XMPro\\SM-variables.json: SM-specific settings C:\\XMPro\\AD-variables.json: AD-specific settings C:\\XMPro\\DS-variables.json: DS-specific settings Note Configuration files are preserved across reinstalls - you'll see your previous settings as defaults. Warning Security Best Practice: For production environments, move sensitive secrets (database passwords, certificate passwords, SMTP credentials) from these configuration files to encrypted secure storage solutions such as Azure Key Vault, HashiCorp Vault, or Windows Credential Manager. This reduces the risk of credential exposure. Next Steps After completing your Windows Server deployment, proceed to: Post-deployment - Complete the setup and configuration of your XMPro environment. Common Installation Scenarios Reinstalling or Updating To reinstall without losing configuration: # Uses existing configuration from C:\\XMPro\\ .\\install-xmpro-application.ps1 -SkipPrompts Need Help? Troubleshooting Guide - Fix common issues Multi-Server Deployment - Deploy across multiple servers Airgapped Deployment - Offline installation Note This installer uses native IIS deployment - not Docker containers. All XMPro applications run as standard IIS web applications with dedicated application pools."
  },
  "src/installation/deployment/windows-server-2022/multi-server-deployment.html": {
    "href": "src/installation/deployment/windows-server-2022/multi-server-deployment.html",
    "title": "Multi-Server Deployment | XMPro",
    "summary": "Multi-Server Deployment Introduction Deploy XMPro products across multiple Windows servers for enterprise-scale architectures. This approach enables distributed workloads, product isolation, and high-availability configurations. Use multi-server deployment when you need to scale beyond a single server or require separation between products for security, performance, or compliance requirements. Note Single-Server vs Multi-Server: For simpler deployments where all products run on one server, see the main installation guide. Use multi-server deployment when you need: Distributed load across multiple servers Isolation between products for security or performance Scalability for high-availability architectures Important Deployment Responsibilities Multi-server deployments follow XMPro's two-phase deployment responsibility model: Phase 1 (Customer): Provision all servers, install prerequisites, configure networking and security Phase 2 (XMPro/Partner): Deploy XMPro applications using the installer This guide focuses on Phase 2 application deployment. Ensure Phase 1 infrastructure is complete before proceeding. Prerequisites Each server in your multi-server deployment must meet the standard prerequisites. See Prerequisites for complete requirements including: Windows Server 2022 IIS with required features SQL Server 2022 with Mixed Mode authentication Certificates (signing and SSL) .NET Framework and .NET 8 Hosting Bundle Note Database Configuration: Each product can use different SQL Server instances or credentials. See Database Configuration for all available options. Product Dependencies XMPro products must be installed in this order due to dependencies: SM (Subscription Manager) ↓ AD (App Designer) ← Requires product keys generated by SM ↓ DS (Data Stream Designer) ← Requires product keys generated by SM ↓ SH (Stream Host) ← Requires DS URL and collection details Why this order? SM creates foundational data (company, products, licenses) required by all other products AD and DS both need product keys generated by SM database for authentication and licensing SH needs DS URL and collection details for data stream execution Multi-Server Architecture Important Configuration File Preservation The installer automatically preserves existing configuration from C:\\XMPro\\: Database credentials (SQL Server, username, password) SMTP settings (if previously configured) Certificate paths and passwords Previous product configurations You'll see these as defaults during reinstallation - press Enter to keep them. Installation Workflow Step 1: Install SM (Server 1) Run the installer on your SM server: powershell.exe -ExecutionPolicy Bypass -Command \"$env:SCRIPT_URL='{{INSTALL_URL_PREFIX}}{{VERSION}}/install-xmpro-application.ps1'; iex (irm $env:SCRIPT_URL)\" When prompted, configure: Products: Select SM only Hostname: Enter Server 1's DNS name (e.g., sm.yourcompany.com or sm-server-01) Port: 5201 (default) or custom port Database, SMTP, certificates: Configure as prompted Installation creates: SM database on SQL Server SM IIS application Configuration files in C:\\XMPro\\ Step 2: Copy Configuration to AD Server Copy only the .json configuration files from SM server to AD server: Source: C:\\XMPro\\*.json on SM server (Server 1) Destination: C:\\XMPro\\ on AD server (Server 2) Note What gets copied: Configuration files only (Global-variables.json, Global-settings.json, SM-variables.json, etc.) These contain database credentials, SMTP settings, and certificate paths Security: Ensure certificates themselves are accessible on the destination server at the paths specified in the configuration files. Do not copy certificates - only the configuration that references them. Step 3: Install AD (Server 2) Run the installer on your AD server: powershell.exe -ExecutionPolicy Bypass -Command \"$env:SCRIPT_URL='{{INSTALL_URL_PREFIX}}{{VERSION}}/install-xmpro-application.ps1'; iex (irm $env:SCRIPT_URL)\" When prompted, configure: Products: Select AD only Hostname: Enter Server 2's DNS name (e.g., ad.yourcompany.com or ad-server-01) Port: 5202 (default) or custom port Other settings: Uses existing configuration from C:\\XMPro\\ (press Enter to accept defaults) Installation creates: AD database on SQL Server AD IIS application Step 4: Copy Configuration to DS Server Copy only the .json configuration files from AD server to DS server: Source: C:\\XMPro\\*.json on AD server (Server 2) Destination: C:\\XMPro\\ on DS server (Server 3) Step 5: Install DS (Server 3) Run the installer on your DS server: powershell.exe -ExecutionPolicy Bypass -Command \"$env:SCRIPT_URL='{{INSTALL_URL_PREFIX}}{{VERSION}}/install-xmpro-application.ps1'; iex (irm $env:SCRIPT_URL)\" When prompted, configure: Products: Select DS only Hostname: Enter Server 3's DNS name (e.g., ds.yourcompany.com or ds-server-01) Port: 5203 (default) or custom port Other settings: Uses existing configuration from C:\\XMPro\\ (press Enter to accept defaults) Installation creates: DS database on SQL Server DS IIS application Step 6: Copy Configuration to SH Server Copy only the .json configuration files from DS server to SH server: Source: C:\\XMPro\\*.json on DS server (Server 3) Destination: C:\\XMPro\\ on SH server (Server 4) Step 7: Install SH (Server 4) Run the installer on your SH server: powershell.exe -ExecutionPolicy Bypass -Command \"$env:SCRIPT_URL='{{INSTALL_URL_PREFIX}}{{VERSION}}/install-xmpro-application.ps1'; iex (irm $env:SCRIPT_URL)\" When prompted, configure: Products: Select SH only DS URL: Enter Server 3's DS URL (e.g., https://ds.yourcompany.com:5203 or https://ds-server-01:5203) Other settings: Uses existing configuration from C:\\XMPro\\ (press Enter to accept defaults) Installation creates: Stream Host Windows service Post-Deployment Validation After completing all installation steps, verify that products can communicate across servers: Access SM - Navigate to https://<sm-hostname>:5201 and log in with super admin credentials Access AD - From SM, navigate to App Designer or directly access https://<ad-hostname>:5202 Access DS - From SM, navigate to Data Stream Designer or directly access https://<ds-hostname>:5203 Verify Stream Host - In DS, check that Stream Host appears in the Stream Host list with \"Connected\" status If any product fails to load or Stream Host shows \"Disconnected\", see Troubleshooting Guide. Next Steps After completing your Windows Server deployment, proceed to: Post-deployment - Complete the setup and configuration of your XMPro environment. Need Help? For troubleshooting multi-server deployment issues, see the Troubleshooting Guide."
  },
  "src/installation/deployment/windows-server-2022/troubleshooting.html": {
    "href": "src/installation/deployment/windows-server-2022/troubleshooting.html",
    "title": "Troubleshooting | XMPro",
    "summary": "Troubleshooting This guide helps you resolve common issues when installing XMPro on Windows Server 2022. Tip Quick fixes that solve most issues: Restart IIS: iisreset /restart Restart SQL Server: Restart-Service MSSQLSERVER Check Windows Firewall is not blocking ports 443, 5202, 5203, 1433 Verify you're running PowerShell as Administrator View Application Logs: Check XMPro Log Events documentation for log file locations and troubleshooting guidance Installation Issues Installer Script Execution Blocked Error: .\\install-xmpro-application.ps1 : File cannot be loaded because running scripts is disabled on this system. Solution: # Run PowerShell as Administrator, then: Set-ExecutionPolicy -ExecutionPolicy Bypass -Scope Process -Force # Then run installer: .\\install-xmpro-application.ps1 Prerequisites Not Met Error: Validation failed: IIS is not installed Solution: Check the Prerequisites and install missing components: IIS with required features .NET Framework 4.8 .NET 8 Hosting Bundle SQL Server Certificates Quick check: # Verify IIS Get-Service W3SVC # Verify .NET 8 dotnet --list-runtimes # Verify SQL Server Get-Service MSSQLSERVER Configuration File Missing Error: Global-variables.json not found Solution: If running application installer for the first time: # Create configuration directory New-Item -Path \"C:\\XMPro\" -ItemType Directory -Force # Run installer (will create configuration) .\\install-xmpro-application.ps1 If configuration was accidentally deleted: The installer will recreate it during first run You'll need to re-enter all configuration values Installation Failure Recovery If installation fails on any server: Resolve the underlying issue - See relevant troubleshooting sections below for your specific error Re-run the installer: .\\install-xmpro-application.ps1 The installer will: Completely reinstall IIS applications Preserve database data (migration is idempotent) Use existing configuration from C:\\XMPro Database Issues Cannot Connect to SQL Server Error: A network-related or instance-specific error occurred while establishing a connection to SQL Server Common causes and solutions: 1. SQL Server service not running: # Check service status Get-Service MSSQLSERVER # Start service if stopped Start-Service MSSQLSERVER 2. TCP/IP protocol disabled: # Enable TCP/IP using SQL Server Configuration Manager # Or PowerShell: $wmi = New-Object Microsoft.SqlServer.Management.Smo.Wmi.ManagedComputer $tcp = $wmi.ServerInstances['MSSQLSERVER'].ServerProtocols['Tcp'] $tcp.IsEnabled = $true $tcp.Alter() # Restart SQL Server Restart-Service MSSQLSERVER 3. Firewall blocking SQL Server: # Allow SQL Server through firewall New-NetFirewallRule -DisplayName \"SQL Server\" -Direction Inbound -Protocol TCP -LocalPort 1433 -Action Allow 4. Wrong credentials: # Test SQL Server connection sqlcmd -S hostname -U sa -P YourPassword # If this fails, verify: # - Username is correct (default: sa) # - Password is correct # - Mixed Mode Authentication is enabled SQL Server Certificate Trust Error Symptoms: Application fails to start or connect to database Event Viewer shows SQL connection errors Error message mentioning \"certificate chain\" or \"trust relationship\" Error Example: A connection was successfully established with the server, but then an error occurred during the login process. (provider: SSL Provider, error: 0 - The certificate chain was issued by an authority that is not trusted.) Root Cause: The web server does not trust the SQL Server's SSL/TLS certificate. Solutions: Production Environment (Recommended) Configure the Windows Server to trust the SQL Server certificate by following Microsoft's official documentation: See: SQL Server Certificate Procedures - Export and Import Certificates After importing the certificate, restart IIS: iisreset Non-Production Environment (Quick Fix) Rerun the installer and answer Y (Yes) when prompted \"Trust SQL Server Certificate?\": powershell.exe -ExecutionPolicy Bypass -Command \"$env:SCRIPT_URL='{{INSTALL_URL_PREFIX}}{{VERSION}}/install-xmpro-application.ps1'; iex (irm $env:SCRIPT_URL)\" When prompted, select: Trust SQL Server Certificate: Y (Yes) Keep all other settings the same as your original installation Warning Setting \"Trust SQL Server Certificate\" to Y disables certificate validation and should only be used in non-production environments. Reference: TrustServerCertificate Documentation Database Migration Fails Error: Database migration failed for SM database Solutions: Check database connection: # Test connection with credentials from installer sqlcmd -S your-hostname -U sa -P YourPassword -Q \"SELECT @@VERSION\" Check disk space: # Verify enough disk space for databases Get-PSDrive C | Select-Object Used,Free Check SQL Server error logs: # View SQL Server error log Get-Content \"C:\\Program Files\\Microsoft SQL Server\\MSSQL16.MSSQLSERVER\\MSSQL\\Log\\ERRORLOG\" Manual database creation test: sqlcmd -S hostname -U sa -P YourPassword # At prompt, type: CREATE DATABASE TestDB GO DROP DATABASE TestDB GO # If this fails, SQL Server has permission or configuration issues Database Creation Timeout Error: Unhandled exception. Microsoft.Data.SqlClient.SqlException (0x80131904): Execution Timeout Expired. The timeout period elapsed prior to completion of the operation or the server is not responding. CREATE DATABASE operation failed. Internal service error. Operation cancelled by user. Error Number:-2,State:0,Class:11 SM/AD/DS database migration failed: database migration failed with exit code -532462766 Installation failed: database migration failed with exit code -532462766 What's happening: SQL Server is creating the database in the background The migration tool times out before the database creation completes The database will eventually be created successfully, but the installer exits with an error Root Cause: Database provisioning takes longer than the migration tool's timeout period. Solutions: Option 1: Rerun the Installer Simply rerun the installation script. The database has been created in the background and the installer will detect it exists and continue with the migration: powershell.exe -ExecutionPolicy Bypass -Command \"$env:SCRIPT_URL='{{INSTALL_URL_PREFIX}}{{VERSION}}/install-xmpro-application.ps1'; iex (irm $env:SCRIPT_URL)\" Note You may encounter this timeout for each database (SM, AD, DS) during first-time installation. Simply rerun the installer each time until all databases are created and migrated successfully. Option 2: Manually Create Databases Before Installation Create the databases manually using your SQL admin account (e.g., xmadmin) before running the installer: -- Connect to Azure SQL Database using your admin account -- Example using Azure Data Studio or SQL Server Management Studio -- Create databases CREATE DATABASE SM; CREATE DATABASE AD; CREATE DATABASE DS; Then run the installer normally. It will detect the databases exist and proceed with the migration. Database Already Exists Warning Message: We've noticed that the SM database 'SM' already exists (45 tables found) Please ensure that you've performed a backup before proceeding What this means: Installer detected existing XMPro database Database migration will modify/upgrade existing data Solutions: Option 1: Backup and continue (recommended for upgrades) # Backup existing database first sqlcmd -S hostname -U sa -P YourPassword -Q \"BACKUP DATABASE SM TO DISK='C:\\Backup\\SM.bak'\" # Then press Enter in installer to continue Option 2: Use different database name Cancel installer (Ctrl+C) Re-run with custom database name: SM Database Name: SM_New Data Stream Designer Database Errors Problem: \"Violation of PRIMARY KEY constraint\" errors during Data Stream Designer startup Solution: Restart IIS using iisreset /restart If errors persist, check SQL database for corruption or manually resolve conflicts Verify DS database integrity: # Check for duplicate keys or data issues sqlcmd -S hostname -U sa -P YourPassword -d DS -Q \"DBCC CHECKDB (DS)\" If database corruption is detected, restore from backup or re-run database migration: # Re-run DS database migration .\\install-xmpro-application.ps1 -Products @('DS') IIS Configuration Issues IIS Application Pool Not Starting Error: Application pool stops immediately after starting Check event logs: # View Application event log Get-EventLog -LogName Application -Newest 50 | Where-Object {$_.Source -like \"*IIS*\"} Common causes: 1. .NET runtime not installed: # Verify .NET 8 Hosting Bundle dotnet --list-runtimes | Select-String \"Microsoft.AspNetCore.App 8\" # If missing, download and install: # https://dotnet.microsoft.com/en-us/download/dotnet/8.0 2. Application pool identity permissions: # Reset application pool identity Import-Module WebAdministration Set-ItemProperty IIS:\\AppPools\\XMPro-SM -Name processModel.identityType -Value ApplicationPoolIdentity Restart-WebAppPool -Name \"XMPro-SM\" 3. Port conflict: # Check if port is already in use netstat -ano | findstr \":443\" netstat -ano | findstr \":5202\" netstat -ano | findstr \":5203\" # If port is in use, you can: # - Stop the conflicting application # - Change XMPro application port in IIS Manager Cannot Access XMPro Application Problem: Browser shows \"This site can't be reached\" or connection timeout Solutions: 1. Check Windows Firewall: # Allow inbound connections on XMPro ports New-NetFirewallRule -DisplayName \"XMPro SM\" -Direction Inbound -Protocol TCP -LocalPort 443 -Action Allow New-NetFirewallRule -DisplayName \"XMPro AD\" -Direction Inbound -Protocol TCP -LocalPort 5202 -Action Allow New-NetFirewallRule -DisplayName \"XMPro DS\" -Direction Inbound -Protocol TCP -LocalPort 5203 -Action Allow 2. Verify IIS bindings: # Check IIS site bindings Import-Module WebAdministration Get-WebBinding -Name \"XMPro-SM\" Get-WebBinding -Name \"XMPro-AD\" Get-WebBinding -Name \"XMPro-DS\" 3. Test from localhost first: # Test connection from server itself Invoke-WebRequest -Uri \"https://localhost/\" -UseBasicParsing Invoke-WebRequest -Uri \"https://localhost:5202/\" -UseBasicParsing Invoke-WebRequest -Uri \"https://localhost:5203/\" -UseBasicParsing 4. Check application is running: # Verify application pools are started Get-IISAppPool | Where-Object {$_.Name -like \"XMPro*\"} | Select-Object Name, State HTTP Error 500.19 - Configuration Error Error: HTTP Error 500.19 - Internal Server Error Cannot read configuration file Solutions: 1. IIS URL Rewrite module not installed: # Download and install: # https://www.iis.net/downloads/microsoft/url-rewrite # Verify installation: Get-WebConfiguration -Filter \"system.webServer/rewrite/rules\" 2. web.config file corrupted: # Check web.config exists and is readable Test-Path \"C:\\inetpub\\wwwroot\\XMPro-SM\\web.config\" # View web.config for XML errors Get-Content \"C:\\inetpub\\wwwroot\\XMPro-SM\\web.config\" 3. File permissions: # Grant IIS_IUSRS read access to application directory $acl = Get-Acl \"C:\\inetpub\\wwwroot\\XMPro-SM\" $rule = New-Object System.Security.AccessControl.FileSystemAccessRule(\"IIS_IUSRS\",\"ReadAndExecute\",\"ContainerInherit,ObjectInherit\",\"None\",\"Allow\") $acl.SetAccessRule($rule) Set-Acl \"C:\\inetpub\\wwwroot\\XMPro-SM\" $acl HTTP Error 404.15 - Request URL Too Long Error: Request URL too long error when accessing XMPro applications Solution: You need to make two changes to fix this issue: Increase the httpRuntime maxQueryStringLength and maxUrlLength in the system.web section Add requestFiltering settings in the system.webServer section Steps: Navigate to C:\\inetpub\\wwwroot\\XMPro-SM and open web.config in a text editor Update the httpRuntime line in the system.web section: <!-- Find this line --> <httpRuntime targetFramework=\"4.8\" maxUrlLength=\"1024\" /> <!-- Change it to this --> <httpRuntime targetFramework=\"4.8\" maxUrlLength=\"8192\" maxQueryStringLength=\"8192\" /> Repeat for AD and DS web.config files: C:\\inetpub\\wwwroot\\XMPro-AD\\web.config C:\\inetpub\\wwwroot\\XMPro-DS\\web.config Restart IIS: iisreset /restart HTTP Error 400 - Bad Request (Request Too Long) Error: HTTP 400 error due to large request headers Solution: This issue requires registry changes to increase HTTP.sys limits: Open Registry Editor by pressing Win+R, typing \"regedit\" and pressing Enter Navigate to: HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Services\\HTTP\\Parameters Look for these two registry keys: MaxFieldLength MaxRequestBytes If they don't exist, create them as DWORD (32-bit) values: Right-click in the right pane and select \"New\" → \"DWORD (32-bit) Value\" Name the first value MaxFieldLength: Double-click it to edit Select \"Decimal\" as the base Enter a value of 65536 (or higher if needed) Click OK Right-click again and add a second DWORD value: Name it MaxRequestBytes Double-click to edit Select \"Decimal\" as the base Enter a value of 65536 (or higher if needed) Click OK After adding or modifying these values, restart HTTP service and IIS: net stop http /y net start http iisreset Warning Stopping the HTTP service will temporarily interrupt all IIS websites and services on the server. Certificate Issues Browser Shows Certificate Warning Warning: \"Your connection is not private\" or \"NET::ERR_CERT_AUTHORITY_INVALID\" Cause: Self-signed certificate not trusted by browser Solutions: Option 1: Trust the certificate (for testing): In browser, click \"Advanced\" Click \"Proceed to hostname (unsafe)\" Certificate will be trusted for this session Option 2: Install root certificate in browser: # Export root certificate Export-Certificate -Cert (Get-ChildItem Cert:\\LocalMachine\\My | Where-Object {$_.Subject -like \"*XMPro Root CA*\"}) -FilePath \"C:\\XMPro\\XMProRootCA.cer\" # Manually import to browser: # - Open certificate file # - Install to \"Trusted Root Certification Authorities\" Option 3: Use production certificate (recommended): Obtain certificate from trusted Certificate Authority Import to Windows Certificate Store Update IIS bindings to use new certificate Certificate Private Key Not Accessible Error: Cannot access private key for certificate Solution: # Grant IIS application pool permission to certificate private key # Find certificate thumbprint Get-ChildItem Cert:\\LocalMachine\\My | Where-Object {$_.Subject -like \"*hostname*\"} # Grant permission using certificate MMC: # 1. Run: certlm.msc # 2. Navigate to Personal > Certificates # 3. Right-click certificate > All Tasks > Manage Private Keys # 4. Add \"IIS AppPool\\XMPro-SM\" with Read permission # 5. Repeat for AD and DS application pools JWT Token Signing Certificate Error Error: Failed to load signing certificate for JWT tokens Solution: # Verify JWT certificate exists Get-ChildItem Cert:\\LocalMachine\\My | Where-Object {$_.Subject -like \"*JWT*\"} If certificate is missing, create a new signing certificate: # Configuration $certPath = \"C:\\XMPro\\Certificates\\sign.crt\" $pfxPath = \"C:\\XMPro\\Certificates\\sign.pfx\" $certPassword = \"xmpro123\" # Change this to a secure password # Create directory if needed New-Item -Path \"C:\\XMPro\\Certificates\" -ItemType Directory -Force | Out-Null # Create self-signed certificate $cert = New-SelfSignedCertificate -Subject \"CN=sm\" ` -KeyLength 4096 -KeyAlgorithm RSA -HashAlgorithm SHA256 ` -NotAfter (Get-Date).AddYears(1) ` -CertStoreLocation \"Cert:\\LocalMachine\\My\" ` -KeyUsage DigitalSignature -KeyExportPolicy Exportable -KeySpec KeyExchange # Export certificate files $securePassword = ConvertTo-SecureString -String $certPassword -Force -AsPlainText Export-Certificate -Cert $cert -FilePath $certPath -Type CERT | Out-Null Export-PfxCertificate -Cert $cert -FilePath $pfxPath -Password $securePassword | Out-Null # Remove from store (we only need the files) Remove-Item -Path \"Cert:\\LocalMachine\\My\\$($cert.Thumbprint)\" -Force Write-Host \"Signing certificate created at: $pfxPath\" Write-Host \"Password: $certPassword\" Update configuration to use the new certificate: # Update appsettings.json with correct certificate path $config = Get-Content \"C:\\inetpub\\wwwroot\\XMPro-SM\\appsettings.json\" | ConvertFrom-Json $config.JwtSettings.CertificatePath # Should point to: C:\\XMPro\\Certificates\\sign.pfx SMTP Configuration Issues Email Not Sending Problem: Password reset emails, notifications not being sent Check SMTP configuration: 1. Verify SMTP settings in configuration: # Check Global-variables.json Get-Content \"C:\\XMPro\\Global-variables.json\" | ConvertFrom-Json | Select-Object -ExpandProperty database | Select-Object -ExpandProperty smtp 2. Test SMTP connection: # Test SMTP server connectivity Test-NetConnection -ComputerName smtp.example.com -Port 587 # Send test email Send-MailMessage -From \"test@example.com\" -To \"test@example.com\" ` -Subject \"Test\" -Body \"Test\" ` -SmtpServer \"smtp.example.com\" -Port 587 ` -UseSsl -Credential (Get-Credential) 3. Check IIS environment variables: # Verify EMAIL_* environment variables set for SM application Get-WebConfigurationProperty -PSPath \"IIS:\\Sites\\XMPro-SM\" -Filter \"system.webServer/aspNetCore\" -Name \"environmentVariables\" 4. Common SMTP issues: Issue Solution Port blocked Check firewall allows outbound on port 587 or 465 Authentication failed Verify username/password, may need app-specific password (Gmail) TLS/SSL error Ensure enableSsl: true for port 587, check TLS version support Relay denied SMTP server must allow relay from Windows Server IP 5. Re-configure SMTP: # Edit Global-variables.json and re-run installer .\\install-xmpro-application.ps1 -SkipDatabaseMigration Stream Host Service Issues Stream Host Service Won't Start Error: StreamHost-{hostname} service fails to start Check service status: # Get Stream Host service name $serviceName = Get-Service | Where-Object {$_.Name -like \"StreamHost*\"} | Select-Object -ExpandProperty Name # Check service status Get-Service $serviceName # View service error Get-EventLog -LogName Application -Source $serviceName -Newest 10 Common causes: 1. CollectionId or Secret missing: # Verify Global-settings.json contains collection info Get-Content \"C:\\XMPro\\Global-settings.json\" | ConvertFrom-Json | Select-Object CollectionId, CollectionSecret # If missing, DS database migration failed # Re-run installer with DS selected 2. Cannot connect to DS: # Test DS connectivity Invoke-WebRequest -Uri \"https://hostname:5203/version\" -UseBasicParsing # Check Stream Host config file Get-Content \"C:\\Program Files\\XMPro\\StreamHost\\appsettings.json\" # Verify DataStreamDesignerUrl is correct 3. Permission issues: # Stream Host service runs as NetworkService by default # Grant NetworkService access to installation directory $acl = Get-Acl \"C:\\Program Files\\XMPro\\StreamHost\" $rule = New-Object System.Security.AccessControl.FileSystemAccessRule(\"NT AUTHORITY\\NetworkService\",\"FullControl\",\"ContainerInherit,ObjectInherit\",\"None\",\"Allow\") $acl.SetAccessRule($rule) Set-Acl \"C:\\Program Files\\XMPro\\StreamHost\" $acl 4. Reinstall Stream Host: # Uninstall service $serviceName = Get-Service | Where-Object {$_.Name -like \"StreamHost*\"} | Select-Object -ExpandProperty Name Stop-Service $serviceName sc.exe delete $serviceName # Re-run installer .\\install-xmpro-application.ps1 -Products @('SH') Authentication and Login Issues Cannot Login with Admin Credentials Problem: Login fails with correct username/password Solutions: 1. Verify credentials: Username format: admin@xmpro.onxmpro.com (super admin) or firstname.lastname@companyname.onxmpro.com (company admin) Password: Must meet complexity requirements (8+ chars, uppercase, lowercase, number, special char) 2. Check SM application is running: # Verify SM application pool Get-IISAppPool -Name \"XMPro-SM\" | Select-Object Name, State # Restart if stopped Start-WebAppPool -Name \"XMPro-SM\" 3. Check SM database: # Verify SM database exists and has data sqlcmd -S hostname -U sa -P YourPassword -Q \"SELECT TOP 5 * FROM SM.dbo.Users\" 4. Reset admin password (if forgotten): # Contact XMPro Support for password reset procedure # Or re-run database migration (will reset passwords) .\\install-xmpro-application.ps1 -SkipPrompts # Select SM for migration 401 Unauthorized After Login Problem: Login succeeds but redirects show 401 Unauthorized Cause: OIDC (OpenID Connect) hostname case sensitivity issue Solution: # Check hostname case [System.Net.Dns]::GetHostName() # Hostname must be lowercase in all configurations # Edit Global-variables.json if needed and re-run installer Performance and Stability Issues High CPU Usage Check which process: # Identify top CPU consumers Get-Process | Sort-Object CPU -Descending | Select-Object -First 10 Name, CPU, Id Common causes: w3wp.exe: IIS worker process (normal during data processing) sqlservr.exe: SQL Server (check for slow queries) StreamHost service: Processing data streams (normal during active streams) Solutions: Increase server CPU resources Optimize data stream configurations Add additional Stream Host services for load distribution Memory Issues Check memory usage: # View available memory Get-CimInstance Win32_OperatingSystem | Select-Object TotalVisibleMemorySize, FreePhysicalMemory # Check application pool memory Get-Process w3wp | Select-Object Id, ProcessName, WorkingSet, PrivateMemorySize Solutions: Increase server RAM Configure application pool recycling Monitor for memory leaks in data streams Getting More Help Collect Information for Support When contacting XMPro Support, provide: # 1. System information Get-ComputerInfo | Select-Object WindowsVersion, OsHardwareAbstractionLayer # 2. Installed .NET versions dotnet --list-runtimes # 3. IIS application pools status Get-IISAppPool | Where-Object {$_.Name -like \"XMPro*\"} | Format-Table Name, State # 4. Service status Get-Service | Where-Object {$_.Name -like \"*XMPro*\" -or $_.Name -like \"StreamHost*\"} | Format-Table Name, Status # 5. Recent errors Get-EventLog -LogName Application -EntryType Error -Newest 20 | Format-Table TimeGenerated, Source, Message # 6. Installation logs Get-Content \"C:\\XMPro\\Prerequisites\\XMPro-Prerequisites-Install.log\" -Tail 50 Get-Content \"$env:TEMP\\XMPro-Application-Install.log\" -Tail 50 XMPro Support Resources Support Portal: https://xmpro.na1.teamsupport.com/ Documentation: https://documentation.xmpro.com/ Community Forum: https://community.xmpro.com/ Additional Resources Installation Guide - Main deployment documentation Multi-Server Deployment - Distributed deployments Airgapped Deployment - Offline installation Installer README - Complete technical reference Note For issues specific to the optional prerequisites script (install-xmpro-prerequisites.ps1), note that this tool is not supported by XMPro. For prerequisites issues, refer to the Prerequisites section in the installation guide."
  },
  "src/installation/overview.html": {
    "href": "src/installation/overview.html",
    "title": "XMPro Deployment Overview | XMPro",
    "summary": "XMPro Deployment Overview XMPro platform deployment follows a two-phase responsibility model designed to leverage customer infrastructure expertise while ensuring successful application deployment. This approach separates infrastructure provisioning (customer responsibility) from application deployment (XMPro/Implementation Partner responsibility), enabling efficient deployment across Azure cloud and Windows Server environments. Key Benefits: Clear Ownership: Defined responsibility boundaries prevent deployment delays Customer Control: Infrastructure remains under customer governance and compliance Expertise Alignment: Customers manage infrastructure, XMPro manages application deployment Flexibility: Supports both Azure cloud and on-premises Windows Server deployments Deployment Responsibility Matrix Customer Responsibilities XMPro / Implementation Partner Responsibilities Infrastructure Provisioning Provision all required infrastructure resources including compute, database, storage, and networking components as specified in the respective deployment documentation (Azure Terraform, Windows Server 2022) Application Deployment Deploy XMPro applications using automated deployment scripts and configuration management Platform Configuration Configure compute resources, networking, security groups, and ensure all prerequisites are met Service Integration Configure inter-service communication, authentication flows, and application-specific settings Database Setup Install and configure SQL Server, create required databases with proper security and network access Data Migration Execute database schema migrations and populate configuration data during deployment Security & Compliance Implement firewall rules, certificate management, and ensure compliance with organizational policies Application Security Configure application-level security, encryption, and authentication between XMPro services Network & Access Control Configure network access, load balancing, and provide secure access for deployment team Operational Validation Perform end-to-end testing, health checks, and validate all XMPro functionality Documentation & Handoff Provide access credentials, network topology, and infrastructure documentation to deployment team Knowledge Transfer Deliver operational documentation, training, and ongoing support for XMPro platform Two-Phase Deployment Model XMPro deployments follow a two-phase approach that separates infrastructure provisioning from application deployment: Phase 1: Infrastructure Provisioning Objective: Establish the foundational infrastructure required for XMPro applications Customer Focus: Provision resources or infrastructure Configure networking, security, and database systems Ensure all prerequisites are met per specifications XMPro / Implementation Partner Focus: Provide technical guidance and infrastructure requirements Validate that infrastructure meets application needs Approve readiness for application deployment Phase 2: Application Deployment Objective: Deploy and configure XMPro applications on the prepared infrastructure Customer Focus: Provide access and coordinate with deployment team Review and approve go-live authorization XMPro / Implementation Partner Focus: Execute application deployment using automated scripts Configure inter-service communication and security Perform end-to-end testing and validation Deliver knowledge transfer and documentation Key Benefits of This Approach Clear Separation: Infrastructure and application concerns are handled independently Expertise Alignment: Each party focuses on their area of expertise Risk Mitigation: Issues are identified and resolved at the appropriate phase Flexibility: Works with or without implementation partners RACI Matrix Activity Customer XMPro / Implementation Partner Infrastructure Provisioning A/R C Platform Configuration A/R C Database Setup A/R C Security & Compliance A/R C Network & Access Control A/R C Documentation & Handoff A/R I Application Deployment C A/R Service Integration C A/R Data Migration C A/R Application Security C A/R Operational Validation C A/R Knowledge Transfer I A/R RACI Legend: R - Responsible (performs the work) A - Accountable (ensures completion and quality) C - Consulted (provides input and expertise) I - Informed (kept updated on progress) Documentation Requirements Customer Must Provide Infrastructure Documentation: Network architecture and security configurations Access credentials and administrative permissions Environment specifications and resource details Compliance and security policy requirements XMPro / Implementation Partner Will Provide Deployment Documentation: Installation procedures and validation steps Configuration guides and operational manuals Architecture diagrams and technical specifications Troubleshooting guides and ongoing support documentation Deployment Process Overview Infrastructure Deployment Deploy XMPro - Infrastructure provisioning and platform deployment using: Azure Terraform Deployment - Modern container-based deployment for Azure environments Windows Installer - Native IIS deployment for on-premises Windows Server environments Legacy Options - ARM templates for v4.4 and earlier versions Post-Deployment Configuration Post-deployment - Complete the setup with: Tenant Configuration - Set up your first tenant company Stream Host Deployment - Add additional processing capacity as needed Agents & Connectors - Upload and configure integration components This responsibility model ensures successful XMPro deployments while maintaining clear boundaries, leveraging respective expertise, and enabling scalable deployment processes across diverse customer environments."
  },
  "src/release-notes/index.html": {
    "href": "src/release-notes/index.html",
    "title": "Platform | XMPro",
    "summary": "Platform v4.5 Release Notes This section contains the release notes for XMPro v4.5 platform, providing information about new features, improvements, and bug fixes across all core products. Warning Security update: Mitigate high-severity vulnerabilities by upgrading all products to v4.5.1+. Breaking change: v4.5.4 contains a breaking change to the Azure Terraform deployment. Known Issues Product Description Reported Fixed App Designer Team Support 15739: Alert Action button not working as expected when an Action is also defined v4.4.16 v4.5.4 App Designer Bug 20828: Assigning or Sharing a recommendation alert results in an error message when using the Alert Action Block v4.5.0 v4.5.3 App Designer Bug 21266: Data Grid is no longer converting datetimes from UTC time to local v4.5.0 v4.5.3 App Designer Team Support 16872: Data Grid header filter does not apply local timezone formatting like it does to the columns data v4.4.22 v4.5.4 App Designer Team Support 16939: Recommendation Version misleads to a different version on Title Modification v4.5.3 v4.5.4 Data Stream Designer Team Support 16609: Removing 'View Collection' right causes errors, but including it exposes Collection secret v4.5.1 v4.5.3 Package Manager Team Support 15214: Sort Index does not save on Sub Groups v4.4.19 v4.5.4 Stream Host Team Support 16822: Stream Host SignalR connection interruptions require manual intervention to restore connectivity v4.4.22 v4.5.4 Stream Host Team Support 16827: Data Stream Agent continues polling after unpublish with \"Error Polling - No Agent instance yet\" errors v4.4.22 v4.5.4 v4.5.4 Date Released: 26 Nov 2025 Change Type Description Security Product security and stability: We've mitigated security vulnerabilities and implemented comprehensive security hardening across the platform: Removed Microsoft.VisualStudio.Web.CodeGeneration.Design from App Designer for CVE-2025-55247. Upgraded Node.js from 6.17.1 to 22.11.0 and resolved transitive dependency vulnerabilities (tough-cookie, form-data, unset-value, braces, jsrsasign) in Subscription Manager to remediate 1 Very High and 4 High severity Veracode vulnerabilities caused by an outdated package-lock.json file generated with npm 3.10.10. Limit Data Access: Implemented the Principle of Least Privilege across App Designer and Data Stream Designer by adding endpoint-level authorization to affected controllers. Input Validation: Implemented comprehensive input validation and sanitization using FluentValidation to affected endpoints in App Designer and Data Stream Designer. Feature Windows Server 2022 deployment capabilities: Introduced a one-click Windows installer that automates the complete deployment of XMPro platform components (Subscription Manager, App Designer, Data Stream Designer, and Stream Host) in under 30 minutes, including all prerequisites, database migrations, IIS configuration, and SSL certificate setup. The installer supports multi-server deployments and air-gapped environments, with comprehensive validation and automated rollback capabilities. Deployment Azure Terraform Deployment Enhancements Providing enterprise-grade security, flexibility, and compliance: Azure AD Authentication for SQL Server: Enables passwordless authentication using managed identities, improving security posture and eliminating the need to manage SQL passwords. Custom Database Naming: Supports custom database names throughout the deployment stack (including AAD SQL users and licenses containers), enabling compliance with enterprise naming conventions. Private Endpoint Support: Comprehensive private endpoint configuration for all XMPro App Services (AD, DS, SM, AI) with automatic DNS integration, enabling secure private network access for production deployments. Configurable RBAC Authorization: Added support for both Azure RBAC and legacy access policies for Key Vaults, providing deployment flexibility for different enterprise security models. Removal of Hardcoded Passwords: Eliminated all hardcoded passwords from Terraform modules to meet security compliance requirements. Breaking change - Passwords must now be explicitly provided via tfvars files. Redis SignalR Configuration: Added Redis connection string configuration to Subscription Manager prep container, enabling proper SignalR Redis backplane for scaled deployments. Enhancement Deployment At Scale - Enhanced Authentication: New zip-based import and export endpoints allow solution developers to handle their own repository authentication without being limited to Git. Existing Git-based endpoints have been enhanced to support nested repository URLs for Enterprise GitLab compatibility. Enhancement Team Support 16908: Data Grid Override Values from Data Source: The Data Grid now supports override values from data sources in \"Batch with External Save\" mode. You can now configure override values (such as BusinessRoleId) that are automatically included in insert and update payloads, ensuring data integrity when saving grid data externally. Enhancement Team Support 17151: Recurrence Schedule Handling After Stream Host Restart: When a Stream Host restarts, Data Streams wait for their next scheduled occurrence rather than executing immediately, ensuring predictable execution patterns and not overloading the Stream Host. Execution behavior examples were added to the Recurrent Data Streams article. Fix Package Manager: Multilingual Support: Dropdown options and pre-filled field values are not translated to your selected language, appearing only in English regardless of your preferred language. Dropdown options and pre-filled field values are now included in the translation system using TranslationMap properties. Application Stability: You experience unexpected crashes when deleting grid controls or creating new connector packages, causing loss of work. Package Manager now gracefully handles errors without terminating, protecting your work and providing diagnostic information for troubleshooting. Team Support 15214: Sub-Group Sort Index Persistence: When you reorder sub-groups in settings, the ordering reverts to the original configuration after saving, preventing you from organizing settings in your preferred logical order. Sub-group sort index values now persist correctly after saving. Fix Team Support 15739: Alert Action Button Execution Order: When you configure an Alert Action button under the Recommendations block with both a dialog action (like \"Assign This Recommendation Alert\") and a custom action (like navigating to a page or updating a data source), the custom action executes before the dialog opens, making the Alert Action control unusable. The operation order has been corrected so that the dialog now opens first, allowing you to complete the dialog interaction before any custom actions execute. Fix Team Support 16822: Stream Host SignalR Connection Stability: When network issues occur, you experience SignalR connection interruptions requiring manual intervention to restore connectivity to the Data Stream Designer. SignalR connections now automatically reconnect when network interruptions occur using stateful reconnection, eliminating the need for manual intervention and maintaining your connection to the Data Stream Designer during temporary network issues. Fix Team Support 16827: Data Stream Agent Polling Error After Unpublish: When you unpublish a recurring Data Stream that contains polling agents (such as SQL Context Provider), the Stream Host continues attempting to poll and reports \"Error Polling - No Agent instance yet\" errors. This creates confusion and unnecessary error logs in your Stream Host. The Stream Host now terminates all polling operations when a Data Stream is unpublished, ensuring that agent instances are properly cleaned up and no further polling errors occur after unpublishing. Fix Team Support 16872: Data Grid Header Filter Timezone Formatting: Date filters in Data Grid headers display dates in UTC format while the grid columns show dates in your local timezone, with inaccurate results. Date filters in Data Grid headers now apply the same local timezone formatting as the grid columns, ensuring consistency between what you see in the cells and what you can filter by. Fix Team Support 16939: Recommendation Version Navigation on Title Modification: When you modify a recommendation title and click Save, the application unexpectedly navigates you to a different recommendation version instead of staying on the current version, causing confusion and making it difficult to verify your changes. The Save operation now maintains your current recommendation version context, allowing you to verify your updates without losing your place in the workflow. v4.5.3 Date Released: 29 Sep 2025 Change Type Description Security Enhanced Security Framework: Significant security hardening across the XMPro platform, including protection against clickjacking and reverse tabnabbing attacks, improved error handling and input validation, and resolution of multiple medium-severity vulnerabilities in core dependencies. We've implemented comprehensive security header enforcement across all API controllers in the Application Designer (AD), Data Stream Designer (DS), and Subscription Manager (SM) components, upgraded JavaScript libraries to address known vulnerabilities, and enhanced cookie security attributes. Additional improvements include container-level security updates and strengthened endpoint protection to prevent unauthorized resource enumeration. Enhancement Deployment At Scale - Enhanced validation and error reporting: More details are provided for individual component failures during import, enabling faster resolution. Report all version differences found per Agent/Connector - rather than the first - so that all can be resolved in a single pass. Fix Bug 20828: Assigning or Sharing a recommendation alert results in an error message when using the Alert Action Block: When you assign or share a recommendation alert using the Alert Action Block, you encounter an error \"Unable to assign Recommendation\" that prevents the operation from completing. Fix Bug 21266: Data Grid is no longer converting datetimes from UTC time to local: Date values displayed in Data Grid are shown in UTC time instead of being converted to your local timezone, making it difficult to interpret timestamps correctly. Fix Team Support 16609: Removing 'View Collection' right causes errors, but including it exposes Collection secret: When you remove \"View Collection\" permission from a user who should have read-only access to some data streams (to hide the Collection secret), they encounter an error \"Unable to fetch Devices\" when viewing a category that contains published data streams. v4.5.2 Date Released: 15 Aug 2025 Change Type Description Feature Azure Terraform deployment capabilities, replacing previous manual deployment processes with an automated, streamlined infrastructure provisioning experience and delivering major improvements to Azure deployment along with complete documentation. v4.5.1 Date Released: 28 Jul 2025 Change Type Description Security Product security and stability: We've mitigated several high-severity vulnerabilities by upgrading the corresponding NuGet packages: Upgraded system.formats.asn1 from 6.0.0 to 6.0.1 in App Designer for CVE-2024-38095 Upgraded system.security.cryptography.xml from 4.4.0 to 4.4.2 in App Designer for CVE-2018-0764/CVE-2018-0765 Upgraded Microsoft.Extensions.Caching.Memory from 8.0.0 to 8.0.1 in Data Stream Designer for CVE-2024-43483 Deployment Container-Based Enhancements: Introduced runtime certificate generation using dedicated builder containers, eliminating baked-in certificates and supporting both self-signed and customer-provided certificates Implemented hybrid configuration support to enable Subscription Manager (SM) running on a Windows host while other applications run in Linux containers, resolving SM's Linux container reliability issues. Resolved SM connectivity issues in container deployments by implementing proper BaseUrl/InternalBaseUrl handling, ensuring applications connect correctly from both server-side and client-side perspectives. v4.5.0 Date Released: 20 Jul 2025 Common Change Type Description Feature Containerized Deployment: Both App Designer and Data Stream Designer can now be deployed as containers using Docker and orchestration platforms like Kubernetes. This containerized approach provides consistent deployment environments, improved scalability, and simplified infrastructure management. As an administrator, you can now deploy XMPro applications using modern container orchestration tools, enabling easier scaling, rolling updates, and integration with cloud-native infrastructure while maintaining environment consistency across development, staging, and production. Feature Deployment At Scale: A comprehensive set of REST APIs for managing application deployments across enterprise environments. These APIs provide programmatic access to export and import applications, manage Git repositories, handle deployment dependencies, and control access through new ManageDeployment permissions with secure CORS configuration. This means you can now automate your deployment processes, integrate XMPro with CI/CD pipelines, and manage large-scale deployments programmatically rather than through manual processes. App Designer Change Type Description Enhancement Enhanced Expression Component: The Expression component can now read data from multiple parent components simultaneously. Previously, expressions were limited to reading from a single parent, which restricted your ability to create complex calculations and data relationships. This enhancement allows you to build more sophisticated expressions that combine data from multiple sources in your application. Fix Survey Archiving Display: When you archive a survey in a recommendation, the survey would continue to appear active until you manually refreshed the page. This was confusing as it suggested the archiving action hadn't worked. The survey block now updates its display state immediately when archived, providing instant visual feedback that the action was successful. Fix Timeline URL Navigation: When you click on timeline entries to navigate to specific time periods or events, the URL navigation wasn't working properly, leaving you on the same view regardless of your selection. Timeline navigation now works correctly, allowing you to bookmark specific time periods and navigate directly to timeline events via URL parameters. Fix Email Notification Links: When you receive email notifications about alerts, clicking the links in the email would take you to the standard alert view instead of the specific alert context. Email notification links now direct you to the appropriate alert view with proper context, making it easier to act on notifications directly from your inbox. Fix Tree Grid Selection Persistence: When you configure a Tree Grid with multiple selection enabled and set default selections, the defaults wouldn't persist after page load. You would have to manually reselect items each time you visited the page. Tree Grid controls now properly retain their multiple selection defaults on page load, maintaining your configured selections. Fix Data Grid DateTime Filters: When you set up a Data Grid with DateTime columns, the row filter options didn't match those available for Date columns, limiting your filtering capabilities. DateTime columns now have the same comparison operators as Date columns, giving you consistent filtering options across different date-related data types. Fix Data Source Field Sorting: When you configure data sources in App Designer, the field list wasn't sorted alphabetically, making it difficult to find specific fields in large datasets. Data source fields are now sorted alphabetically, improving the designer experience when working with complex data structures. Fix Template Category Persistence: When you assign a template category to an application, the category would sometimes disappear or not save properly. Template categories now persist correctly, ensuring your application organization and categorization remains intact. Fix Validation Groups: When you use validation groups in App Designer, various issues could occur that prevented proper validation behavior. Validation group functionality has been improved to work reliably across different component configurations. Fix Notes Auto-Update Prevention: When you work with notes in recommendations, notes would automatically update without prompting you, even when notes were null or previously saved. This could lead to unintended overwrites of your content. Notes now only update when you explicitly save them, preventing accidental data loss and ensuring your notes remain under your control. Fix Application Name Translations: Application names were inconsistently translated across different products, with some showing incorrect or misleading translations (particularly affecting Portuguese-Brazil). Application names now display consistently and accurately across all products and locales. Data Stream Designer Change Type Description Fix Timeline Form Updates: When you use agents in your data streams, timeline views wouldn't show form updates properly, making it difficult to track changes and modifications. Timeline components now correctly display form updates when agents are involved, providing complete visibility into your data stream modifications and agent interactions. Subscription Manager Change Type Description Fix Language Dropdown Population: When you access the profile settings, the language dropdown would intermittently appear empty, preventing you from changing your language preference. The language dropdown now populates consistently, ensuring you can always modify your language settings when needed. Fix Company Request Rejections (Non-English): When your system is configured for non-English languages, you were unable to reject company subscription requests, limiting your ability to manage subscriptions in localized environments. Company request rejections now work properly across all supported languages. Fix Product Description Translations: Product descriptions in Subscription Manager weren't being translated, showing only English text regardless of your selected language. Product descriptions now display in the appropriate language based on your locale settings. Fix Search Criteria Spacing: When you perform searches in Subscription Manager, extra spaces were being added to search criteria results, affecting the display formatting and potentially impacting search accuracy. Search results now display without unwanted spacing. Fix Settings Blade Translation Coverage: Various text elements in the settings blade weren't translated, creating an inconsistent user experience in non-English environments. Missing translations have been added to provide complete localization coverage in the settings interface. Fix Home Page Subscription Messages: Subscription access messages on the SM home page weren't translated, displaying only in English regardless of your language preference. These messages now appear in the appropriate language based on your locale settings. Fix Password Change Confirmation: When you change your password, the confirmation message wasn't translated, appearing only in English. Password change confirmation messages now display in the appropriate language for your locale. Fix Spanish Layout Heading Issues: When using Spanish (es-ES) locale, headings weren't being translated correctly, causing display issues and confusion. Spanish headings now translate properly across all interface elements. Fix Email Template Address Updates: All email notification templates across the platform now use the correct company address. This ensures that automated emails sent from XMPro (including alerts, invitations, and notifications) display the proper contact information, improving professional communication with users and external stakeholders. Package Manager Change Type Description Enhancement Settings Reordering: You can now reorder Groups and Settings within the Package Manager Settings Blade using drag-and-drop functionality. This allows you to organize your agent configuration options in a logical order that makes sense for your specific use case, improving the user experience when configuring agents. Fix File Type Support: You can now attach any file type when adding Resource references in the Package Manager. Previously, only specific file types were supported, which limited your ability to include custom documentation, configuration files, or other resources with your agent packages. This enhancement removes file type restrictions, giving you greater flexibility in packaging your integrations. Fix Crash Prevention: When working with connector packages, you previously encountered app crashes when deleting grid controls or creating new connector packages. The application would force close unexpectedly, losing your work. This issue has been resolved, and the Package Manager now handles grid deletions and connector package creation safely without crashing. NuGet Packages Agent Development No changes to XMPro.XMIoT.Framework. Connector Development No changes to XMPro.Integration.Framework, XMPro.Integration.Helpers, or XMPro.Integration.Settings."
  },
  "src/resources/faqs/agent-faqs.html": {
    "href": "src/resources/faqs/agent-faqs.html",
    "title": "Agent FAQs | XMPro",
    "summary": "Agent FAQs Frequently asked questions regarding Agents. Are Agents thread-safe when running in a Data Stream? Yes, Agents are thread-safe. Each Stream Object (an Agent added to a Data Stream), including multiple instances of the same Agent, is an independent entity. How do Agents process events? Each Stream Object (an Agent added to a Data Stream) has its own thread-safe incoming event queue and processing thread. They receive events via input their endpoints according to the arrows added in the Data Stream. Further Reading Agent Endpoints Can Agents influence each other outside of the regular publish/subscribe mechanism? While Agents are designed to communicate only through the arrows, there are potential ways they might interact: Shared global variables (as the current Stream Host runs streams in a single process) Network communications Indirect effects, such as: One agent consuming excessive CPU processing power Multiple Agents making conflicting use of a shared resource (e.g., a physical device) Multiple Agents using the same shared library in a non-thread-safe manner What is a Stream Host? A Stream Host is the environment in which Data Streams run. It manages the execution of multiple Stream Objects within a single process. Further Reading Collection and Stream Host What are Arrows in the context of XMPro? Arrows are the links between Stream Object endpoints in a Data Stream. They represent the pathways through which Stream Objects pass data to each other. Further Reading Adding an Agent to the Canvas Input Mapping and Arrow Configuration What is a Data Stream? A Data Stream is a visual display of data flow, where the flow is represented by Stream Objects connected by arrows that perform actions on the data in real-time. Further Reading Data Stream Do Agents have memory buffers, and how do they work? Yes, each Agent has a memory buffer for events to be processed. This buffer is part of the Agent's thread-safe incoming event queue. Important characteristics of these buffers include: Fixed size: The buffer has a predetermined capacity to prevent excessive memory consumption on Stream Host devices, especially in cases of misconfigured data streams. Overflow behavior: When an agent's buffer is full, new incoming events will not be processed. This can lead to data loss if the incoming data rate consistently exceeds the agent's processing rate. Configuration considerations: It's crucial to properly configure data streams and monitor agent performance to ensure that buffer overflow situations are minimized, maintaining efficient data processing. Further Reading Agent Event Queue Capacity"
  },
  "src/resources/faqs/configuration.html": {
    "href": "src/resources/faqs/configuration.html",
    "title": "Configuration FAQs | XMPro",
    "summary": "Configuration FAQs Find answers to some of the most frequently asked configuration questions. App Designer What should I do when my SQL stored procedure exceeds the 30-second timeout? It is not possible to change the 30-second timeout limit. First optimize your stored procedure with the help of a tool like Claude. If it still times out, use this asynchronous approach with Data Streams to ensure users don't wait: Create a Queue Table CREATE TABLE StoredProcQueue ( ID BIGINT IDENTITY(1,1) PRIMARY KEY, Parameters NVARCHAR(MAX), Status TINYINT NOT NULL DEFAULT 0, -- 0=Pending, 1=Processing, 2=Completed, 3=Failed CreatedDate DATETIME2 DEFAULT GETDATE(), CompletedDate DATETIME2 NULL ); -- Critical indexes for performance CREATE INDEX IX_StoredProcQueue_Status_Created ON StoredProcQueue (Status, CreatedDate) WHERE Status IN (0,1); -- Only index active records CREATE INDEX IX_StoredProcQueue_Cleanup ON StoredProcQueue (Status, CompletedDate) WHERE Status IN (2,3); -- For cleanup operations Modify Your App's button action to insert a record into the queue table with input parameters Create a Data Stream a. SQL Listener Agent to trigger the data stream when new records are inserted into StoredProcQueue b. SQL Action Agent to execute your stored procedure using the parameters from the queue record, with an appropriate execution timeout. Optionally, update the queue record status when processing completes. Your App can query the table to display progress to users. Further Reading SQL Server Listener and Action Agents How do I pass selected grid rows to a stored procedure? You can accomplish this by linking the grid's selection to a variable, then using that variable as input to your stored procedure. Follow these steps: Create a String Variable SelectedWorkOrderIDs to store the comma-delimited list of selected primary key values Configure the Data Grid to allow multiple selection and bind the Value property to Variables > SelectedWorkOrderIDs so that the variable is automatically updated when a user selects/deselects rows Add a Box to hold the button. Connect the Data Source to your stored procedure and bind the stored procedure input parameter to the variable using \"Dynamic Properties\". Add a Button within the Box. Set the Action to Refresh Data Source (the parent Box's stored procedure), so that when clicked it will execute the stored procedure with the selected primary key values as input. Important Considerations To avoid errors when the button executes on page load or when clicked without any orders selected, ensure the stored procedure handles null or empty string parameters gracefully. You could return a value from the stored procedure, e.g. status message. If your stored procedure takes longer than 30 seconds to execute, see What should I do when my SQL stored procedure exceeds the 30-second timeout? Further Reading Data Grid Properties Page Variables Why can't I de-select 3000+ rows in my Data Grid? I have enabled paging and multi-select. You are likely using the Multiple Selection Mode \"All Pages\" option - which will have difficulty with such dataset over 200 records. Rather use \"Pages\" option, which selects and de-selects rows on the current page, removing performance issues regardless of the size of your dataset. If you need cross-page selection, evaluate whether filtering could reduce your dataset before selection. Or perhaps you could include a \"Process All\" button. How do I rotate text in App Designer? In the video below, we demonstrate how to rotate text -90 degrees around the z-axis using block styling's transform option. How do I export Grid Data from my App to Microsoft Excel? In the video below, we demonstrate how to toggle on your Data Grid's export button so that at runtime the grid contents can be exported to Excel. Further Reading Data Grid Properties - Allow Export To Excel Why doesn't the Date selector in my App match my computer's local date format? \"My computer is configured to use the date format DD/MM/YYYY, but my date selector is formatted as MM/DD/YYYY. How do I change it?\" The Date Selector date display format is based on the browser display language, not your computer's local settings. For example: When the browser display language is set to English (Australia), the date format will be DD/MM/YYYY. When the browser display language is set to English (United States), the format will be MM/DD/YYYY. You should adjust your browser's display language settings - rather than your computer's local settings - to change the date format in XMPro. I've added a new recommendation - why can't I see the triggered alerts in the recommendation grid view? You, as the owner of the recommendation, will not see the recommendation alerts unless you give yourself Run Access to your own recommendations. How to manage run access How do I drill down with data from a chart? You can achieve this by combining navigating between pages and passing data to the Page by configuring the Pass Page Parameters. The data passed can be static, an expression, or dynamic. Please refer to the how-to article below for step-by-step instructions. Further Reading Navigation and parameters How to pass dynamic data to the page Data Stream Designer Can I use an older version of an Agent in a Data Stream? \"I'm copying the same pattern used in another Data Stream and I want to use the same version of a specific Agent (v2.7) when a newer version is available (v2.8).\" No, using an older version of an Agent when a newer version is available is not possible. The latest Agent should incorporate all of the functionalities of the previous version as well as any further modifications made. However, you could clone the original Data Stream and choose not to upgrade the Agent to the latest version. Further Reading Cloning Upgrade a Stream Object Version How do I view errors on my Stream Host? In the video below, we demonstrate how to view the log for a particular Stream Host in a Collection. The log contains errors encountered when publishing or running a Data Stream. Further Reading Stream Host Logs How to check Data Stream Logs How are the Stream Load Metrics calculated? \"I'm trying to reconcile the Stream Load metric in Data Stream designer with what I'm expecting based on the listeners. Is the metric calculated on the stream outputs or the inputs? I have 3 listeners, each running at a 1 second interval, so I expect a 180/min metric. Is the ~360/min metric because there are double the number of outputs (action agents) per listener?\" Stream load is different from ingestion rate. The Stream load represents the total number of events published by all Stream Objects on the canvas. In this case, 60 x the total number of agents on the screen (assuming your Listeners bring back 1 record on every poll). You would notice the actual number is much less because although you want it to run every second, the calls to dependencies like SQL etc do not return its data as quickly and hence the actual rate is less. Generally, the number of events published per Agent decreases as you work through your data stream, because the intention is to work towards a smaller payload focused on the event in which you're interested. Can I use more than one Run Recommendation Agent in a Data Stream? We advise you to only have one recommendation agent on a data stream. A recommendation rule is configured against a single Data Stream, not a given Stream Object in a Stream. It will find the first Run Recommendation in the selected Data Stream and let you define your Recommendation Rule against the output payload of that Agent. If the payload differs at runtime, you may get weird results when triggering a recommendation alert. If the data cannot be merged (using a join or union transformation) and used in the different recommendations, then consider creating 3 different data streams. Remember you can have one data stream feed data to as many recommendations as you want to, BUT you should only have one run recommendation agent on a data stream canvas. My Data Stream Connector can do everything. Why use the other Connectors? Although a wide variety of data can be surfaced from a Data Stream into your Application using the Data Stream Connector, there is a downside. The Data Stream is constantly pushing data, which can lead to out-of-resource errors - which appear as XMPro product errors. If your data requirement is ad-hoc, consider the other Connectors. Further Reading List of App Designer Connectors Connector How do I set up Stream Host Variables/provide unique Asset configuration? Although each Stream Host in a given Collection downloads the same definition of a Data Stream, the Variables defined in Data Stream Designer can be overridden by the individual Stream Host to provide the unique configuration per Asset e.g. OPC IP Address. Please refer to the how-to articles below for step-by-step instructions. Further Reading How to override Stream Host variables How to manage variables I am the co-owner of the data stream and an administrator - why is the \"Delete\" button disabled? To delete a Data Stream, your account must meet the following conditions: You need Co-Owner or Write access to the specific Data Stream. You must have the DeleteUseCase product right assigned to your user account, which is configured in Subscription Manager. Once you have access to the Data Stream and the right to delete, click Properties to access the Delete button. The Delete button on the canvas is used to delete Stream Objects. Further Reading Sharing Access to a Data Stream Editing Rights and Access for a User Deleting a Data Stream Deleting a Stream Object"
  },
  "src/resources/faqs/general.html": {
    "href": "src/resources/faqs/general.html",
    "title": "General FAQs | XMPro",
    "summary": "General FAQs Find answers to some of the most frequently asked general questions. Training Is there a training outline? An end-to-end course can be found at XMPro Courses. It is broken down into 17 lessons - totaling 7 hours - covering an overview, Data Stream Designer, Recommendations, and App Designer. You can also find an extensive array of YouTube videos on various topics of interest on our YouTube channel XMPro learning. Are there any prerequisites for the training? As XMPro is a no-code platform, there are no technical prerequisites. We do recommend the following to make your training more effective: Start with a Use Case/problem statement in mind Have access to an XMPro instance so you can practice and work out issues Session Timeout How does the XMPro sign-in process work? When you try to sign in to XMPro Data Stream Designer or App Designer, you're redirected to the linked XMPro Subscription Manager's sign-in page. Enter your username and password to log in. Upon signing in, you receive credentials as browser cookies for both Subscription Manager and the site you wish to access. Subscription Manager redirects you back to the requested site, granting you an access token using those cookie credentials. The access token is valid for the duration specified in the site's Session Timeout setting, while cookies last for longer periods (e.g., an hour). Cookies enable access to the website's pages and assets like JavaScript and images, while the access token allows you to access the site's data, which is essential for activities like navigating, viewing live updates on app pages and saving changes. Note The Session Timeout setting is accessible by the Site Admin and can be found in Subscription Manager under the details blade for the product (e.g., App Designer). How long do I stay signed in? Without \"Remember Me\": you stay signed in for 1 hour or until your browser session ends (e.g. closing the browser window). With \"Remember Me\": you stay signed in for 30 days or until the site is unable to silently refresh the credentials. Note The Remember Me checkbox can be found when signing into XMPro. How does the Silent Refresh functionality work? When using XMPro App Designer, Data Stream Designer, or Subscription Manager, the site attempts a silent refresh of the credentials as the access token nears its expiry time. If successful, a new token is granted, valid for the duration specified in the Session Timeout setting. If unsuccessful, the site displays a login expired warning with a prompt to sign in again. Clicking the button redirects you to Subscription Manager for credentials. If the Subscription Manager cookie is still valid, it automatically issues a new access token and redirects back to the original site; otherwise, you're prompted to sign in again. Successful attempts through either path will refresh the cookie credentials if they're nearing expiry and meet refresh conditions. Refreshing the page will also update the credentials. Versioning What version of XMPro am I using? Whether you are logging a support issue or looking for a specific product feature, knowing the version of the XMPro Platform you're using is important. Click the help icon top right of the web applications to view the help blade. It contains the version number as well as helpful links such as release notes and logging a support ticket. From v4.4.4 onwards, you can access more details in the following ways: For web applications only, check the /version endpoint, which produces a response such as... { \"ApplicationTitle\": \"XMPro App Designer\", \"XMProPlatformVersion\": \"4.4.4\", \"InformationalVersion\": \"4.4.4.28+8c9912b045\", \"GitCommitId\": \"8c9912b04592ac2d54bf4fa9a522203cbd21bc98\", \"GitCommitDate\": \"2024-05-10T04:41:02Z\" } For all applications, check the log files. On application start, a log event like the following will be generated. [12:00:00.123] [Information] [XMPro.Runtime.Runtime] Running \"XMPro Stream Host\" \"4.4.4.33+bc71a3ebfc\" on \"Ubuntu\" [RuntimeInfo] RuntimeInfo { Title = XMPro Stream Host, XMProPlatformVersion = 4.4.4, AssemblyInformationalVersion = 4.4.4.33+bc71a3ebfc, GitCommitId = bc71a3ebfc82632d60586503878e8867fbf2e0b4, GitCommitDate = 2024-05-13T07:10:29Z }"
  },
  "src/resources/faqs/implementation.html": {
    "href": "src/resources/faqs/implementation.html",
    "title": "Implementation FAQs | XMPro",
    "summary": "Implementation Find answers to some of the most frequently asked implementation questions. Starting Out Where do I start with XMPro? XMPro strongly recommends that all projects should have a defined ROI. Therefore the initial Use Cases, collection of data pertaining to the Business Problems that you are seeking to resolve, and evaluation of project outcome at the midpoint and project close are vital to substantiate the ROI. A synopsis of our framework for a project is as follows: Define the Business Problem that needs to be addressed Identify Bad Actors Care must be taken to identify the initial Use Case Refer McKinsey study 4 steps on page 12 Refer McKinsey study Avoid Pilot Purgatory Gather data for the initial Proof of Value or Pilot Commence Proof of Value or Pilot Hold a mid-point review & measure success against these questions Does the tool work? Does it deliver value? Would the customer use it? Collect the ROI achieved in the Pilot Period Project Gate = Go / No Go decision To build a Digital Twin of a factory, do I start with the whole factory or start small? Always start small. Digital transformation is achieved by many small projects that lock in success at each step. The overall goal is to achieve project success early and expand. There will be many challenges for you to achieve success, by starting with small projects you lower the overall risk of failure. The positive flip side of small projects is that you fail fast, and the costs are limited. I want Predictive Maintenance, and I want it now. We think it makes sense to think of two components of PdM (Predictive Maintenance): First Principle / Engineering Models – The starting point for most predictive solutions supported by real-time sensor data AI / Statistical Models – Use the AI / Statistical models to augment decision support but requires quality data and contextual models Subject to quality data, the First Principle / Engineering Models are the fast start as the formula is agreed upon and the model is ready to go. AI / Statistical Models require more effort and analysis – one will need the assets failure history and time and resources to refine your models. Another view of your predictive maintenance goal is to consider the maturity of the use cases. Smart Asset Management includes the smart use of condition monitoring, predictive maintenance, and process optimization. What is XMPro's approach to AI? XMPro is not an AI company. We can call the AI / Statistical models and use the output to trigger recommendation alerts, but the models are sourced from you or one of our AI partners. How does XMPro do it? We provide integration building blocks in our Data Streams to call the model and use the model output for computation of the real-time data stream, which is used in the creation of a recommendation for the asset. XMPro has the capability to pass data to Azure Machine Learning and train models. These models can be called by other XMPro Data Streams to use the model output for evaluation of real-time streaming data. For example, the RUL of a Secondary Crusher. Further Reading How to work with Data Streams Python Integration Azure ML Integration I've seen Mining examples. Can XMPro compose a Digital Twin for utilities? Yes, we can. In 2021/22 XMPro predominantly worked in the Mining and Oil & Gas sectors, and we are now expanding to other asset-intensive industries such as Utilities and Chemicals. These asset-intensive industries all have similar equipment, challenges, and use cases. We find that we can transport solutions from one to the other in these industries. The lessons learned from Mining can accelerate solutions for Utilities, bringing a slightly different perspective on how to approach challenges from a \"bad actor\" and failure analysis point of view rather than a traditional \"similar industry\" approach. Below is our strategy for expansion in asset-intensive industries with transferable use cases around asset availability problems. Architecture Can XMPro be installed and used on-premise? Yes. Currently, the majority of XMPro deployments are Cloud-based. XMPro can be deployed on-premises, on Azure/AWS, or as a hybrid with parts on-premises and in the cloud. Typically for the hybrid deployment, the stream host is deployed on-premises with the core application being hosted on the cloud. On-premise deployments have been driven by the need for remote locations, as well as constraints on internet access from within a corporate network. If XMPro is in the Cloud, can I connect to my On-Premise application(s)? Yes. If your applications are internet-facing, then a cloud stream host can be used. If your applications are behind a firewall and internal to your network, then in this instance XMPro will be a hybrid deployment model, with the stream host located on-premises. Do I need a separate server for the stream host, or will it run on the same application server? The preferred approach is to have a separate infrastructure for the stream host. It is possible that your XMPro deployment has only one Stream Host. However, this is rarely the case and we suggest the following considerations: Consider each location having a dedicated Stream Host A critical Data Stream, like pressure readings on a pressure vessel, may have its own dedicated Stream Host If a payload for a Data Stream is large and frequent, then consider a dedicated Stream Host for that Data Stream. Having several Stream Hosts can improve the resilience of your system Network latency and geographical spread could be factors in considering the case for multiple Stream Hosts Performance A look beneath the hood of XMPro Charts and Time Series Analysis Charts Often the first time that users are aware of the components that make up XMPro charts is when they experience slow rendering times. This article seeks to explain the structure behind the XMPro charts and the components that impact chart performance. Performance is not limited to the Time Series Analysis as the same pattern pertains to other XMPro charts too, such as the Chart Block. With an understanding of the influences on chart performance, the reader will be in an informed position to address their requirement. The current Time Series Analysis use SQL and Azure ADX as data sources. XMPro as an Event Intelligence platform XMPro is purpose-built to manage events in real-time. This means its technologies can be used for Business Intelligence purposes. The processing of large swathes of past time series data is possible, but there are circumstances where this will not be an optimal user experience as the connectors work on the basis of 'Get All Data' and not incremental steps like for example, Grafana. XMPro App Designer Server memory scenarios The XMPro App Designer Server will reserve the required memory for each unique query while there is at least 1 active user interacting with it. A unique query is defined as a Time Series Chart instance, with the same date selection and same data source. The number of concurrent queries with at least 1 active user will have an influence on the XMPro App Designer Server performance. If one user runs a query that consumes 2 GB of server memory and a different user performs that same query, then the server consumes no additional memory and instead used the cached query. If a different query is run that consumes 4 GB of server memory, then a total of 6 GB of memory would be consumed, and so on. Depending on the server configuration this could impact overall server performance and response time (user experience).\" Settings that could impact performance There are several influences on XMPro App Designer Server and XMPro App Designer Client performance. The main influences would include: Web Server memory Web Server CPU Load balancing / Auto Scaling (scale out) Data Size (size and number of rows) Data Complexity (type and relationship of data) Where aggregation is performed (Data Layer vs Web Server vs Chart Control) Network speed and reliability (Data Layer, Web Server, and Client Browser) Client Available CPU speed Client Available Memory Web Browser and Version XMPro Platform Version SQL vs ADX The first consideration that impacts response time is the amount of data queried at the data source and the volume of data transmitted in response. The second consideration is the volume and complexity of data that the App Designer Server needs to parse. Figures 1 & 2 illustrate the reason for the improved performance of ADX over SQL. Amending the aggregation period will be almost instantaneous on ADX. On SQL this is likely to be slower. Issues for consideration to address overall performance The Time Series Analysis data loads initially and then again whenever the date selection is changed. Thus the initial selection should be limited, e.g. 3 hours. The appropriate initial selection depends upon the frequency of data points, i.e., if the time interval is every second, every minute, or every hour. The number of assets affects performance - not whether they are selected. All data points for all assets for the data range selection are loaded so that the query does not need to be reloaded when a user changes their asset selection. Limit the number of records fetched from the source system, either by using aggregation at the source if possible (or) by limiting to a shorter date range selection. Consider whether this is tracking events in real-time or requires discovery in a BI environment. Consider the number of simultaneous users and unique query combinations and whether sufficient resources have been allocated. Appendix 1: Elapsed Time for Time Series Analysis, Regular Charts, and D3 Charts Chart Comparison Appendix"
  },
  "src/resources/faqs/index.html": {
    "href": "src/resources/faqs/index.html",
    "title": "Frequently Asked Questions | XMPro",
    "summary": "Frequently Asked Questions This section contains answers to frequently asked questions about XMPro. The FAQs are organized into the following categories: Implementation FAQs Questions related to implementing XMPro in your organization. View Implementation FAQs Configuration FAQs Questions related to configuring XMPro. View Configuration FAQs Agent FAQs Questions related to XMPro Agents. View Agent FAQs General FAQs General questions about XMPro. View General FAQs"
  },
  "src/resources/icon-library.html": {
    "href": "src/resources/icon-library.html",
    "title": "Icon Library | XMPro",
    "summary": "Icon Library The following is a list of icons that you can use when you create a new App, Data Stream, Recommendation, or any other XMPro Object. You can download these directly and upload them as part of the steps outlined in the various How-To guides. Download Icon Library (ZIP) Note A zip file containing all the icons is available for download. The images listed below are for reference. Widgets These icons are available for use in widgets: Icon and Filename Icon and Filename Icon and Filename widget-1.png widget-2.png widget-3.png widget-4.png widget-5.png widget-6.png widget-7.png widget-8.png widget-9.png widget-10.png widget-11.png Icons Analytics Analytics-related icons: Icon and Filename Icon and Filename Icon and Filename analytics-1.png analytics-2.png analytics-3.png analytics-4.png analytics-5.png analytics-6.png analytics-7.png analytics-8.png analytics-9.png analytics-10.png analytics-11.png analytics-12.png analytics-13.png analytics-14.png analytics-15.png Borers Borer-related icons: Icon and Filename Icon and Filename Icon and Filename borer-1.png borer-2.png borer-3.png borer-4.png borer-5.png Compressors Compressor-related icons: Icon and Filename Icon and Filename Icon and Filename compressor-1.png compressor-2.png Conveyer Conveyor-related icons: Icon and Filename Icon and Filename Icon and Filename conveyor-1.png conveyor-2.png conveyor-3.png conveyor-4.png Crusher Crusher-related icons: Icon and Filename Icon and Filename Icon and Filename crusher-1.png crusher-2.png Fan Fan-related icons: Icon and Filename Icon and Filename Icon and Filename fan-1.png fan-2.png fan-3.png Gears Gear-related icons: Icon and Filename Icon and Filename Icon and Filename gears-1.png gears-2.png gears-3.png gears-4.png gears-5.png Maintenance Maintenance-related icons: Icon and Filename Icon and Filename Icon and Filename maintenance-1.png maintenance-2.png maintenance-3.png maintenance-4.png maintenance-5.png maintenance-6.png maintenance-7.png maintenance-8.png Oil and Gas Oil and gas-related icons: Icon and Filename Icon and Filename Icon and Filename oil-1.png oil-2.png oil-3.png oil-4.png oil-5.png oil-6.png oil-7.png oil-8.png oil-9.png oil-10.png oil-11.png oil-12.png oil-13.png oil-14.png oil-15.png oil-16.png Other Other miscellaneous icons: Icon and Filename Icon and Filename Icon and Filename Admin.png alert-dark-theme.png caution-icon.png Grids.png Hydraulic.png Mill-Icon.png Mind.png my-sandbox.png red-lock.png Other Equipment Other equipment-related icons: Icon and Filename Icon and Filename Icon and Filename other-1.png other-2.png other-3.png other-4.png other-5.png other-6.png Pumps Pump-related icons: Icon and Filename Icon and Filename Icon and Filename pump1.png pump2.png pump3.png pump4.png pump5.png pump6.png pump7.png pump8.png pump9.png pump10.png pump11.png pump12.png pump13.png pump14.png pump15.png pump16.png pump17.png pump18.png pump19.png pump20.png pump21.png pump22.png pump23.png pump24.png pump25.png pump26.png pump27.png pump28.png pump29.png pump30.png pump31.png pump32.png pump33.png pump34.png pump35.png pump36.png pump37.png pump38.png pump39.png pump40.png pump41.png pump42.png pump43.png pump44.png pump45.png pump46.png pump47.png pump48.png pump49.png pump50.png Recommendations Dark Blue Dark blue recommendation icons: Icon and Filename Icon and Filename Icon and Filename continuous-miner.png cooling.png gas-station.png pressure-gauge.png pump.png rubber-stamp.png temperature.png Light Blue Light blue recommendation icons: Icon and Filename Icon and Filename Icon and Filename business-management.png factory.png humidity.png power-plant.png rock.png worker.png Orange Orange recommendation icons: Icon and Filename Icon and Filename Icon and Filename account.png compressor.png expired.png factory-breakdown.png lock.png maintenance.png severity.png support.png temperature.png warning-shield.png Purple Purple recommendation icons: Icon and Filename Icon and Filename Icon and Filename disconnected.png gear.png information.png mine-cart.png production-machine.png time.png Violet Violet recommendation icons: Icon and Filename Icon and Filename Icon and Filename audio-wave.png gas-station.png maintenance.png pump.png screwdriver.png work.png Red Red recommendation icons: Icon and Filename Icon and Filename Icon and Filename cancel.png decline.png engine-oil.png error.png gears.png heating.png oil-industry.png oil-storage-tank.png pressure.png question-mark.png scales.png Yellow Yellow recommendation icons: Icon and Filename Icon and Filename Icon and Filename cancel.png decline.png engine-oil.png error.png gears.png heating.png oil-industry.png oil-storage-tank.png pressure.png question-mark.png scales.png yellow-notification.png"
  },
  "src/resources/platform-security.html": {
    "href": "src/resources/platform-security.html",
    "title": "Platform Security | XMPro",
    "summary": "Platform Security XMPro places a high priority on security, performing app security checks every 3 months using Veracode. Veracode's comprehensive analysis helps identify, prevent, and fix vulnerabilities through multiple testing methods: Static Analysis (white-box testing), Dynamic Analysis (black-box testing), and Software Composition Analysis. Security Technologies and Practices Our suite of products leverages robust technologies and practices to maintain a high security standard: App Designer, Data Stream Designer, and XMPro AI are built on dotnet 8. Subscription Manager is built on Microsoft .NET Framework 4.8 Runtime. In the event a vulnerability is identified in any of these technologies, Microsoft promptly releases an update. We integrate these updates into our products and regularly release new versions that include essential security fixes. Static Application Security Testing (SAST) Static Application Security Testing (SAST) is a form of white-box testing used to scan an application's source, binary, or byte code. Dynamic Application Security Testing (DAST) Dynamic Application Security Testing (DAST) analyzes a web application through the front end to find vulnerabilities through simulated attacks. This is also called Penetration testing. Software Composition Analysis (SCA) Software Composition Analysis scans all the components used in an application for security risks and vulnerabilities. Results Product SAST Score DAST Score Date Subscription Manager 4.4.18 92 95 20 Mar 25 App Designer 4.4.18 78 95 20 Mar 25 Data Stream Designer 4.4.18 89 95 20 Mar 25 XMPro AI 4.4.18 96 95 20 Mar 25 WorkFlow 97 91 20 Mar 25 Support and Recommendations .NET versions are supported by Microsoft for 3 years after release, as detailed in their support policy. To ensure you have the most secure XMPro offerings, we recommend upgrading at least every 3 months to take advantage of the latest security updates and features."
  },
  "src/resources/practice-notes/index.html": {
    "href": "src/resources/practice-notes/index.html",
    "title": "Practice Notes | XMPro",
    "summary": "Practice Notes This section contains practice notes and best practices for using XMPro effectively. These notes are based on real-world experience and provide guidance on how to get the most out of XMPro. Available Practice Notes Unified Recommendation Alert Management Learn how to implement a unified approach to managing recommendation alerts in XMPro. Performant Landing Pages in Real-Time Monitoring Best practices for creating performant landing pages for real-time monitoring applications."
  },
  "src/resources/practice-notes/performant-landing-pages-in-real-time-monitoring.html": {
    "href": "src/resources/practice-notes/performant-landing-pages-in-real-time-monitoring.html",
    "title": "Performant Landing Pages in Real-Time Monitoring | XMPro",
    "summary": "Performant Landing Pages in Real-Time Monitoring XMPro Design Patterns, Published Mar 2025 Performant Landing Pages v1.0.pdf Problem Statement A poorly performing landing page creates frustrated, disconnected users. Imagine waiting for data to load, knowing it won't tell you what you need to know – so you'll have to change a filter or navigate elsewhere and wait all over again! One reason for a poor landing page is if it is loaded up with a Unity 3D model of a beautiful long-haul truck or wind farm. Seeing a Caterpillar truck in 3D with real-time sensor readings and alerts is a thing of beauty, but do you need to see it 1st time every time? This is the question for page designers who may confuse 'sizzle' with a real-life working dashboard. The usefulness of the page balanced with performance should be top of mind. \"What is the problem the user is seeking to answer\" should drive every component of every page. Introduction Landing page design requires a balanced approach that addresses both technical performance and user experience needs. Successful implementation depends on recognizing that these dimensions are interconnected—technical decisions directly shape how users interact with and perceive XMPro applications. In industrial environments, landing pages serve operational personnel who require immediate access to actionable information. The effectiveness of these pages directly impacts decision-making processes, situational awareness, and operational efficiency. Thus, technical implementation must align with specific operational contexts and user workflows. Key principles that connect technical implementation to user impact include: Performance directly shapes initial user perception - Load times establish immediate trust in the system and determine whether users engage effectively Data relevance is as important as data speed - Users need not just fast access, but immediate visibility of the specific information required for their role Interface design must balance visual clarity with resource efficiency - Technical optimization and intuitive design work together to guide users to essential functions Device context significantly affects both technical requirements and user needs - Implementation must account for varying operational environments and device capabilities Scale considerations affect both system architecture and user comprehension - As data volumes grow, adapt technical approaches and information presentation The following sections explore how these principles translate to specific implementation strategies across the key aspects of landing page design—balancing technical performance with meaningful user experiences. Performance & First Impressions Critical First Moments Initial page load performance establishes immediate user trust and engagement you're your XMPro industrial applications. Users form judgments about system reliability within milliseconds of their first interaction, making the technical optimization of landing pages a direct driver of user confidence and operational effectiveness. The \"time to first meaningful paint\"—when users first see and can interact with essential content—directly shapes their perception of the entire system. In industrial environments, this initial impression extends beyond mere satisfaction to affect operational readiness and decision-making capability. Make the user journey easy, fast and relevant. Performance Targets Landing pages must meet specific performance targets across different operational contexts: Fixed workstations and laptops: maximum 2 seconds Research shows user frustration begins at 2 seconds Enterprise infrastructure should support optimal performance Portable devices (tablets and phones) on 5G networks: maximum 3 seconds Field operations require rapid mobile access Enterprise security adds processing overhead These targets ensure that all users, regardless of their work environment, can immediately engage with critical operational data. Strategic Content Distribution Strategically distribute content across primary landing pages and drill-down views to optimize performance: Landing Page Essentials Include only critical metrics, alerts, and primary controls on initial landing pages (Data that matters) Focus on immediate visibility of essential operational indicators Utilize lightweight visualization components (tiles, simple charts, status indicators) Drill-down Resource Management Place resource-intensive visualizations (maps, Unity 3D models, complex dashboards) on separate drill-down pages, ensuring these elements load only when explicitly requested by users Provide clear visual indicators of what detailed information is available For example, a manufacturing operations landing page should immediately show critical KPIs and alert counts, with clear pathways to detailed floor visualizations that load only when selected. This approach ensures immediate access to essential information while preserving system responsiveness. Device-Specific Optimization Rather than a one-page-fits-all approach, each device category requires specific optimization approaches: Control Room Displays Optimized for large screens and multiple monitors Focused on comprehensive data visualization Designed for mouse and keyboard interaction Field Tablets Simplified interface for touch interaction Prioritized critical metrics for mobile viewing Adapted for variable lighting conditions Mobile Devices Streamlined for essential operational data Optimized for single-hand operation Designed for intermittent connectivity Note Summary: Performance optimization directly impacts first impressions and operational effectiveness Ensure landing pages load within device-specific target times Include only essential elements on initial landing pages Place resource-intensive visualizations on separate drill-down pages Adapt interface and content based on device context and user role Provide clear pathways to detailed information Data Strategy & Content Relevance Connecting Data Management with User Needs Data management and content prioritization work together to create effective landing pages. How we handle data directly affects what users see and how quickly they can access important information. Smart Data Architecture Choices Effective implementation requires careful consideration of data scope, storage location, and access patterns to achieve optimal response times. Consider these key architectural decisions: Data Volume Control Use focused data sets with clear time boundaries (like 30-day windows) Prioritize data that supports immediate operational decisions Provide clear paths to historical data when needed Storage Strategy Optimization Choose storage solutions based on access frequency and performance requirements Keep critical operational metrics in fast-access storage Balance query speed against storage costs (e.g. ADX vs SQL) For industrial applications, this means deciding which metrics need immediate visibility vs which can be accessed through drilldowns. For example, a plant manager's landing page might show current production rates and critical alerts, while detailed equipment metrics remain accessible through clear navigation options. Content Organization for Different Users XMPro landing pages must adapt content presentation based on both technical limits and user priorities: Role-Based Content Focus Show the most relevant information for each role immediately Adjust content organization based on device type and operational context Keep critical alerts and indicators visible regardless of device Structure information to support common decision workflows Adaptive Information Density Adjust information density based on device capabilities Present complex visualizations differently across device types Ensure important metrics remain prominent on all devices Provide consistent access to essential functions across all formats For example, when showing industrial processes on mobile devices, the system might display simplified status indicators with clear paths to detailed diagrams, while workstations receive more comprehensive initial visualizations. Data Currency Management Resource-intensive calculations and complex aggregations form the foundation of landing page metrics. However, daily sensor readings don't warrant hourly recalculation, while production metrics might require more frequent updates. Balancing data freshness with performance requires a strategic approach to updates: Scheduled Calculations Perform resource-intensive calculations during off-peak times Match refresh intervals to actual data change patterns Show clear timestamps indicating last calculation time Provide manual refresh capabilities for users Real-Time vs. Pre-Calculated Data Use pre-calculated metrics for landing page elements to improve load speed Reserve real-time queries for critical operational metrics and drill-down views Balance real-time capabilities with system performance Clearly indicate which metrics are real-time versus aggregated summaries The goal is to provide rapid access to summarized metrics while enabling detailed exploration of current data. The currency data should always be displayed for each component. Note Summary: Effective data strategy connects technical performance with operational relevance Match data scope and access methods to specific operational roles Prioritize content based on device context and user responsibilities Implement appropriate data currency strategies for different metric types Structure information to support operational decision-making Balance information density with clarity across all device types Interface Design & User Navigation Integrating Design Structure with User Interaction Pathways Interface architecture and user navigation function as interconnected systems that determine operational efficiency. Research-based design principles support efficient information access while enabling critical industrial functions[1]. Effective integration of these components creates landing pages that guide users naturally through their workflows. Layout Optimization User interaction research reveals that effective landing page design must strategically position elements to align with natural viewing patterns and business objectives. The dominant F-pattern[2] scanning behavior shows users first view the top-left area, then scan horizontally before moving downward. This research provides clear guidance for element placement. Critical Component Positioning Position critical metrics and status indicators in the top-left quadrant, for immediate visibility Structure navigation elements to start key processes, reducing cognitive load Organize visual elements by usage frequency and business priority - following the natural F-pattern scanning path In industrial control interfaces, this evidence-based approach to layout design directly impacts user engagement and task completion rates across all device formats. Visualization Strategy Implementation Component selection is a tradeoff between system performance and user engagement. While simpler visualizations deliver better performance, they may reduce user insight and satisfaction; conversely, sophisticated visualizations that delight users often impose significant performance costs. Effective visualization requires balancing these competing demands. Component Selection Parameters Choose visualization types based on data volume, update frequency, and performance impact Reserve resource-intensive components (maps, time series, Unity models) for drill-down views, i.e. requested by a user rather than automatically loaded Utilize efficient components (charts, grids, tiles) for primary metrics display Adapt visualization complexity inversely to data volume (simpler views for larger datasets) For example, when displaying sensor data across multiple sites, consider using a simplified grid view for the landing page rather than an interactive map visualization. These more complex visualizations should load when specifically requested, preserving system responsiveness while maintaining access to detailed information. Clear Action Pathways Conversion path clarity in effective landing pages ensures that primary user actions remain clear and accessible across devices. users can efficiently navigate to primary actions across all devices. Call-to-Action (CTA) elements require careful design consideration to maintain their prominence and effectiveness regardless of display context. This aspect of interface design supports operational effectiveness by minimizing cognitive effort during task execution. Action Element Consistency Maintain consistent CTA visibility across all device types Adapt interactive element sizes to device input methods Optimize touch targets for mobile and tablet interfaces In practical implementation, an \"Overdue Recommendations\" function might span the full width on mobile screens for easy touch access, while appearing as a compact button in a consistent location on desktop interfaces. Although the appearance adapts, the function and its importance remain clear to users regardless of device. Note Summary: Effective interface design integrates layout principles with navigation pathways Position key elements according to validated visual scanning patterns Select visualization components based on performance and usability requirements Design clear interaction paths for essential operational functions Preserve visual hierarchy across different screen sizes [1] https://www.finoit.com/articles/maximizing-user-experience-design-through-information-architecture/ [2] LinkedIn: Understanding and Leveraging the F-Pattern in UX Design Operational Context Adaptation Content Prioritization Across Devices How information is structured and presented must adapt to different screen sizes while maintaining operational relevance. Content prioritization ensures critical information remains accessible regardless of viewing context. Device-Specific Content Hierarchy Adapt content structure based on device constraints and operational context Maintain critical alert visibility across all form factors Implement progressive disclosure for complex information sets Provide clear paths to detailed information On smaller devices, complex features like process diagrams or digital twin demonstrations should be simplified initially, with clear options to access detailed views. This approach preserves XMPro's industrial process capabilities while adapting to device constraints, ensuring the strong value proposition is maintained without overwhelming users. Device-Specific Implementation Strategies Different operational environments demand tailored interface approaches while maintaining functional consistency. Understanding how each device type is used in industrial contexts shapes implementation decisions. Control Room Environments Design for extended monitoring sessions with comprehensive information display Support advanced interactions using precision input devices Enable systematic comparison between related process parameters Optimize for continuous operational oversight Field Operations Support Prioritize glance-based information access for mobile contexts Provide simplified status indicators with clear paths to details Design for variable environmental conditions (lighting, distractions) Optimize for potentially intermittent connectivity Cross-Device Integration Ensure users maintain consistent mental models across devices Preserve work state during device transitions Implement unified notification systems across all platforms Support seamless operational continuity regardless of access point Note Summary: Operational context variations necessitate adaptation while preserving core functionality Prioritize content based on device context and operational roles Implement device-specific interfaces while maintaining consistent functionality Ensure device choice never impedes operational workflows Scale Considerations System scale fundamentally impacts implementation decisions across data architecture and visualization strategies. Each order of magnitude (10^4, 10^6, and 10^8) presents distinct optimization requirements that affect both performance and user experience. Landing page design must anticipate and adapt to these scale transitions to maintain effective operation. In industrial environments, scale considerations directly impact implementation choices. For example, a dashboard displaying real-time sensor data might use detailed line graphs when monitoring ten devices but must switch to aggregated heat maps when tracking thousands of sensors. Similarly, a landing page designed for a single manufacturing site requires different optimization strategies than one managing global operations. As noted by Peter van Hardenberg, increasing scale changes everything about a system - from data architecture to visualizations. Rather than attempting to design for all scale possibilities, implementations should target specific scale ranges and plan for transitions as operational needs evolve. Note Summary: Key principles for managing scale Match implementation to current operational requirements Implement appropriate data aggregation methods Select visualization techniques suitable for data volume Design and test at production-equivalent scale Plan system rebuilds at major scale transition points (10^4, 10^6, 10^8) Avoid over-engineering for future scale requirements Implement appropriate monitoring for scale-related performance metrics Conclusion Successful landing page implementation in industrial environments requires careful balance across multiple dimensions: performance requirements, data architecture, and user experience. Key success metrics include initial load time performance, data currency management, and operational workflow efficiency. These metrics must be evaluated within the context of device-specific requirements and scale considerations. Implementation teams should focus on delivering robust core functionality that meets essential operational needs. This approach aligns with industrial reliability requirements, where consistent performance takes precedence over non-essential features. As with choosing between a Toyota Corolla and a Tesla, the goal is to match implementation complexity to actual requirements - sometimes reliability and simplicity are key, while other situations may warrant more sophisticated solutions. Acknowledgements I want to acknowledge the valuable feedback from projects, clients, and customers that motivated me to compile these guidelines. Their practical experiences have shaped this document and reinforced the importance of performant landing page design in industrial applications. I have leaned towards the XMPro teams' experiences and intentionally not made this document a rehash of the ASM Consortium Guidelines Effective Console Operator HMI Design[1]. [1] https://www.asmconsortium.net/Documents/ASM_Handout_Display.pdf Appendix 1 - Summary of the integration of interface architecture and user navigation The usefulness of an XMPro page is the integration[1] of interfacing architecture and user navigation to enhance operational efficiency and support critical industrial functions. Here are some references and explanations that support this assertion: Navigation Design and User Experience: Effective navigation design is crucial for creating a seamless user experience. It involves analyzing and implementing ways for users to navigate through digital platforms efficiently, which directly impacts operational efficiency[2]. Research-based design principles, like user-centered design and iterative testing, ensure that navigation systems are intuitive and easy to use. Information Architecture Principles: Dan Brown's 10 principles of information architecture provide a comprehensive framework for designing user-friendly information systems. Principles like \"Focused Navigation\" and \"Multiple Classifications\" help ensure that users can access information efficiently, which is essential for operational efficiency[3]. These principles support the idea that well-structured information architectures enable critical functions by making information accessible and organized. Best Practices in Navigation and Information Architecture: Best practices in UX/UI design emphasize the importance of intuitive menus and navigation systems. These systems are fundamental in helping users explore and navigate through digital interfaces, which is critical for guiding users through workflows[4]. Effective organization of information and visual hierarchy are key considerations for ensuring that users can easily find what they need, thereby enhancing operational efficiency. Landing Page Design: While the statement specifically mentions landing pages, effective landing page design often incorporates principles of navigation and information architecture. For example, landing pages like those of Workable and Trello use minimalistic designs and intuitive navigation to guide users through workflows efficiently[5]. These designs are based on understanding the target audience's needs and behaviors, which aligns with research-based design principles. In summary, the integration of interface architecture and user navigation is supported by research-based design principles that enhance operational efficiency and support critical industrial functions. Effective navigation and information architecture are crucial for creating seamless user experiences and guiding users naturally through workflows, including landing pages. [1] https://www.finoit.com/articles/maximizing-user-experience-design-through-information-architecture/ [2] https://www.justinmind.com/blog/navigation-design-almost-everything-you-need-to-know/ [3] https://adamfard.com/blog/10-principles-information-architecture [4] https://www.linkedin.com/pulse/best-practices-navigation-information-architecture-florencia-marelli/ [5] https://www.getresponse.com/blog/landing-page-examples"
  },
  "src/resources/practice-notes/unified-recommendation-alert-management.html": {
    "href": "src/resources/practice-notes/unified-recommendation-alert-management.html",
    "title": "Unified Recommendation Alert Management | XMPro",
    "summary": "Unified Recommendation Alert Management Design Patterns for APM Capabilities and Recommendation Alerts 2025 v3.pdf Glossary Acronym Description ADT Asset Digital Twin APM Asset Performance Management CBC Composable Business Capabilities CMMS Computerized Maintenance Management System EAM Enterprise Asset Management EWMA Exponentially Weighted Moving Average LOESS Locally estimated scatterplot smoothing LOWESS Locally weighted scatterplot smoothing PBC Packaged Business Capabilities RPN Risk Priority Number Audience The readers who will find this documentation most useful will have a working knowledge of XMPro and use XMPro to address asset performance business problems. It is suggested that new users of XMPro should workshop their requirements with their XMPro partners. It is useful to emphasise that XMPro is an Intelligent Business Operations Solution (iBOS). Introduction This document has arisen from the work done with partners and seeks to align some APM capabilities pertaining to Recommendation Alert Management with XMPro configurations based on standard XMPro capability. For ease of use we have labelled those configurations 'Design Patterns\". We call these patterns 'Composable Business Capabilities'. (CBC[1]) The customer will need to adapt the design pattern to their own situation. Some of the Design Patterns have been further developed and are available as Apps in our GitHub[2] – these are enabled 'Packaged Business Capabilities' (PBC)[3]. [1] Gartner Reference Model for Intelligent Composable Business Applications [2] https://xmpro.github.io/Blueprints-Accelerators-Patterns/ [3] Gartner Reference Model for Intelligent Composable Business Applications Summary High Level Summarization APM Capability Associated Design Pattern Application Description Management of Prioritized Recommendation Alerts Unified view of Recommendation Alerts, reliability health and risk scores Asset and alert rating - Asset criticality - Recommendation severity - Recommendation alert priority Recommendation alert management Priority map of asset criticality Strategy and Aggregator Pattern - Recommendation Alert Scoring (including Asset Criticality) - Workbench - Asset Analysis meta tags - Recommendation Analysis meta tags - Shutdown Prioritization of Assets subject to open prioritized Recommendation Alerts Unified view of Recommendation Alerts by asset Asset and alert rating - Asset criticality - Recommendation severity - Recommendation alert priority Priority map of asset criticality Strategy and Aggregator Pattern - Recommendation Alert Scoring (including Asset Criticality) - Asset Analysis meta tags Management of Recommendation Alerts during Shutdowns Capability to suspend alerts during a Shutdown process. State and Observer Pattern - Shutdown Ability to track Work Orders arising from Recommendation Alerts Reliability-Centered Maintenance (RCM) and Work Order Management Aggregator Pattern - Work Bench - Configured Recommendation Alert page Categorization of Recommendation Alerts Recommendation alert management Decorator Pattern - Recommendation Analysis meta tags Categorization of Assets Asset hierarchy will cater for user defined categorization. Asset hierarchy capability within the system and not rely on the historian asset hierarchies. Decorator Pattern - Asset Analysis meta tags Part 1: APM Capability 1. Management of Prioritized Recommendation Alerts and Prioritized Assets subject to Recommendation Alerts APM capabilities Unified view of Recommendation Alerts Asset and alert rating Asset criticality Recommendation severity Recommendation alert priority Recommendation alert management Priority map of asset criticality Design Pattern Recommendation alert scoring – Strategy Pattern Workbench – Aggregator Pattern Asset Analysis Meta Tags – Decorator Pattern Recommendation Analysis Meta Tags – Decorator Pattern APM requirements A number of the requirements are addressed out of the box. Design patterns can be used to further enhance the systems capability. Unified view The APM system will provide a unified view of the reliability health and risk scores through integration of asset strategy, condition monitoring, analytics, and APM data systems to measure cost, failure rates and compliance metrics. Priority The APM system will provide a standard process for defining the criticality of assets. The APM system will provide a standard process for defining the Risk Priority Number (RPN) / severity score of recommendation alerts. The APM system will provide a standard process for prioritising recommendation alerts by the measure of an alert's Risk Priority Number (RPN) and an asset criticality score. The APM system will provide a modifiable risk matrix that can be adjusted to the company's definition of risk. Recommendation management The APM system will provide the ability to create recommendations within each area of functionality that can be associated to an equipment ID or functional location. The APM system will provide means to track and follow up recommendations from several hierarchical levels perspective in the organization (site, areas, units, system, and assets). The APM system can provide the ability to schedule an alert email message to be sent to the person responsible for ensuring that the recommendation is addressed. The APM system will provide concise reporting and alerting capability to track outstanding and past-due recommendations. The APM system will provide the ability to initiate recommendations for further planning and execution. 2. Management of Recommendation Alerts during Shutdowns The Shutdown Management App uses the State and Observer Patterns to manage preplanned shutdowns effectively. During a shutdown, the app transitions assets to a \"Disabled\" state using the State Pattern, silencing recommendations and preventing the creation of equipment alerts based on anomalies. The Observer Pattern ensures stakeholders are notified about the shutdown schedule via email, enhancing communication and coordination. This approach maintains system integrity and operational efficiency by ensuring that no unnecessary alerts are generated during maintenance periods. APM capability Capability to suspend alerts during a Shutdown process. Associated Design Pattern Shutdown – Object, Observer patterns APM requirements A number of the requirements are addressed out of the box. However, the design patterns can be used to enhance the systems capability. The APM system will provide the capability to automatically suspend generate alerts during a planned shutdown / start up. The APM system will provide the capability to amend planned shutdown and startup times for a planned shutdown / start up. The APM system will optionally categorize, and store alerts generated during the shutdown and start up procedures. 3. Ability to track Work Orders arising from Recommendation Alerts APM capability Paper free integration to CMMS for work order process. Associated Design Pattern Work Bench – Aggregator Pattern Custom Recommendation Alert page – Aggregator Pattern APM requirements The APM system will provide linkage from the analysis of recommendation alerts to the resulting work order. The APM system will provide integration to a maintenance management / paper free work order process. 4. Categorization of Recommendation Alerts A Recommendation Meta Tag App uses the Decorator Pattern to dynamically enhance asset data without altering the original schema. By assigning meta tags such as performance metrics, maintenance recommendations, and operational statuses to assets, the app enriches contextual data, enabling more informed decision-making. This approach allows for flexible and scalable data enhancement, improving predictive maintenance, performance monitoring, and overall asset management within the APM framework. APM capability Ability to contextualize and categorizes alerts by customizable metrics for targeted filtering. Design Pattern Workbench – Aggregator Pattern Recommendation Analysis meta tags – Decorator Pattern APM requirements A number of the requirements are addressed out of the box. However, the design patterns can be used to enhance the systems capability. Recommendation management The APM system will provide the capability to filter and categorize alerts, and by fault mechanism. 5. Categorization of Assets An Asset Master Hierarchy App utilizes the Decorator Pattern to dynamically enhance the hierarchical representation of assets without altering the original asset structure. This app assigns hierarchical meta tags, such as parent-child relationships, asset dependencies, and location mappings to assets, for more informed decision-making. APM capability Asset hierarchy will cater for user defined categorization. Asset hierarchy capability within the system and not rely on the historian asset hierarchies. Associated Associated Design Pattern Asset Analysis meta tags – Decorator Pattern APM requirements A number of the requirements are addressed out of the box. However, design patterns can be used to enhance the systems capability. Recommendation management The APM system will provide the capability to filter and categorize assets. The APM system will provide the capability to allocate a criticality score to each asset. Part 2: XMPro configurations as Design Patterns This section articulates how using XMPro capabilities the APM requirement is addressed. This assembly of configured XMPro capability is the foundation for a low code XMPro App. The authors have used standard XMPro functionality to create the various Design patterns. This Practice Note is primarily concerned with a unified view of prioritized Recommendation Alerts. The most popular Design Pattern is definitely 'Work Bench', but we recommend that the other Design Patterns should be reviewed and considered. 1. Design Pattern: Work Bench The objective of the Recommendation Alerts Workbench design pattern is to allow for the prioritization, categorization and filtering of alerts. The workbench addresses the following APM capabilities: Unified view of Recommendation Alerts, reliability health and risk scores Asset and alert rating Asset criticality Recommendation severity Recommendation alert priority Recommendation alert management Priority map of asset criticality Generic querying, reporting, graphing, and searching capabilities for all asset types, alert histories, and work orders. Users have a high-level unified view to assist in their workflow process by providing the ability to see XMPro alerts filtered by criticality and status as well as associated WO's. In the above example the first three tabs focus on the status of Recommendation Alerts – Open, Assigned without WO and Assigned with WO. The landing page alert tabs will include all unassigned alerts. The last three tabs focus on linked WO and the appropriate status; Open, Complete WO and Closed WO. The filtering, tabs, actions, and various status would be set for your circumstance. The aim is to give the user situational awareness to all the elements of the Recommendation Alert. The above example page provides the relevant information on an alert to allow users to: See a holistic view of a piece of equipment (ability to see all alerts related to that asset) Any associated discussion which may provide insights into investigation and actions take Data at time of alert triggering Relevant metrics (schematics, score history) In the Figure 3 this shows an example of assigning many Alerts to one WO. This page shows all open work orders and associated Recommendation Alerts. Additionally, users can create custom recommendation pages which display relevant data to the alert including: Other alerts associated with the Asset ID Metadata associated with the alert Ability to tie a WO/WR to the alert All WO/WR available 2. Design Pattern: Asset Prioritization Asset Prioritization= (Severity (Recommendation Alert Setting) X Occurrence X Detectability) X Asset Criticality settings (assigned at Asset level). Severity set at Recommendation level with Recommendation Category factor, Recommendation Factor and Recommendation Rule Factor. Occurrence is measured in the Data Stream and updated with the 'Run Recommendation' agent. Note: For calculating Occurrences with tags, log on all occurrences should be enabled for your recommendations Occurrence can be calculated with two methods which is based on the data. A) Event Frames B) Tags Refer to Appendix A Note An occurrence may not necessarily correspond to a new Recommendation Alert. For example, when polling OSI PI tags, the current occurrence might be part of an existing fault that previously triggered an open Recommendation Alert, or it could trigger a new alert if none is currently open. In such cases, an occurrence count is used to indicate the number of polling intervals during which the alert logic is met. Conversely, if the Data Stream is ingesting OSI Event Frames (EF), then each new EF is treated as a separate occurrence. This distinction is vital for accurately defining the measure for occurrence count. Detectability is omitted as we assume that the Failure Mode is detectable if a recommendation rule exists. Default score = 1 Asset Criticality is assigned at an Asset level in the Asset Master, Asset Hierarchy or Asset meta tags. Ideally, this is pulled from a source system to match the existing criticalities you are utilizing for other reliability activities. If this is unavailable, this can be stored in XMPro. XMPro capability on Recommendation scoring [4]. Note We suggest the initial default values be 1. We would expect that there will be several cycles as the various score settings are fine tuned. [4] How is the scoring calculated 3. Design Pattern: Asset Shutdown The purpose of the app is to allow users to silence alert generation for specific assets in recommendations while still maintaining the published state of the recommendation. This activation/deactivation will take place automatically based on predefined start/stop dates. The application will also notify users when the shutdown will start and end to determine if a modification is necessary and as a verification step. In the examples below we have explained the concept detailing a shutdown by asset. However, we strongly suggest that the first iteration allows for shutdown by a level in the asset hierarchy or some other mechanism the sites may have. Example you may wish to shut assets within a certain location. If your organization analyses Recommendation Alerts across the organization, the analysis is not clouded by the need to omit alerts triggered during a shutdown and the subsequent start up. This page will be used to create new shutdowns and edit existing shutdowns. For existing shutdowns, assigned assets will appear below the shutdown grid. This page will be used to assign Assets to an existing shutdown. The \"Previously Selected\" column tells shutdown planners what Assets are already assigned to a shutdown. 4. Design Pattern: Recommendation Meta Tags Administration The Recommendation Meta Tag Application enriches asset data by dynamically adding meta tags with maintenance recommendations, operational statuses, and performance metrics. This contextual information aids in making informed maintenance decisions and optimizing asset performance. By enhancing data without altering the original asset schema, the application supports predictive maintenance and improves overall asset management, leading to increased operational efficiency and reliability. In this page we have opted to distinguish between 'Not Allocated', or 'Not Reviewed'. 'Not Allocated' means that the Meta Tag is not relevant to the Recommendation (In the above this is the preferred allocation as not blank) and 'Not Reviewed' means that no selection has been decided for this asset. In the page above we have assigned Meta Tag Values to a Recommendation. This page creates or edits the Meta Tag Values. The Meta Tag column will populate a dropdown of existing options from the list of available options Created on the Meta Tags page. This page contains a grid where the user can create or edit the Meta Tags. 5. Design Pattern: Asset Meta Tags Administration The Asset Meta Tag Application enhances asset management by dynamically adding meta tags to asset data. These tags include performance metrics, maintenance recommendations, and operational statuses, providing enriched contextual information. This additional data helps in predictive maintenance, performance monitoring, and informed decision-making without altering the original asset schema. The application enables better tracking and management of assets, leading to improved operational efficiency and reliability. In this page we have opted to distinguish between 'Not Allocated', or 'Not Reviewed'. 'Not Allocated' means that the Meta Tag is not relevant to the Asset (A preferred allocation rather than blank) and 'Not Reviewed' means that no selection has been made for this asset. This page will be used to assign Meta Tag Values to an Asset. Each Meta Tag will populate a row with the corresponding Meta Tag Values for selection from the dropdown. This page contains a grid where the user can create or edit the Meta Tag Values. The Meta Tag column will populate a dropdown of existing options from the list of available options Created on the Meta Tags page. This page contains a grid where the user can create or edit the Meta Tags. Appendix 1 – Calculation of Recommendation Alert and Asset Priority Scores Definitions Term Description Asset Criticality Score Asset Criticality is a value (1-10) you set for your site assets based on how critical those site assets are to you. A value of 1 indicates the lowest level of importance, while a value of 10 is absolutely critical to your company. Asset Criticality is assigned at an Asset level in the Asset Master, Asset Hierarchy, or Asset meta tags. Asset Priority Score Asset Criticality * Weighted Risk Priority Number for all applicable Recommendation Alerts Recommendation Alert Priority Score Risk Priority Number * Asset Criticality Risk Priority Number (RPN) Severity * Detectability * Occurrence Severity The severity of the failure mode is rated on a scale from 1 (low) to 1000 (high). A high severity rating indicates severe risk. Recommendation Category Factor * Recommendation Factor * Recommendation Rule Factor. Detectability Set at 1 as all asset conditions measured are detectable Occurrence The logarithmic function Frequency = 1/a * logb(mx) + c to measuring operational alarms in a system. 1. Approach to Scoring Occurrence for an individual Recommendation Alert 1.1 Event Frames (Logarithmic Formula) Event Frames monitor all occurrences unlike the Recommendation Alerts where the occurrence is measured at the polling. Consequently, a Recommendation Alert does not equal all occurrences. Outcome – Recommendation Alert Priority Score Formula: \\(Recommendation Alert Priority Score = (Severity * Occurrence* X Detectability) * Asset Criticality settings (assigned at Asset level)\\) Severity & Detectability as stated in 'Definitions' above. Occurrence is a measure of the count that the recommendation logic is met. We use the logarithmic function to calculate 'Occurrence'. The logarithmic function to measuring operational alarms in a system. \\(Occurance= 1/a* 〖log〗_b (mx)+c\\) Where: x is the number of alerts for that specific alert type a is a scaling factor m is the multiplier for x c is a vertical shift Examples for each constant: x: Number of alerts in the last x hours [x is a global parameter] Let's say x = 100 alerts were recorded in the past 24 hours. a: Scaling factor for the overall frequency Example: a = 0.5 A smaller value of 'a' will increase the overall frequency, making the system more sensitive to changes in the number of alerts. b: Base of the logarithm Example: b = 10 Using base 10 is common and makes the scale easy to interpret. Each order of magnitude increase in alerts will correspond to a unit increase in the log value. m: Multiplier for x (alert count) Example: m = 0.1 This scales down the number of alerts. If m < 1, it reduces the impact of large numbers of alerts, preventing the frequency from growing too quickly. c: Vertical shift Example: c = 3 This adds a constant to the result, effectively setting a minimum frequency even when there are very few alerts. The logarithmic function helps to compress the range of occurrence values, preventing the RPN from growing too quickly for assets with very frequent alerts. Adjusting the parameters a, b, m, and c allows you to fine-tune the sensitivity of the occurrence calculation to best fit your risk assessment needs. The formula can be enhanced to incorporate multiple variables. Example for a pump \\(1/a * logb(mx * V * T * F * E) + c\\) Where: x = number of alerts in the last 24 hours V = vibration level factor T = temperature factor F = flow rate factor E = efficiency metric factor 1.2 Tags (Using time decay) In the situation where Recommendation Alerts are created from polling asset tags, we normalize the occurrence count with a time decay function. \\[ Recommendation Alert Priority Score = (Severity * Occurrence* X Detectability) * Asset Criticality settings (assigned at Asset level) \\] Severity & Detectability as stated in 'Definitions' above. Occurrence is a measure of the count that the recommendation logic is met. This approach accounts for two factors: The gradual decrease in an alert's significance over time The varying sampling frequencies across different data sources. The resulting score reflects both the event's severity and its temporal relevance. The following equation can be used: \\(Occurrence= n* e ^ (-λt)\\) Where: \\(λ\\) is the decay rate \\(t\\) is the duration from the current time \\(n\\) is percentage of time an alert was open normalized To calculate \\(n\\), use the following ratio \\[ n=(Actual number of Occurrence for a duration)/(Total Potential Occurance in that duration) \\] For example, we have two alerts open. Alert 1: \\(λ\\) is .01 \\(t\\) is every 24 hours \\(n\\) is percentage of time an alert was open normalized Polling Rate = 12 hours Polling Duration = 24 hours Total Polling Time Frame = 3 Days Alert 2: \\(λ\\) is .01 \\(t\\) is every 24 hours \\(n\\) is percentage of time an alert was open normalized Polling Rate = 24 hours Polling Duration = 24 hours Total Polling Time Frame = 3 Days The duration in this scenario is set largest duration between polls (in this case 24 hours). If we had the following data for the alerts: Days 1 1 2 2 3 3 Alert 1 Poll x x x x 0 x Alert 2 Poll - x - x - x In the grid above, \"x\" is an occurrence, \"0\" is no occurrence, and \"–\" indicates no poll. To normalize so we would get the same number of time frames to calculate occurrence for, we would divide the number of total occurrences in each time frame by the number of potential occurrences Days Alert 1 Alert 2 Time (hrs) Alert 1 Occ. Score by Day Alert 2 Occ. Score by Day 1 2/2 1/1 48 .618 .618 2 2/2 1/1 24 .786 .786 3 1/2 1/1 0 .5 1 Total 1.90 2.40 Alert 2, which occurs at every interval, has an occurrence score of 2.4 with an aggressive decay factor. While the most recent occurrence receives the maximum score of 1.0, the high decay factor significantly reduces the weight of occurrences from three days ago. For comparison, we applied the same decay factor to Alert 1. However, Alert 1's latest value was normalized to 0.5 since the condition was true for only half of the potential instances. This normalization reduced Alert 1's occurrence score to 1.90, compared to Alert 2's score of 2.4. The difference in scores demonstrates how recent occurrences have a stronger influence than older ones. The combination of normalization and decay rates effectively handles both varying polling frequencies and the diminishing relevance of historical occurrences Scores can also be adjusted based on other factors. Below shows an example based on the type of alert and how different decay rates affect the scores if decay rates are based on recommendations. Hours Elapsed Critical (rate: 0.05) Vibration (rate: 0.1) Temperature (rate: 0.3) Pressure (rate: 0.5) Transient (rate: 0.8) 0 1.000 1.000 1.000 1.000 1.000 1 0.951 0.905 0.741 0.607 0.449 2 0.905 0.819 0.549 0.368 0.202 4 0.819 0.670 0.301 0.135 0.041 8 0.670 0.449 0.091 0.018 0.002 12 0.549 0.301 0.027 0.002 0.000 24 0.301 0.091 0.001 0.000 0.000 Decay rates can also be adjusted based on an asset's criticality. For example: Critical assets: Use lower decay rates (0.05 - 0.1) Non-critical assets: Use higher decay rates (0.3 - 0.5) Maintenance-dependent alerts: Use very low decay rates (0.01 - 0.05) 2. Priority by Asset for Multiple Recommendation Alert Types Outcome – Priority score by Asset For the various recommendation alert types for an asset, we need to calculate individual occurrence scores for each Recommendation Alert type and then aggregate them into a single asset-level occurrence score. This approach ensures that we consider all alert types while maintaining a single score for use in the RPN (Risk Priority Number) calculation. Step 1: Calculate Individual Occurrence Scores Calculated as per Section 1 or Section 2 Step 2: Aggregate Occurrence Scores After calculating individual occurrence scores, aggregate them into a single asset-level score. Here are three methods to consider: Maximum Method: Asset Occurrence = max(O₁, O₂, ..., Oₙ) Where O₁, O₂, etc. are occurrence scores for each alert type. Weighted Average: (Recommended) Asset Occurrence = (w₁ * O₁ + w₂ * O₂ + ... + wₙ * Oₙ) / (w₁ + w₂ + ... + wₙ) Where w₁, w₂, etc. are weights assigned to each alert type based on their importance. Logarithmic Sum: Asset Occurrence = exp(log(O₁) + log(O₂) + ... + log(Oₙ)) Weighted Average is recommended as the preferred method. the method that best fits your system's requirements and risk assessment strategy. Step 3: Normalize the Score Ensure the final asset occurrence score falls within your desired range (e.g., 1-10) by applying appropriate scaling or normalization. Step 4: Integrate with RPN Calculation for each asset Use this aggregated asset occurrence score in your RPN formula: RPN = Severity * Asset Occurrence * Detectability Example Calculation using Event Frames. Refer Section 1.2 for the calculation of occurrence for tags. Let's consider an asset with two alert types: Alert Type 1: x₁ = 100 alerts a = 0.5, m = 0.1, c = 3 Occurrence₁ = 1/0.5 * log₂(0.1 * 100) + 3 = 9.64 Alert Type 2: x₂ = 50 alerts a = 0.5, m = 0.2, c = 3 Occurrence₂ = 1/0.5 * log₂(0.2 * 50) + 3 = 9.32 Using the weighted average method with w₁ = 1.2 and w₂ = 1: Asset Occurrence = (1.2 * 9.64 + 1 * 9.32) / (1.2 + 1) = 9.50 Step 5: Calculate the Asset Priority Asset Priority = Asset Criticality * RPN Considerations Address assets with no alerts of a particular type by setting a minimum occurrence value (e.g., 1) or using zero, depending on your risk assessment strategy. The 'Run Recommendation' agent should update the 'x' values (number of alerts) for each alert type. The logarithmic function moderates the growth of the occurrence score for assets with frequent alerts while still capturing the significance of alert frequency. Regularly review and adjust the parameters (a, m, c, and weights) to ensure the system accurately reflects your organization's risk priorities. Appendix 2 - Analysis of Risk Priority Number (RPN) Implementation in Asset Performance Management: Limitations and Opportunities Abstract We examine the theoretical foundations and practical limitations of Risk Priority Number (RPN) implementation in Asset Performance Management (APM) systems. While RPN serves as a cornerstone metric in failure mode and effects analysis (FMEA), significant challenges emerge in its practical application. Through critical analysis of current literature and industry practices, this study identifies key limitations in RPN methodology and proposes potential enhancements for more effective risk assessment in industrial settings. Introduction Risk Priority Number (RPN) has long served as a fundamental tool in risk assessment and failure mode analysis. However, as industrial systems grow in complexity and the demands for precise risk quantification increase, the traditional RPN methodology faces several challenges that warrant careful examination. This paper aims to critically analyse these limitations and explore potential solutions for modern industrial applications. 1. Theoretical Framework 1.1 Traditional RPN Calculation The traditional RPN calculation follows the formula: RPN = Severity × Occurrence × Detection Where: Severity (S) represents the seriousness of failure Occurrence (O) represents the likelihood of failure Detection (D) represents the probability of detecting failure before impact 1.2 Mathematical Limitations 1.2.1 Scale Constraints Despite the theoretical range of 1-1000, the multiplicative nature of RPN produces only 120 unique values, creating significant gaps in the risk assessment spectrum. This limitation impacts the granularity of risk differentiation and can lead to clustering of risk scores. 1.2.2 Equal Weighting Problem The multiplicative relationship between factors assumes equal importance of S, O, and D, which often contradicts operational reality where severity might warrant greater consideration in critical systems. 1.2.3 Different Polling Intervals Traditional Risk Priority Number (RPN) calculations face significant challenges when applied to modern asset monitoring systems. In XMPro, data collection happens at widely varying intervals - from every 5 minutes to every 90 days - rather than continuously. This creates a fundamental measurement problem: alerts from different sampling frequencies cannot be directly compared. For example, equipment monitored every 5 minutes has 288 daily opportunities to trigger an alert, while quarterly oil sampling provides only 4 chances per year. Additionally, we cannot accurately measure how long a condition persists between samples. These limitations require a new approach that accounts for both sampling frequency differences and condition duration. 2. Practical Implementation Challenges 2.1 Subjectivity in Scoring A significant challenge in RPN implementation lies in the subjective nature of score assignment. Different assessors may assign varying scores to identical situations based on: Personal experience and expertise Local operational context Individual risk perception Organizational culture 2.2 Contextual Limitations 2.2.1 Industry-Specific Concerns The generic nature of RPN calculation fails to account for industry-specific risk factors and regulatory requirements. Different industries may require different emphasis on various risk components. 2.2.2 Asset-Specific Considerations The standardized approach may not adequately address: Unique failure modes of specific asset types Complex interdependencies between systems Varying operational contexts 2.2.3 Risk Masking Critical risks may be obscured when: High-severity risks receive low overall RPN due to low occurrence Critical failure modes are underweighted due to high detection capability Multiple moderate risks accumulate without triggering threshold alerts 3. Proposed Enhancements 3.1 Modified RPN Calculations To address the limitations of traditional RPN, several modified approaches warrant consideration: 3.1.1 Weighted RPN We propose an enhanced calculation methodology incorporating weighted components: Modified RPN = (w₁S × w₂O × w₃D) Where w₁, w₂, and w₃ represent relative importance weights determined through systematic analysis of operational requirements and risk profiles. 3.1.2 Cost-Based RPN Financial impact consideration enhances risk assessment accuracy through: Cost-Based RPN = Modified RPN × Financial Impact Factor This approach provides more nuanced risk prioritization aligned with business objectives. 3.2 Advanced Risk Assessment Framework A more comprehensive framework should include: Multiple risk assessment methodologies Industry-specific risk factors Dynamic threshold adjustment capabilities Integration with asset criticality metrics 4. Implementation Recommendations 4.1 Systematic Approach Organizations implementing RPN should: Establish clear scoring guidelines Provide comprehensive assessor training Implement regular calibration exercises Document scoring rationale Regularly review and update risk assessment criteria 4.2 Technology Integration Modern APM systems should incorporate: Machine learning for pattern recognition Real-time data analytics Automated threshold adjustment Historical trend analysis Integration with broader asset management systems 5. Future Research Directions Several areas warrant further investigation: Development of industry-specific RPN modifications Integration of artificial intelligence in risk assessment Validation of modified RPN methodologies Quantification of subjective assessment impacts Cost-benefit analysis of enhanced risk assessment methods 6. Conclusion While RPN remains a valuable tool in risk assessment, its limitations necessitate careful consideration and potential modification for modern industrial applications. The proposed enhancements and implementation recommendations provide a framework for improving risk assessment accuracy while maintaining practical applicability in industrial settings."
  },
  "src/resources/sizing-guideline.html": {
    "href": "src/resources/sizing-guideline.html",
    "title": "Sizing Guideline | XMPro",
    "summary": "Sizing Guideline This is a guideline for the compute resources needed for the different components in a deployment. Small, medium, and large sizing estimates are provided. The small option starts with the minimum recommended resources and, generally, each subsequent size doubles the number of CPU cores and available RAM. Not all components experience the same increase in load, so the estimates may not increase at the same rate for all components. Many factors influence the number of Apps and Data Streams a deployment can effectively run. These factors include: the number of data streams, how frequently the streams process data, the size of the data payload, the number of recommendations to be monitored, the number of apps and event boards being served, the complexity of apps and event boards (the number of elements and integration points), and the number of concurrent users accessing the apps and event boards. As a rough guide, an example workload for a Medium-sized deployment would be: ~200 Data Streams running across ~15 Stream Hosts, serving data and triggering recommendations for ~10 Apps On-Premise Component Small Medium Large Subscription Manager (SM) 1 2 CPU 8GB RAM 2 CPU 8GB RAM 4 CPU 16GB RAM Application Designer (AD) 2 CPU 8GB RAM 4 CPU 16GB RAM 8 CPU 32GB RAM Data Stream Designer (DS) 2 CPU 8GB RAM 4 CPU 16GB RAM 8 CPU 32GB RAM Stream Host Server (SH) 2,3 2 CPU 8GB RAM 4 CPU 16GB RAM 8 CPU 32GB RAM SQL Database Server (Combined for SM, AD, DS) 4 2 CPU 8GB RAM 4 CPU 16GB RAM 8 CPU 32GB RAM Note Footnotes 1 High volumes of concurrent users may require additional compute. 2 Multiple Stream Hosts can be deployed to the Stream Host Server. 3 If the Stream Host needs more resources, consider increasing the RAM before adding additional CPU cores as Stream Hosts perform in-memory processing of events. 4 High volumes of recommendations may require additional compute and storage. Azure Estimates for Azure target the Premium v3 service plan for applications, and Azure SQL Database for the databases. Azure SQL database estimates are based on the General-Purpose service tier and use the DTU-based purchasing model (a blended measure of compute, storage, and IO resources). Component Small Medium Large Subscription Manager (SM) App Service Plan 1 P1v3 P1v3 P2v3 Application Designer (AD) App Service Plan P1v3 P2v3 P3v3 Data Stream Designer (DS) App Service Plan P1v3 P1v3 P2v3 Stream Host Server (SH) App Service Plan 2,3 P1v3 P2v3 P3v3 Azure SQL Database (For each of SM, AD, DS) 4 Standard – 20 DTUs Standard – 50 DTUs Standard – 100 DTUs Note Footnotes 1 High volumes of concurrent users may require additional compute. 2 Multiple Stream Hosts can be deployed to the Stream Host App Service Plan. 3 If the Stream Host needs more resources, consider increasing the RAM before adding additional CPU cores as Stream Hosts perform in-memory processing of events. 4 High volumes of recommendations may require additional compute and storage. For additional details please see Azure App Service Pricing and Azure SQL Database Pricing. AWS Estimates for AWS target Amazon EC2 T3 instances for applications, and an Amazon RDS T3 instance for the databases. Component Small Medium Large Subscription Manager (SM) EC2 Instance 1 t3.large t3.large t3.xlarge Application Designer (AD) EC2 Instance t3.large t3.xlarge t3.2xlarge Data Stream Designer (DS) EC2 Instance t3.large t3.large t3.xlarge Stream Host Server (SH) EC2 Instance 2,3 t3.large t3.xlarge t3.2xlarge Amazon RDS for SQL (Combined for SM, AD, DS) 4 t3.large t3.xlarge t3.2xlarge Note Footnotes 1 High volumes of concurrent users may require additional compute. 2 Multiple Stream Hosts can be deployed to the Stream Host Server. 3 If the Stream Host needs more resources, consider increasing the RAM before adding additional CPU cores as Stream Hosts perform in-memory processing of events. 4 High volumes of recommendations may require additional compute and storage. For additional details please see AWS EC2 and RDS instance types."
  },
  "src/technical-reference/health-checks.html": {
    "href": "src/technical-reference/health-checks.html",
    "title": "Health Checks | XMPro",
    "summary": "Health Checks Note For Azure Terraform deployments, health checks are automatically configured and enabled. Overview Health checks are diagnostic tools that monitor the readiness of your XMPro services. They evaluate various aspects of system health including: XMPro service availability Database connectivity Redis Cache status (when configured) Health checks are disabled by default but are highly recommended for production environments to ensure service reliability and enable automatic recovery mechanisms. Health Endpoints Each XMPro application exposes health check endpoints: Application Health Endpoint Health UI Application Designer (AD) /health /health-ui Data Stream Designer (DS) /health /health-ui Subscription Manager (SM) /health /health-ui XMPro AI /health /health-ui The health endpoint returns JSON with detailed status information: { \"status\": \"Healthy\", \"data\": {}, \"description\": \"Service is running\", \"duration\": \"00:00:00.0123456\", \"tags\": [\"database\", \"cache\"] } Health UI The Health UI provides a user-friendly display of health check results: Accessible via /health-ui path Shows real-time status of all configured health checks Displays response times and error details Provides historical health data Configure Health Checks Note For Azure Terraform deployments, health checks are automatically configured and enabled. Adding Third-Party Endpoints Note For Azure Terraform deployments, third-party endpoints can be configured through environment variables."
  },
  "src/technical-reference/mosquitto-mqtt-broker.html": {
    "href": "src/technical-reference/mosquitto-mqtt-broker.html",
    "title": "Self-Hosted Mosquitto MQTT Broker Implementation | XMPro",
    "summary": "Self-Hosted Mosquitto MQTT Broker Implementation Introduction This reference guides organizations to build and maintain their own Mosquitto MQTT broker implementation, removing dependency on XMPro's previous pre-built Mosquitto MQTT broker solution while maintaining compatibility with XMPro platform requirements. What You'll Find Here Sample Dockerfile and configuration for building your own Mosquitto container Basic authentication setup using environment variables Migration guidance from XMPro's previous implementation Deployment configuration example Note: This is a reference implementation. Organizations should review and adapt the configuration based on their specific security, networking, and operational requirements before production deployment. This implementation requires a mosquitto.conf configuration file, proper volume mounts for data persistence, and consideration of TLS/SSL setup for production environments. Organizations are responsible for understanding and configuring Mosquitto MQTT broker according to their needs. Sample Implementation with Basic Authentication For reference, here's a sample implementation with basic authentication: Dockerfile FROM eclipse-mosquitto:2 COPY entrypoint.sh /entrypoint.sh RUN mkdir -p /etc/mosquitto && touch /etc/mosquitto/passwd && chmod 0700 /etc/mosquitto/passwd && \\ chown mosquitto:mosquitto /etc/mosquitto/passwd && \\ chmod +x /entrypoint.sh ENTRYPOINT [\"/entrypoint.sh\"] Entrypoint Script (entrypoint.sh) #!/bin/sh # Set up MQTT credentials from environment variables if [ -n \"$MQTT_USER\" ] && [ -n \"$MQTT_PASSWORD\" ]; then echo \"Setting up MQTT authentication...\" mosquitto_passwd -b /etc/mosquitto/passwd \"$MQTT_USER\" \"$MQTT_PASSWORD\" echo \"Authentication configured for user: $MQTT_USER\" else echo \"No MQTT credentials provided. Running without authentication.\" fi # Start Mosquitto with custom configuration exec mosquitto -c /mosquitto/config/mosquitto.conf Sample Configuration File (mosquitto.conf) allow_anonymous true password_file /etc/mosquitto/passwd listener 1883 log_dest file /mosquitto/logs/mosquitto.log Key Features Authentication: Uses environment variables MQTT_USER and MQTT_PASSWORD Configuration: Expects mosquitto.conf at /mosquitto/config/mosquitto.conf Password Management: Automatically creates password file from environment variables Implementation Details Build Process # Build the custom image docker build -t your-mosquitto . # Run with authentication and proper volume mounts docker run -d \\ --name mosquitto-broker \\ -e MQTT_USER=youruser \\ -e MQTT_PASSWORD=yourpass \\ -p 1883:1883 \\ -v /path/to/your/mosquitto.conf:/mosquitto/config/mosquitto.conf:ro \\ -v mosquitto-data:/mosquitto/data \\ -v mosquitto-logs:/mosquitto/log \\ your-mosquitto # Alternative with bind mounts docker run -d \\ --name mosquitto-broker \\ -e MQTT_USER=youruser \\ -e MQTT_PASSWORD=yourpass \\ -p 1883:1883 \\ -v $(pwd)/mosquitto.conf:/mosquitto/config/mosquitto.conf:ro \\ -v $(pwd)/data:/mosquitto/data \\ -v $(pwd)/logs:/mosquitto/log \\ your-mosquitto Container Configuration The implementation expects: Base image: eclipse-mosquitto:2 Configuration file: /mosquitto/config/mosquitto.conf Password file: /etc/mosquitto/passwd (auto-generated) Required environment variables: MQTT_USER, MQTT_PASSWORD Migration from XMPro Organizations migrating from XMPro's mosquitto implementation should: Build their own container using this reference Deploy to their own container registry Update deployment manifests to reference the new image Test authentication and configuration compatibility Deployment Configuration Replace XMPro image reference in your deployment manifest: # Replace XMPro image reference in your deployment manifest: spec: containers: - name: mosquitto image: your-registry/your-mosquitto:latest # Configure ports, environment variables, volume mounts, # resource limits, and other deployment requirements # according to your infrastructure and security policies"
  },
  "src/technical-reference/redis-cache-implementation.html": {
    "href": "src/technical-reference/redis-cache-implementation.html",
    "title": "Redis Cache Implementation | XMPro",
    "summary": "Redis Cache Implementation Note For Azure Terraform deployments, Redis autoscaling is automatically configured when enabled. Introduction XMPro uses Redis as a distributed caching solution to improve performance and enable scalability across multiple application instances. Redis is automatically activated when you enable AutoScale in your XMPro configuration and will gracefully fall back to single-server operation when disabled. This guide explores Redis implementation in XMPro, focusing on how Redis server configuration impacts XMPro performance and behavior. We'll cover usage patterns across products, data caching strategies, capacity management scenarios, configuration best practices, and troubleshooting guidance - with particular attention to what happens when Redis capacity limits are reached. Redis Usage per XMPro Product XMPro uses Redis to store data for caching and passing through data for SignalR. The XMPro Products use it as follows: Product Redis Usage App Designer Full (Cache + SignalR) Data Stream Designer SignalR Only Subscription Manager SignalR Only AI None Stream Host None Data Caching Purpose: Caches real-time Data Stream data sent by the XMPro App Agent to App Designer via the Data Streams Connector Data Source. This allows preservation of temporary data even if the App Designer server restarts and avoids consuming the server's memory. Structure: Key Values are stored in the Redis Cache as a mix of Hash and List types. Groups of Keys are created for each Connection created with the Data Streams Connector. The keys are prefixed to indicate their grouping with the following format: DS:<AD Connection Id>-<DS Stream Object Id>:* SignalR Backplane Purpose: Enables SignalR message distribution across multiple server instances. SignalR is used to send real time data between XMPro Products like Database changes or Notifications. This ensures that when one server instance receives a message, all other instances are automatically notified, keeping users connected to different servers synchronized with the same real-time information. Single Server Performance: Even on a single server deployment, Redis backplane can improve SignalR performance by offloading message routing from server memory to Redis, reducing memory pressure and improving scalability for high-frequency real-time updates. Redis Cache Capacity and Expiry Configuration in XMPro The XMPro App Agent and Data Streams Connector provide options to configure how data is stored: Cache Size limits, Sliding Expiry, and Cache Clearing. Cache Size Limits: XMPro implements its own cache size management via the Agent and Connector When inserting new items that exceed the configured cache size, oldest items are removed to give way to new data Sliding Expiry: Cache items have configurable sliding expiration times Items are automatically removed by Redis after expiration Expiration is refreshed on access to keep frequently used data in cache Cache Clearing: Cache items can be cleared via the XMPro App Agent if the Data Stream definition is changed, making the cached data no longer relevant Only data related to that XMPro App Agent is cleared Impact When Capacity is Reached on the Redis Server When a Redis server reaches its memory capacity limits, the impact on the XMPro Products varies significantly between SignalR Backplane and Data Caching usage patterns. Understanding these differences is critical for capacity planning and performance expectations. Overview SignalR: Automatic fallback to default behavior, no functionality loss within servers Data Caching: Data sent by the data stream while at capacity will not be cached, creating gaps in the cached data timeline; caching resumes when capacity is restored. See Data Caching Impact (Stored Data) for details as actual behavior depends on Redis server configuration. SignalR Backplane Impact (Message Pass-Through) SignalR Usage: Redis serves as a temporary message broker between XMPro servers Messages are passed through Redis but not permanently stored Used by App Designer, Data Stream Designer, and Subscription Manager Behavior When Capacity Reached: Automatic Fallback: XMPro falls back to single-server SignalR using its configured product SQL database - no functionality loss Performance Impact: Increased database load as cache misses increase Potential for increased latency in real-time data updates User Impact: Real-time updates work normally for users on the same server Cross-server real-time synchronization temporarily unavailable Example: When Design User A updates a block or agent, Design Users B & C on the same server see the real-time update immediately, but Design Users X, Y & Z on a different server won't see it until they refresh or Redis capacity is restored. Recovery: Automatic restoration when Redis capacity returns - no manual intervention needed Data Safety: No data loss - SignalR uses Redis for pass-through messaging only, all business data remains in SQL databases Data Caching Impact (Stored Data) Data Caching Usage: Redis stores actual cached data from Data Streams Connector Cached data persists in Redis for performance optimization Used primarily in App Designer for metric data in a dashboard application page Behavior When Capacity Reached: App Designer Cached Data: Data Loss: Cached real-time values displayed in applications will be lost New Data Behavior: Behavior for which data is lost depends on the configured Redis Memory Policy: With allkeys-lru policy: New data replaces old data With noeviction policy: New data is rejected, existing cached data remains Application Display: Users will see gaps in historical dashboard data Recovery: When Redis capacity returns to normal, the cache will gradually repopulate as new data flows through the application. If it is important to fill in the gap, missed data would have to be resent via the Data Stream. Redis Server Configuration Note For Azure Terraform deployments, Redis autoscaling is automatically configured when enabled. Connection Configuration Redis connection is configured via connection strings Supports both standard Redis and Azure Redis Cache Connection multiplexer is registered as a singleton for connection pooling Redis Memory Policies These policies are configured during Redis service setup. They determine how Redis handles memory limits and what happens when the server reaches its maximum memory capacity. Redis server typically uses: Default Policy: noeviction - Returns errors when memory limit reached Recommended: allkeys-lru - Evicts least recently used keys Alternative: volatile-lru - Evicts LRU keys with expiration set Recommendations Data Caching Recommendations These Redis configuration practices specifically address XMPro data caching performance and help prevent the capacity-related data gaps described above. Configure Appropriate Eviction Policies Set Redis maxmemory-policy to allkeys-lru to automatically remove least-recently-used data when capacity is reached Configure maxmemory limit based on available resources Consider Redis clustering for high-volume deployments Cache Size Configuration Adjust XMPro cache size limits based on your expected data throughput Balance between memory usage and cache expiry duration Monitor cache effectiveness and adjust limits accordingly General Recommendations These broader Redis server configurations support overall system performance and reliability. Monitor Redis Memory Usage Set up monitoring for Redis memory consumption Configure alerts before reaching capacity Plan for Redis scaling based on data volume High Availability Use Redis persistence for critical cache data Implement Redis replication for failover Consider Redis Sentinel or Cluster for production Troubleshooting When Autoscaling is enabled, Redis connection can be checked using the XMPro Health check URL. Common issues are: Tip For comprehensive information about XMPro health check endpoints and troubleshooting, see the Health Checks technical reference. Connection Failures: Redis server is unhealthy from the Health Check URL Fix: Restart Redis service, verify network connectivity, and confirm correct connection string in XMPro configuration Memory Errors: Monitor Redis memory usage and eviction statistics Fix: Increase Redis memory allocation, set maxmemory-policy to allkeys-lru, or optimize XMPro cache size limits Performance Degradation: Review cache hit/miss ratios and adjust cache sizes Fix: Increase Redis memory, adjust cache expiration times, or review data patterns to optimize cache effectiveness See the Redis Documentation on how to solve more issues regarding the Server. Diagnostic Commands Use these common Redis CLI commands from your Redis server or any machine with Redis CLI to help in your investigation # Check Redis memory usage redis-cli INFO memory # Monitor evicted keys redis-cli INFO stats | grep evicted # View current memory policy redis-cli CONFIG GET maxmemory-policy Summary Redis serves different functions across XMPro products, with SignalR backplane providing graceful fallback when capacity is reached, while data caching can experience gaps in cached data. Understanding these behavioral differences and properly configuring Redis memory policies, monitoring, and capacity planning ensures optimal XMPro performance and prevents data loss scenarios. The key insight is that Redis server configuration directly affects how XMPro handles capacity constraints, making proper setup and monitoring essential for reliable operation."
  },
  "src/technical-reference/sso-adfs.html": {
    "href": "src/technical-reference/sso-adfs.html",
    "title": "SSO - ADFS | XMPro",
    "summary": "SSO - ADFS In this article, we will look at how to set up AD FS so that it can be used as an external identity provider for Subscription Manager, allowing single sign-on capability between AD FS and Subscription Manager. Follow the steps below: IIS Navigate to the location in IIS where Subscription Manager was installed. Note You can right-click on the application name in IIS and choose \"Explore\". Open the web.config file. Scroll down to the \"xmpro\" section. Note It might be encrypted, which will require you to decrypt it first. For instructions, please refer to the How to encrypt and decrypt a web.config file Knowledge Base article. Under the \"identityProviders\" element, add a new element called \"adfs\". Specify the metadata address of your AD FS, as per the image below: Note Set the correct URL for the metadataAddress value. An example of how the URL might look is \"_https://adfs.domain.com/federationmetadata/2007-06/federationmetadata.xml_\". Verify your URL by browsing to it in a browser. Copy the \"baseUrl\" value in the web.config - you will need it later in this guide. Warning You will use this value to create a relying party trust between the Subscription Manager application and AD FS Server Manager Log on to your AD FS server and go to Tools –> AD FS Management Relying Party Trust Click Add Relying Party Trust Select Claims aware and click Start Select Enter data about the relying party manually and click Next Choose a display name and click Next and Next again Select Enable support for the WS-Federation Passive protocol, add the URL and click Next Note This is the base URL you copied from the web.config file. Add the identifier for the application. Use the URL for Subscription Manager Add the URL and click Next Choose an access control policy and click Next. Continue to the last screen Note For this article, we are going to choose Permit everyone Claims Issuance Policy Select Configure claims issuance policy for this application and finish In the AD FS Management window, click Edit Claim Issuance Policy… and click Add Rule In the Claim rule template drop-down, select Send LDAP Attributes as Claims and click Next Choose a name for the rule and map the claims Login to Subscription Manager using AD FS Now you should be ready. If you navigate to the Subscription Manager application, you will see the AD FS login option. Log in with your AD FS credentials. Note You will be asked to link your account when you sign in for the first time. If so, fill in your information and click Link Account"
  },
  "src/technical-reference/sso-azure-ad.html": {
    "href": "src/technical-reference/sso-azure-ad.html",
    "title": "SSO - Azure Entra ID | XMPro",
    "summary": "SSO - Azure Entra ID In this article, we will look at how to set up Azure AD so that it can be used as an external identity provider for Subscription Manager, allowing single sign-on capability between Azure AD and Subscription Manager. Register application Start by registering a new application in Azure AD by following these instructions. Copy application (client) ID Immediately after registering your application, an overview page will be opened for the new application. A unique application (client) ID would have been assigned to the application. Warning Copy this ID. You will add it in Subscription Manager's web.config file shortly. Credentials Next, create a secret for Subscription Manager. Follow the steps below: On the left, click on Certificates & secrets. Click on New client secret. Add a description for your new client secret. Choose a duration. Click Add. Copy the value of the newly generated secret and store it safely for later use. Warning Both the application client ID and the secret need to be added to Subscription Manager's web.config file. You will not be able to retrieve the secret once the page has been closed. Make sure to copy and safely store the secret before the page is closed, or you will need to repeat the previous steps. On the left, click Token Configuration. Click Add Optional Claim. Select the ID token type. Select upn from the list of claims. Click Add Click '...' -> Edit Set 'Externally authenticated' to Yes Save Open the app Manifest. Set \"acceptMappedClaims\": true (applies from v4.4.19+) Navigate to the IIS location where Subscription Manager has been installed. Open the file web.config file. Scroll down to the \"xmpro\" section. Note This section might have to be decrypted, for which you can find instructions here. Add the application (client) ID that you copied earlier to the clientId attribute of the azureAD element Copy the secret and add it to the web.config. Note If you're using the Azure key store to manage app settings and secrets, use the ${} syntax for the azureAD attributes in the web.config, similar to: <azureAD clientId=\"${ADClientID}\" key=\"${ADSecret}\" /> And define the following secrets in the key store: Name Value ADClientID Application Id ADSecret Application Secret Authentication Copy the baseUrl value in the web.config - you will need it later in this guide. In Azure Portal, click on Authentication and add the following URL in the space provided: The URL where Subscription Manager is hosted (base URL, which you have just copied), ending in \"identity/signin-azuread\" Example: https://mysampleserver/xmprosubscriptionmanager/identity/signin-azuread On the Authentication page, scroll down until you see \"Advanced Settings\". Select \"ID tokens\" and click Save. API permissions Select API permissions on the left-hand menu. Make sure the permissions set on the application correspond to the image below. Sync Azure AD Role to SM's Business Role This optional functionality allows a user's Business Role to be synced to a corresponding Azure AD Claim each time they log in. Get the desired user claim name from Azure AD. Navigate to the IIS location where Subscription Manager has been installed. Open the web.config file. Add the claim name to the \"businessRoleClaim\" attribute in the \"identityProviders\" tag. <identityProviders businessRoleClaim=\"PUT THE CLAIM NAME HERE\"> Save the file and restart the Subscription Manager service. See the Sync Business Roles from Azure Entra ID article for more information. Guest User access across Tenants When your Azure AD is in a different Tenant to Subscription Manager and the User has Guest membership in Azure AD, then add the TenantID for Azure AD."
  },
  "src/technical-reference/xmpro-log-events/ai-log-events.html": {
    "href": "src/technical-reference/xmpro-log-events/ai-log-events.html",
    "title": "AI Log Events | XMPro",
    "summary": "AI Log Events AI generates log events that monitor the core application operations including web application lifecycle, file upload activities, and HTTP request processing. These events provide essential monitoring and troubleshooting information for the AI platform. The tables below organize log events by severity level, with each entry showing the message template you'll see in your logs and the context explaining what triggers that event. The levels are: Fatal Error Information Fatal Level Fatal events indicate critical system failures that cause the application to terminate unexpectedly. These require immediate attention as they represent complete system breakdown. Message Template Context Summary \"Application terminated unexpectedly\" Application startup failure causing termination Error Level Error events indicate serious problems that prevent normal operation but don't necessarily cause application termination. These require prompt investigation and resolution. Message Template Context Summary \"An error occurred on {RequestPath} with {Message}\" HTTP request processing errors Information Level Information events track normal system operations and user activities. These provide audit trails and operational insights for system monitoring. Message Template Context Summary \"Starting web application\" Application startup logging \"Uploading file with max width {MaxWidth} and height {MaxHeight}\" File upload operations"
  },
  "src/technical-reference/xmpro-log-events/app-designer-log-events.html": {
    "href": "src/technical-reference/xmpro-log-events/app-designer-log-events.html",
    "title": "App Designer Log Events | XMPro",
    "summary": "App Designer Log Events App Designer generates log events that provide visibility into application operations and user activities. These events cover application lifecycle management, WebSocket connection handling, connector and integration management, media file processing, AI service integrations (ChatGPT/Azure OpenAI), and user access control operations. The tables below organize log events by severity level, with each entry showing the message template you'll see in your logs and the context explaining what triggers that event. The levels are: Fatal Error Warning Information Debug Fatal Level Fatal events indicate critical system failures that cause the application to terminate unexpectedly. These require immediate attention as they represent complete system breakdown. Message Template Context Summary \"Application terminated unexpectedly\" Application startup failure causing termination Error Level Error events indicate serious problems that prevent normal operation but don't necessarily cause application termination. These require prompt investigation and resolution. Message Template Context Summary \"Unable to get Universal ID for StreamObjectID {StreamObjectID}\" Integration hub universal ID retrieval failure \"Failed to connect to target WebSocket server: {Url} for connection {connectionId}\" WebSocket middleware connection failures \"Error during WebSocket communication for connection {connectionId}\" WebSocket communication errors \"Unhandled error in WebSocket proxy for connection {connectionId}\" Unhandled WebSocket proxy errors \"Failed to parse connection info JSON\" JSON parsing errors in WebSocket middleware \"Unexpected error while modifying message. Sending original message instead\" Message modification errors in WebSocket \"Error during graceful shutdown\" Application shutdown errors \"Error exporting application to Git: {Message}\" Git export operation failures \"Error importing package from Git: {Message}\" Git import operation failures \"Error getting package import summary: {Message}\" Package summary retrieval failures \"Error getting application summary: {Message}\" Application summary retrieval failures \"Error getting recommendation summary: {Message}\" Recommendation summary retrieval failures \"Error getting Git Branches\" Git branch retrieval failures \"Error getting Git solutions\" Git solutions retrieval failures \"Error getting Git tags\" Git tags retrieval failures \"Failed to get entities for connection with Id {ConnectionId}\" Connection entity retrieval failures \"Failed to get DataStream entities\" DataStream entity retrieval failures \"Failed to get entity {EntityName} for connection with Id {ConnectionId}\" Specific entity retrieval failures \"An error occured while trying to upload media files\" Media file upload failures \"An error occured trying to delete media file: {mediaFileName}\" Media file deletion failures \"AzureOpenAI prompt response failed. Error: {Message}\" Azure OpenAI integration failures \"ChatGPT prompt response failed. Error: {Message}\" ChatGPT integration failures \"An error occurred while setting favorite for block {BlockId}\" Block favorite operation failures \"An error occurred while fetching favorite blocks for user {UserId} and company {CompanyId}\" Favorite blocks retrieval failures \"Error while importing template\" Template import failures \"Error while importing Application\" Application import failures \"Error while importing App Page\" App page import failures \"Error while importing Template\" Template import failures Warning Level Warning events indicate potential issues or unusual conditions that don't prevent operation but may lead to problems if not addressed. Monitor these for trends. Message Template Context Summary \"Failed to receive valid connection info for connection {connectionId}\" Invalid WebSocket connection info \"Expected text message for connection info, received: {messageType}\" Unexpected WebSocket message type \"Invalid connection info received\" Invalid connection information \"Destination WebSocket is not open. State: {state}\" WebSocket destination state issues \"Graceful shutdown timed out after {timeout} seconds\" Shutdown timeout warnings \"Error during connection cleanup for {connectionId}\" Connection cleanup warnings \"WebSocket error during message forwarding\" Message forwarding warnings \"User {UserId} lacks permission for export operation\" Permission denied for exports \"User {UserId} lacks permission for import operation\" Permission denied for imports \"User {UserId} lacks permission to access package summary\" Permission denied for package access \"User {UserId} lacks permission to access application {ApplicationId}\" Application access permission warnings \"User {UserId} lacks permission to access recommendation {RecommendationId}\" Recommendation access permission warnings \"Cannot trigger Rule {RuleId} with Entity Id {EntityId}. The data parameter value is null.\" Rule trigger data validation warnings \"Cannot trigger Rule {RuleId} with Entity Id {EntityId}. It either does not exist or is not published.\" Rule trigger state warnings \"SM Server BaseUrl is not valid, Origin for AllowGet CORS policy will not be applied.\" CORS configuration warnings \"SM Server BaseUrl is not valid, Origin for AllowPost CORS policy will not be applied.\" CORS configuration warnings \"Subscription Manager server URL is not configured or invalid. SubscriptionManagerService may fail when used.\" Service configuration warnings \"Data Stream Designer server URL is not configured or invalid. DataStreamService may fail when used.\" Service configuration warnings Information Level Information events track normal system operations and user activities. These provide audit trails and operational insights for system monitoring. Message Template Context Summary \"Starting web application\" Application startup \"Application shutdown initiated. Beginning graceful shutdown of WebSocket connections.\" Graceful shutdown process \"Deleting connectors with Ids {ConnectorIds}\" Connector deletion operations \"Deleting connector with Id {ConnectorId} with versions {Versions}\" Connector version deletion \"Uploading connector with Id {ConnectorId}\" Connector upload operations \"Uploading connectors with Ids {ConnectorIds}\" Bulk connector uploads \"Deleting connections with Ids {ConnectionIds}\" Connection deletion operations \"Populating configuration with connector Id {ConnectorId} with versions {Versions}\" Configuration population \"Inserting record with integration id {IntegrationId} and page Id {PageId} with values {Values}\" Record insertion operations \"Updating record with integration id {IntegrationId} and page Id {PageId} with values {Values}\" Record update operations \"Deleting record with integration id {IntegrationId} and page Id {PageId}\" Record deletion operations \"Saving changes to connector\" Connector save operations \"Saving changes to connection\" Connection save operations \"Upload media file request received.\" Media upload request logging \"Delete media file request received.\" Media deletion request logging \"Creating application\" Application creation operations \"Editing application\" Application editing operations \"Saving changes to application access\" Application access save operations \"Reassigning categories with Ids {CategoryIds} to new category Id {NewCatId}\" Category reassignment operations \"Deleting application files with ids {ApplicationFileIds}\" Application file deletion \"Deleting application with Ids {ApplicationIds}\" Application deletion operations \"Deleting application pages with Ids {ApplicationPageIds}\" Application page deletion \"Deleting templates with Ids {TemplateIds}\" Template deletion operations \"Publishing application with Id {ApplicationId} with version {Version}\" Application publishing \"Unpublishing application with Id {ApplicationId}\" Application unpublishing \"Publishing applications with Ids {ApplicationIds}\" Bulk application publishing \"Unpublishing applications with Ids {ApplicationIds}\" Bulk application unpublishing \"Copying applications with Id {ApplicationId} with version {Version}\" Application copying operations Debug Level Debug events provide detailed technical information for troubleshooting specific operations. These are typically enabled only when investigating particular issues. Message Template Context Summary \"Logging information for Client Id: {clientId} with Entity Name: {entityName}, Data Binding Id: {dataBindingId}, Filter: {filter} and Load Options: {loadOptions}\" Connector proxy debugging \"Logging information for Page: {pageId} with Integration: {integrationId}, Data Binding Id: {dataBindingId}, Filter: {filter} and Load Options: {loadOptions}\" Live connector debugging \"Triggering recommendation alert with rule Id {RuleId} and entity Id {EntityId}\" Recommendation alert triggering \"Updating recommendation alert fields with alert Id {AlertId} and control values {ControlValues}\" Alert field updates \"Unknown field {fValue.Key} when updating recommendation alert fields with alert Id {AlertId} and control values {ControlValues}\" Unknown field debugging \"Updating recommendation alert with alert Id {AlertId} with comments {Comments} and helpful flag set to {HelpfulFlag}\" Alert updates with comments \"Resolving recommendation with rule Id {RuleId} and entity Id {EntityId}\" Recommendation resolution \"Resolving recommendation alert with Id {AlertId}\" Alert resolution operations \"Setting close action request with action Id {ActionId}\" Action request closure \"Publishing connection with connection Id {ConnectionId} and entity name {EntityName}\" Connection publishing \"Publishing connector with connector Id {ConnectorId} and entity name {EntityName}\" Connector publishing"
  },
  "src/technical-reference/xmpro-log-events/data-stream-designer-log-events.html": {
    "href": "src/technical-reference/xmpro-log-events/data-stream-designer-log-events.html",
    "title": "Data Stream Designer Log Events | XMPro",
    "summary": "Data Stream Designer Log Events Data Stream Designer generates log events that track real-time data processing operations and system management activities. These events cover use case management and deployment operations, data stream import/export processes, agent configuration and deployment lifecycle, file processing activities, stream host service management, and user authentication and authorization validation throughout the system. The tables below organize log events by severity level, with each entry showing the message template you'll see in your logs and the context explaining what triggers that event. The levels are: Fatal Error Warning Information Debug Trace Verbose Fatal Level Fatal events indicate critical system failures that cause the application to terminate unexpectedly. These require immediate attention as they represent complete system breakdown. Message Template Context Summary \"Application terminated unexpectedly\" Application startup failure in main program Error Level Error events indicate serious problems that prevent normal operation but don't necessarily cause application termination. These require prompt investigation and resolution. Message Template Context Summary \"Error retrieving use case summaries for entities by user {UserId}\" Deployment manager entity summary retrieval errors \"Error retrieving use case summaries with version by user {UserId}\" Deployment manager version summary retrieval errors \"Error retrieving use case summaries by user {UserId}\" Deployment manager general summary retrieval errors \"Error exporting use case {UniversalId} by user {UserId}\" Use case export operation errors \"Error importing data streams by user {UserId}\" Data stream import operation errors \"Error retrieving agents for user {UserId}\" Agent retrieval operation errors \"Error deserializing collection mapping\" Collection mapping deserialization errors \"Error deserializing agent version mapping\" Agent version mapping deserialization errors \"Error extracting import parameters\" Import parameter extraction errors \"Error executing post processing logic\" Post-processing logic execution errors in collections \"An error occurred while setting favorite for agent {AgentId}\" Agent favorite setting errors \"User {UserId} does not exist or is not in the specified company\" User validation errors during agent operations \"An error occurred while toggling favorite for agent {AgentId} for user {UserId} in company {CompanyId}\" Agent favorite toggle errors \"Failed to get StreamObject Outputs for StreamObject {StreamObjectId}\" Stream object output retrieval errors \"Timeout occured when attempting to interact with the device\" Device interaction timeout errors \"Error while configuring stream object\" Stream object configuration errors \"Error parsing XML for data stream {FileName}\" XML parsing errors during import \"Error saving data stream {FileName}\" Data stream saving errors during import \"Error processing file {FileName}\" General file processing errors during import \"UseCaseFile failed to Deserialize from memory stream\" Use case file deserialization errors \"Failed to create UseCaseFile from memory stream\" Use case file creation errors \"Error occurred while importing use case\" Use case import operation errors \"Error occurred while importing use case version\" Use case version import operation errors \"Error in Stream Host\" Stream host console application errors \"Error in Stream Host service\" Stream host service errors \"Error in Stream Host ServiceRunner\" Stream host service runner errors \"Error starting Stream Host service\" Stream host service startup errors \"Error stopping Stream Host service\" Stream host service shutdown errors Warning Level Warning events indicate potential issues or unusual conditions that don't prevent operation but may lead to problems if not addressed. Monitor these for trends. Message Template Context Summary \"User {UserId} attempted to retrieve summaries without providing request\" User input validation warnings for summaries \"User {UserId} attempted to retrieve summaries without providing entity IDs\" User input validation warnings for entity IDs \"User {UserId} attempted to access entity IDs {EntityIds} without any permission\" User permission validation warnings \"Invalid request for use case summaries by user {UserId}\" Invalid use case summary request warnings \"Unauthorized access attempt by user {UserId}\" Unauthorized access attempt warnings \"User {UserId} attempted to retrieve version summaries without providing request\" Version summary request validation warnings \"User {UserId} attempted to retrieve version summaries without providing versions\" Version summary input validation warnings \"User {UserId} attempted to access versions without permission\" Version access permission warnings \"Invalid request for version summaries by user {UserId}\" Invalid version summary request warnings \"Unauthorized version access attempt by user {UserId}\" Unauthorized version access warnings \"User {UserId} attempted to retrieve summaries without providing Universal IDs\" Universal ID input validation warnings \"User {UserId} attempted to access Universal IDs {UniversalIds} without permission\" Universal ID access permission warnings \"User {UserId} attempted to export without providing request\" Export request validation warnings \"User {UserId} attempted to export without providing Universal ID\" Export Universal ID validation warnings \"User {UserId} attempted to export use case {UniversalId} without permission\" Export permission validation warnings \"Unauthorized export attempt by user {UserId} for use case {UniversalId}\" Unauthorized export attempt warnings \"User {UserId} attempted import without providing files\" Import file validation warnings \"User {UserId} provided invalid import parameters: {Error}\" Import parameter validation warnings \"Invalid import request by user {UserId}\" Invalid import request warnings \"Unauthorized import attempt by user {UserId}\" Unauthorized import attempt warnings \"User {UserId} attempted to retrieve agents without providing request\" Agent retrieval request validation warnings \"User {UserId} attempted to retrieve agents without providing IDs\" Agent ID validation warnings \"User {UserId} attempted to access agents not in their company {CompanyId}\" Agent company access validation warnings \"Invalid agent request by user {UserId}\" Invalid agent request warnings \"SM Server BaseUrl is not valid, Origin for AllowSMGet CORS policy will not be applied\" CORS policy configuration warnings \"SM Server BaseUrl is not valid, Origin for AllowPost CORS policy will not be applied\" CORS policy configuration warnings Information Level Information events track normal system operations and user activities. These provide audit trails and operational insights for system monitoring. Message Template Context Summary \"Starting web application\" Application startup information \"Stream Metrics Service - Started\" Metrics cleanup service initialization \"Stream Metrics Service - No task is running, check for new job\" Metrics cleanup service task status \"Stream Metrics Service - There is a task still running, wait for next cycle\" Metrics cleanup service concurrency control \"Stream Metrics Service - Skipping cleanup as another instance may already have completed the operation\" Metrics cleanup service coordination \"Stream Metrics Service - Initiate graceful shutdown\" Metrics cleanup service shutdown \"Retrieving use case summaries for {Count} universal IDs\" Use case summary retrieval operations \"Exporting use case to Git with universal Id {UniversalId} with version {Version}\" Use case export operations \"Saving changes to dashboard\" Dashboard modification operations \"Creating dashboard\" Dashboard creation operations \"Cloning dashboard with Id {DashboardId} with clone name {CloneName}\" Dashboard cloning operations \"Revoking collection key with Id {CollectionId}\" Collection key management operations \"Serializing variable {Variable} files\" Variable serialization operations \"Deleting collection with Id {CollectionId}\" Collection deletion operations \"Saving changes to collection\" Collection modification operations \"Creating collection\" Collection creation operations \"Saving changes to variable\" Variable modification operations \"Deleting variables with names {VariableNames}\" Variable deletion operations \"Uploading file with max width {MaxWidth} and height {MaxHeight}\" File upload operations \"Publishing use case with Id {UseCaseId} with major version {MajorVersion}\" Use case publishing operations \"Unpublishing use case with Id {UseCaseId}\" Use case unpublishing operations \"Publishing use cases with Ids {UseCaseIds}\" Bulk use case publishing operations \"Unpublishing use cases with Ids {UseCaseIds}\" Bulk use case unpublishing operations \"Copying stream with Id {StreamId} with version {Version}\" Stream copying operations \"Exporting use case by Id {UseCaseId} with version {Version}\" Use case export by ID operations \"Exporting use case with universal Id {UniversalId} with version {Version}\" Use case export by Universal ID operations \"Cloning use case with Id {UseCaseId} and name {CloneName}\" Use case cloning operations \"Deleting use case with Id {UseCaseId}\" Use case deletion operations \"Deleting stream with Id {StreamId} with major version {MajorVersion}\" Stream deletion operations \"Deleting all devices failures by use case Id {UseCaseId}\" Device failure cleanup operations \"Deleting specific device with Id {DeviceId}\" Specific device deletion operations \"Saving changes to use case\" Use case modification operations \"Creating use case\" Use case creation operations \"Reassigning categories with Ids {CategoryIds} to new category Id {NewCategoryId}\" Category reassignment operations \"Reassigning collection with collection Id {CollectionId} with use case Id {UseCaseId}\" Collection reassignment operations \"Importing use case with Id {UserCaseId}\" Use case import operations \"Importing stream with version {StreamVersion} with use case Id {UseCaseId}\" Stream import operations \"Configuring agent with Id {AgentId}\" Agent configuration operations \"Remote configuration for agent with Id {AgentId} and version {version}\" Remote agent configuration operations \"Updating settings with name {SettingName}\" Settings update operations Debug Level Debug events provide detailed technical information for troubleshooting specific operations. These are typically enabled only when investigating particular issues. Message Template Context Summary \"API {message:l}\" API operation debug messages Trace Level Trace events provide the most detailed diagnostic information for deep troubleshooting. These are typically used for low-level debugging. Message Template Context Summary \"Authorization header validation succeeded: {reason}\" Bearer token validation success \"Authorization header validation failed: {reason}\" Bearer token validation failures \"Bearer token validation failed: {reason}\" Bearer token processing failures Verbose Level (Serilog) Verbose events provide extremely detailed logging for comprehensive system tracing. These generate high volume logs and should be used sparingly. Message Template Context Summary \"API ({invocationId:l}) {instance:l}.{method:l}({parameters})\" REST client method invocation tracing \"API ({invocationId:l}) Returning {returnValue}\" REST client method return value tracing \"API ({invocationId:l}) {statusCode} {requestUri}\" REST client HTTP response tracing \"API ({invocationId:l}) {method:l} {requestUri}\" REST client HTTP request tracing"
  },
  "src/technical-reference/xmpro-log-events/index.html": {
    "href": "src/technical-reference/xmpro-log-events/index.html",
    "title": "XMPro Log Events | XMPro",
    "summary": "XMPro Log Events Introduction When your XMPro application stops responding, data streams fail, or users report performance issues, log events are your first line of defense for rapid diagnosis. Each XMPro component generates structured log events with specific messages that pinpoint exactly what's happening in your system - from authentication failures and database connection issues to performance bottlenecks and configuration errors. These detailed event references help you interpret what's happening in your system and assess the severity of issues affecting your XMPro deployment. Log Event References Each product link below provides complete log event listings with message templates and trigger contexts. Log levels in decreasing severity are critical, fatal, error, warning, information, debug, trace, and verbose. App Designer Log Events Data Stream Designer Log Events AI Log Events Subscription Manager Log Events Stream Host Log Events Troubleshooting Understanding what log events mean for your technical work is essential - these structured events help you quickly identify root causes, set up automated monitoring and alerts, track system performance, generate audit trails, and provide detailed diagnostic information when working with XMPro support. Log events are crucial for: Debugging application issues - Identify specific problems in your XMPro applications Monitoring system health - Track the overall health and performance of your XMPro deployment Audit trails - Maintain records of system activities and user actions Performance analysis - Understand system behavior and identify bottlenecks Each log event document provides detailed information about events and severity levels. Tip For Azure Terraform deployments, see the Azure Terraform Troubleshooting Guide for information on accessing logs through Application Insights. Summary XMPro log events provide structured diagnostic information across all platform components, enabling rapid issue identification and system health monitoring. Use the product-specific event references above to decode system behavior, assess issue severity, and maintain optimal XMPro performance."
  },
  "src/technical-reference/xmpro-log-events/stream-host-log-events.html": {
    "href": "src/technical-reference/xmpro-log-events/stream-host-log-events.html",
    "title": "Stream Host Log Events | XMPro",
    "summary": "Stream Host Log Events Stream Host generates log events that monitor real-time stream processing operations and runtime system health. These events cover stream processing execution, agent lifecycle management (creation, startup, and disposal), SignalR communication for live data updates, API integration operations, dependency resolution issues, and critical system failures that may cause service termination. The tables below organize log events by severity level, with each entry showing the message template you'll see in your logs and the context explaining what triggers that event. The levels are: Critical Fatal Error Warning Critical Level Critical events represent the highest severity level, indicating catastrophic failures that will cause the Stream Host to shut down completely. These require immediate attention. Message Template Context Summary \"An unhandled exception was thrown and the stream host will shut down\" Fatal unhandled exception causing stream host termination Fatal Level Fatal events indicate critical system failures that cause the application to terminate unexpectedly. These require immediate attention as they represent complete system breakdown. Message Template Context Summary \"Unhandled fatal error in Stream Host\" Fatal unhandled exception in main program entry point Error Level Error events indicate serious problems that prevent normal operation but don't necessarily cause application termination. These require prompt investigation and resolution. Message Template Context Summary \"GetConfiguration method failed for {StreamObjectId}\" Agent configuration retrieval failure in AgentHandler \"Validate method failed for {StreamObjectId}\" Agent validation failure in AgentHandler \"GetAttributes method failed for {StreamObjectId}\" Agent attribute retrieval failure in AgentHandler \"Retrieving encryption password and parameters from API failed. If you are running an earlier version of DS that doesn't support this, you may need to enable the {nameof(GatewayFeatureFlagsElement.EnableLegacyCrypto)} feature flag and configure a {nameof(XMCryptographyElement.TripleDES)} key.\" Encryption key retrieval from DS API failure with legacy fallback suggestion \"Error retrieving variables from API\" API variable retrieval failure during cache refresh \"variables.xv decryption failed, it may have been encrypted with a different key\" Variables file decryption failure due to wrong encryption key \"Reading variables.xv file failed\" Variables file reading/processing failure \"Received StopStream request with null Id\" StopStream SignalR request with null stream identifier \"Error in GetConfiguration\" GetConfiguration SignalR handler error \"Error in Validate\" Validate SignalR handler error \"Error in GetAttributes\" GetAttributes SignalR handler error \"Error in UpdateVariables\" UpdateVariables SignalR handler error \"Agent Destroy() failed\" Agent disposal failure in Luigi stream core \"API ({invocationId:l}) Error\" REST API client error during API call (Serilog) \"Retrieving stream information from API failed\" Stream information API retrieval failure \"Failed to start stream\" Stream factory startup failure \"Error stopping stream {StreamID} ({StreamName}) v{StreamMajorVersion}.{StreamMinorVersion}\" Stream disposal/stopping error \"Error processing request\" Background request processing failure \"Error creating agent\" Agent creation/initialization failure \"Error starting agent\" Agent startup failure \"Error deregistering from {nameof(ILiveViewManager)}\" Live view manager deregistration failure \"Error stopping polling task\" Polling task stop failure \"Agent Destroy() failed\" Agent Destroy method failure \"Error disposing {nameof(IAgentLoadContext)}\" Agent load context disposal failure \"Error receiving message\" Message processing failure in agent \"Error informing {nameof(IStreamMetricsService)} of published event(s)\" Metrics service event notification failure \"Error posting event(s) to Live View API\" Live view API posting failure \"Error publishing event(s)\" General event publishing failure \"Error informing {nameof(IStreamMetricsService)} of error\" Metrics service error notification failure \"Error publishing error to the Error endpoint\" Error endpoint publishing failure \"Error logging error\" Recursive error logging failure \"Error polling\" Agent polling operation failure \"Agent reported an error\" Agent error event reporting \"Agent Dispose() failed\" Agent disposal failure in AgentLoadContext \"Unloading AssemblyLoadContext failed\" Assembly unloading failure \"Unable to resolve agent dependency {FullName}\" Agent dependency resolution failure \"Unable to resolve unmanaged agent dependency {name}\" Unmanaged dependency resolution failure Warning Level Warning events indicate potential issues or unusual conditions that don't prevent operation but may lead to problems if not addressed. Monitor these for trends. Message Template Context Summary \"Agent attempted to get the value of a null variable name\" Variable service null name request \"Failed to connect\" SignalR connection failure with retry \"SignalR connection closed\" Unexpected SignalR connection closure \"Agent attempted to decrypt a null value\" Null decryption request from agent \"Stopping recurrence task\" Scheduled polling task termination \"Loading agent {typeName} non-isolated, unexpected results may occur\" Non-isolated agent loading warning \"Unexpectedly resolving agent {agentTypeName} dependency {fullName} with no short assembly Name, falling back to default loading behaviour, unexpected results may occur\" Assembly name resolution fallback \"Unexpectedly re-resolving agent {agentTypeName} dependency {fullName} that appears to have already been loaded {existingFullName}\" Duplicate assembly resolution attempt \"Agent {agentTypeName} dependency {fullName} specifies no version, may not be compatible with resolved Stream Host assembly {defaultFullName}\" Version compatibility warning - no version \"Resolved agent {agentTypeName} dependency {fullName} to Stream Host assembly {defaultFullName} which specifies no version and may not be compatible\" Version compatibility warning - no resolved version \"Resolved agent {agentTypeName} dependency {fullName} to Stream Host assembly {defaultFullName} which is a different major version and may not be compatible\" Major version compatibility warning \"Resolved agent {agentTypeName} dependency {fullName} to Stream Host assembly {defaultFullName} which is an older minor version and may not be compatible\" Minor version compatibility warning"
  },
  "src/technical-reference/xmpro-log-events/subscription-manager-log-events.html": {
    "href": "src/technical-reference/xmpro-log-events/subscription-manager-log-events.html",
    "title": "Subscription Manager Log Events | XMPro",
    "summary": "Subscription Manager Log Events Subscription Manager generates log events that monitor identity and subscription management operations across the XMPro platform. These events cover user authentication and registration processes, database migration operations, email notification activities, license and subscription management, assembly loading diagnostics for system components, and OWIN/WebAPI request processing for service operations. The tables below organize log events by severity level, with each entry showing the message template you'll see in your logs and the context explaining what triggers that event. The levels are: Error Warning Information Debug Verbose Error Level Error events indicate serious problems that prevent normal operation but don't necessarily cause application termination. These require prompt investigation and resolution. Message Template Context Summary \"Application_Start() failed\" Application startup failure \"Error loading {dllFile}\" Assembly loading diagnostics - DLL file loading failure \"Error loading reference {referenceName}\" Assembly loading diagnostics - reference loading failure \"Error loading type from {AssemblyName}\" Assembly loading diagnostics - type loading failure \"Cannot send User Invite. Email notification is disabled\" Registration service - user invitation blocked \"Unexpected Error in sending Email\" Registration service - email sending failure \"Cannot send Reset Password Request. Email notification is disabled\" Registration service - password reset blocked \"Cannot send email. Notification is Disabled\" Email notification service - disabled notification \"Unexpected error inside Email Module\" Email notification service - general email failure \"Unhandled exception in ASP.NET WebAPI controller\" WebAPI exception logging \"Unhandled exception processing OWIN request\" OWIN request processing failure \"Cookie authentication exception\" Cookie authentication error \"Registration request failed for {username} with error:{errorMessage}\" User registration failure \"Password reset failed with error: {error}\" Password reset failure \"Error encountered when sending invite user request: {errorMessage}\" User invitation failure \"No valid username claim found for external registration\" External registration claim validation Warning Level Warning events indicate potential issues or unusual conditions that don't prevent operation but may lead to problems if not addressed. Monitor these for trends. Message Template Context Summary \"Unable to mitigate duplicate Content-Length header, client may complain or fail\" HTTP header mitigation failure \"{assemblyName} references {referenceName} {referenceVersion} but lower {loadedVersion} in use\" Assembly version mismatch warning Information Level Information events track normal system operations and user activities. These provide audit trails and operational insights for system monitoring. Message Template Context Summary \"Preloading all assemblies to check for issues\" Assembly loading diagnostics startup \"Running SM database migrations\" Database migration execution \"Skipping SM database migrations\" Database migration skip \"Registration requested by {username} for {company} Company\" User registration initiation \"Password reset requested for {UserName}\" Password reset initiation \"Verifying password reset details for {UserName}\" Password reset verification \"Processing password reset for {UserName}\" Password reset processing \"Subscription Requested: {SubscriptionProductId}\" License service subscription request \"User {UserId} deleted categories: {CategoryIds}\" Category management \"Saving Server Variables for User {UserId}\" Server variable management \"User {UserId} is deleting variables: {Variables}\" Variable deletion \"User {UserId} is deleting variable categories: {VariableCategories}\" Variable category deletion \"Deleting user: {deleteUserId}\" User deletion \"Saving Profile Request for User: {UserId}\" User profile management \"Requesting License for {CompanyRequest} Company by User {UserId}\" License request \"Rejecting access request for user {0}\" Access request rejection \"Sending email to reject access request for user {0}\" Access rejection notification \"Rejecting subscription request for user {0}\" Subscription rejection \"Sending email to reject Subscription: {0}\" Subscription rejection notification \"Adjusted request URL from {originalUrl} to {adjustedUrl}\" Identity client URL adjustment Debug Level Debug events provide detailed technical information for troubleshooting specific operations. These are typically enabled only when investigating particular issues. Message Template Context Summary \"Beginning Application_Start()\" Application startup initialization \"Beginning OwinStartup\" OWIN startup initialization Verbose Level Verbose events provide extremely detailed logging for comprehensive system tracing. These generate high volume logs and should be used sparingly. Message Template Context Summary \"Preloading main assembly\" Assembly loading diagnostics \"Preloading assembly from {dllFile}\" Assembly loading from DLL \"Preloading {assemblyName}\" Individual assembly preloading \"Loading reference {referenceName}\" Reference assembly loading \"Incoming OWIN request\" OWIN request logging \"Outgoing OWIN response\" OWIN response logging \"Cookie authentication redirect to {url}\" Cookie authentication redirect \"Cookie authentication signed in\" Cookie authentication success \"Cookie authentication sign in\" Cookie authentication attempt \"Cookie authentication sign out\" Cookie authentication logout \"Cookie authentication identity validated\" Cookie identity validation \"Making request\" Identity client HTTP request \"Received response {status}\" Identity client HTTP response \"Adjusted request URL\" Identity client URL adjustment \"Adjusted URLs in .well-known/openid-configuration response\" OpenID configuration adjustment"
  },
  "terraform-pr/README.html": {
    "href": "terraform-pr/README.html",
    "title": "XMPro Documentation PR Preview Infrastructure | XMPro",
    "summary": "XMPro Documentation PR Preview Infrastructure This Terraform module creates temporary Azure infrastructure for previewing XMPro documentation pull requests. It provides isolated environments for each PR to enable reviewers to see documentation changes before they're merged. Overview When a PR is created against the documentation, this module: Creates isolated Azure resources - Each PR gets its own resource group and storage account Deploys static website hosting - Azure Storage Account with static website features enabled Uploads DocFX documentation - Pipeline builds and uploads the documentation site Provides preview URL - Public URL for reviewers to preview documentation changes Automatic cleanup - Resources are destroyed when the PR is closed Architecture Resource Layout Resource Group (rg-xmpro-docs-pr-preview-{pr_number}) └── Storage Account (xmprodocpr{pr_number}) └── Static Website ($web container) └── DocFX documentation site State Management Azure Storage Backend ├── Container: terraform-state-docs ├── State Files: │ ├── docs-pr-1234.tfstate # PR #1234 state │ ├── docs-pr-1235.tfstate # PR #1235 state │ └── docs-pr-1236.tfstate # PR #1236 state └── Concurrent Build Support: ✓ No locking conflicts Key Design Principles: Complete Isolation: Each PR gets separate resource group and storage account Concurrent Safety: PR-specific state files prevent locking conflicts Cost Effective: Uses cheapest Azure storage options Automatic Cleanup: Resources destroyed when PR closes Usage This module is automatically used by Azure DevOps pipelines when PRs are created. It's not intended for manual deployment. Automated Pipeline Integration PR Creation/Update: Pipeline: docs/docs-build-pr.yml Trigger: Pull request to main or release-* branches Actions: Build documentation → Deploy preview → Comment on PR with URL PR Closure: Pipeline: docs/docs-cleanup-pr.yml Trigger: Pull request closed Actions: Destroy Azure resources → Remove state file State Management Details Backend Configuration The module uses a direct initialization process with PR-specific state files: # main.tf includes backend configuration terraform { required_providers { azurerm = { source = \"hashicorp/azurerm\" version = \"~> 4.0\" } } backend \"azurerm\" { # Backend configuration provided via -backend-config during init } } Initialization Process: # Direct initialization with PR-specific state file terraform init \\ -backend-config=\"storage_account_name=$(storageaccount)\" \\ -backend-config=\"container_name=terraform-state-docs\" \\ -backend-config=\"key=docs-pr-${PR_NUMBER}.tfstate\" Why This Approach? Problem: Multiple PRs building simultaneously would conflict on the same state file Solution: Each PR gets its own state file: docs-pr-{pr_number}.tfstate Benefits: No state locking conflicts between concurrent PR builds Isolated state management per PR Direct backend configuration prevents state file mismatches Consistent state management across pipeline steps Pipeline Workflow 1. PR Build Pipeline (docs/docs-build-pr.yml) Triggers: Pull request to main or release-* branches Stages: graph LR A[Build DocFX] --> B[Deploy Preview] B --> C[Upload Docs] C --> D[Comment on PR] Detailed Steps: Build Stage: DocFX builds documentation, creates _site artifact Deploy Stage: Initialize Terraform directly with PR-specific state file Apply Terraform to create/update Azure resources Sync documentation to storage account using az storage blob sync Display preview URL with changed documentation pages 2. PR Cleanup Pipeline (docs/docs-cleanup-pr.yml) Triggers: Pull request closed Actions: Initialize Terraform with PR-specific state file Run terraform destroy to remove all Azure resources State file is automatically removed during destroy Variables Name Description Type Default Notes pr_number Pull request number string Required Used in resource naming build_id Azure DevOps build ID string Required Used for tagging location Azure region for resources string eastus Where resources are created resource_group_name Base name of resource group string rg-xmpro-docs-pr-preview PR number is appended Outputs Name Description Usage docs_preview_url Static website URL Posted in PR comments for reviewers storage_account_name Storage account name Used by pipeline to upload files storage_account_key Storage account access key Used by pipeline for authentication resource_group_name Full resource group name Used for resource management Azure Resources Created Per PR Resources # Resource Group rg-xmpro-docs-pr-preview-{pr_number} # Storage Account (with static website) xmprodocpr{pr_number} ├── $web container (static website files) ├── Primary web endpoint (public URL) └── Access keys (for upload authentication) Resource Naming Rules Storage Account: xmprodocpr{pr_number} (max 24 chars, lowercase only) Resource Group: rg-xmpro-docs-pr-preview-{pr_number} State File: docs-pr-{pr_number}.tfstate Dependencies Azure DevOps Variable Groups terraform-devtestplan-state: Contains backend configuration service_name: Azure service connection name key_vault_name: Key Vault containing secrets storageaccount: Terraform state storage account container: Container name (overridden to terraform-state-docs) Azure Key Vault Secrets Retrieved automatically via terraform-devtestplan-state group: sas-token: Storage account SAS token for state backend az-client-id: Service principal client ID az-client-secret: Service principal secret az-subscription: Azure subscription ID az-tenant: Azure tenant ID Cost Considerations Resource Costs Per PR: Storage Account: ~$0.05/month (Standard LRS, minimal usage) Static Website: No additional cost Resource Group: No cost Cost Management: Resources are automatically cleaned up when PRs are closed Maximum lifetime: Duration of PR (typically days, not months) Estimated cost per PR: < $0.50 USD total Cost Optimization: Uses cheapest storage replication (LRS) No compute resources (static hosting only) Automatic cleanup prevents cost accumulation Security Data Protection Static websites are publicly accessible (by design for PR reviews) HTTPS enforced on all storage account endpoints No sensitive data should be included in documentation Access keys marked sensitive in Terraform outputs Authentication & Authorization Service Principal authentication for Terraform operations Azure Key Vault for secret management RBAC permissions controlled via Azure DevOps service connections State file access controlled via storage account permissions Security Best Practices Documentation contains only public information No API keys, passwords, or internal URLs in docs Preview URLs are time-limited (PR lifetime only) Regular cleanup prevents data persistence Cleanup Process Automatic Cleanup Triggers Resources are automatically cleaned up when: PR is closed (merged or abandoned) PR cleanup pipeline runs successfully Manual Cleanup (if needed) # If automatic cleanup fails, manually run: cd docs/terraform-pr terraform init \\ -backend-config=\"storage_account_name=STORAGE_ACCOUNT\" \\ -backend-config=\"container_name=terraform-state-docs\" \\ -backend-config=\"key=docs-pr-{PR_NUMBER}.tfstate\" \\ -reconfigure terraform destroy \\ -var=\"pr_number={PR_NUMBER}\" \\ -var=\"build_id=manual-cleanup\" \\ -auto-approve Cleanup Verification Check Azure Portal: Resource group should be deleted Check state storage: docs-pr-{pr_number}.tfstate should be removed No ongoing costs should appear in Azure billing Troubleshooting Common Issues 1. Preview URL Not Working Symptoms: 404 error or blank page Solutions: Verify storage account was created: az storage account show -n xmprodocpr{pr_number} Check static website enabled: Look for primary_web_endpoint in outputs Confirm files uploaded: Check $web container contents Wait 2-3 minutes for DNS propagation 2. State Lock Issues Symptoms: \"Backend configuration changed\" or lock errors Solutions: Concurrent builds: PR-specific state files prevent most locking conflicts Stuck locks: Locks auto-expire after 15 minutes Manual unlock: Use terraform force-unlock with lock ID State mismatch: Ensure backend configuration includes proper azurerm block 3. Storage Account Name Conflicts Symptoms: \"Storage account name already exists\" Solutions: Check if previous cleanup failed: Look for existing xmprodocpr{pr_number} Manual cleanup of orphaned resources Storage account names are globally unique across Azure 4. Pipeline Authentication Failures Symptoms: \"Unauthorized\" or \"Forbidden\" errors Solutions: Verify terraform-devtestplan-state variable group exists Check Azure Key Vault permissions for service principal Confirm service connection is valid and not expired 5. Terraform Init Failures Symptoms: Backend initialization errors Solutions: Verify terraform-state-docs container exists in storage account Check SAS token permissions and expiration Ensure storage account allows Terraform operations Verify main.tf includes proper backend \"azurerm\" block Debug Information Useful Commands # Check storage account details az storage account show -n xmprodocpr{pr_number} -g rg-xmpro-docs-pr-preview-{pr_number} # List state files az storage blob list --container-name terraform-state-docs --account-name {state_storage_account} # Check static website configuration az storage blob service-properties show --account-name xmprodocpr{pr_number} Pipeline Variables to Check System.PullRequest.PullRequestId: Should contain PR number storageaccount: Backend storage account name sas-token: Should not be empty or expired key_vault_name: Key Vault containing secrets Getting Help If issues persist: Check Azure DevOps pipeline logs for detailed error messages Verify Azure Portal for resource creation status Check variable group values in Azure DevOps Contact platform team with PR number and error details Maintenance Regular Tasks Monitor costs: Review Azure billing for unexpected charges Clean up orphaned resources: Check for resources not cleaned up automatically Update documentation: Keep README current with any pipeline changes Review security: Ensure no sensitive data in documentation Updates Required When Azure provider version changes: Update required_providers in main.tf Pipeline template changes: Update deployment template if process changes Variable group changes: Update documentation if new secrets added Naming conventions change: Update resource naming rules This module provides a robust, cost-effective solution for documentation PR previews with proper isolation and automatic cleanup."
  }
}